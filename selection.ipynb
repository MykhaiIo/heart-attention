{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from utils.dataloader import DataLoader\n",
        "from settings.constants import TRAIN_CSV\n",
        "\n",
        "train = pd.read_csv(TRAIN_CSV, header = 0)\n",
        "\n",
        "X_raw = train.drop(\"stroke\", axis=1)\n",
        "\n",
        "loader = DataLoader()\n",
        "loader.fit(X_raw)\n",
        "X = loader.load_data()\n",
        "y = train[\"stroke\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div><div id=73783397-001a-47e6-b5fb-2e651d481860 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('73783397-001a-47e6-b5fb-2e651d481860').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>hypertension</th>\n",
              "      <th>heart_disease</th>\n",
              "      <th>ever_married</th>\n",
              "      <th>work_type</th>\n",
              "      <th>avg_glucose_level</th>\n",
              "      <th>bmi</th>\n",
              "      <th>smoking_status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.713046</td>\n",
              "      <td>0.888092</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.040347</td>\n",
              "      <td>0.275466</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.746745</td>\n",
              "      <td>0.302726</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.247576</td>\n",
              "      <td>0.197991</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.138999</td>\n",
              "      <td>0.216643</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table></div>"
            ],
            "text/plain": [
              "   age  hypertension  heart_disease  ever_married  work_type  \\\n",
              "0   13             1              0             1          3   \n",
              "1   13             0              1             1          3   \n",
              "2    9             1              0             1          2   \n",
              "3    4             0              0             0          2   \n",
              "4    8             0              0             1          2   \n",
              "\n",
              "   avg_glucose_level       bmi  smoking_status  \n",
              "0           0.713046  0.888092               2  \n",
              "1           0.040347  0.275466               3  \n",
              "2           0.746745  0.302726               3  \n",
              "3           0.247576  0.197991               0  \n",
              "4           0.138999  0.216643               0  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "age  hypertension  heart_disease  ever_married  work_type  avg_glucose_level  bmi       smoking_status\n",
              "0    0             0              0             3          0.041270           0.126100  0                 1\n",
              "10   0             0              0             2          0.034531           0.346041  2                 1\n",
              "9    1             0              1             3          0.108762           0.281525  2                 1\n",
              "                                                           0.127828           0.498534  2                 1\n",
              "                                                           0.197904           0.322581  3                 1\n",
              "                                                                                                         ..\n",
              "4    1             0              1             0          0.170760           0.904692  2                 1\n",
              "                                                2          0.436525           0.510264  2                 1\n",
              "5    0             0              0             0          0.024190           0.202346  2                 1\n",
              "                                                           0.081387           0.174487  0                 1\n",
              "14   1             1              1             3          0.692965           0.171554  2                 1\n",
              "Length: 4088, dtype: int64"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({0: 3889, 1: 199})"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "counter = Counter(y)\n",
        "pos_weight = counter[0]/counter[1]\n",
        "counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Traditional ML models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "from IPython.display import display\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit, cross_validate\n",
        "from sklearn.metrics import roc_auc_score, fbeta_score, recall_score, average_precision_score, make_scorer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import optuna as opt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Base estimator performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:    0.6s remaining:    0.4s\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.9s finished\n"
          ]
        },
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "alignmentgroup": "True",
                  "hovertemplate": "test_score=%{y}<extra></extra>",
                  "legendgroup": "",
                  "marker": {
                    "color": "#636efa"
                  },
                  "name": "",
                  "notched": false,
                  "offsetgroup": "",
                  "orientation": "v",
                  "showlegend": false,
                  "type": "box",
                  "x0": " ",
                  "xaxis": "x",
                  "y": [
                    0.13850881556836228,
                    0.19016516533131492,
                    0.14735189457169967,
                    0.18258055766100653,
                    0.21061480903624316,
                    0.20820230701859188,
                    0.15465698992814295,
                    0.173787408720119,
                    0.19028077187760822,
                    0.14250582302778453
                  ],
                  "y0": " ",
                  "yaxis": "y"
                }
              ],
              "layout": {
                "boxmode": "group",
                "legend": {
                  "tracegroupgap": 0
                },
                "margin": {
                  "t": 60
                },
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "heatmapgl": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmapgl"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                },
                "xaxis": {
                  "anchor": "y",
                  "domain": [
                    0,
                    1
                  ]
                },
                "yaxis": {
                  "anchor": "x",
                  "domain": [
                    0,
                    1
                  ],
                  "title": {
                    "text": "test_score"
                  }
                }
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.3, random_state=0)\n",
        "\n",
        "base_clf = RandomForestClassifier(class_weight='balanced', \n",
        "                                  n_jobs=-1)\n",
        "\n",
        "scores = cross_validate(base_clf, X, y, scoring='average_precision', cv=sss, verbose=1, n_jobs=-1)\n",
        "fig = px.box(scores, y='test_score')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "dmatrix = xgb.DMatrix(data=X, label=y)\n",
        "xgb_params = {\n",
        "    'eval_metric':'aucpr',\n",
        "    'objective': 'binary:logistic', \n",
        "    'scale_pos_weight': pos_weight/100\n",
        "    }\n",
        "\n",
        "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.3, random_state=0)\n",
        "\n",
        "cv_res = xgb.cv(dtrain=dmatrix,\n",
        "                params=xgb_params,\n",
        "                num_boost_round=1000,\n",
        "                folds=sss,\n",
        "                early_stopping_rounds=50,\n",
        "                metrics='aucpr')\n",
        "\n",
        "print(f'Validation precision-recall AUC {round(cv_res.loc[len(cv_res) - 1, \"test-aucpr-mean\"], 3)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train-aucpr-mean</th>\n",
              "      <th>train-aucpr-std</th>\n",
              "      <th>test-aucpr-mean</th>\n",
              "      <th>test-aucpr-std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.048584</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.048900</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.096060</td>\n",
              "      <td>0.074255</td>\n",
              "      <td>0.067361</td>\n",
              "      <td>0.029035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.165443</td>\n",
              "      <td>0.044576</td>\n",
              "      <td>0.131288</td>\n",
              "      <td>0.021847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.204629</td>\n",
              "      <td>0.042659</td>\n",
              "      <td>0.163699</td>\n",
              "      <td>0.045364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.248437</td>\n",
              "      <td>0.046257</td>\n",
              "      <td>0.187921</td>\n",
              "      <td>0.048214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.291187</td>\n",
              "      <td>0.043155</td>\n",
              "      <td>0.187693</td>\n",
              "      <td>0.043316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.330229</td>\n",
              "      <td>0.039177</td>\n",
              "      <td>0.201494</td>\n",
              "      <td>0.047785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.360072</td>\n",
              "      <td>0.033901</td>\n",
              "      <td>0.210732</td>\n",
              "      <td>0.043398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.376122</td>\n",
              "      <td>0.031856</td>\n",
              "      <td>0.214001</td>\n",
              "      <td>0.043703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.393402</td>\n",
              "      <td>0.030021</td>\n",
              "      <td>0.216299</td>\n",
              "      <td>0.043727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.408814</td>\n",
              "      <td>0.032700</td>\n",
              "      <td>0.219717</td>\n",
              "      <td>0.046504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.424578</td>\n",
              "      <td>0.031332</td>\n",
              "      <td>0.221857</td>\n",
              "      <td>0.046292</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    train-aucpr-mean  train-aucpr-std  test-aucpr-mean  test-aucpr-std\n",
              "0           0.048584         0.000000         0.048900        0.000000\n",
              "1           0.096060         0.074255         0.067361        0.029035\n",
              "2           0.165443         0.044576         0.131288        0.021847\n",
              "3           0.204629         0.042659         0.163699        0.045364\n",
              "4           0.248437         0.046257         0.187921        0.048214\n",
              "5           0.291187         0.043155         0.187693        0.043316\n",
              "6           0.330229         0.039177         0.201494        0.047785\n",
              "7           0.360072         0.033901         0.210732        0.043398\n",
              "8           0.376122         0.031856         0.214001        0.043703\n",
              "9           0.393402         0.030021         0.216299        0.043727\n",
              "10          0.408814         0.032700         0.219717        0.046504\n",
              "11          0.424578         0.031332         0.221857        0.046292"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cv_res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "clf = xgb.XGBClassifier(**xgb_params)\n",
        "clf.fit(X, y)\n",
        "xgb.plot_importance(clf)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Optuna optimizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "XGB_DB_URL = os.getenv('XGB_DB_URL')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-10-21 22:25:24,258]\u001b[0m A new study created in RDB with name: xgboost-reduced\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\study\\study.py:393: FutureWarning:\n",
            "\n",
            "`n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.\n",
            "\n",
            "\u001b[32m[I 2021-10-21 22:25:42,981]\u001b[0m Trial 5 finished with value: 0.2464995 and parameters: {'alpha': 0.009591110997023316, 'colsample_bytree': 0.942612085816292, 'subsample': 0.9451880620199111, 'scale_pos_weight': 1.549243022311114, 'gamma': 0.021805722416554138, 'eta': 0.21341819631571582}. Best is trial 5 with value: 0.2464995.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:25:43,370]\u001b[0m Trial 1 finished with value: 0.24818389999999999 and parameters: {'alpha': 0.005285618654081135, 'colsample_bytree': 0.9579596008501592, 'subsample': 0.9455053223232528, 'scale_pos_weight': 1.539676638478191, 'gamma': 0.025510642575480906, 'eta': 0.2076328239227961}. Best is trial 1 with value: 0.24818389999999999.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:25:43,778]\u001b[0m Trial 4 finished with value: 0.2555163 and parameters: {'alpha': 0.0055253963019286, 'colsample_bytree': 0.9322714717280214, 'subsample': 0.9433063836320635, 'scale_pos_weight': 1.5354472651931557, 'gamma': 0.016250253244916957, 'eta': 0.20969689096154429}. Best is trial 4 with value: 0.2555163.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:25:44,411]\u001b[0m Trial 7 finished with value: 0.24905049999999998 and parameters: {'alpha': 0.008947850986193185, 'colsample_bytree': 0.9526716031147863, 'subsample': 0.9448201956644691, 'scale_pos_weight': 1.5307380066441212, 'gamma': 0.025547819214339358, 'eta': 0.21289664885331044}. Best is trial 4 with value: 0.2555163.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:25:44,847]\u001b[0m Trial 6 finished with value: 0.25545389999999996 and parameters: {'alpha': 0.007946879314458949, 'colsample_bytree': 0.9545420728919836, 'subsample': 0.9443031018770578, 'scale_pos_weight': 1.5306078783981292, 'gamma': 0.029054965778990634, 'eta': 0.21217248129248145}. Best is trial 4 with value: 0.2555163.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:25:45,062]\u001b[0m Trial 0 finished with value: 0.24309599999999998 and parameters: {'alpha': 0.008589594627760263, 'colsample_bytree': 0.9385307314445429, 'subsample': 0.9453296181482255, 'scale_pos_weight': 1.5334618417524855, 'gamma': 0.013646090786889345, 'eta': 0.20836006255735828}. Best is trial 4 with value: 0.2555163.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:25:45,071]\u001b[0m Trial 2 finished with value: 0.24435959999999998 and parameters: {'alpha': 0.005107422085956695, 'colsample_bytree': 0.9557079800716425, 'subsample': 0.9459988006303498, 'scale_pos_weight': 1.5488829614194435, 'gamma': 0.015534894901756356, 'eta': 0.20922355853882413}. Best is trial 4 with value: 0.2555163.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:25:45,197]\u001b[0m Trial 3 finished with value: 0.256212 and parameters: {'alpha': 0.006477978498703813, 'colsample_bytree': 0.9325101545078358, 'subsample': 0.9438771308511329, 'scale_pos_weight': 1.5452518586417758, 'gamma': 0.019987069001167937, 'eta': 0.20892729969256307}. Best is trial 3 with value: 0.256212.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:26:11,692]\u001b[0m Trial 9 finished with value: 0.25648119999999996 and parameters: {'alpha': 0.0075274213110723565, 'colsample_bytree': 0.9327253907505669, 'subsample': 0.9440527359428611, 'scale_pos_weight': 1.5434995652966343, 'gamma': 0.01046465538305304, 'eta': 0.2098336146388696}. Best is trial 9 with value: 0.25648119999999996.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:26:11,936]\u001b[0m Trial 8 finished with value: 0.2548641 and parameters: {'alpha': 0.009795527468761587, 'colsample_bytree': 0.9587392417902044, 'subsample': 0.9434159805780364, 'scale_pos_weight': 1.5392391385794857, 'gamma': 0.012840817763425041, 'eta': 0.20648107011316402}. Best is trial 9 with value: 0.25648119999999996.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:26:12,812]\u001b[0m Trial 10 finished with value: 0.2558698 and parameters: {'alpha': 0.007052071559783096, 'colsample_bytree': 0.9370455575176508, 'subsample': 0.9437802509162949, 'scale_pos_weight': 1.534415173133456, 'gamma': 0.012477482275246674, 'eta': 0.20974630466663327}. Best is trial 9 with value: 0.25648119999999996.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:26:13,032]\u001b[0m Trial 12 finished with value: 0.2477465 and parameters: {'alpha': 0.009991370754711404, 'colsample_bytree': 0.9317607903901185, 'subsample': 0.9455784180695651, 'scale_pos_weight': 1.5345680269074744, 'gamma': 0.008996326054273458, 'eta': 0.21105212334965917}. Best is trial 9 with value: 0.25648119999999996.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:26:13,482]\u001b[0m Trial 11 finished with value: 0.24780459999999999 and parameters: {'alpha': 0.007560164713839888, 'colsample_bytree': 0.9339445146926441, 'subsample': 0.9443594504020336, 'scale_pos_weight': 1.5314191636586745, 'gamma': 0.016982713100363957, 'eta': 0.21003987768840895}. Best is trial 9 with value: 0.25648119999999996.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:26:13,798]\u001b[0m Trial 13 finished with value: 0.24833249999999998 and parameters: {'alpha': 0.009081222642015257, 'colsample_bytree': 0.9432924473760561, 'subsample': 0.9447699962056549, 'scale_pos_weight': 1.5417853906923924, 'gamma': 0.0290246871161828, 'eta': 0.21196190893667513}. Best is trial 9 with value: 0.25648119999999996.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:26:13,980]\u001b[0m Trial 14 finished with value: 0.25473920000000005 and parameters: {'alpha': 0.007356318096841587, 'colsample_bytree': 0.9529317762630338, 'subsample': 0.9432466551900003, 'scale_pos_weight': 1.544517419275331, 'gamma': 0.02139629831593335, 'eta': 0.20772722656638096}. Best is trial 9 with value: 0.25648119999999996.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:26:14,633]\u001b[0m Trial 15 finished with value: 0.24775509999999995 and parameters: {'alpha': 0.006757302458500524, 'colsample_bytree': 0.9463142730161558, 'subsample': 0.944299742579834, 'scale_pos_weight': 1.5481315751009312, 'gamma': 0.010239011244634994, 'eta': 0.21170396871488353}. Best is trial 9 with value: 0.25648119999999996.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:26:17,453]\u001b[0m Trial 20 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:26:17,827]\u001b[0m Trial 22 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:26:17,926]\u001b[0m Trial 21 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:26:31,149]\u001b[0m Trial 16 finished with value: 0.2505895 and parameters: {'alpha': 0.006888857711625368, 'colsample_bytree': 0.9526108961946157, 'subsample': 0.9431750071294857, 'scale_pos_weight': 1.546847062274494, 'gamma': 0.019317991369759088, 'eta': 0.21310823357723827}. Best is trial 9 with value: 0.25648119999999996.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:26:31,726]\u001b[0m Trial 17 finished with value: 0.25473789999999996 and parameters: {'alpha': 0.0070010137148578495, 'colsample_bytree': 0.9479178895143713, 'subsample': 0.9440840329336343, 'scale_pos_weight': 1.5434524541962595, 'gamma': 0.008684434651039437, 'eta': 0.21139301007864406}. Best is trial 9 with value: 0.25648119999999996.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:26:32,162]\u001b[0m Trial 19 finished with value: 0.2448719 and parameters: {'alpha': 0.006607775247460767, 'colsample_bytree': 0.9455150333473841, 'subsample': 0.9440952945891955, 'scale_pos_weight': 1.5447764194833224, 'gamma': 0.019929716318160297, 'eta': 0.20591800940998461}. Best is trial 9 with value: 0.25648119999999996.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:26:32,603]\u001b[0m Trial 18 finished with value: 0.2547096 and parameters: {'alpha': 0.0067464227191909275, 'colsample_bytree': 0.9301145331967765, 'subsample': 0.9441080555373369, 'scale_pos_weight': 1.5452946320552028, 'gamma': 0.008055458876769951, 'eta': 0.21145775606983028}. Best is trial 9 with value: 0.25648119999999996.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:26:33,941]\u001b[0m Trial 23 finished with value: 0.2516613 and parameters: {'alpha': 0.006209530714738974, 'colsample_bytree': 0.9300909829307847, 'subsample': 0.9438020944532961, 'scale_pos_weight': 1.5452274720645993, 'gamma': 0.019962607103801357, 'eta': 0.2149445306643157}. Best is trial 9 with value: 0.25648119999999996.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:26:37,083]\u001b[0m Trial 26 finished with value: 0.253307 and parameters: {'alpha': 0.0059387743959257505, 'colsample_bytree': 0.9383157777009044, 'subsample': 0.9430230654140817, 'scale_pos_weight': 1.5416201452904699, 'gamma': 0.018113592970090624, 'eta': 0.21079760873527814}. Best is trial 9 with value: 0.25648119999999996.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:26:37,170]\u001b[0m Trial 24 finished with value: 0.25311239999999996 and parameters: {'alpha': 0.00607592399007404, 'colsample_bytree': 0.9301964440889269, 'subsample': 0.9438195384887759, 'scale_pos_weight': 1.545290540196808, 'gamma': 0.017950109205445586, 'eta': 0.21462097428075838}. Best is trial 9 with value: 0.25648119999999996.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:26:37,553]\u001b[0m Trial 25 finished with value: 0.25467589999999996 and parameters: {'alpha': 0.005900518553346126, 'colsample_bytree': 0.9368435524616539, 'subsample': 0.9436615393190555, 'scale_pos_weight': 1.5421327241486604, 'gamma': 0.018932916133420453, 'eta': 0.21077013559480975}. Best is trial 9 with value: 0.25648119999999996.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:26:58,130]\u001b[0m Trial 27 finished with value: 0.24996430000000003 and parameters: {'alpha': 0.005741452054713312, 'colsample_bytree': 0.9371195474109223, 'subsample': 0.9446161869082254, 'scale_pos_weight': 1.5419737312068091, 'gamma': 0.025398565321569047, 'eta': 0.2145996866974866}. Best is trial 9 with value: 0.25648119999999996.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:26:59,004]\u001b[0m Trial 28 finished with value: 0.2556667 and parameters: {'alpha': 0.0059388138816638715, 'colsample_bytree': 0.9363518861834793, 'subsample': 0.943609558436519, 'scale_pos_weight': 1.5374578438038555, 'gamma': 0.011763499628149028, 'eta': 0.21040347323058492}. Best is trial 9 with value: 0.25648119999999996.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:26:59,623]\u001b[0m Trial 29 finished with value: 0.25070549999999997 and parameters: {'alpha': 0.005980845076330009, 'colsample_bytree': 0.9366210400770529, 'subsample': 0.9436330794592137, 'scale_pos_weight': 1.5373020223900178, 'gamma': 0.011088988550994626, 'eta': 0.21481857834850593}. Best is trial 9 with value: 0.25648119999999996.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:27:00,698]\u001b[0m Trial 30 finished with value: 0.2507082 and parameters: {'alpha': 0.006038537018722019, 'colsample_bytree': 0.9352760704233138, 'subsample': 0.9436055823313348, 'scale_pos_weight': 1.5374181350071199, 'gamma': 0.011366379832855255, 'eta': 0.21484426965638592}. Best is trial 9 with value: 0.25648119999999996.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:27:02,476]\u001b[0m Trial 31 finished with value: 0.2550057 and parameters: {'alpha': 0.005903726494703698, 'colsample_bytree': 0.9368511340828427, 'subsample': 0.9435222548413704, 'scale_pos_weight': 1.5372163991429526, 'gamma': 0.011607039316295403, 'eta': 0.21037598124328463}. Best is trial 9 with value: 0.25648119999999996.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:27:04,786]\u001b[0m Trial 32 finished with value: 0.2556131 and parameters: {'alpha': 0.008025422396839715, 'colsample_bytree': 0.9361728597190786, 'subsample': 0.9435571291144325, 'scale_pos_weight': 1.538115663140904, 'gamma': 0.012132401859424331, 'eta': 0.20874566252057203}. Best is trial 9 with value: 0.25648119999999996.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:27:06,707]\u001b[0m Trial 33 finished with value: 0.2550865 and parameters: {'alpha': 0.008068587164614543, 'colsample_bytree': 0.9360121770282931, 'subsample': 0.943639215532526, 'scale_pos_weight': 1.5417125287692381, 'gamma': 0.011555504061826509, 'eta': 0.20887098334598164}. Best is trial 9 with value: 0.25648119999999996.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:27:07,751]\u001b[0m Trial 34 finished with value: 0.2556131 and parameters: {'alpha': 0.007670222511007804, 'colsample_bytree': 0.9349082360657537, 'subsample': 0.9435802295788911, 'scale_pos_weight': 1.5384182300330203, 'gamma': 0.01158104548013641, 'eta': 0.2089742108443338}. Best is trial 9 with value: 0.25648119999999996.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:27:10,669]\u001b[0m Trial 40 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:27:13,426]\u001b[0m Trial 42 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:27:29,057]\u001b[0m Trial 37 finished with value: 0.2546059 and parameters: {'alpha': 0.008140244463357243, 'colsample_bytree': 0.9345342171723747, 'subsample': 0.9434842928989612, 'scale_pos_weight': 1.5468457915514782, 'gamma': 0.014425255083324819, 'eta': 0.20889428730128595}. Best is trial 9 with value: 0.25648119999999996.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:27:29,249]\u001b[0m Trial 35 finished with value: 0.2567946 and parameters: {'alpha': 0.007991047517789701, 'colsample_bytree': 0.9348846132042606, 'subsample': 0.9436673955116351, 'scale_pos_weight': 1.5372158662409219, 'gamma': 0.011802419103099863, 'eta': 0.20885022342576445}. Best is trial 35 with value: 0.2567946.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:27:29,566]\u001b[0m Trial 36 finished with value: 0.25560499999999997 and parameters: {'alpha': 0.008092254364329492, 'colsample_bytree': 0.9343428004507004, 'subsample': 0.9435835284582746, 'scale_pos_weight': 1.5369688388299834, 'gamma': 0.014667202437829024, 'eta': 0.2088303066526164}. Best is trial 35 with value: 0.2567946.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:27:29,998]\u001b[0m Trial 38 finished with value: 0.2533031 and parameters: {'alpha': 0.008074743917907126, 'colsample_bytree': 0.9407043155434823, 'subsample': 0.9434759193745964, 'scale_pos_weight': 1.5324150091644895, 'gamma': 0.01357085591799859, 'eta': 0.2082486879521577}. Best is trial 35 with value: 0.2567946.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:27:32,062]\u001b[0m Trial 39 finished with value: 0.2546889 and parameters: {'alpha': 0.008142900222398218, 'colsample_bytree': 0.9406649501522173, 'subsample': 0.9440612672179819, 'scale_pos_weight': 1.5324178454364297, 'gamma': 0.01438265790920884, 'eta': 0.2088490746108834}. Best is trial 35 with value: 0.2567946.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:27:34,464]\u001b[0m Trial 41 finished with value: 0.24616310000000002 and parameters: {'alpha': 0.007302830765211219, 'colsample_bytree': 0.9335165774054649, 'subsample': 0.9445262538951339, 'scale_pos_weight': 1.5352536418899747, 'gamma': 0.01428952573101427, 'eta': 0.20784524192100984}. Best is trial 35 with value: 0.2567946.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:27:37,878]\u001b[0m Trial 43 finished with value: 0.2571392 and parameters: {'alpha': 0.005267318562108731, 'colsample_bytree': 0.9404753023591609, 'subsample': 0.9441255308843788, 'scale_pos_weight': 1.5355602713697742, 'gamma': 0.014474959797431214, 'eta': 0.20953508437337448}. Best is trial 43 with value: 0.2571392.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:27:39,305]\u001b[0m Trial 44 finished with value: 0.25704049999999995 and parameters: {'alpha': 0.008388400933269284, 'colsample_bytree': 0.933576393581177, 'subsample': 0.9441220319691357, 'scale_pos_weight': 1.5355072521167257, 'gamma': 0.013762732591409732, 'eta': 0.20953428367026788}. Best is trial 43 with value: 0.2571392.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:27:50,918]\u001b[0m Trial 45 finished with value: 0.2570628 and parameters: {'alpha': 0.007129548333846737, 'colsample_bytree': 0.9327587854706855, 'subsample': 0.9441862560000946, 'scale_pos_weight': 1.5349253452826273, 'gamma': 0.022898576182084827, 'eta': 0.20971057516994723}. Best is trial 43 with value: 0.2571392.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:27:52,215]\u001b[0m Trial 47 finished with value: 0.2570731 and parameters: {'alpha': 0.008340550045952515, 'colsample_bytree': 0.9327561832780369, 'subsample': 0.9442222172788111, 'scale_pos_weight': 1.5358117660264383, 'gamma': 0.022899083674191544, 'eta': 0.20967434607838023}. Best is trial 43 with value: 0.2571392.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:27:53,098]\u001b[0m Trial 48 finished with value: 0.25704439999999995 and parameters: {'alpha': 0.00859740762331929, 'colsample_bytree': 0.9324369748664796, 'subsample': 0.9441544050013282, 'scale_pos_weight': 1.5350361000890393, 'gamma': 0.009830575492501091, 'eta': 0.20956951095596738}. Best is trial 43 with value: 0.2571392.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:27:53,473]\u001b[0m Trial 46 finished with value: 0.25710390000000005 and parameters: {'alpha': 0.008592132118643684, 'colsample_bytree': 0.932864330906498, 'subsample': 0.9442187468432255, 'scale_pos_weight': 1.5402399388603272, 'gamma': 0.02357942712834634, 'eta': 0.2098136726781213}. Best is trial 43 with value: 0.2571392.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:27:54,082]\u001b[0m Trial 49 finished with value: 0.2555306 and parameters: {'alpha': 0.00843351004283165, 'colsample_bytree': 0.9326732688863902, 'subsample': 0.94335591985275, 'scale_pos_weight': 1.535621451758342, 'gamma': 0.010121355451780282, 'eta': 0.20958972002298248}. Best is trial 43 with value: 0.2571392.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:27:57,075]\u001b[0m Trial 50 finished with value: 0.25553879999999995 and parameters: {'alpha': 0.007672284282399858, 'colsample_bytree': 0.9327532231296537, 'subsample': 0.9433646744817017, 'scale_pos_weight': 1.5357411349613463, 'gamma': 0.023220898226334656, 'eta': 0.20959295838442085}. Best is trial 43 with value: 0.2571392.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:27:57,887]\u001b[0m Trial 51 finished with value: 0.2565786 and parameters: {'alpha': 0.008547650959303153, 'colsample_bytree': 0.9323684624284896, 'subsample': 0.9442982717202176, 'scale_pos_weight': 1.5400633664628267, 'gamma': 0.00968331345540792, 'eta': 0.20959419539399204}. Best is trial 43 with value: 0.2571392.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:27:59,593]\u001b[0m Trial 52 finished with value: 0.2570731 and parameters: {'alpha': 0.008645787511758806, 'colsample_bytree': 0.932557736007427, 'subsample': 0.9442225924863286, 'scale_pos_weight': 1.5358338356689991, 'gamma': 0.016300066599813524, 'eta': 0.209629143632365}. Best is trial 43 with value: 0.2571392.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:28:08,351]\u001b[0m Trial 53 finished with value: 0.2570578 and parameters: {'alpha': 0.008800539290057032, 'colsample_bytree': 0.9322784004634026, 'subsample': 0.9442771819144716, 'scale_pos_weight': 1.5360647615534622, 'gamma': 0.022936857811758485, 'eta': 0.20947377939284764}. Best is trial 43 with value: 0.2571392.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:28:09,501]\u001b[0m Trial 54 finished with value: 0.2570198 and parameters: {'alpha': 0.008738789587781936, 'colsample_bytree': 0.932072180770208, 'subsample': 0.9442448115647246, 'scale_pos_weight': 1.536054753641849, 'gamma': 0.0231574703762468, 'eta': 0.20945249667448743}. Best is trial 43 with value: 0.2571392.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:28:10,711]\u001b[0m Trial 55 finished with value: 0.2532803 and parameters: {'alpha': 0.008562490781867129, 'colsample_bytree': 0.9318331767162579, 'subsample': 0.9442773547846582, 'scale_pos_weight': 1.536114759708228, 'gamma': 0.023307729835276687, 'eta': 0.20688399805791888}. Best is trial 43 with value: 0.2571392.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:28:11,242]\u001b[0m Trial 56 finished with value: 0.24752110000000002 and parameters: {'alpha': 0.008863303034783266, 'colsample_bytree': 0.9318724539778018, 'subsample': 0.9449637510449588, 'scale_pos_weight': 1.536098097025564, 'gamma': 0.02308593710748954, 'eta': 0.20952804403116482}. Best is trial 43 with value: 0.2571392.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:28:11,725]\u001b[0m Trial 57 finished with value: 0.25571079999999996 and parameters: {'alpha': 0.008935704927250432, 'colsample_bytree': 0.9316903436141791, 'subsample': 0.9442727070115136, 'scale_pos_weight': 1.5404331756420802, 'gamma': 0.023310456290551177, 'eta': 0.207192552964503}. Best is trial 43 with value: 0.2571392.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:28:11,877]\u001b[0m Trial 61 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:28:14,545]\u001b[0m Trial 58 finished with value: 0.2571526 and parameters: {'alpha': 0.00888870398223739, 'colsample_bytree': 0.931681737928292, 'subsample': 0.9442612009726581, 'scale_pos_weight': 1.540350853521867, 'gamma': 0.023053904891983217, 'eta': 0.21005508884095359}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:28:15,496]\u001b[0m Trial 59 finished with value: 0.2550972 and parameters: {'alpha': 0.008855979839036587, 'colsample_bytree': 0.9313184591483825, 'subsample': 0.9442145976722806, 'scale_pos_weight': 1.5341657368711294, 'gamma': 0.02314825489350549, 'eta': 0.21003769034026393}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:28:17,033]\u001b[0m Trial 60 finished with value: 0.2550105 and parameters: {'alpha': 0.009055038716028783, 'colsample_bytree': 0.931246791329993, 'subsample': 0.9442375543585556, 'scale_pos_weight': 1.5345152636740707, 'gamma': 0.023397952931283657, 'eta': 0.2072653724439593}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:28:28,098]\u001b[0m Trial 62 finished with value: 0.251436 and parameters: {'alpha': 0.009291440449080148, 'colsample_bytree': 0.9313263637421739, 'subsample': 0.9449228069405787, 'scale_pos_weight': 1.5342960027849724, 'gamma': 0.024636497837893182, 'eta': 0.2101279200923025}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:28:29,157]\u001b[0m Trial 63 finished with value: 0.24811100000000003 and parameters: {'alpha': 0.00925423960009603, 'colsample_bytree': 0.931098291986485, 'subsample': 0.945057540928685, 'scale_pos_weight': 1.5344682012645905, 'gamma': 0.024737270741220146, 'eta': 0.21021312394419178}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:28:30,320]\u001b[0m Trial 64 finished with value: 0.25268229999999997 and parameters: {'alpha': 0.009469420362243151, 'colsample_bytree': 0.9385539537325719, 'subsample': 0.9444237557532479, 'scale_pos_weight': 1.534089139712349, 'gamma': 0.02496534037730698, 'eta': 0.21013348055730982}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:28:30,988]\u001b[0m Trial 65 finished with value: 0.25472929999999994 and parameters: {'alpha': 0.009311686323343085, 'colsample_bytree': 0.943550681362027, 'subsample': 0.9444225648177368, 'scale_pos_weight': 1.5392252501702326, 'gamma': 0.02810166065747066, 'eta': 0.2101896983803809}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:28:31,447]\u001b[0m Trial 66 finished with value: 0.2529772 and parameters: {'alpha': 0.009278652754510173, 'colsample_bytree': 0.9431333669045286, 'subsample': 0.9447058043111204, 'scale_pos_weight': 1.5340826058007206, 'gamma': 0.026349196781370172, 'eta': 0.2101041217753779}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:28:34,131]\u001b[0m Trial 68 finished with value: 0.25477059999999996 and parameters: {'alpha': 0.009447318447750591, 'colsample_bytree': 0.9433808521523733, 'subsample': 0.9444440996898757, 'scale_pos_weight': 1.538455419495004, 'gamma': 0.02695881438558006, 'eta': 0.21045855441015032}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:28:34,420]\u001b[0m Trial 67 finished with value: 0.25307799999999997 and parameters: {'alpha': 0.009266498194940092, 'colsample_bytree': 0.9505068221257024, 'subsample': 0.9446907987990313, 'scale_pos_weight': 1.5410124877452829, 'gamma': 0.027156191743005962, 'eta': 0.21019066609008932}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:28:36,206]\u001b[0m Trial 69 finished with value: 0.25472989999999995 and parameters: {'alpha': 0.009309645145063005, 'colsample_bytree': 0.9381875429475904, 'subsample': 0.9443668622253106, 'scale_pos_weight': 1.5388996916884894, 'gamma': 0.02682264571504016, 'eta': 0.21002327277929578}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:28:48,677]\u001b[0m Trial 71 finished with value: 0.25319769999999997 and parameters: {'alpha': 0.009425449377377855, 'colsample_bytree': 0.9384929216968565, 'subsample': 0.9446866285803898, 'scale_pos_weight': 1.5390947620666853, 'gamma': 0.02732149921623625, 'eta': 0.21072288011362406}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:28:49,007]\u001b[0m Trial 70 finished with value: 0.2550596 and parameters: {'alpha': 0.009269127267665106, 'colsample_bytree': 0.937998680069702, 'subsample': 0.9443930902739884, 'scale_pos_weight': 1.5392301401179307, 'gamma': 0.027106683459777535, 'eta': 0.21092500507554007}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:28:51,756]\u001b[0m Trial 72 finished with value: 0.2567672 and parameters: {'alpha': 0.00826739938032732, 'colsample_bytree': 0.9504092943445066, 'subsample': 0.9440065520450398, 'scale_pos_weight': 1.539046756089369, 'gamma': 0.026449051553412418, 'eta': 0.21068878520950374}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:28:52,694]\u001b[0m Trial 74 finished with value: 0.25625390000000003 and parameters: {'alpha': 0.008300073898083762, 'colsample_bytree': 0.9335481633240708, 'subsample': 0.9440148164111459, 'scale_pos_weight': 1.5405600865751539, 'gamma': 0.016023911012324067, 'eta': 0.2091870583772791}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:28:53,110]\u001b[0m Trial 73 finished with value: 0.2541135 and parameters: {'alpha': 0.008294176476212035, 'colsample_bytree': 0.9338165956102679, 'subsample': 0.9447267125770614, 'scale_pos_weight': 1.5408701530248075, 'gamma': 0.026246329325960886, 'eta': 0.21079615741385038}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:28:56,046]\u001b[0m Trial 76 finished with value: 0.25674270000000005 and parameters: {'alpha': 0.005041739715668515, 'colsample_bytree': 0.9334763567227642, 'subsample': 0.943967821802263, 'scale_pos_weight': 1.5392967866266272, 'gamma': 0.022156837206243007, 'eta': 0.2110776884543835}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:28:56,061]\u001b[0m Trial 75 finished with value: 0.25672740000000005 and parameters: {'alpha': 0.005018654052147158, 'colsample_bytree': 0.9335968051425158, 'subsample': 0.9439920660017851, 'scale_pos_weight': 1.5407721627577124, 'gamma': 0.016050242177972775, 'eta': 0.21106620170239954}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:28:59,695]\u001b[0m Trial 77 finished with value: 0.25477740000000004 and parameters: {'alpha': 0.008308338903553395, 'colsample_bytree': 0.9564434907684519, 'subsample': 0.9439639089318205, 'scale_pos_weight': 1.5425411927761168, 'gamma': 0.015450958144461333, 'eta': 0.21097911221119758}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:29:12,895]\u001b[0m Trial 78 finished with value: 0.25665759999999993 and parameters: {'alpha': 0.00504938465204752, 'colsample_bytree': 0.9340609039236243, 'subsample': 0.9440428037470283, 'scale_pos_weight': 1.5365780144323846, 'gamma': 0.022019244732502316, 'eta': 0.20920088025586003}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:29:13,190]\u001b[0m Trial 79 finished with value: 0.2567666 and parameters: {'alpha': 0.00838398704039256, 'colsample_bytree': 0.9332885362045051, 'subsample': 0.9439924847192449, 'scale_pos_weight': 1.5365399766672354, 'gamma': 0.022090375007264882, 'eta': 0.2112376632337586}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:29:16,259]\u001b[0m Trial 80 finished with value: 0.2567825 and parameters: {'alpha': 0.00873808731944745, 'colsample_bytree': 0.933408958967126, 'subsample': 0.9441686295247557, 'scale_pos_weight': 1.5426951465411745, 'gamma': 0.016065401485352977, 'eta': 0.2092792542420501}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:29:16,682]\u001b[0m Trial 82 finished with value: 0.2541133 and parameters: {'alpha': 0.005034850432470685, 'colsample_bytree': 0.9328853438743822, 'subsample': 0.9441643939359079, 'scale_pos_weight': 1.5301231620400317, 'gamma': 0.02127718202988605, 'eta': 0.20919642191195065}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:29:16,937]\u001b[0m Trial 81 finished with value: 0.2571437 and parameters: {'alpha': 0.005009889800691488, 'colsample_bytree': 0.9337271130078468, 'subsample': 0.9441487631660943, 'scale_pos_weight': 1.5350475507632237, 'gamma': 0.022367202424326296, 'eta': 0.20922503153884575}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:29:20,485]\u001b[0m Trial 83 finished with value: 0.2570405 and parameters: {'alpha': 0.008688470014011256, 'colsample_bytree': 0.9354324048810446, 'subsample': 0.9441358294051257, 'scale_pos_weight': 1.5366388393732306, 'gamma': 0.022131908259902966, 'eta': 0.20923425899358378}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:29:21,198]\u001b[0m Trial 84 finished with value: 0.2556736 and parameters: {'alpha': 0.008677076003579556, 'colsample_bytree': 0.9567976463188171, 'subsample': 0.9441659688086868, 'scale_pos_weight': 1.5431496434069358, 'gamma': 0.022055029558733702, 'eta': 0.208490900292633}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:29:23,193]\u001b[0m Trial 85 finished with value: 0.2559516 and parameters: {'alpha': 0.009855269941162714, 'colsample_bytree': 0.9354851934558582, 'subsample': 0.944149454159261, 'scale_pos_weight': 1.5366226131144438, 'gamma': 0.024105717715337496, 'eta': 0.20854255611524816}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:29:33,851]\u001b[0m Trial 86 finished with value: 0.2549704 and parameters: {'alpha': 0.009722957880478495, 'colsample_bytree': 0.9357556133531549, 'subsample': 0.9441471591066578, 'scale_pos_weight': 1.5313215052618434, 'gamma': 0.020688748021496665, 'eta': 0.20925863791429825}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:29:36,180]\u001b[0m Trial 87 finished with value: 0.25710520000000003 and parameters: {'alpha': 0.008669335789919415, 'colsample_bytree': 0.9358125469119793, 'subsample': 0.9441540653573042, 'scale_pos_weight': 1.537922753893052, 'gamma': 0.02124508279061624, 'eta': 0.20985558699585113}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:29:38,237]\u001b[0m Trial 88 finished with value: 0.25712749999999995 and parameters: {'alpha': 0.008716862741018629, 'colsample_bytree': 0.9354008282802848, 'subsample': 0.9441606778259046, 'scale_pos_weight': 1.5349918978372536, 'gamma': 0.01730339434545881, 'eta': 0.20989862341366583}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:29:38,896]\u001b[0m Trial 89 finished with value: 0.25594589999999995 and parameters: {'alpha': 0.007862300085042281, 'colsample_bytree': 0.935134808047183, 'subsample': 0.944150844037863, 'scale_pos_weight': 1.5350680257545306, 'gamma': 0.017411863889762295, 'eta': 0.20849161472555408}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:29:39,221]\u001b[0m Trial 91 finished with value: 0.2535493 and parameters: {'alpha': 0.005490503906014262, 'colsample_bytree': 0.9308396151253646, 'subsample': 0.9445827462773142, 'scale_pos_weight': 1.5350222700113543, 'gamma': 0.020539358735728017, 'eta': 0.20981172537195095}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:29:40,299]\u001b[0m Trial 90 finished with value: 0.25650200000000006 and parameters: {'alpha': 0.005290263310170902, 'colsample_bytree': 0.9356404572779073, 'subsample': 0.9438415179409465, 'scale_pos_weight': 1.5353093477062851, 'gamma': 0.017542669148905274, 'eta': 0.20860355728499572}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:29:42,569]\u001b[0m Trial 92 finished with value: 0.25665879999999996 and parameters: {'alpha': 0.005516679664567518, 'colsample_bytree': 0.935614803407497, 'subsample': 0.9438540419630829, 'scale_pos_weight': 1.5350884958000797, 'gamma': 0.024038215888231573, 'eta': 0.2097688377654665}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:29:47,032]\u001b[0m Trial 93 finished with value: 0.25673450000000003 and parameters: {'alpha': 0.005662083498545819, 'colsample_bytree': 0.9305649712068279, 'subsample': 0.9438465702241883, 'scale_pos_weight': 1.5350153827408477, 'gamma': 0.02086863821813495, 'eta': 0.20986423307705382}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:29:48,648]\u001b[0m Trial 100 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:29:54,145]\u001b[0m Trial 101 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:30:17,453]\u001b[0m Trial 94 finished with value: 0.2567359 and parameters: {'alpha': 0.005525062023396311, 'colsample_bytree': 0.9306692450265518, 'subsample': 0.9437250435803752, 'scale_pos_weight': 1.5350331882342938, 'gamma': 0.02405842845135786, 'eta': 0.20988693356504506}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:30:31,687]\u001b[0m Trial 98 finished with value: 0.25673450000000003 and parameters: {'alpha': 0.005630091990878659, 'colsample_bytree': 0.9345944635473509, 'subsample': 0.9438345365773609, 'scale_pos_weight': 1.5380861815308227, 'gamma': 0.019113043888950312, 'eta': 0.20983903085561523}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:30:31,770]\u001b[0m Trial 95 finished with value: 0.25673450000000003 and parameters: {'alpha': 0.005297618254416269, 'colsample_bytree': 0.9344613927410358, 'subsample': 0.94384993057527, 'scale_pos_weight': 1.5380134252904496, 'gamma': 0.017205590687810232, 'eta': 0.2098016739323429}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:30:34,410]\u001b[0m Trial 97 finished with value: 0.2547356 and parameters: {'alpha': 0.00575800068566575, 'colsample_bytree': 0.9373219718320817, 'subsample': 0.9438430167044306, 'scale_pos_weight': 1.5335866603373247, 'gamma': 0.01919746104415076, 'eta': 0.20984828284567789}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:30:34,951]\u001b[0m Trial 96 finished with value: 0.25662219999999997 and parameters: {'alpha': 0.007720498864924512, 'colsample_bytree': 0.9305191590201545, 'subsample': 0.9437326560179142, 'scale_pos_weight': 1.5378685071742748, 'gamma': 0.01756352900100012, 'eta': 0.20987969410814641}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:30:37,327]\u001b[0m Trial 99 finished with value: 0.25658259999999994 and parameters: {'alpha': 0.0052109399065069974, 'colsample_bytree': 0.930367105136231, 'subsample': 0.9443204147188141, 'scale_pos_weight': 1.5380902980326592, 'gamma': 0.023977581295498245, 'eta': 0.2097892823128339}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:30:43,516]\u001b[0m Trial 102 finished with value: 0.24811029999999995 and parameters: {'alpha': 0.00912554437502042, 'colsample_bytree': 0.9374439536433674, 'subsample': 0.9443328256000996, 'scale_pos_weight': 1.5397687231991193, 'gamma': 0.01839523586507354, 'eta': 0.20807396638262976}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:30:46,127]\u001b[0m Trial 103 finished with value: 0.2565795 and parameters: {'alpha': 0.005196601548124624, 'colsample_bytree': 0.9374256050956298, 'subsample': 0.9443039118582017, 'scale_pos_weight': 1.5398483978152473, 'gamma': 0.022799027304045698, 'eta': 0.2104395966552188}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:30:52,668]\u001b[0m Trial 104 finished with value: 0.2492701 and parameters: {'alpha': 0.008491091037673978, 'colsample_bytree': 0.9344940270531296, 'subsample': 0.9443390945775831, 'scale_pos_weight': 1.537721393152204, 'gamma': 0.02263626442442984, 'eta': 0.2089846525960839}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:30:53,448]\u001b[0m Trial 109 finished with value: 0.25657729999999995 and parameters: {'alpha': 0.008515725901470157, 'colsample_bytree': 0.9324412975354691, 'subsample': 0.9443456404110107, 'scale_pos_weight': 1.535976626593068, 'gamma': 0.022433243006642137, 'eta': 0.21047096753668482}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:30:54,216]\u001b[0m Trial 106 finished with value: 0.2565707 and parameters: {'alpha': 0.009133863141040583, 'colsample_bytree': 0.9372698589035147, 'subsample': 0.9443171525307595, 'scale_pos_weight': 1.540086432934546, 'gamma': 0.02131388877269201, 'eta': 0.20937255765819915}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:30:54,773]\u001b[0m Trial 105 finished with value: 0.25657729999999995 and parameters: {'alpha': 0.009111078963979504, 'colsample_bytree': 0.9326629931721572, 'subsample': 0.9443202297077714, 'scale_pos_weight': 1.5359100645973212, 'gamma': 0.0153700238347871, 'eta': 0.21051511996114705}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:30:55,597]\u001b[0m Trial 107 finished with value: 0.2545136 and parameters: {'alpha': 0.009139034228703092, 'colsample_bytree': 0.9393295412199095, 'subsample': 0.9443107411466233, 'scale_pos_weight': 1.532680036900656, 'gamma': 0.022665198391198783, 'eta': 0.21045765497992636}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:30:56,439]\u001b[0m Trial 108 finished with value: 0.256613 and parameters: {'alpha': 0.008478717712713846, 'colsample_bytree': 0.9323903084669494, 'subsample': 0.9443446571185894, 'scale_pos_weight': 1.5399124537254874, 'gamma': 0.022443927901077028, 'eta': 0.21042170592502812}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:31:03,675]\u001b[0m Trial 110 finished with value: 0.2565415999999999 and parameters: {'alpha': 0.008491113664998003, 'colsample_bytree': 0.9325671025132771, 'subsample': 0.9440742414628341, 'scale_pos_weight': 1.5359363423756967, 'gamma': 0.02265380536180103, 'eta': 0.20938818774233325}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:31:05,512]\u001b[0m Trial 111 finished with value: 0.25713010000000003 and parameters: {'alpha': 0.008591794880091578, 'colsample_bytree': 0.9324883669264307, 'subsample': 0.9442111116916532, 'scale_pos_weight': 1.535940679617531, 'gamma': 0.022726901438324613, 'eta': 0.20940176556596818}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:31:14,003]\u001b[0m Trial 112 finished with value: 0.25703919999999997 and parameters: {'alpha': 0.008550106826739911, 'colsample_bytree': 0.9323055876859988, 'subsample': 0.9442182714601866, 'scale_pos_weight': 1.535880837092094, 'gamma': 0.01678323226705188, 'eta': 0.20943613045858608}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:31:14,592]\u001b[0m Trial 113 finished with value: 0.2551085 and parameters: {'alpha': 0.00861854175228725, 'colsample_bytree': 0.9325236256310613, 'subsample': 0.9442224434355379, 'scale_pos_weight': 1.5325757734786138, 'gamma': 0.021354266876589544, 'eta': 0.20950365773155818}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:31:15,691]\u001b[0m Trial 114 finished with value: 0.2560518 and parameters: {'alpha': 0.008633387980733315, 'colsample_bytree': 0.9322452836727949, 'subsample': 0.9442144973928258, 'scale_pos_weight': 1.534657955414332, 'gamma': 0.012993956460620496, 'eta': 0.20902926707085087}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:31:16,528]\u001b[0m Trial 115 finished with value: 0.2550975 and parameters: {'alpha': 0.008948752647324193, 'colsample_bytree': 0.9394306628182627, 'subsample': 0.944223888288738, 'scale_pos_weight': 1.5323772481303206, 'gamma': 0.01991075551153421, 'eta': 0.2095102089916373}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:31:16,794]\u001b[0m Trial 116 finished with value: 0.25665249999999995 and parameters: {'alpha': 0.008615404375946068, 'colsample_bytree': 0.9364272646946384, 'subsample': 0.9440894516033962, 'scale_pos_weight': 1.5369619285798883, 'gamma': 0.012736251075112651, 'eta': 0.20900088486446833}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:31:18,126]\u001b[0m Trial 117 finished with value: 0.25512729999999995 and parameters: {'alpha': 0.008628056084760756, 'colsample_bytree': 0.9319127141618964, 'subsample': 0.9442267228264783, 'scale_pos_weight': 1.5336650960362677, 'gamma': 0.016451177291759374, 'eta': 0.20964572033827253}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:31:18,391]\u001b[0m Trial 120 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:31:18,977]\u001b[0m Trial 121 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:31:20,559]\u001b[0m Trial 123 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:31:26,979]\u001b[0m Trial 118 finished with value: 0.2570198 and parameters: {'alpha': 0.008711299253981444, 'colsample_bytree': 0.9419600907484292, 'subsample': 0.9442041197986157, 'scale_pos_weight': 1.5368797745225076, 'gamma': 0.012842681648344217, 'eta': 0.20957126804321008}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:31:30,381]\u001b[0m Trial 119 finished with value: 0.25703919999999997 and parameters: {'alpha': 0.008662828100438271, 'colsample_bytree': 0.9419572216159681, 'subsample': 0.9442242208762223, 'scale_pos_weight': 1.5369438593769698, 'gamma': 0.01994320924344572, 'eta': 0.20956688814404864}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:31:54,385]\u001b[0m Trial 122 finished with value: 0.2546713 and parameters: {'alpha': 0.008927220548432773, 'colsample_bytree': 0.9330784718666665, 'subsample': 0.9439300246702854, 'scale_pos_weight': 1.5336985439347866, 'gamma': 0.01988216242270916, 'eta': 0.2096209783345439}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:31:56,057]\u001b[0m Trial 124 finished with value: 0.25268519999999994 and parameters: {'alpha': 0.00877696714766037, 'colsample_bytree': 0.9318060186888144, 'subsample': 0.9444783106621728, 'scale_pos_weight': 1.5337259433724537, 'gamma': 0.02375812108686844, 'eta': 0.21025143865380946}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:31:57,731]\u001b[0m Trial 126 finished with value: 0.2565277 and parameters: {'alpha': 0.008785716760316403, 'colsample_bytree': 0.9331491182858558, 'subsample': 0.944069254354662, 'scale_pos_weight': 1.535559106555219, 'gamma': 0.023617757369170003, 'eta': 0.20875891098747548}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:31:57,998]\u001b[0m Trial 125 finished with value: 0.25477059999999996 and parameters: {'alpha': 0.008211779010357741, 'colsample_bytree': 0.9595833840180262, 'subsample': 0.9444514854550579, 'scale_pos_weight': 1.541228018536704, 'gamma': 0.02365385141222315, 'eta': 0.21026493005294247}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:31:58,648]\u001b[0m Trial 127 finished with value: 0.2564938 and parameters: {'alpha': 0.008790539761669252, 'colsample_bytree': 0.9331458431755169, 'subsample': 0.9439145395924108, 'scale_pos_weight': 1.5355599575409828, 'gamma': 0.02368847880670466, 'eta': 0.20876024615106456}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:31:59,827]\u001b[0m Trial 128 finished with value: 0.25672819999999996 and parameters: {'alpha': 0.008722383512883168, 'colsample_bytree': 0.9330613899443335, 'subsample': 0.9439172073315456, 'scale_pos_weight': 1.5362339280076331, 'gamma': 0.023719649974896416, 'eta': 0.2100507034986861}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:32:04,235]\u001b[0m Trial 129 finished with value: 0.2565415999999999 and parameters: {'alpha': 0.008202617409947452, 'colsample_bytree': 0.9330754869327313, 'subsample': 0.9440797886980913, 'scale_pos_weight': 1.535542783581175, 'gamma': 0.023624428737932517, 'eta': 0.20932752832816479}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:32:07,087]\u001b[0m Trial 130 finished with value: 0.2567638 and parameters: {'alpha': 0.008802891501294936, 'colsample_bytree': 0.9330589551007769, 'subsample': 0.9440983098137483, 'scale_pos_weight': 1.5363005797047855, 'gamma': 0.023567564955788697, 'eta': 0.21029413681465034}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:32:18,003]\u001b[0m Trial 131 finished with value: 0.2567104 and parameters: {'alpha': 0.008210584111625625, 'colsample_bytree': 0.9341024274673093, 'subsample': 0.944086209301897, 'scale_pos_weight': 1.5355417685175272, 'gamma': 0.02372980102250248, 'eta': 0.21002975225373158}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:32:19,214]\u001b[0m Trial 132 finished with value: 0.25592079999999995 and parameters: {'alpha': 0.008210563565998323, 'colsample_bytree': 0.9338277466810795, 'subsample': 0.9440720390820442, 'scale_pos_weight': 1.5354395243389456, 'gamma': 0.02350958599995436, 'eta': 0.21250847729902977}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:32:22,501]\u001b[0m Trial 134 finished with value: 0.2567097 and parameters: {'alpha': 0.00835941209299509, 'colsample_bytree': 0.9338781303057284, 'subsample': 0.9441130272569621, 'scale_pos_weight': 1.5363779343679802, 'gamma': 0.024535133553282816, 'eta': 0.2100391956096816}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:32:23,195]\u001b[0m Trial 133 finished with value: 0.25709360000000003 and parameters: {'alpha': 0.008197318864259107, 'colsample_bytree': 0.9340000907712607, 'subsample': 0.9441223239090138, 'scale_pos_weight': 1.5363207209443697, 'gamma': 0.0256276034255795, 'eta': 0.2100330701632101}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:32:24,658]\u001b[0m Trial 135 finished with value: 0.2567747 and parameters: {'alpha': 0.00833492263367497, 'colsample_bytree': 0.9340465875666055, 'subsample': 0.9440538223255401, 'scale_pos_weight': 1.5385949998984134, 'gamma': 0.025535870967960263, 'eta': 0.21003864191461386}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:32:27,162]\u001b[0m Trial 136 finished with value: 0.25182119999999997 and parameters: {'alpha': 0.008393649422575783, 'colsample_bytree': 0.9339955150819318, 'subsample': 0.9441067461792136, 'scale_pos_weight': 1.5385820681211508, 'gamma': 0.00921849361110653, 'eta': 0.21373928256687066}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:32:28,422]\u001b[0m Trial 140 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:32:32,929]\u001b[0m Trial 144 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:32:33,725]\u001b[0m Trial 137 finished with value: 0.25709360000000003 and parameters: {'alpha': 0.00838393801676543, 'colsample_bytree': 0.9340244419358517, 'subsample': 0.9441250886715842, 'scale_pos_weight': 1.5362486372791702, 'gamma': 0.024439771918823266, 'eta': 0.21006642479240087}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:32:37,328]\u001b[0m Trial 138 finished with value: 0.2560942 and parameters: {'alpha': 0.008374276759999617, 'colsample_bytree': 0.9339376506733894, 'subsample': 0.9441279780734714, 'scale_pos_weight': 1.536452566748857, 'gamma': 0.011025538579138575, 'eta': 0.21247728522496326}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:32:46,227]\u001b[0m Trial 139 finished with value: 0.2569352 and parameters: {'alpha': 0.008415827746409373, 'colsample_bytree': 0.9360583415275062, 'subsample': 0.9441309448427074, 'scale_pos_weight': 1.5345871329387997, 'gamma': 0.02444341521799192, 'eta': 0.20929614524229997}. Best is trial 58 with value: 0.2571526.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:32:51,260]\u001b[0m Trial 142 finished with value: 0.2571847 and parameters: {'alpha': 0.007912013448058435, 'colsample_bytree': 0.9349209100537451, 'subsample': 0.9441584418083023, 'scale_pos_weight': 1.5385183017626884, 'gamma': 0.025453499846945726, 'eta': 0.20927891921824257}. Best is trial 142 with value: 0.2571847.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:32:51,937]\u001b[0m Trial 141 finished with value: 0.25366809999999995 and parameters: {'alpha': 0.006351112622150849, 'colsample_bytree': 0.9361459056277814, 'subsample': 0.9440191122701337, 'scale_pos_weight': 1.5347798887138848, 'gamma': 0.01359573765415461, 'eta': 0.2138307671306405}. Best is trial 142 with value: 0.2571847.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:32:52,010]\u001b[0m Trial 143 finished with value: 0.2570494 and parameters: {'alpha': 0.00841061832644361, 'colsample_bytree': 0.9349244696273761, 'subsample': 0.9441502781770478, 'scale_pos_weight': 1.5347200103353653, 'gamma': 0.02435463107045356, 'eta': 0.20923661459706902}. Best is trial 142 with value: 0.2571847.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:32:53,629]\u001b[0m Trial 145 finished with value: 0.2571681 and parameters: {'alpha': 0.0070877621734125595, 'colsample_bytree': 0.9359813797109534, 'subsample': 0.9442727488642683, 'scale_pos_weight': 1.5374400323267396, 'gamma': 0.022823821018507596, 'eta': 0.20929569812168342}. Best is trial 142 with value: 0.2571847.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:32:56,758]\u001b[0m Trial 146 finished with value: 0.2571794 and parameters: {'alpha': 0.007362390471447967, 'colsample_bytree': 0.9364219072815347, 'subsample': 0.944170930661371, 'scale_pos_weight': 1.5374736636565003, 'gamma': 0.024320642674562805, 'eta': 0.2105977680877294}. Best is trial 142 with value: 0.2571847.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:32:57,785]\u001b[0m Trial 147 finished with value: 0.25715869999999996 and parameters: {'alpha': 0.007936387923845632, 'colsample_bytree': 0.9361932688943728, 'subsample': 0.9442567453259881, 'scale_pos_weight': 1.5373487706270734, 'gamma': 0.024396570763063685, 'eta': 0.21066091267986817}. Best is trial 142 with value: 0.2571847.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:33:00,219]\u001b[0m Trial 148 finished with value: 0.2571681 and parameters: {'alpha': 0.006312611057690573, 'colsample_bytree': 0.9352402141762528, 'subsample': 0.9442700096965685, 'scale_pos_weight': 1.5375305360307918, 'gamma': 0.024338828247805647, 'eta': 0.20966118831117903}. Best is trial 142 with value: 0.2571847.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:33:07,219]\u001b[0m Trial 149 finished with value: 0.25665760000000004 and parameters: {'alpha': 0.00796517348787346, 'colsample_bytree': 0.9309715877453886, 'subsample': 0.944011341966188, 'scale_pos_weight': 1.5352686759595522, 'gamma': 0.02491442720518204, 'eta': 0.20964685196492586}. Best is trial 142 with value: 0.2571847.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:33:17,613]\u001b[0m Trial 150 finished with value: 0.25676439999999995 and parameters: {'alpha': 0.007916507557671353, 'colsample_bytree': 0.9442509282568162, 'subsample': 0.9440052877015548, 'scale_pos_weight': 1.5374482674197454, 'gamma': 0.025895937655022534, 'eta': 0.21065959120391153}. Best is trial 142 with value: 0.2571847.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:33:23,620]\u001b[0m Trial 151 finished with value: 0.2570578 and parameters: {'alpha': 0.007981161199167638, 'colsample_bytree': 0.9349546316027513, 'subsample': 0.9442796457026561, 'scale_pos_weight': 1.5376277534178044, 'gamma': 0.025980307452979405, 'eta': 0.20973422487833596}. Best is trial 142 with value: 0.2571847.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:33:26,121]\u001b[0m Trial 152 finished with value: 0.2551037 and parameters: {'alpha': 0.007867865993893582, 'colsample_bytree': 0.9349027802231435, 'subsample': 0.9442742205115704, 'scale_pos_weight': 1.5341972160252606, 'gamma': 0.025159302259939564, 'eta': 0.20968926009905403}. Best is trial 142 with value: 0.2571847.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:33:29,362]\u001b[0m Trial 153 finished with value: 0.25705370000000005 and parameters: {'alpha': 0.00713231110265431, 'colsample_bytree': 0.9450541697948751, 'subsample': 0.9442557400524307, 'scale_pos_weight': 1.5374456670404046, 'gamma': 0.025783633046599246, 'eta': 0.20969561137350243}. Best is trial 142 with value: 0.2571847.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:33:38,310]\u001b[0m Trial 154 finished with value: 0.25716680000000003 and parameters: {'alpha': 0.007333850382890857, 'colsample_bytree': 0.9363986419351364, 'subsample': 0.9442727802615428, 'scale_pos_weight': 1.5376219985587056, 'gamma': 0.024865029328088775, 'eta': 0.21064136798917424}. Best is trial 142 with value: 0.2571847.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:33:41,710]\u001b[0m Trial 155 finished with value: 0.25716680000000003 and parameters: {'alpha': 0.007943808917324687, 'colsample_bytree': 0.936818520003286, 'subsample': 0.9442646429107531, 'scale_pos_weight': 1.5374611435361278, 'gamma': 0.02595090051513148, 'eta': 0.2107537773434914}. Best is trial 142 with value: 0.2571847.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:33:45,629]\u001b[0m Trial 156 finished with value: 0.25715639999999995 and parameters: {'alpha': 0.007408203897576187, 'colsample_bytree': 0.9365203011139593, 'subsample': 0.9442630961497284, 'scale_pos_weight': 1.537462874995137, 'gamma': 0.026157033471995734, 'eta': 0.21147243866983909}. Best is trial 142 with value: 0.2571847.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:33:53,327]\u001b[0m Trial 157 finished with value: 0.25715639999999995 and parameters: {'alpha': 0.007371815203837804, 'colsample_bytree': 0.9367585813827893, 'subsample': 0.9442631055376085, 'scale_pos_weight': 1.5374719981218414, 'gamma': 0.02583714072574628, 'eta': 0.21141569158926043}. Best is trial 142 with value: 0.2571847.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:33:58,199]\u001b[0m Trial 158 finished with value: 0.2571548 and parameters: {'alpha': 0.007629151633245951, 'colsample_bytree': 0.9363393583303193, 'subsample': 0.9442555156916548, 'scale_pos_weight': 1.5374441803376575, 'gamma': 0.025113254215391335, 'eta': 0.21078967826064188}. Best is trial 142 with value: 0.2571847.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:34:00,001]\u001b[0m Trial 160 finished with value: 0.25715869999999996 and parameters: {'alpha': 0.007492099054559658, 'colsample_bytree': 0.9368839295568576, 'subsample': 0.944259361456306, 'scale_pos_weight': 1.5375060690632152, 'gamma': 0.015066914862829073, 'eta': 0.21063167589976603}. Best is trial 142 with value: 0.2571847.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:34:00,482]\u001b[0m Trial 159 finished with value: 0.2571523 and parameters: {'alpha': 0.007775008688059383, 'colsample_bytree': 0.9369456003117023, 'subsample': 0.9442766863168093, 'scale_pos_weight': 1.5373330138634802, 'gamma': 0.024941761433204097, 'eta': 0.2117742779286233}. Best is trial 142 with value: 0.2571847.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:34:01,720]\u001b[0m Trial 161 finished with value: 0.257151 and parameters: {'alpha': 0.007448030378659717, 'colsample_bytree': 0.9362269259782607, 'subsample': 0.944191679452166, 'scale_pos_weight': 1.5383521210303432, 'gamma': 0.02532336114463114, 'eta': 0.2113760120382558}. Best is trial 142 with value: 0.2571847.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:34:05,271]\u001b[0m Trial 162 finished with value: 0.25438510000000003 and parameters: {'alpha': 0.007414046891505809, 'colsample_bytree': 0.9366375198291517, 'subsample': 0.9445523780956128, 'scale_pos_weight': 1.5386533503049922, 'gamma': 0.025285185907426868, 'eta': 0.21170941668963278}. Best is trial 142 with value: 0.2571847.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:34:05,778]\u001b[0m Trial 163 finished with value: 0.255105 and parameters: {'alpha': 0.0074813521172377336, 'colsample_bytree': 0.9367700821370043, 'subsample': 0.9446004872345639, 'scale_pos_weight': 1.5384317250313264, 'gamma': 0.025484469679270445, 'eta': 0.21147061845772208}. Best is trial 142 with value: 0.2571847.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:34:07,950]\u001b[0m Trial 164 finished with value: 0.257151 and parameters: {'alpha': 0.007545855862889212, 'colsample_bytree': 0.9367771678353336, 'subsample': 0.9441933262768689, 'scale_pos_weight': 1.5387848037185021, 'gamma': 0.02532472573287807, 'eta': 0.21160425140331007}. Best is trial 142 with value: 0.2571847.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:34:18,822]\u001b[0m Trial 165 finished with value: 0.25513479999999994 and parameters: {'alpha': 0.007364888977631442, 'colsample_bytree': 0.936830468546246, 'subsample': 0.9445660090971786, 'scale_pos_weight': 1.5382535136769282, 'gamma': 0.0249580963589055, 'eta': 0.21134674951418356}. Best is trial 142 with value: 0.2571847.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:34:24,272]\u001b[0m Trial 166 finished with value: 0.2534262 and parameters: {'alpha': 0.007357016441497898, 'colsample_bytree': 0.9366113145820097, 'subsample': 0.944608906416778, 'scale_pos_weight': 1.5383329002461892, 'gamma': 0.02744301623780569, 'eta': 0.21187242250336827}. Best is trial 142 with value: 0.2571847.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:34:25,036]\u001b[0m Trial 167 finished with value: 0.25509889999999996 and parameters: {'alpha': 0.00750531112946989, 'colsample_bytree': 0.9368245665412422, 'subsample': 0.9443870813516266, 'scale_pos_weight': 1.5384188119448605, 'gamma': 0.026649390524614604, 'eta': 0.21142509709541296}. Best is trial 142 with value: 0.2571847.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:34:25,441]\u001b[0m Trial 169 finished with value: 0.2551042 and parameters: {'alpha': 0.007517770882113254, 'colsample_bytree': 0.9367098876573233, 'subsample': 0.944564882593365, 'scale_pos_weight': 1.5382955753990122, 'gamma': 0.02771703523561855, 'eta': 0.21149810714622122}. Best is trial 142 with value: 0.2571847.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:34:25,926]\u001b[0m Trial 168 finished with value: 0.2534262 and parameters: {'alpha': 0.007411172196792117, 'colsample_bytree': 0.9368493840588564, 'subsample': 0.9445726311415104, 'scale_pos_weight': 1.5382823369283245, 'gamma': 0.027810716536874742, 'eta': 0.21171670458950043}. Best is trial 142 with value: 0.2571847.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:34:30,660]\u001b[0m Trial 171 finished with value: 0.25509889999999996 and parameters: {'alpha': 0.00760113458009918, 'colsample_bytree': 0.9379696932713306, 'subsample': 0.9443821208318299, 'scale_pos_weight': 1.5374795628527353, 'gamma': 0.026334981532336994, 'eta': 0.21177681775210008}. Best is trial 142 with value: 0.2571847.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:34:30,847]\u001b[0m Trial 170 finished with value: 0.25509889999999996 and parameters: {'alpha': 0.0075284750907962175, 'colsample_bytree': 0.9380902558028151, 'subsample': 0.9443905021033924, 'scale_pos_weight': 1.5382816554098575, 'gamma': 0.02802010324327296, 'eta': 0.21151449231690572}. Best is trial 142 with value: 0.2571847.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:34:32,873]\u001b[0m Trial 172 finished with value: 0.2541022 and parameters: {'alpha': 0.007591289437391763, 'colsample_bytree': 0.9379796341010799, 'subsample': 0.9443928481410516, 'scale_pos_weight': 1.5372751097886108, 'gamma': 0.02781334306034147, 'eta': 0.21189528813007474}. Best is trial 142 with value: 0.2571847.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:34:57,030]\u001b[0m Trial 173 finished with value: 0.2540864 and parameters: {'alpha': 0.007583645414699951, 'colsample_bytree': 0.938745122183225, 'subsample': 0.9443905661041305, 'scale_pos_weight': 1.5394599617607139, 'gamma': 0.026487830496455284, 'eta': 0.21196792795454597}. Best is trial 142 with value: 0.2571847.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:36:26,443]\u001b[0m Trial 175 finished with value: 0.257187 and parameters: {'alpha': 0.007627228133326711, 'colsample_bytree': 0.9378475020357221, 'subsample': 0.9442701674499747, 'scale_pos_weight': 1.5373054933634454, 'gamma': 0.02627048769193617, 'eta': 0.21118624989045484}. Best is trial 175 with value: 0.257187.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:36:26,641]\u001b[0m Trial 174 finished with value: 0.25513359999999996 and parameters: {'alpha': 0.007577857034169708, 'colsample_bytree': 0.9379874417178587, 'subsample': 0.9443918680539384, 'scale_pos_weight': 1.53722873071085, 'gamma': 0.02667638137938978, 'eta': 0.21121471741435918}. Best is trial 175 with value: 0.257187.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:36:29,683]\u001b[0m Trial 176 finished with value: 0.257187 and parameters: {'alpha': 0.0077501472892089925, 'colsample_bytree': 0.9378418494572006, 'subsample': 0.9442787847208512, 'scale_pos_weight': 1.5373436336325907, 'gamma': 0.02625989041870047, 'eta': 0.2111780219250121}. Best is trial 176 with value: 0.257187.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:36:32,599]\u001b[0m Trial 177 finished with value: 0.2561664 and parameters: {'alpha': 0.007665571996242534, 'colsample_bytree': 0.9377671821188777, 'subsample': 0.944283728462179, 'scale_pos_weight': 1.5373948015521417, 'gamma': 0.026250110360307125, 'eta': 0.21206360627467957}. Best is trial 176 with value: 0.257187.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:36:36,024]\u001b[0m Trial 178 finished with value: 0.25620539999999997 and parameters: {'alpha': 0.00771466995048432, 'colsample_bytree': 0.9378824537003385, 'subsample': 0.9442754816790603, 'scale_pos_weight': 1.537175870838878, 'gamma': 0.02492405728947659, 'eta': 0.21212555486819062}. Best is trial 176 with value: 0.257187.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:36:38,118]\u001b[0m Trial 180 finished with value: 0.257187 and parameters: {'alpha': 0.00775034273355659, 'colsample_bytree': 0.9361306662289385, 'subsample': 0.9442842264563033, 'scale_pos_weight': 1.5393464591998876, 'gamma': 0.025998788648274603, 'eta': 0.21113393489420326}. Best is trial 176 with value: 0.257187.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:36:38,731]\u001b[0m Trial 179 finished with value: 0.255899 and parameters: {'alpha': 0.007737302296565905, 'colsample_bytree': 0.9378843538615579, 'subsample': 0.9442942102649466, 'scale_pos_weight': 1.5372242531853944, 'gamma': 0.026008588739015334, 'eta': 0.21202013331575228}. Best is trial 176 with value: 0.257187.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:36:46,106]\u001b[0m Trial 181 finished with value: 0.257187 and parameters: {'alpha': 0.0077378503877180696, 'colsample_bytree': 0.9376004906553532, 'subsample': 0.9442677566599502, 'scale_pos_weight': 1.5377741642621783, 'gamma': 0.024763566469086628, 'eta': 0.21110855889015862}. Best is trial 181 with value: 0.257187.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:36:59,295]\u001b[0m Trial 182 finished with value: 0.2569225 and parameters: {'alpha': 0.007755926648499696, 'colsample_bytree': 0.9359609668151774, 'subsample': 0.9443069204543808, 'scale_pos_weight': 1.5388373859408035, 'gamma': 0.024822425086274726, 'eta': 0.21120382653130768}. Best is trial 181 with value: 0.257187.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:37:04,272]\u001b[0m Trial 184 finished with value: 0.257187 and parameters: {'alpha': 0.007745244106548568, 'colsample_bytree': 0.9360741136270423, 'subsample': 0.9442733090263319, 'scale_pos_weight': 1.53890910391906, 'gamma': 0.025974728912328833, 'eta': 0.21097034545309512}. Best is trial 181 with value: 0.257187.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:37:05,714]\u001b[0m Trial 183 finished with value: 0.2571629 and parameters: {'alpha': 0.0072352547689069294, 'colsample_bytree': 0.9361884169203735, 'subsample': 0.9442817691496519, 'scale_pos_weight': 1.5377066703479998, 'gamma': 0.02597363310374756, 'eta': 0.21094134356976788}. Best is trial 181 with value: 0.257187.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:37:08,882]\u001b[0m Trial 185 finished with value: 0.2571848 and parameters: {'alpha': 0.007745124106712494, 'colsample_bytree': 0.9362257342326362, 'subsample': 0.9442637797129361, 'scale_pos_weight': 1.5389053826192791, 'gamma': 0.024834806310528267, 'eta': 0.2109317579937233}. Best is trial 181 with value: 0.257187.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:37:10,107]\u001b[0m Trial 187 finished with value: 0.2571848 and parameters: {'alpha': 0.007243271052534206, 'colsample_bytree': 0.9389468605568898, 'subsample': 0.9442746332025044, 'scale_pos_weight': 1.5389525102375594, 'gamma': 0.02581874947240347, 'eta': 0.2109125435138493}. Best is trial 181 with value: 0.257187.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:37:10,828]\u001b[0m Trial 186 finished with value: 0.2571629 and parameters: {'alpha': 0.007238533455074232, 'colsample_bytree': 0.9359531818624035, 'subsample': 0.9442625373005382, 'scale_pos_weight': 1.5377759833595082, 'gamma': 0.025784516625564184, 'eta': 0.21093269786024876}. Best is trial 181 with value: 0.257187.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:37:12,029]\u001b[0m Trial 188 finished with value: 0.25717890000000004 and parameters: {'alpha': 0.007173647151382449, 'colsample_bytree': 0.9357965653364796, 'subsample': 0.9442488700176688, 'scale_pos_weight': 1.5387876068693807, 'gamma': 0.0253743961340404, 'eta': 0.21109271811428165}. Best is trial 181 with value: 0.257187.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:37:19,149]\u001b[0m Trial 189 finished with value: 0.2571629 and parameters: {'alpha': 0.007246782158410562, 'colsample_bytree': 0.9360735045081054, 'subsample': 0.944261515929444, 'scale_pos_weight': 1.5377688048409426, 'gamma': 0.02521400251527843, 'eta': 0.2109054494643582}. Best is trial 181 with value: 0.257187.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:37:26,623]\u001b[0m Trial 190 finished with value: 0.2571548 and parameters: {'alpha': 0.007298418084467172, 'colsample_bytree': 0.9373513930729875, 'subsample': 0.9442478232637123, 'scale_pos_weight': 1.537727643764285, 'gamma': 0.025271326174839, 'eta': 0.21088737375559705}. Best is trial 181 with value: 0.257187.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:37:29,352]\u001b[0m Trial 191 finished with value: 0.2571767 and parameters: {'alpha': 0.007827119509227013, 'colsample_bytree': 0.9390157020861903, 'subsample': 0.94425027556747, 'scale_pos_weight': 1.5378456161322198, 'gamma': 0.025655788779119466, 'eta': 0.21093455942388636}. Best is trial 181 with value: 0.257187.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:37:30,895]\u001b[0m Trial 192 finished with value: 0.2571767 and parameters: {'alpha': 0.00723174786109974, 'colsample_bytree': 0.9388102738863024, 'subsample': 0.9442508232950433, 'scale_pos_weight': 1.5378613791687228, 'gamma': 0.02698258255513927, 'eta': 0.21103693613829866}. Best is trial 181 with value: 0.257187.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:37:33,691]\u001b[0m Trial 193 finished with value: 0.25659529999999997 and parameters: {'alpha': 0.007185887207767419, 'colsample_bytree': 0.9387894085002124, 'subsample': 0.9443449042762118, 'scale_pos_weight': 1.5377056816620087, 'gamma': 0.025808887746615806, 'eta': 0.21094104922941928}. Best is trial 181 with value: 0.257187.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:37:34,006]\u001b[0m Trial 195 finished with value: 0.25692029999999993 and parameters: {'alpha': 0.007246621579538853, 'colsample_bytree': 0.9355633612354312, 'subsample': 0.9443384878278903, 'scale_pos_weight': 1.5378104906058903, 'gamma': 0.026997223876783008, 'eta': 0.21097297742230087}. Best is trial 181 with value: 0.257187.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:37:34,301]\u001b[0m Trial 194 finished with value: 0.25692029999999993 and parameters: {'alpha': 0.007243900932205527, 'colsample_bytree': 0.9387073699391092, 'subsample': 0.9443396052509554, 'scale_pos_weight': 1.5377393022790753, 'gamma': 0.025874793767993242, 'eta': 0.21102528412164331}. Best is trial 181 with value: 0.257187.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:37:36,350]\u001b[0m Trial 196 finished with value: 0.25692029999999993 and parameters: {'alpha': 0.007220368239061969, 'colsample_bytree': 0.9389369211811555, 'subsample': 0.9443406650038852, 'scale_pos_weight': 1.5378601109814214, 'gamma': 0.026990178949997515, 'eta': 0.21094421003102629}. Best is trial 181 with value: 0.257187.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:37:43,815]\u001b[0m Trial 197 finished with value: 0.2569225 and parameters: {'alpha': 0.007230633423371809, 'colsample_bytree': 0.9386607418057117, 'subsample': 0.9443354469360256, 'scale_pos_weight': 1.5395517620236008, 'gamma': 0.02694248858424343, 'eta': 0.21094443573093036}. Best is trial 181 with value: 0.257187.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:37:53,016]\u001b[0m Trial 198 finished with value: 0.2569225 and parameters: {'alpha': 0.007202059097488749, 'colsample_bytree': 0.9355816524344897, 'subsample': 0.9443381540446522, 'scale_pos_weight': 1.5395077729084898, 'gamma': 0.025906899447900263, 'eta': 0.2110197212874356}. Best is trial 181 with value: 0.257187.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:37:54,215]\u001b[0m Trial 199 finished with value: 0.24924519999999997 and parameters: {'alpha': 0.007174484087032065, 'colsample_bytree': 0.9387232628677985, 'subsample': 0.9452896833119693, 'scale_pos_weight': 1.5393729854911378, 'gamma': 0.02703352031796937, 'eta': 0.2109855218296618}. Best is trial 181 with value: 0.257187.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:37:59,399]\u001b[0m Trial 200 finished with value: 0.2569225 and parameters: {'alpha': 0.007121875816303545, 'colsample_bytree': 0.9387556881043279, 'subsample': 0.9443386000403636, 'scale_pos_weight': 1.5388987079641265, 'gamma': 0.02702968991569078, 'eta': 0.2110833434563816}. Best is trial 181 with value: 0.257187.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:38:02,221]\u001b[0m Trial 201 finished with value: 0.25718159999999995 and parameters: {'alpha': 0.007243026193018393, 'colsample_bytree': 0.9399835957306353, 'subsample': 0.9441861302584821, 'scale_pos_weight': 1.5392778466791668, 'gamma': 0.026934641757908336, 'eta': 0.21117058565252006}. Best is trial 181 with value: 0.257187.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:38:03,191]\u001b[0m Trial 203 finished with value: 0.25516869999999997 and parameters: {'alpha': 0.0069822590872850145, 'colsample_bytree': 0.939488690749592, 'subsample': 0.9444390161493964, 'scale_pos_weight': 1.5391305241313338, 'gamma': 0.0243393603659028, 'eta': 0.21114020636683012}. Best is trial 181 with value: 0.257187.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:38:03,592]\u001b[0m Trial 202 finished with value: 0.2571838 and parameters: {'alpha': 0.007079857358595158, 'colsample_bytree': 0.9399453711152419, 'subsample': 0.9441889824696628, 'scale_pos_weight': 1.5394463064936463, 'gamma': 0.026838621162675873, 'eta': 0.21120625317087519}. Best is trial 181 with value: 0.257187.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:38:07,309]\u001b[0m Trial 204 finished with value: 0.2572217 and parameters: {'alpha': 0.006970520075664316, 'colsample_bytree': 0.935495431642134, 'subsample': 0.9441832990159295, 'scale_pos_weight': 1.5389210174364985, 'gamma': 0.024447131510588027, 'eta': 0.21110806838050414}. Best is trial 204 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:38:16,607]\u001b[0m Trial 205 finished with value: 0.2572217 and parameters: {'alpha': 0.006921726299338945, 'colsample_bytree': 0.9398029467751952, 'subsample': 0.944184989706611, 'scale_pos_weight': 1.5390022003464374, 'gamma': 0.02892249945024649, 'eta': 0.21116092411232582}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:38:30,060]\u001b[0m Trial 207 finished with value: 0.2547674999999999 and parameters: {'alpha': 0.007010327136568321, 'colsample_bytree': 0.9399745913695197, 'subsample': 0.9444351253040636, 'scale_pos_weight': 1.5390367509839102, 'gamma': 0.025537355670443417, 'eta': 0.21066213263742808}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:38:30,539]\u001b[0m Trial 206 finished with value: 0.25718159999999995 and parameters: {'alpha': 0.006965592954489379, 'colsample_bytree': 0.9398736951106977, 'subsample': 0.9441862902119127, 'scale_pos_weight': 1.5390941673308505, 'gamma': 0.024347360025838847, 'eta': 0.21117704966299353}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:38:40,410]\u001b[0m Trial 210 finished with value: 0.2571794 and parameters: {'alpha': 0.007837139077750854, 'colsample_bytree': 0.9373611553559625, 'subsample': 0.9441944079889945, 'scale_pos_weight': 1.5388108953476418, 'gamma': 0.028635462030973686, 'eta': 0.21062304747682092}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:38:42,683]\u001b[0m Trial 208 finished with value: 0.2571794 and parameters: {'alpha': 0.007018859622995736, 'colsample_bytree': 0.9395171294052846, 'subsample': 0.944177459549636, 'scale_pos_weight': 1.5388500274589823, 'gamma': 0.024199016422664688, 'eta': 0.21061255102948684}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:38:42,855]\u001b[0m Trial 209 finished with value: 0.2571838 and parameters: {'alpha': 0.006986062434302996, 'colsample_bytree': 0.9398065558053313, 'subsample': 0.9441958528033678, 'scale_pos_weight': 1.539159842373928, 'gamma': 0.02855620738437317, 'eta': 0.21120611055610605}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:38:43,032]\u001b[0m Trial 211 finished with value: 0.2571806 and parameters: {'alpha': 0.007039457762709656, 'colsample_bytree': 0.9399671162304294, 'subsample': 0.9442090678855593, 'scale_pos_weight': 1.5388827706076076, 'gamma': 0.028454902597227966, 'eta': 0.21076679981391708}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:38:49,985]\u001b[0m Trial 212 finished with value: 0.257151 and parameters: {'alpha': 0.007022729238887831, 'colsample_bytree': 0.9404401565567705, 'subsample': 0.9441929437598361, 'scale_pos_weight': 1.5388975339522215, 'gamma': 0.026660077267120545, 'eta': 0.21121174264869078}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:38:55,492]\u001b[0m Trial 213 finished with value: 0.257151 and parameters: {'alpha': 0.007020032754278989, 'colsample_bytree': 0.9403515728332338, 'subsample': 0.9441875406534632, 'scale_pos_weight': 1.5387993346774107, 'gamma': 0.0296408482014678, 'eta': 0.21121220695984969}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:39:12,206]\u001b[0m Trial 214 finished with value: 0.2571911 and parameters: {'alpha': 0.006595980160642961, 'colsample_bytree': 0.940218251575329, 'subsample': 0.9441793909592525, 'scale_pos_weight': 1.5398447254212586, 'gamma': 0.026499007846075326, 'eta': 0.21127697745081056}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:39:13,394]\u001b[0m Trial 215 finished with value: 0.2571911 and parameters: {'alpha': 0.00665653864680183, 'colsample_bytree': 0.9402836695588738, 'subsample': 0.9441851640576957, 'scale_pos_weight': 1.540272979976081, 'gamma': 0.028776188328052413, 'eta': 0.2112133862203816}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:39:21,183]\u001b[0m Trial 216 finished with value: 0.25716710000000004 and parameters: {'alpha': 0.006715090640501162, 'colsample_bytree': 0.9410764921848082, 'subsample': 0.944186366326079, 'scale_pos_weight': 1.5400073677418535, 'gamma': 0.029122651549919325, 'eta': 0.2111889554462233}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:39:31,597]\u001b[0m Trial 219 finished with value: 0.2571911 and parameters: {'alpha': 0.006683132387465882, 'colsample_bytree': 0.9412127656498902, 'subsample': 0.9441760201585162, 'scale_pos_weight': 1.539871464740689, 'gamma': 0.0287443054458947, 'eta': 0.21122300391495097}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:39:57,746]\u001b[0m Trial 218 finished with value: 0.2571911 and parameters: {'alpha': 0.00661014282694712, 'colsample_bytree': 0.9415768813398987, 'subsample': 0.9441821251611258, 'scale_pos_weight': 1.5399715260748998, 'gamma': 0.02834088293879909, 'eta': 0.21119460195354378}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:40:01,489]\u001b[0m Trial 217 finished with value: 0.257151 and parameters: {'alpha': 0.0065247063845679425, 'colsample_bytree': 0.9403961349987378, 'subsample': 0.9441972153438344, 'scale_pos_weight': 1.539885953520639, 'gamma': 0.029646874835480914, 'eta': 0.21126430461734877}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:41:06,721]\u001b[0m Trial 220 finished with value: 0.2571911 and parameters: {'alpha': 0.006762469763495614, 'colsample_bytree': 0.9411136403091798, 'subsample': 0.9441802567489995, 'scale_pos_weight': 1.5399671789069, 'gamma': 0.029313737208931778, 'eta': 0.21127377834473934}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:41:19,715]\u001b[0m Trial 221 finished with value: 0.2571911 and parameters: {'alpha': 0.006774318922452027, 'colsample_bytree': 0.941144707988193, 'subsample': 0.9441707703955624, 'scale_pos_weight': 1.5396994510619433, 'gamma': 0.02848321862093026, 'eta': 0.21125050175898483}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:41:42,285]\u001b[0m Trial 222 finished with value: 0.2571911 and parameters: {'alpha': 0.00673379918817534, 'colsample_bytree': 0.9411153441785843, 'subsample': 0.944183937074191, 'scale_pos_weight': 1.5397425485144876, 'gamma': 0.028930442193709396, 'eta': 0.2112144940106103}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:41:44,518]\u001b[0m Trial 223 finished with value: 0.2571911 and parameters: {'alpha': 0.006736923045283333, 'colsample_bytree': 0.9414833878956992, 'subsample': 0.9441729368370833, 'scale_pos_weight': 1.5401227265309487, 'gamma': 0.028701207738561066, 'eta': 0.21129344705699254}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:41:50,318]\u001b[0m Trial 224 finished with value: 0.2571911 and parameters: {'alpha': 0.006880004105726992, 'colsample_bytree': 0.9417102883222874, 'subsample': 0.9441759241393259, 'scale_pos_weight': 1.5404513856940598, 'gamma': 0.028199668358786966, 'eta': 0.211316293354912}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:41:55,442]\u001b[0m Trial 225 finished with value: 0.2571911 and parameters: {'alpha': 0.00660284018545741, 'colsample_bytree': 0.941564428751354, 'subsample': 0.9441660278343739, 'scale_pos_weight': 1.540307316839254, 'gamma': 0.028580457965887523, 'eta': 0.21131377453300854}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:41:55,807]\u001b[0m Trial 226 finished with value: 0.257091 and parameters: {'alpha': 0.006518448137798235, 'colsample_bytree': 0.941322995382999, 'subsample': 0.9441550340966374, 'scale_pos_weight': 1.5402620297496734, 'gamma': 0.028623097764522893, 'eta': 0.21136214070604306}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:41:57,570]\u001b[0m Trial 227 finished with value: 0.25672459999999997 and parameters: {'alpha': 0.006743162351629159, 'colsample_bytree': 0.9415511285330697, 'subsample': 0.9440714458541068, 'scale_pos_weight': 1.540494276063179, 'gamma': 0.02842943655321202, 'eta': 0.2112850774028023}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:42:07,962]\u001b[0m Trial 228 finished with value: 0.2571237 and parameters: {'alpha': 0.006799193225767692, 'colsample_bytree': 0.9412063855739196, 'subsample': 0.9441496363330758, 'scale_pos_weight': 1.5405009133637697, 'gamma': 0.028451949426468958, 'eta': 0.21129758346265684}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:42:15,729]\u001b[0m Trial 229 finished with value: 0.25672459999999997 and parameters: {'alpha': 0.0067966161475819685, 'colsample_bytree': 0.9413922204180497, 'subsample': 0.9440778193874911, 'scale_pos_weight': 1.5397053842809658, 'gamma': 0.028501047492760313, 'eta': 0.21134437698016936}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:42:25,856]\u001b[0m Trial 230 finished with value: 0.25672459999999997 and parameters: {'alpha': 0.0067055335606416655, 'colsample_bytree': 0.9414561908207915, 'subsample': 0.944070985920474, 'scale_pos_weight': 1.5405805415860572, 'gamma': 0.02857188102403316, 'eta': 0.21132100056222117}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:42:27,615]\u001b[0m Trial 231 finished with value: 0.25672459999999997 and parameters: {'alpha': 0.006799692153546336, 'colsample_bytree': 0.9414442017286588, 'subsample': 0.9440613313478546, 'scale_pos_weight': 1.5403684964041149, 'gamma': 0.028492385056586227, 'eta': 0.21132528831703074}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:42:30,639]\u001b[0m Trial 232 finished with value: 0.25672740000000005 and parameters: {'alpha': 0.00676477826878973, 'colsample_bytree': 0.9417121860996865, 'subsample': 0.944032741337384, 'scale_pos_weight': 1.540509371285683, 'gamma': 0.029023476874657776, 'eta': 0.2113491977210432}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:42:32,687]\u001b[0m Trial 234 finished with value: 0.25673070000000003 and parameters: {'alpha': 0.006803454430970397, 'colsample_bytree': 0.9420829267191806, 'subsample': 0.944039002771086, 'scale_pos_weight': 1.54131191208876, 'gamma': 0.028990118360406908, 'eta': 0.21151826495122636}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:42:33,996]\u001b[0m Trial 233 finished with value: 0.25669410000000004 and parameters: {'alpha': 0.0067603398117646145, 'colsample_bytree': 0.9416826431192451, 'subsample': 0.9440959212373158, 'scale_pos_weight': 1.5405907772715042, 'gamma': 0.029219649683503872, 'eta': 0.2115652256084601}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:42:35,972]\u001b[0m Trial 235 finished with value: 0.25669410000000004 and parameters: {'alpha': 0.006593754485558881, 'colsample_bytree': 0.9422337496347816, 'subsample': 0.9441138392977748, 'scale_pos_weight': 1.5411025079263607, 'gamma': 0.029133864810553366, 'eta': 0.2115968587155931}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:42:36,940]\u001b[0m Trial 236 finished with value: 0.2566733 and parameters: {'alpha': 0.006615620806621881, 'colsample_bytree': 0.9422339543146661, 'subsample': 0.9440399809554904, 'scale_pos_weight': 1.5409782282520255, 'gamma': 0.029058251887028597, 'eta': 0.2115544400121897}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:42:43,052]\u001b[0m Trial 237 finished with value: 0.2567088 and parameters: {'alpha': 0.00660174129054028, 'colsample_bytree': 0.9426184087993245, 'subsample': 0.9440253360279196, 'scale_pos_weight': 1.5413689720410408, 'gamma': 0.029110577770283946, 'eta': 0.2114862964362308}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:42:51,292]\u001b[0m Trial 238 finished with value: 0.25711349999999994 and parameters: {'alpha': 0.006615726103788079, 'colsample_bytree': 0.942444183756586, 'subsample': 0.9441246572335931, 'scale_pos_weight': 1.5409829225208993, 'gamma': 0.02922025095332241, 'eta': 0.21163982676971213}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:42:53,310]\u001b[0m Trial 239 finished with value: 0.2571129 and parameters: {'alpha': 0.006898885677141209, 'colsample_bytree': 0.94226390889869, 'subsample': 0.9441236789892319, 'scale_pos_weight': 1.54129087309536, 'gamma': 0.029217203380282702, 'eta': 0.21157862434181687}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:42:56,430]\u001b[0m Trial 240 finished with value: 0.257091 and parameters: {'alpha': 0.006600749678420652, 'colsample_bytree': 0.9427838789273465, 'subsample': 0.9441254736484345, 'scale_pos_weight': 1.5413649063412802, 'gamma': 0.029167426896660357, 'eta': 0.2114810486185562}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:42:57,505]\u001b[0m Trial 241 finished with value: 0.257091 and parameters: {'alpha': 0.006628991026519314, 'colsample_bytree': 0.943041228497843, 'subsample': 0.9441553759338066, 'scale_pos_weight': 1.53965527343084, 'gamma': 0.029371328246356868, 'eta': 0.2116283474743856}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:42:59,671]\u001b[0m Trial 242 finished with value: 0.257091 and parameters: {'alpha': 0.0066141445301188245, 'colsample_bytree': 0.9408497080103855, 'subsample': 0.9441312967296562, 'scale_pos_weight': 1.5396267588486436, 'gamma': 0.029685105852504414, 'eta': 0.2115926511808577}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:43:01,044]\u001b[0m Trial 244 finished with value: 0.25712149999999995 and parameters: {'alpha': 0.006893921201086935, 'colsample_bytree': 0.9409303682251833, 'subsample': 0.9441405319119324, 'scale_pos_weight': 1.5397956344957968, 'gamma': 0.029931093371941112, 'eta': 0.21113863426588889}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:43:01,339]\u001b[0m Trial 243 finished with value: 0.2571237 and parameters: {'alpha': 0.006908401744522984, 'colsample_bytree': 0.9426622871257356, 'subsample': 0.944144616507472, 'scale_pos_weight': 1.5396105705308416, 'gamma': 0.02980921060502087, 'eta': 0.21116651044957002}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:43:07,780]\u001b[0m Trial 245 finished with value: 0.25712149999999995 and parameters: {'alpha': 0.006912337308072522, 'colsample_bytree': 0.9408393866032119, 'subsample': 0.9441500305505492, 'scale_pos_weight': 1.5396636855253294, 'gamma': 0.02960072749390825, 'eta': 0.2111477851343666}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:43:16,425]\u001b[0m Trial 246 finished with value: 0.2572217 and parameters: {'alpha': 0.006882179392003975, 'colsample_bytree': 0.9409320339665984, 'subsample': 0.9441655758291675, 'scale_pos_weight': 1.5395727131121344, 'gamma': 0.027450625873434196, 'eta': 0.21114958452594731}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:43:17,899]\u001b[0m Trial 247 finished with value: 0.2572217 and parameters: {'alpha': 0.006683870034297295, 'colsample_bytree': 0.9408660290374692, 'subsample': 0.9441780061408603, 'scale_pos_weight': 1.5397452893436387, 'gamma': 0.028085604742608454, 'eta': 0.21108679437067765}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:43:21,624]\u001b[0m Trial 248 finished with value: 0.2572217 and parameters: {'alpha': 0.006442776717788709, 'colsample_bytree': 0.940661786073528, 'subsample': 0.9441732468400297, 'scale_pos_weight': 1.5397028576512257, 'gamma': 0.029911553828847755, 'eta': 0.21111978213529328}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:43:22,148]\u001b[0m Trial 249 finished with value: 0.25718159999999995 and parameters: {'alpha': 0.006422532393564967, 'colsample_bytree': 0.9399791259767775, 'subsample': 0.944200529291739, 'scale_pos_weight': 1.5392698689547912, 'gamma': 0.02772638322621283, 'eta': 0.21111929119069123}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:43:26,200]\u001b[0m Trial 250 finished with value: 0.257151 and parameters: {'alpha': 0.006448869517956435, 'colsample_bytree': 0.939966291769624, 'subsample': 0.9442006007384287, 'scale_pos_weight': 1.5393235716046505, 'gamma': 0.028074087120559935, 'eta': 0.2111899001123254}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:43:26,453]\u001b[0m Trial 251 finished with value: 0.25717890000000004 and parameters: {'alpha': 0.006400753598777036, 'colsample_bytree': 0.9397056156032642, 'subsample': 0.9442077985222102, 'scale_pos_weight': 1.539337535621359, 'gamma': 0.027896655468950583, 'eta': 0.2111106436565746}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:43:27,662]\u001b[0m Trial 252 finished with value: 0.25717890000000004 and parameters: {'alpha': 0.006401421498831545, 'colsample_bytree': 0.9400793301906584, 'subsample': 0.944207923291505, 'scale_pos_weight': 1.5392568355045093, 'gamma': 0.02798245244986702, 'eta': 0.21112346762893747}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:43:40,338]\u001b[0m Trial 253 finished with value: 0.2571806 and parameters: {'alpha': 0.006483727885342858, 'colsample_bytree': 0.9399966112016808, 'subsample': 0.9442114781755321, 'scale_pos_weight': 1.5392344821452946, 'gamma': 0.027980479554901995, 'eta': 0.21076507398538616}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:43:45,608]\u001b[0m Trial 254 finished with value: 0.2571786 and parameters: {'alpha': 0.0065039166464735156, 'colsample_bytree': 0.9399154118929349, 'subsample': 0.9442179686587163, 'scale_pos_weight': 1.5401115477723977, 'gamma': 0.027486617414072538, 'eta': 0.21113003266824748}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:43:48,747]\u001b[0m Trial 255 finished with value: 0.2571806 and parameters: {'alpha': 0.006462153189880854, 'colsample_bytree': 0.940149298172004, 'subsample': 0.9442095774925637, 'scale_pos_weight': 1.5401350807254452, 'gamma': 0.027456698696949503, 'eta': 0.2108159854526692}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:43:49,604]\u001b[0m Trial 257 finished with value: 0.2571806 and parameters: {'alpha': 0.006477514773354453, 'colsample_bytree': 0.9407017387512354, 'subsample': 0.9442106899025698, 'scale_pos_weight': 1.5401303692399047, 'gamma': 0.02753452442262428, 'eta': 0.2108225694564076}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:43:52,271]\u001b[0m Trial 256 finished with value: 0.2571742 and parameters: {'alpha': 0.006482884646913113, 'colsample_bytree': 0.9405314972700245, 'subsample': 0.9442197733373612, 'scale_pos_weight': 1.5401000744720952, 'gamma': 0.028124832031556385, 'eta': 0.21084558551556826}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:43:54,318]\u001b[0m Trial 259 finished with value: 0.2571742 and parameters: {'alpha': 0.0066941689844490235, 'colsample_bytree': 0.9407459927639139, 'subsample': 0.9442268608151513, 'scale_pos_weight': 1.5401019121799708, 'gamma': 0.028284169964928517, 'eta': 0.2108274675998525}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:43:57,510]\u001b[0m Trial 260 finished with value: 0.2567405 and parameters: {'alpha': 0.0066937394161027865, 'colsample_bytree': 0.9408258238959426, 'subsample': 0.9439521412807956, 'scale_pos_weight': 1.5400329005791895, 'gamma': 0.027600006608776734, 'eta': 0.21080265205785723}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:43:57,885]\u001b[0m Trial 258 finished with value: 0.2571742 and parameters: {'alpha': 0.006680639762541448, 'colsample_bytree': 0.9408535189682359, 'subsample': 0.9442175437094708, 'scale_pos_weight': 1.5400712254548325, 'gamma': 0.027933124659471408, 'eta': 0.210829266917227}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:44:03,146]\u001b[0m Trial 268 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:44:07,802]\u001b[0m Trial 261 finished with value: 0.25671960000000005 and parameters: {'alpha': 0.0061543492359060585, 'colsample_bytree': 0.9406876599641585, 'subsample': 0.9441026243013562, 'scale_pos_weight': 1.5399650348611165, 'gamma': 0.027464420033807547, 'eta': 0.21085292410152967}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:44:13,890]\u001b[0m Trial 262 finished with value: 0.2532991 and parameters: {'alpha': 0.006826914651817819, 'colsample_bytree': 0.9408175414263144, 'subsample': 0.9430412134487897, 'scale_pos_weight': 1.5401003118744996, 'gamma': 0.028771852703179033, 'eta': 0.21081608420101725}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:44:18,245]\u001b[0m Trial 263 finished with value: 0.2567007 and parameters: {'alpha': 0.006843966937331373, 'colsample_bytree': 0.9407460113035312, 'subsample': 0.943981097925685, 'scale_pos_weight': 1.5398112532794814, 'gamma': 0.02866819718685121, 'eta': 0.21136206368880442}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:44:19,270]\u001b[0m Trial 264 finished with value: 0.2531245 and parameters: {'alpha': 0.00669299342774783, 'colsample_bytree': 0.9408103470377334, 'subsample': 0.9431554172477618, 'scale_pos_weight': 1.5400104888972919, 'gamma': 0.028721319290986896, 'eta': 0.2113709778978869}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:44:22,758]\u001b[0m Trial 265 finished with value: 0.25669410000000004 and parameters: {'alpha': 0.006214907419739542, 'colsample_bytree': 0.9410845055250054, 'subsample': 0.9440997545396879, 'scale_pos_weight': 1.5397579019816658, 'gamma': 0.028597722907299214, 'eta': 0.2113845972166928}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:44:24,123]\u001b[0m Trial 266 finished with value: 0.25669410000000004 and parameters: {'alpha': 0.006749954754825008, 'colsample_bytree': 0.9409494115018604, 'subsample': 0.9441039869908451, 'scale_pos_weight': 1.5396779131253988, 'gamma': 0.0287929152878909, 'eta': 0.2113958814327769}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:44:26,772]\u001b[0m Trial 267 finished with value: 0.25669410000000004 and parameters: {'alpha': 0.006853870422735109, 'colsample_bytree': 0.9393125603107179, 'subsample': 0.9440900900309057, 'scale_pos_weight': 1.5395223473174968, 'gamma': 0.028798133131401657, 'eta': 0.21137241651083374}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:44:28,595]\u001b[0m Trial 274 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:44:33,068]\u001b[0m Trial 269 finished with value: 0.2568919 and parameters: {'alpha': 0.00687151185205498, 'colsample_bytree': 0.9417678709614842, 'subsample': 0.9443079625726303, 'scale_pos_weight': 1.5398721755813272, 'gamma': 0.02881735141533259, 'eta': 0.2113699452954162}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:44:35,928]\u001b[0m Trial 270 finished with value: 0.2568919 and parameters: {'alpha': 0.006837701237606492, 'colsample_bytree': 0.9439501705966682, 'subsample': 0.9443127402353749, 'scale_pos_weight': 1.5396279718286123, 'gamma': 0.028877167236967323, 'eta': 0.21135020508748667}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:44:39,736]\u001b[0m Trial 271 finished with value: 0.2568919 and parameters: {'alpha': 0.006864803695235252, 'colsample_bytree': 0.9436637963690797, 'subsample': 0.9443064999336206, 'scale_pos_weight': 1.5396918038883374, 'gamma': 0.02641628783132807, 'eta': 0.21137853864522116}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:44:40,115]\u001b[0m Trial 272 finished with value: 0.2569225 and parameters: {'alpha': 0.007792361089477349, 'colsample_bytree': 0.9393440637396585, 'subsample': 0.9443097238316637, 'scale_pos_weight': 1.5395340451846948, 'gamma': 0.026348776735623632, 'eta': 0.2110215870853989}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:44:44,247]\u001b[0m Trial 273 finished with value: 0.2556653 and parameters: {'alpha': 0.007807239104333079, 'colsample_bytree': 0.9417351264074563, 'subsample': 0.9443049487974342, 'scale_pos_weight': 1.540711628662482, 'gamma': 0.02644912095026132, 'eta': 0.21181626343264617}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:44:47,540]\u001b[0m Trial 275 finished with value: 0.257187 and parameters: {'alpha': 0.0077431399550505035, 'colsample_bytree': 0.9417181660117897, 'subsample': 0.9442865553251085, 'scale_pos_weight': 1.5406238986181817, 'gamma': 0.026433091559096424, 'eta': 0.21114789981084098}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:44:48,918]\u001b[0m Trial 276 finished with value: 0.2558753 and parameters: {'alpha': 0.007778483736033926, 'colsample_bytree': 0.943749342759868, 'subsample': 0.9443106451254362, 'scale_pos_weight': 1.5407791825550927, 'gamma': 0.026540464263679463, 'eta': 0.21182947717100534}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:44:49,448]\u001b[0m Trial 277 finished with value: 0.2569225 and parameters: {'alpha': 0.00766485699673497, 'colsample_bytree': 0.9394002098881952, 'subsample': 0.9443150465855905, 'scale_pos_weight': 1.5404894768032553, 'gamma': 0.028167713539502925, 'eta': 0.21104311325704814}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:44:54,992]\u001b[0m Trial 278 finished with value: 0.2569225 and parameters: {'alpha': 0.00781847374032242, 'colsample_bytree': 0.9415654642504745, 'subsample': 0.9443078544319373, 'scale_pos_weight': 1.540556391343747, 'gamma': 0.02999597387628421, 'eta': 0.2110299161433806}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:44:57,724]\u001b[0m Trial 279 finished with value: 0.2572217 and parameters: {'alpha': 0.007724025822866058, 'colsample_bytree': 0.941710655802752, 'subsample': 0.9441621760837908, 'scale_pos_weight': 1.5407709311656435, 'gamma': 0.026386289074383628, 'eta': 0.21102161187762772}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:44:58,364]\u001b[0m Trial 281 finished with value: 0.2572217 and parameters: {'alpha': 0.007698428403888268, 'colsample_bytree': 0.939370519984805, 'subsample': 0.9441652947194663, 'scale_pos_weight': 1.5406336474645295, 'gamma': 0.02822381060598781, 'eta': 0.2110519025292412}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:45:03,784]\u001b[0m Trial 280 finished with value: 0.2572217 and parameters: {'alpha': 0.007735942914726618, 'colsample_bytree': 0.9414124043640071, 'subsample': 0.9441644919280325, 'scale_pos_weight': 1.540730331802296, 'gamma': 0.029972379727848344, 'eta': 0.21103168478508824}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:45:11,565]\u001b[0m Trial 282 finished with value: 0.2571844 and parameters: {'alpha': 0.007701367007770667, 'colsample_bytree': 0.9413185538340119, 'subsample': 0.9441569424489088, 'scale_pos_weight': 1.5386433717947314, 'gamma': 0.029930830946604668, 'eta': 0.21107893693534005}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:45:14,214]\u001b[0m Trial 283 finished with value: 0.25718159999999995 and parameters: {'alpha': 0.007690029977676086, 'colsample_bytree': 0.9418119202349737, 'subsample': 0.9441578396190339, 'scale_pos_weight': 1.5407497105038734, 'gamma': 0.029859327742955136, 'eta': 0.21103120225873634}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:45:18,528]\u001b[0m Trial 284 finished with value: 0.2572217 and parameters: {'alpha': 0.0076585349445590775, 'colsample_bytree': 0.9416736856155757, 'subsample': 0.944167004956982, 'scale_pos_weight': 1.5405087383856018, 'gamma': 0.029959963351190406, 'eta': 0.2110538824680202}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:45:19,210]\u001b[0m Trial 285 finished with value: 0.25712149999999995 and parameters: {'alpha': 0.007895307188614102, 'colsample_bytree': 0.9420257986321999, 'subsample': 0.9441402010789256, 'scale_pos_weight': 1.5386554974515796, 'gamma': 0.027274287066384417, 'eta': 0.21103564905573047}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:45:24,508]\u001b[0m Trial 292 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:45:27,673]\u001b[0m Trial 286 finished with value: 0.25712149999999995 and parameters: {'alpha': 0.007683538267083718, 'colsample_bytree': 0.9417431829247179, 'subsample': 0.9441477942509436, 'scale_pos_weight': 1.5385839805609682, 'gamma': 0.0293756159124548, 'eta': 0.2110145289106145}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:45:30,552]\u001b[0m Trial 287 finished with value: 0.2551721 and parameters: {'alpha': 0.007677441528308381, 'colsample_bytree': 0.9420436445997282, 'subsample': 0.9441490475814519, 'scale_pos_weight': 1.5416886484629246, 'gamma': 0.027316036988389216, 'eta': 0.21053400496789879}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:45:31,242]\u001b[0m Trial 288 finished with value: 0.25717890000000004 and parameters: {'alpha': 0.007675824189671825, 'colsample_bytree': 0.9420492540911305, 'subsample': 0.9442559076149062, 'scale_pos_weight': 1.5408996712221295, 'gamma': 0.029523776549873867, 'eta': 0.21099873506117509}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:45:35,603]\u001b[0m Trial 289 finished with value: 0.25715930000000004 and parameters: {'alpha': 0.007720798525779953, 'colsample_bytree': 0.9421326974567944, 'subsample': 0.9441546030045953, 'scale_pos_weight': 1.5408308257615275, 'gamma': 0.02966177509094367, 'eta': 0.21050990403297704}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:45:42,537]\u001b[0m Trial 290 finished with value: 0.2547511 and parameters: {'alpha': 0.007689672560502907, 'colsample_bytree': 0.9418448834190069, 'subsample': 0.9440364639649956, 'scale_pos_weight': 1.5419062681733313, 'gamma': 0.02948606743924183, 'eta': 0.2104727938961832}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:45:44,912]\u001b[0m Trial 291 finished with value: 0.2547931 and parameters: {'alpha': 0.007623692275535668, 'colsample_bytree': 0.94232440426788, 'subsample': 0.9440282782477234, 'scale_pos_weight': 1.542004135557865, 'gamma': 0.02937427268804766, 'eta': 0.21049059650372212}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:45:47,021]\u001b[0m Trial 293 finished with value: 0.25470859999999995 and parameters: {'alpha': 0.007665054209043452, 'colsample_bytree': 0.9426989821751552, 'subsample': 0.9440497436430328, 'scale_pos_weight': 1.5420743605497584, 'gamma': 0.029440671086853814, 'eta': 0.21169411263537405}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:45:50,627]\u001b[0m Trial 294 finished with value: 0.2547462 and parameters: {'alpha': 0.0065647368968096, 'colsample_bytree': 0.9426553484920124, 'subsample': 0.9440572409612245, 'scale_pos_weight': 1.542088309397299, 'gamma': 0.029344572883904952, 'eta': 0.21051155923033693}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:45:57,061]\u001b[0m Trial 295 finished with value: 0.25475180000000003 and parameters: {'alpha': 0.006559690909251902, 'colsample_bytree': 0.9424011844496899, 'subsample': 0.9440413091136297, 'scale_pos_weight': 1.542050384850715, 'gamma': 0.029424365249868873, 'eta': 0.21050014552877083}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:46:00,424]\u001b[0m Trial 297 finished with value: 0.25667389999999995 and parameters: {'alpha': 0.00654464458656988, 'colsample_bytree': 0.942909736238688, 'subsample': 0.9440443352976404, 'scale_pos_weight': 1.5404397898305144, 'gamma': 0.029477327953983643, 'eta': 0.2116539872233884}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:46:01,048]\u001b[0m Trial 296 finished with value: 0.25669580000000003 and parameters: {'alpha': 0.006602931671022326, 'colsample_bytree': 0.9426587588104137, 'subsample': 0.9440980735320826, 'scale_pos_weight': 1.5420072536139982, 'gamma': 0.029520750053185787, 'eta': 0.21164178950806856}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:46:06,279]\u001b[0m Trial 298 finished with value: 0.256714 and parameters: {'alpha': 0.00665330112770141, 'colsample_bytree': 0.9430731889090088, 'subsample': 0.9440446827537193, 'scale_pos_weight': 1.5403286646989278, 'gamma': 0.029149380694864176, 'eta': 0.2116961828986039}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:46:09,511]\u001b[0m Trial 304 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:46:14,303]\u001b[0m Trial 299 finished with value: 0.25669410000000004 and parameters: {'alpha': 0.006536544268541659, 'colsample_bytree': 0.9425670276086981, 'subsample': 0.9440858441629495, 'scale_pos_weight': 1.5403921903435747, 'gamma': 0.028171219017952383, 'eta': 0.21155202416727778}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:46:16,136]\u001b[0m Trial 300 finished with value: 0.25667389999999995 and parameters: {'alpha': 0.006617230261255228, 'colsample_bytree': 0.9428098236737225, 'subsample': 0.9440596121745786, 'scale_pos_weight': 1.5404314486301747, 'gamma': 0.02820864588716397, 'eta': 0.2116660867767039}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:46:19,454]\u001b[0m Trial 301 finished with value: 0.25672680000000003 and parameters: {'alpha': 0.006633044095631534, 'colsample_bytree': 0.9413980864298157, 'subsample': 0.9440942390129244, 'scale_pos_weight': 1.54028384681747, 'gamma': 0.028198837293856794, 'eta': 0.21123048587886858}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:46:25,021]\u001b[0m Trial 302 finished with value: 0.2571483 and parameters: {'alpha': 0.006654516395732438, 'colsample_bytree': 0.9412928463742054, 'subsample': 0.9442425969586133, 'scale_pos_weight': 1.5403551424551165, 'gamma': 0.028265548035263523, 'eta': 0.21123241315309924}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:46:30,807]\u001b[0m Trial 303 finished with value: 0.2571483 and parameters: {'alpha': 0.006634392862012253, 'colsample_bytree': 0.9413535230617465, 'subsample': 0.9442418768423941, 'scale_pos_weight': 1.5404022203524927, 'gamma': 0.028204997407225835, 'eta': 0.21155184857629067}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:46:33,080]\u001b[0m Trial 305 finished with value: 0.2490541 and parameters: {'alpha': 0.0067064527885017464, 'colsample_bytree': 0.9411614298886419, 'subsample': 0.9442465886685081, 'scale_pos_weight': 1.5471546808376202, 'gamma': 0.028277331425229205, 'eta': 0.2112737142274454}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:46:34,220]\u001b[0m Trial 306 finished with value: 0.25522969999999995 and parameters: {'alpha': 0.006721690863954764, 'colsample_bytree': 0.9412568270841227, 'subsample': 0.9442275373106299, 'scale_pos_weight': 1.540351489948944, 'gamma': 0.028174923157879655, 'eta': 0.21126448582470056}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:46:36,527]\u001b[0m Trial 307 finished with value: 0.2552482 and parameters: {'alpha': 0.006755594481623722, 'colsample_bytree': 0.9544143194021838, 'subsample': 0.9442441735805182, 'scale_pos_weight': 1.5403594510312713, 'gamma': 0.028200181770621745, 'eta': 0.21233568982225362}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:46:39,549]\u001b[0m Trial 308 finished with value: 0.25522969999999995 and parameters: {'alpha': 0.006754104555666492, 'colsample_bytree': 0.941342103209767, 'subsample': 0.9442351900672351, 'scale_pos_weight': 1.5414599510191471, 'gamma': 0.02998454754070056, 'eta': 0.211254909087075}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:46:40,229]\u001b[0m Trial 315 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:46:40,565]\u001b[0m Trial 309 finished with value: 0.25526249999999995 and parameters: {'alpha': 0.006750942547760347, 'colsample_bytree': 0.9413560374468365, 'subsample': 0.9442346004990778, 'scale_pos_weight': 1.5413578447644836, 'gamma': 0.028122934257140405, 'eta': 0.2112336551759653}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:46:42,931]\u001b[0m Trial 310 finished with value: 0.25526249999999995 and parameters: {'alpha': 0.007863090227846885, 'colsample_bytree': 0.9402200394088065, 'subsample': 0.9442284208815431, 'scale_pos_weight': 1.5412327301652688, 'gamma': 0.027929659413942518, 'eta': 0.2112334341774436}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:46:47,008]\u001b[0m Trial 311 finished with value: 0.2572217 and parameters: {'alpha': 0.007866017988746282, 'colsample_bytree': 0.9460186152914338, 'subsample': 0.9441750475876739, 'scale_pos_weight': 1.5413600661646663, 'gamma': 0.027676003820711035, 'eta': 0.21072986521404433}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:46:52,300]\u001b[0m Trial 312 finished with value: 0.25721950000000005 and parameters: {'alpha': 0.0067641000678347295, 'colsample_bytree': 0.9404046103311063, 'subsample': 0.9441793244663099, 'scale_pos_weight': 1.5414917261050964, 'gamma': 0.027800814937919777, 'eta': 0.21072591004536295}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:46:53,967]\u001b[0m Trial 313 finished with value: 0.2550935 and parameters: {'alpha': 0.007855568901628104, 'colsample_bytree': 0.9404099584461443, 'subsample': 0.9443716528260214, 'scale_pos_weight': 1.5410238423331388, 'gamma': 0.028961127070849753, 'eta': 0.2107403827382347}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:46:55,521]\u001b[0m Trial 314 finished with value: 0.2550935 and parameters: {'alpha': 0.007888783953186238, 'colsample_bytree': 0.9404070785834739, 'subsample': 0.9443737527702698, 'scale_pos_weight': 1.5412178435058699, 'gamma': 0.027697213404476298, 'eta': 0.21079089474452245}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:47:01,633]\u001b[0m Trial 316 finished with value: 0.2550913 and parameters: {'alpha': 0.007859023646394464, 'colsample_bytree': 0.9404567578951858, 'subsample': 0.9443789259270202, 'scale_pos_weight': 1.5408879071194272, 'gamma': 0.027726035535003486, 'eta': 0.21071194134243149}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:47:02,324]\u001b[0m Trial 317 finished with value: 0.2572217 and parameters: {'alpha': 0.007525532632076615, 'colsample_bytree': 0.9404280810618996, 'subsample': 0.944181027060091, 'scale_pos_weight': 1.5409871099568246, 'gamma': 0.02762821142205821, 'eta': 0.21077518016973198}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:47:02,750]\u001b[0m Trial 318 finished with value: 0.25721950000000005 and parameters: {'alpha': 0.00755242187379748, 'colsample_bytree': 0.940316157033483, 'subsample': 0.9441713769230459, 'scale_pos_weight': 1.5399073215882737, 'gamma': 0.02764000658677876, 'eta': 0.21072378054112492}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:47:05,286]\u001b[0m Trial 319 finished with value: 0.2571794 and parameters: {'alpha': 0.007514940840635229, 'colsample_bytree': 0.9404407321004413, 'subsample': 0.9441574669369988, 'scale_pos_weight': 1.5409325899061235, 'gamma': 0.027525568620848834, 'eta': 0.2107228652545446}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:47:08,920]\u001b[0m Trial 320 finished with value: 0.2572217 and parameters: {'alpha': 0.007828645923882122, 'colsample_bytree': 0.9467561224657001, 'subsample': 0.9441621882447624, 'scale_pos_weight': 1.5410438793213423, 'gamma': 0.027387006390672233, 'eta': 0.2107859241820559}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:47:13,368]\u001b[0m Trial 321 finished with value: 0.2508721 and parameters: {'alpha': 0.006321705880839772, 'colsample_bytree': 0.9402141709135876, 'subsample': 0.944837333919363, 'scale_pos_weight': 1.540980167685914, 'gamma': 0.027592122497948367, 'eta': 0.21067556980056648}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:47:14,919]\u001b[0m Trial 322 finished with value: 0.25721950000000005 and parameters: {'alpha': 0.006353809727385175, 'colsample_bytree': 0.9456816746805475, 'subsample': 0.9441692823536251, 'scale_pos_weight': 1.5408673474654464, 'gamma': 0.02755218048079458, 'eta': 0.2107159895804203}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:47:16,352]\u001b[0m Trial 323 finished with value: 0.25721950000000005 and parameters: {'alpha': 0.006345948171253658, 'colsample_bytree': 0.9472458834513457, 'subsample': 0.944159009006782, 'scale_pos_weight': 1.5408922180227898, 'gamma': 0.027321206576421654, 'eta': 0.21070258953760235}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:47:23,579]\u001b[0m Trial 324 finished with value: 0.2572217 and parameters: {'alpha': 0.006963064168022867, 'colsample_bytree': 0.9395271749028521, 'subsample': 0.9441644048163115, 'scale_pos_weight': 1.5398548045099292, 'gamma': 0.027331996983828752, 'eta': 0.21093884085913678}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:47:23,958]\u001b[0m Trial 326 finished with value: 0.2567405 and parameters: {'alpha': 0.006960162966413956, 'colsample_bytree': 0.9457745524741875, 'subsample': 0.9439609787838287, 'scale_pos_weight': 1.5408746904796897, 'gamma': 0.027453830151863017, 'eta': 0.21065284880118376}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:47:24,455]\u001b[0m Trial 325 finished with value: 0.2552301 and parameters: {'alpha': 0.006936048211262013, 'colsample_bytree': 0.9449655167640862, 'subsample': 0.9441657159918114, 'scale_pos_weight': 1.5442517412036183, 'gamma': 0.02729709664956599, 'eta': 0.21093593806053493}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:47:27,171]\u001b[0m Trial 327 finished with value: 0.25718159999999995 and parameters: {'alpha': 0.006362946402277978, 'colsample_bytree': 0.9393612219344947, 'subsample': 0.9441622125398791, 'scale_pos_weight': 1.5398650608443816, 'gamma': 0.027377295421443675, 'eta': 0.21027397252593102}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:47:30,709]\u001b[0m Trial 328 finished with value: 0.25715930000000004 and parameters: {'alpha': 0.006336972568052757, 'colsample_bytree': 0.9461355226201675, 'subsample': 0.9441540974017225, 'scale_pos_weight': 1.5415106433066705, 'gamma': 0.027336411799428327, 'eta': 0.2103101026005075}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:47:34,008]\u001b[0m Trial 329 finished with value: 0.25519440000000004 and parameters: {'alpha': 0.006930101425118931, 'colsample_bytree': 0.940947860809054, 'subsample': 0.9441626518806775, 'scale_pos_weight': 1.5428679639845009, 'gamma': 0.027263121561703324, 'eta': 0.21088670459487968}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:47:42,571]\u001b[0m Trial 330 finished with value: 0.25715420000000005 and parameters: {'alpha': 0.00636577701007989, 'colsample_bytree': 0.9458281399417163, 'subsample': 0.9441449689874577, 'scale_pos_weight': 1.5424421433218258, 'gamma': 0.02718951180727542, 'eta': 0.21037546085046316}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:47:44,755]\u001b[0m Trial 331 finished with value: 0.2551714 and parameters: {'alpha': 0.00612255343133111, 'colsample_bytree': 0.9469883577897783, 'subsample': 0.9441271933427631, 'scale_pos_weight': 1.5425758204024365, 'gamma': 0.0272015104157097, 'eta': 0.2104055441422164}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:47:50,795]\u001b[0m Trial 332 finished with value: 0.25674850000000005 and parameters: {'alpha': 0.006205286780129795, 'colsample_bytree': 0.9467814457843597, 'subsample': 0.9439836400759832, 'scale_pos_weight': 1.541542520312799, 'gamma': 0.027288620332350664, 'eta': 0.21020519522728828}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:47:53,658]\u001b[0m Trial 334 finished with value: 0.257147 and parameters: {'alpha': 0.006045217538207302, 'colsample_bytree': 0.9465089360719436, 'subsample': 0.9441258772297945, 'scale_pos_weight': 1.5415592399577032, 'gamma': 0.027195453200536877, 'eta': 0.2106018163556779}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:47:54,331]\u001b[0m Trial 333 finished with value: 0.2567276 and parameters: {'alpha': 0.006328065420299109, 'colsample_bytree': 0.9470569533108922, 'subsample': 0.944119960806216, 'scale_pos_weight': 1.5416032972492584, 'gamma': 0.027235727787494796, 'eta': 0.21039968673339263}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:47:55,579]\u001b[0m Trial 335 finished with value: 0.2567283 and parameters: {'alpha': 0.006336128072210632, 'colsample_bytree': 0.9474462821891815, 'subsample': 0.9441075486281194, 'scale_pos_weight': 1.5416228317062446, 'gamma': 0.027150293658394543, 'eta': 0.2103057656753898}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:48:00,624]\u001b[0m Trial 336 finished with value: 0.2567283 and parameters: {'alpha': 0.006161640805072339, 'colsample_bytree': 0.9485319817132603, 'subsample': 0.944112604064852, 'scale_pos_weight': 1.5424961777492117, 'gamma': 0.027081952068218167, 'eta': 0.2103304641425127}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:48:05,713]\u001b[0m Trial 337 finished with value: 0.25671960000000005 and parameters: {'alpha': 0.006115019040866761, 'colsample_bytree': 0.947214273930322, 'subsample': 0.9441019074739495, 'scale_pos_weight': 1.5415249595761935, 'gamma': 0.02779218200303551, 'eta': 0.2106711102742661}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:48:09,246]\u001b[0m Trial 338 finished with value: 0.2567218 and parameters: {'alpha': 0.006058383092733453, 'colsample_bytree': 0.9397848878861123, 'subsample': 0.9440864561467393, 'scale_pos_weight': 1.5415512003582748, 'gamma': 0.027738594600201106, 'eta': 0.2106568139816781}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:48:09,796]\u001b[0m Trial 339 finished with value: 0.2567672 and parameters: {'alpha': 0.006049256762725532, 'colsample_bytree': 0.947149565915273, 'subsample': 0.9439914595374733, 'scale_pos_weight': 1.5415887512553947, 'gamma': 0.02777089527926771, 'eta': 0.2107485550211112}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:48:14,607]\u001b[0m Trial 340 finished with value: 0.25671960000000005 and parameters: {'alpha': 0.0068377661770214725, 'colsample_bytree': 0.9476770601605786, 'subsample': 0.9441074939083002, 'scale_pos_weight': 1.54072221615755, 'gamma': 0.02788652744163095, 'eta': 0.21067332386033674}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:48:17,250]\u001b[0m Trial 341 finished with value: 0.25671960000000005 and parameters: {'alpha': 0.0064292532585599315, 'colsample_bytree': 0.9485876475704443, 'subsample': 0.944089775171572, 'scale_pos_weight': 1.539950952749247, 'gamma': 0.027777854614512237, 'eta': 0.21081381930949103}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:48:17,732]\u001b[0m Trial 342 finished with value: 0.25671960000000005 and parameters: {'alpha': 0.006860964064539553, 'colsample_bytree': 0.9483845774524646, 'subsample': 0.9440809897548531, 'scale_pos_weight': 1.540769987393429, 'gamma': 0.027837990969761136, 'eta': 0.2107946467121563}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:48:18,713]\u001b[0m Trial 343 finished with value: 0.25671960000000005 and parameters: {'alpha': 0.006472578167700068, 'colsample_bytree': 0.9487630177051379, 'subsample': 0.9440830945798814, 'scale_pos_weight': 1.540723223397911, 'gamma': 0.02788795639422333, 'eta': 0.2107973429262528}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:48:29,475]\u001b[0m Trial 344 finished with value: 0.2567405 and parameters: {'alpha': 0.00681112186832921, 'colsample_bytree': 0.9484809519391949, 'subsample': 0.9439837779630612, 'scale_pos_weight': 1.5407482994105777, 'gamma': 0.027905160749772985, 'eta': 0.2108056422735722}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:48:42,459]\u001b[0m Trial 345 finished with value: 0.2567405 and parameters: {'alpha': 0.0068218571104764906, 'colsample_bytree': 0.9481684321289303, 'subsample': 0.9439346732740177, 'scale_pos_weight': 1.5407198216348108, 'gamma': 0.027805683043441862, 'eta': 0.21086234796710338}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:48:50,648]\u001b[0m Trial 347 finished with value: 0.2572217 and parameters: {'alpha': 0.006859383207037545, 'colsample_bytree': 0.944484675227464, 'subsample': 0.9441837133346551, 'scale_pos_weight': 1.5407897891352111, 'gamma': 0.02787986957363947, 'eta': 0.21089079701997276}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:48:52,158]\u001b[0m Trial 346 finished with value: 0.2572217 and parameters: {'alpha': 0.006858213880383808, 'colsample_bytree': 0.9452687110081327, 'subsample': 0.944178425891511, 'scale_pos_weight': 1.540841541230825, 'gamma': 0.027823658715002947, 'eta': 0.21086290783263398}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:49:03,273]\u001b[0m Trial 348 finished with value: 0.2567405 and parameters: {'alpha': 0.006524792628162556, 'colsample_bytree': 0.9463548712029249, 'subsample': 0.9439018538409637, 'scale_pos_weight': 1.5400027823138838, 'gamma': 0.02888852470848853, 'eta': 0.21087907377960005}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:49:05,282]\u001b[0m Trial 349 finished with value: 0.25674270000000005 and parameters: {'alpha': 0.007086306044045569, 'colsample_bytree': 0.9483647514440966, 'subsample': 0.9439071691543046, 'scale_pos_weight': 1.5407038271804556, 'gamma': 0.028794921049946895, 'eta': 0.21094073801039395}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:49:05,691]\u001b[0m Trial 350 finished with value: 0.25718159999999995 and parameters: {'alpha': 0.00745733289773379, 'colsample_bytree': 0.9491579429795378, 'subsample': 0.9441858265130227, 'scale_pos_weight': 1.541047798732269, 'gamma': 0.02854807943697492, 'eta': 0.2109122863716097}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:49:06,592]\u001b[0m Trial 351 finished with value: 0.2572217 and parameters: {'alpha': 0.007497137050123547, 'colsample_bytree': 0.94480154777867, 'subsample': 0.9441815319567416, 'scale_pos_weight': 1.5410472674795024, 'gamma': 0.028740391319127194, 'eta': 0.21097740898898548}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:49:11,104]\u001b[0m Trial 352 finished with value: 0.25718159999999995 and parameters: {'alpha': 0.007485953118225405, 'colsample_bytree': 0.9448528251903618, 'subsample': 0.9441908173814023, 'scale_pos_weight': 1.5401863474319746, 'gamma': 0.028538634690189777, 'eta': 0.21095536609225748}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:49:15,895]\u001b[0m Trial 353 finished with value: 0.25718159999999995 and parameters: {'alpha': 0.007543980675802965, 'colsample_bytree': 0.9462769072349508, 'subsample': 0.9441942947984261, 'scale_pos_weight': 1.5402467066405394, 'gamma': 0.028568628142424585, 'eta': 0.21098517252997454}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:49:19,229]\u001b[0m Trial 355 finished with value: 0.25718159999999995 and parameters: {'alpha': 0.007045260686584481, 'colsample_bytree': 0.9449179040887055, 'subsample': 0.9441953693777142, 'scale_pos_weight': 1.5411922028818026, 'gamma': 0.026765881845812675, 'eta': 0.21097332550964515}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:49:20,507]\u001b[0m Trial 354 finished with value: 0.2572217 and parameters: {'alpha': 0.007024221934566094, 'colsample_bytree': 0.9464417871484135, 'subsample': 0.9441807733821153, 'scale_pos_weight': 1.5411691963305862, 'gamma': 0.02678493392132992, 'eta': 0.2109583700814671}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:49:25,576]\u001b[0m Trial 356 finished with value: 0.25718159999999995 and parameters: {'alpha': 0.0070604637287306525, 'colsample_bytree': 0.9451869722252045, 'subsample': 0.9442005674517171, 'scale_pos_weight': 1.5411180140216652, 'gamma': 0.02677480031147627, 'eta': 0.21100505930055194}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:49:27,896]\u001b[0m Trial 358 finished with value: 0.25718159999999995 and parameters: {'alpha': 0.006998703110063497, 'colsample_bytree': 0.9449377804747062, 'subsample': 0.9442008533844167, 'scale_pos_weight': 1.5412099297091948, 'gamma': 0.028235165140926874, 'eta': 0.2105572169641442}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:49:28,244]\u001b[0m Trial 357 finished with value: 0.25718159999999995 and parameters: {'alpha': 0.006984278377838938, 'colsample_bytree': 0.9444263933577802, 'subsample': 0.9441936130578197, 'scale_pos_weight': 1.541043912180281, 'gamma': 0.0285663451993154, 'eta': 0.21101733185953073}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:49:29,540]\u001b[0m Trial 359 finished with value: 0.25720350000000003 and parameters: {'alpha': 0.008045772369534658, 'colsample_bytree': 0.9441760611744606, 'subsample': 0.9441934803874028, 'scale_pos_weight': 1.541111598289166, 'gamma': 0.026809816021562766, 'eta': 0.21099624339735906}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:49:32,377]\u001b[0m Trial 360 finished with value: 0.2571821 and parameters: {'alpha': 0.008108978849002666, 'colsample_bytree': 0.9443676395806962, 'subsample': 0.9442062128759997, 'scale_pos_weight': 1.5404588433447444, 'gamma': 0.02673320672478215, 'eta': 0.21059546831438955}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:49:42,051]\u001b[0m Trial 361 finished with value: 0.2567324 and parameters: {'alpha': 0.007024619471698204, 'colsample_bytree': 0.9451949098267232, 'subsample': 0.9440342741869353, 'scale_pos_weight': 1.5411593996595228, 'gamma': 0.026871138905233224, 'eta': 0.21053112893242718}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:49:45,311]\u001b[0m Trial 362 finished with value: 0.2567687 and parameters: {'alpha': 0.006939257357029973, 'colsample_bytree': 0.9452894788486097, 'subsample': 0.9440310642451585, 'scale_pos_weight': 1.541156879363863, 'gamma': 0.029981881819994914, 'eta': 0.2106060383128591}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:49:46,591]\u001b[0m Trial 363 finished with value: 0.2567218 and parameters: {'alpha': 0.0069564389544856855, 'colsample_bytree': 0.9453915345571954, 'subsample': 0.9440621933200818, 'scale_pos_weight': 1.5411822325848537, 'gamma': 0.029130287081983, 'eta': 0.2105589593175356}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:49:51,475]\u001b[0m Trial 364 finished with value: 0.2567687 and parameters: {'alpha': 0.00803662722056305, 'colsample_bytree': 0.9442843932273571, 'subsample': 0.9440257026069352, 'scale_pos_weight': 1.5410030026359671, 'gamma': 0.026990537891411225, 'eta': 0.21065230678011368}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:49:52,117]\u001b[0m Trial 365 finished with value: 0.25673830000000003 and parameters: {'alpha': 0.00803246442737647, 'colsample_bytree': 0.9457072311607491, 'subsample': 0.9440380813171582, 'scale_pos_weight': 1.541123502455342, 'gamma': 0.029867918181110682, 'eta': 0.21051218563283874}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:49:53,822]\u001b[0m Trial 366 finished with value: 0.25673320000000005 and parameters: {'alpha': 0.008024102582473873, 'colsample_bytree': 0.9453922116669374, 'subsample': 0.9440462848395748, 'scale_pos_weight': 1.541817608271037, 'gamma': 0.029856029590411285, 'eta': 0.21044840743447854}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:49:54,619]\u001b[0m Trial 367 finished with value: 0.2547462 and parameters: {'alpha': 0.008073021628128185, 'colsample_bytree': 0.9455119261329055, 'subsample': 0.944055955437481, 'scale_pos_weight': 1.5418821993428422, 'gamma': 0.026803341651114594, 'eta': 0.21056623281066641}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:49:56,190]\u001b[0m Trial 373 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:49:57,364]\u001b[0m Trial 368 finished with value: 0.2547931 and parameters: {'alpha': 0.007985889957568717, 'colsample_bytree': 0.9460128093605955, 'subsample': 0.9440152578533689, 'scale_pos_weight': 1.5419579394130998, 'gamma': 0.026825256650754165, 'eta': 0.21056165799770724}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:50:02,382]\u001b[0m Trial 369 finished with value: 0.25474549999999996 and parameters: {'alpha': 0.006943000052108813, 'colsample_bytree': 0.9456511647284678, 'subsample': 0.9441173861631107, 'scale_pos_weight': 1.5418704302552264, 'gamma': 0.027594284895915082, 'eta': 0.21061430941219914}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:50:05,176]\u001b[0m Trial 370 finished with value: 0.2551736 and parameters: {'alpha': 0.007947130616464284, 'colsample_bytree': 0.94592238029099, 'subsample': 0.944120560540105, 'scale_pos_weight': 1.5419672485865477, 'gamma': 0.02692938102715826, 'eta': 0.2106939385870455}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:50:06,295]\u001b[0m Trial 371 finished with value: 0.2547346 and parameters: {'alpha': 0.006898568873241663, 'colsample_bytree': 0.945962519956507, 'subsample': 0.9441119845135498, 'scale_pos_weight': 1.5417732315392105, 'gamma': 0.02754957105349953, 'eta': 0.21079935579578743}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:50:10,898]\u001b[0m Trial 372 finished with value: 0.2571406 and parameters: {'alpha': 0.008079756458985517, 'colsample_bytree': 0.9459954632106345, 'subsample': 0.9441283702977907, 'scale_pos_weight': 1.5407862568650055, 'gamma': 0.027428438682660535, 'eta': 0.2110379164479231}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:50:12,699]\u001b[0m Trial 374 finished with value: 0.2551315 and parameters: {'alpha': 0.00739238439835303, 'colsample_bytree': 0.9462413454806863, 'subsample': 0.9441400730695735, 'scale_pos_weight': 1.5419123417911431, 'gamma': 0.0275965334974417, 'eta': 0.21102250352208624}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:50:13,488]\u001b[0m Trial 375 finished with value: 0.2571187 and parameters: {'alpha': 0.007114398852231134, 'colsample_bytree': 0.9458378926130447, 'subsample': 0.9441358480557546, 'scale_pos_weight': 1.5405047783554677, 'gamma': 0.02756689735995033, 'eta': 0.2109916855556684}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:50:14,747]\u001b[0m Trial 376 finished with value: 0.25714770000000003 and parameters: {'alpha': 0.007572337010800473, 'colsample_bytree': 0.9463940450431825, 'subsample': 0.9441290565822991, 'scale_pos_weight': 1.5406243773846193, 'gamma': 0.02754364399590406, 'eta': 0.21083089321766135}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:50:16,450]\u001b[0m Trial 377 finished with value: 0.25714770000000003 and parameters: {'alpha': 0.007574077430954089, 'colsample_bytree': 0.9441564714107358, 'subsample': 0.9441314013695818, 'scale_pos_weight': 1.540655729025219, 'gamma': 0.027509165434166448, 'eta': 0.21082998329799732}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:50:22,402]\u001b[0m Trial 378 finished with value: 0.25714770000000003 and parameters: {'alpha': 0.007584061694258853, 'colsample_bytree': 0.9467458302929479, 'subsample': 0.9441429912532754, 'scale_pos_weight': 1.5406540514065203, 'gamma': 0.02752249005991369, 'eta': 0.21080505084179899}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:50:24,626]\u001b[0m Trial 379 finished with value: 0.2571187 and parameters: {'alpha': 0.007591556843462017, 'colsample_bytree': 0.946694263041543, 'subsample': 0.9441451115074824, 'scale_pos_weight': 1.5405678171773942, 'gamma': 0.027531685235985252, 'eta': 0.21088338632885847}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:50:25,042]\u001b[0m Trial 380 finished with value: 0.25717890000000004 and parameters: {'alpha': 0.007548075020808694, 'colsample_bytree': 0.9443940706073132, 'subsample': 0.9442498149260685, 'scale_pos_weight': 1.540628244491059, 'gamma': 0.02808360740568786, 'eta': 0.2110318921375686}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:50:29,997]\u001b[0m Trial 381 finished with value: 0.2571767 and parameters: {'alpha': 0.007591539450302367, 'colsample_bytree': 0.9474918402345258, 'subsample': 0.9442552436581098, 'scale_pos_weight': 1.5392767710854782, 'gamma': 0.02806154524976328, 'eta': 0.2108744303515034}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:50:31,726]\u001b[0m Trial 382 finished with value: 0.2571767 and parameters: {'alpha': 0.007568413336413031, 'colsample_bytree': 0.944586753405946, 'subsample': 0.944249692841048, 'scale_pos_weight': 1.5394276541173972, 'gamma': 0.028252189937052134, 'eta': 0.21086060687737773}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:50:32,664]\u001b[0m Trial 383 finished with value: 0.25717890000000004 and parameters: {'alpha': 0.007587778540429357, 'colsample_bytree': 0.9445899050833251, 'subsample': 0.9442552828010948, 'scale_pos_weight': 1.5405551533465986, 'gamma': 0.029170022187455097, 'eta': 0.21082980774516338}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:50:33,202]\u001b[0m Trial 384 finished with value: 0.25522969999999995 and parameters: {'alpha': 0.00754929764034406, 'colsample_bytree': 0.9467239703054531, 'subsample': 0.9442401803075193, 'scale_pos_weight': 1.5404356909505434, 'gamma': 0.02814495732604533, 'eta': 0.21145488163359208}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:50:35,351]\u001b[0m Trial 385 finished with value: 0.25715639999999995 and parameters: {'alpha': 0.006869985657164009, 'colsample_bytree': 0.943376983639095, 'subsample': 0.9442801718857707, 'scale_pos_weight': 1.5402478721889914, 'gamma': 0.028121524258866906, 'eta': 0.21142100965870986}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:50:37,330]\u001b[0m Trial 392 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:50:41,540]\u001b[0m Trial 386 finished with value: 0.25717890000000004 and parameters: {'alpha': 0.007855989583114254, 'colsample_bytree': 0.9434323823656939, 'subsample': 0.9442484403496727, 'scale_pos_weight': 1.5400785562716568, 'gamma': 0.028110201245256868, 'eta': 0.211055613674533}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:50:44,197]\u001b[0m Trial 388 finished with value: 0.25715639999999995 and parameters: {'alpha': 0.007783337943475856, 'colsample_bytree': 0.9436542291848318, 'subsample': 0.9442649896410428, 'scale_pos_weight': 1.5413260830590276, 'gamma': 0.028207420792006062, 'eta': 0.21142853836135653}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:50:44,894]\u001b[0m Trial 387 finished with value: 0.25522969999999995 and parameters: {'alpha': 0.007926210921844687, 'colsample_bytree': 0.9434697495382167, 'subsample': 0.9442296155945178, 'scale_pos_weight': 1.540201804317702, 'gamma': 0.028216294182378417, 'eta': 0.2114858672437119}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:50:49,159]\u001b[0m Trial 389 finished with value: 0.25522969999999995 and parameters: {'alpha': 0.006271315389195447, 'colsample_bytree': 0.9434262324874153, 'subsample': 0.9442410339691538, 'scale_pos_weight': 1.5412903335858246, 'gamma': 0.028303591345894663, 'eta': 0.21142981487785562}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:50:49,936]\u001b[0m Trial 390 finished with value: 0.25522969999999995 and parameters: {'alpha': 0.006862859455088666, 'colsample_bytree': 0.9437779553504975, 'subsample': 0.9442220726507641, 'scale_pos_weight': 1.5413726596963673, 'gamma': 0.028225515578901315, 'eta': 0.21145458339071027}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:50:51,683]\u001b[0m Trial 391 finished with value: 0.2569247 and parameters: {'alpha': 0.006857223823916469, 'colsample_bytree': 0.9477775568211606, 'subsample': 0.9443116308497475, 'scale_pos_weight': 1.5414070069667474, 'gamma': 0.0265264550779504, 'eta': 0.21110931343427908}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:50:53,815]\u001b[0m Trial 393 finished with value: 0.25526819999999995 and parameters: {'alpha': 0.007806182234302102, 'colsample_bytree': 0.939596676564523, 'subsample': 0.9442096262584192, 'scale_pos_weight': 1.5413240807918118, 'gamma': 0.029037743377745746, 'eta': 0.2110902533189999}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:50:55,787]\u001b[0m Trial 394 finished with value: 0.2571932 and parameters: {'alpha': 0.007805640542764216, 'colsample_bytree': 0.943397426084893, 'subsample': 0.9441951573533408, 'scale_pos_weight': 1.541249861579541, 'gamma': 0.028462219417182917, 'eta': 0.21022619982562574}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:50:58,931]\u001b[0m Trial 395 finished with value: 0.2571932 and parameters: {'alpha': 0.006830679133298649, 'colsample_bytree': 0.9436938558258321, 'subsample': 0.9441874270994761, 'scale_pos_weight': 1.5413168469208307, 'gamma': 0.027036986212016403, 'eta': 0.21028665079752126}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:51:00,268]\u001b[0m Trial 396 finished with value: 0.2571932 and parameters: {'alpha': 0.006749141915343987, 'colsample_bytree': 0.9393653686895015, 'subsample': 0.9441775753270542, 'scale_pos_weight': 1.5395216567367522, 'gamma': 0.02897010761295469, 'eta': 0.21021635582195497}. Best is trial 205 with value: 0.2572217.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:51:00,458]\u001b[0m Trial 397 finished with value: 0.2572239 and parameters: {'alpha': 0.0062545614364426, 'colsample_bytree': 0.9395599414116251, 'subsample': 0.9441851457784306, 'scale_pos_weight': 1.5413490995959842, 'gamma': 0.008068642975245555, 'eta': 0.21111474540305314}. Best is trial 397 with value: 0.2572239.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:51:02,330]\u001b[0m Trial 398 finished with value: 0.2572217 and parameters: {'alpha': 0.0064862477131847045, 'colsample_bytree': 0.9477767406895474, 'subsample': 0.944185468136847, 'scale_pos_weight': 1.539650465063064, 'gamma': 0.026295215445433773, 'eta': 0.21111433674707453}. Best is trial 397 with value: 0.2572239.\u001b[0m\n",
            "\u001b[32m[I 2021-10-21 22:51:02,587]\u001b[0m Trial 399 finished with value: 0.24988799999999997 and parameters: {'alpha': 0.00709301377600877, 'colsample_bytree': 0.9478871563624949, 'subsample': 0.9441765944891672, 'scale_pos_weight': 1.5458765583616385, 'gamma': 0.027120253117413364, 'eta': 0.21020883156290152}. Best is trial 397 with value: 0.2572239.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "def objective(trial,data=X,target=y):\n",
        "    \n",
        "    clf_params ={\n",
        "        'eval_metric':'aucpr',\n",
        "        'objective': 'binary:logistic',\n",
        "        'booster': 'gbtree',\n",
        "        'max_depth': 3,\n",
        "        'min_child_weight': 6,\n",
        "        'alpha': trial.suggest_uniform('alpha', 5e-3, 1e-2),\n",
        "    }\n",
        "    \n",
        "    if clf_params[\"booster\"] == \"gbtree\" or clf_params[\"booster\"] == \"dart\":\n",
        "        clf_params['colsample_bytree'] = trial.suggest_uniform('colsample_bytree', 0.93, 0.96)\n",
        "        clf_params['subsample'] = trial.suggest_uniform('subsample', 0.943, 0.946)\n",
        "        clf_params['scale_pos_weight'] = trial.suggest_uniform('scale_pos_weight', 1.53, 1.55)\n",
        "        clf_params['gamma'] =  trial.suggest_uniform(\"gamma\", 8e-3, 3e-2)  \n",
        "        clf_params[\"eta\"] = trial.suggest_uniform(\"eta\", 0.205, 0.215)\n",
        "    '''\n",
        "        \n",
        "    if clf_params[\"booster\"] == \"dart\":\n",
        "        clf_params[\"sample_type\"] = trial.suggest_categorical(\"sample_type\", [\"uniform\", \"weighted\"])\n",
        "        clf_params[\"normalize_type\"] = trial.suggest_categorical(\"normalize_type\", [\"tree\", \"forest\"])\n",
        "        clf_params[\"rate_drop\"] = trial.suggest_loguniform(\"rate_drop\", 1e-8, 1.0)\n",
        "        clf_params[\"skip_drop\"] = trial.suggest_loguniform(\"skip_drop\", 1e-8, 1.0)    \n",
        "        \n",
        "    '''\n",
        "    \n",
        "    dmatrix = xgb.DMatrix(data=data, label=target)\n",
        "    \n",
        "    pruning_callback = opt.integration.XGBoostPruningCallback(trial, 'test-aucpr')\n",
        "    xgb_cv_res = xgb.cv(params=clf_params, dtrain=dmatrix, num_boost_round=500,\n",
        "                        folds=StratifiedShuffleSplit(n_splits=10, test_size=0.3, random_state=0), \n",
        "                        early_stopping_rounds=50, metrics='aucpr',\n",
        "                        callbacks=[pruning_callback]\n",
        "                        )\n",
        "    \n",
        "    aucpr = xgb_cv_res.loc[len(xgb_cv_res) - 1, \"test-aucpr-mean\"]\n",
        "    \n",
        "    return aucpr\n",
        "\n",
        "xgb_study = opt.create_study(\n",
        "    pruner=opt.pruners.MedianPruner(n_warmup_steps=10),\n",
        "    direction='maximize',\n",
        "    study_name='xgboost-reduced',\n",
        "    storage=XGB_DB_URL\n",
        "    )\n",
        "\n",
        "xgb_study.optimize(objective, n_trials=400, n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Value 0.2572239\n",
            "{'alpha': 0.0062545614364426, 'colsample_bytree': 0.9395599414116251, 'eta': 0.21111474540305314, 'gamma': 0.008068642975245555, 'scale_pos_weight': 1.5413490995959842, 'subsample': 0.9441851457784306}\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    xgb_study\n",
        "except NameError:\n",
        "    xgb_study = opt.load_study(study_name='xgboost-reduced', storage=XGB_DB_URL)\n",
        "best = xgb_study.best_trial\n",
        "print(f'Value {best.value}')\n",
        "print(best.params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualisations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "mode": "markers",
                  "name": "Objective Value",
                  "type": "scatter",
                  "x": [
                    0,
                    1,
                    2,
                    3,
                    4,
                    5,
                    6,
                    7,
                    8,
                    9,
                    10,
                    11,
                    12,
                    13,
                    14,
                    15,
                    16,
                    17,
                    18,
                    19,
                    23,
                    24,
                    25,
                    26,
                    27,
                    28,
                    29,
                    30,
                    31,
                    32,
                    33,
                    34,
                    35,
                    36,
                    37,
                    38,
                    39,
                    41,
                    43,
                    44,
                    45,
                    46,
                    47,
                    48,
                    49,
                    50,
                    51,
                    52,
                    53,
                    54,
                    55,
                    56,
                    57,
                    58,
                    59,
                    60,
                    62,
                    63,
                    64,
                    65,
                    66,
                    67,
                    68,
                    69,
                    70,
                    71,
                    72,
                    73,
                    74,
                    75,
                    76,
                    77,
                    78,
                    79,
                    80,
                    81,
                    82,
                    83,
                    84,
                    85,
                    86,
                    87,
                    88,
                    89,
                    90,
                    91,
                    92,
                    93,
                    94,
                    95,
                    96,
                    97,
                    98,
                    99,
                    102,
                    103,
                    104,
                    105,
                    106,
                    107,
                    108,
                    109,
                    110,
                    111,
                    112,
                    113,
                    114,
                    115,
                    116,
                    117,
                    118,
                    119,
                    122,
                    124,
                    125,
                    126,
                    127,
                    128,
                    129,
                    130,
                    131,
                    132,
                    133,
                    134,
                    135,
                    136,
                    137,
                    138,
                    139,
                    141,
                    142,
                    143,
                    145,
                    146,
                    147,
                    148,
                    149,
                    150,
                    151,
                    152,
                    153,
                    154,
                    155,
                    156,
                    157,
                    158,
                    159,
                    160,
                    161,
                    162,
                    163,
                    164,
                    165,
                    166,
                    167,
                    168,
                    169,
                    170,
                    171,
                    172,
                    173,
                    174,
                    175,
                    176,
                    177,
                    178,
                    179,
                    180,
                    181,
                    182,
                    183,
                    184,
                    185,
                    186,
                    187,
                    188,
                    189,
                    190,
                    191,
                    192,
                    193,
                    194,
                    195,
                    196,
                    197,
                    198,
                    199,
                    200,
                    201,
                    202,
                    203,
                    204,
                    205,
                    206,
                    207,
                    208,
                    209,
                    210,
                    211,
                    212,
                    213,
                    214,
                    215,
                    216,
                    217,
                    218,
                    219,
                    220,
                    221,
                    222,
                    223,
                    224,
                    225,
                    226,
                    227,
                    228,
                    229,
                    230,
                    231,
                    232,
                    233,
                    234,
                    235,
                    236,
                    237,
                    238,
                    239,
                    240,
                    241,
                    242,
                    243,
                    244,
                    245,
                    246,
                    247,
                    248,
                    249,
                    250,
                    251,
                    252,
                    253,
                    254,
                    255,
                    256,
                    257,
                    258,
                    259,
                    260,
                    261,
                    262,
                    263,
                    264,
                    265,
                    266,
                    267,
                    269,
                    270,
                    271,
                    272,
                    273,
                    275,
                    276,
                    277,
                    278,
                    279,
                    280,
                    281,
                    282,
                    283,
                    284,
                    285,
                    286,
                    287,
                    288,
                    289,
                    290,
                    291,
                    293,
                    294,
                    295,
                    296,
                    297,
                    298,
                    299,
                    300,
                    301,
                    302,
                    303,
                    305,
                    306,
                    307,
                    308,
                    309,
                    310,
                    311,
                    312,
                    313,
                    314,
                    316,
                    317,
                    318,
                    319,
                    320,
                    321,
                    322,
                    323,
                    324,
                    325,
                    326,
                    327,
                    328,
                    329,
                    330,
                    331,
                    332,
                    333,
                    334,
                    335,
                    336,
                    337,
                    338,
                    339,
                    340,
                    341,
                    342,
                    343,
                    344,
                    345,
                    346,
                    347,
                    348,
                    349,
                    350,
                    351,
                    352,
                    353,
                    354,
                    355,
                    356,
                    357,
                    358,
                    359,
                    360,
                    361,
                    362,
                    363,
                    364,
                    365,
                    366,
                    367,
                    368,
                    369,
                    370,
                    371,
                    372,
                    374,
                    375,
                    376,
                    377,
                    378,
                    379,
                    380,
                    381,
                    382,
                    383,
                    384,
                    385,
                    386,
                    387,
                    388,
                    389,
                    390,
                    391,
                    393,
                    394,
                    395,
                    396,
                    397,
                    398,
                    399
                  ],
                  "y": [
                    0.24309599999999998,
                    0.24818389999999999,
                    0.24435959999999998,
                    0.256212,
                    0.2555163,
                    0.2464995,
                    0.25545389999999996,
                    0.24905049999999998,
                    0.2548641,
                    0.25648119999999996,
                    0.2558698,
                    0.24780459999999999,
                    0.2477465,
                    0.24833249999999998,
                    0.25473920000000005,
                    0.24775509999999995,
                    0.2505895,
                    0.25473789999999996,
                    0.2547096,
                    0.2448719,
                    0.2516613,
                    0.25311239999999996,
                    0.25467589999999996,
                    0.253307,
                    0.24996430000000003,
                    0.2556667,
                    0.25070549999999997,
                    0.2507082,
                    0.2550057,
                    0.2556131,
                    0.2550865,
                    0.2556131,
                    0.2567946,
                    0.25560499999999997,
                    0.2546059,
                    0.2533031,
                    0.2546889,
                    0.24616310000000002,
                    0.2571392,
                    0.25704049999999995,
                    0.2570628,
                    0.25710390000000005,
                    0.2570731,
                    0.25704439999999995,
                    0.2555306,
                    0.25553879999999995,
                    0.2565786,
                    0.2570731,
                    0.2570578,
                    0.2570198,
                    0.2532803,
                    0.24752110000000002,
                    0.25571079999999996,
                    0.2571526,
                    0.2550972,
                    0.2550105,
                    0.251436,
                    0.24811100000000003,
                    0.25268229999999997,
                    0.25472929999999994,
                    0.2529772,
                    0.25307799999999997,
                    0.25477059999999996,
                    0.25472989999999995,
                    0.2550596,
                    0.25319769999999997,
                    0.2567672,
                    0.2541135,
                    0.25625390000000003,
                    0.25672740000000005,
                    0.25674270000000005,
                    0.25477740000000004,
                    0.25665759999999993,
                    0.2567666,
                    0.2567825,
                    0.2571437,
                    0.2541133,
                    0.2570405,
                    0.2556736,
                    0.2559516,
                    0.2549704,
                    0.25710520000000003,
                    0.25712749999999995,
                    0.25594589999999995,
                    0.25650200000000006,
                    0.2535493,
                    0.25665879999999996,
                    0.25673450000000003,
                    0.2567359,
                    0.25673450000000003,
                    0.25662219999999997,
                    0.2547356,
                    0.25673450000000003,
                    0.25658259999999994,
                    0.24811029999999995,
                    0.2565795,
                    0.2492701,
                    0.25657729999999995,
                    0.2565707,
                    0.2545136,
                    0.256613,
                    0.25657729999999995,
                    0.2565415999999999,
                    0.25713010000000003,
                    0.25703919999999997,
                    0.2551085,
                    0.2560518,
                    0.2550975,
                    0.25665249999999995,
                    0.25512729999999995,
                    0.2570198,
                    0.25703919999999997,
                    0.2546713,
                    0.25268519999999994,
                    0.25477059999999996,
                    0.2565277,
                    0.2564938,
                    0.25672819999999996,
                    0.2565415999999999,
                    0.2567638,
                    0.2567104,
                    0.25592079999999995,
                    0.25709360000000003,
                    0.2567097,
                    0.2567747,
                    0.25182119999999997,
                    0.25709360000000003,
                    0.2560942,
                    0.2569352,
                    0.25366809999999995,
                    0.2571847,
                    0.2570494,
                    0.2571681,
                    0.2571794,
                    0.25715869999999996,
                    0.2571681,
                    0.25665760000000004,
                    0.25676439999999995,
                    0.2570578,
                    0.2551037,
                    0.25705370000000005,
                    0.25716680000000003,
                    0.25716680000000003,
                    0.25715639999999995,
                    0.25715639999999995,
                    0.2571548,
                    0.2571523,
                    0.25715869999999996,
                    0.257151,
                    0.25438510000000003,
                    0.255105,
                    0.257151,
                    0.25513479999999994,
                    0.2534262,
                    0.25509889999999996,
                    0.2534262,
                    0.2551042,
                    0.25509889999999996,
                    0.25509889999999996,
                    0.2541022,
                    0.2540864,
                    0.25513359999999996,
                    0.257187,
                    0.257187,
                    0.2561664,
                    0.25620539999999997,
                    0.255899,
                    0.257187,
                    0.257187,
                    0.2569225,
                    0.2571629,
                    0.257187,
                    0.2571848,
                    0.2571629,
                    0.2571848,
                    0.25717890000000004,
                    0.2571629,
                    0.2571548,
                    0.2571767,
                    0.2571767,
                    0.25659529999999997,
                    0.25692029999999993,
                    0.25692029999999993,
                    0.25692029999999993,
                    0.2569225,
                    0.2569225,
                    0.24924519999999997,
                    0.2569225,
                    0.25718159999999995,
                    0.2571838,
                    0.25516869999999997,
                    0.2572217,
                    0.2572217,
                    0.25718159999999995,
                    0.2547674999999999,
                    0.2571794,
                    0.2571838,
                    0.2571794,
                    0.2571806,
                    0.257151,
                    0.257151,
                    0.2571911,
                    0.2571911,
                    0.25716710000000004,
                    0.257151,
                    0.2571911,
                    0.2571911,
                    0.2571911,
                    0.2571911,
                    0.2571911,
                    0.2571911,
                    0.2571911,
                    0.2571911,
                    0.257091,
                    0.25672459999999997,
                    0.2571237,
                    0.25672459999999997,
                    0.25672459999999997,
                    0.25672459999999997,
                    0.25672740000000005,
                    0.25669410000000004,
                    0.25673070000000003,
                    0.25669410000000004,
                    0.2566733,
                    0.2567088,
                    0.25711349999999994,
                    0.2571129,
                    0.257091,
                    0.257091,
                    0.257091,
                    0.2571237,
                    0.25712149999999995,
                    0.25712149999999995,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.25718159999999995,
                    0.257151,
                    0.25717890000000004,
                    0.25717890000000004,
                    0.2571806,
                    0.2571786,
                    0.2571806,
                    0.2571742,
                    0.2571806,
                    0.2571742,
                    0.2571742,
                    0.2567405,
                    0.25671960000000005,
                    0.2532991,
                    0.2567007,
                    0.2531245,
                    0.25669410000000004,
                    0.25669410000000004,
                    0.25669410000000004,
                    0.2568919,
                    0.2568919,
                    0.2568919,
                    0.2569225,
                    0.2556653,
                    0.257187,
                    0.2558753,
                    0.2569225,
                    0.2569225,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2571844,
                    0.25718159999999995,
                    0.2572217,
                    0.25712149999999995,
                    0.25712149999999995,
                    0.2551721,
                    0.25717890000000004,
                    0.25715930000000004,
                    0.2547511,
                    0.2547931,
                    0.25470859999999995,
                    0.2547462,
                    0.25475180000000003,
                    0.25669580000000003,
                    0.25667389999999995,
                    0.256714,
                    0.25669410000000004,
                    0.25667389999999995,
                    0.25672680000000003,
                    0.2571483,
                    0.2571483,
                    0.2490541,
                    0.25522969999999995,
                    0.2552482,
                    0.25522969999999995,
                    0.25526249999999995,
                    0.25526249999999995,
                    0.2572217,
                    0.25721950000000005,
                    0.2550935,
                    0.2550935,
                    0.2550913,
                    0.2572217,
                    0.25721950000000005,
                    0.2571794,
                    0.2572217,
                    0.2508721,
                    0.25721950000000005,
                    0.25721950000000005,
                    0.2572217,
                    0.2552301,
                    0.2567405,
                    0.25718159999999995,
                    0.25715930000000004,
                    0.25519440000000004,
                    0.25715420000000005,
                    0.2551714,
                    0.25674850000000005,
                    0.2567276,
                    0.257147,
                    0.2567283,
                    0.2567283,
                    0.25671960000000005,
                    0.2567218,
                    0.2567672,
                    0.25671960000000005,
                    0.25671960000000005,
                    0.25671960000000005,
                    0.25671960000000005,
                    0.2567405,
                    0.2567405,
                    0.2572217,
                    0.2572217,
                    0.2567405,
                    0.25674270000000005,
                    0.25718159999999995,
                    0.2572217,
                    0.25718159999999995,
                    0.25718159999999995,
                    0.2572217,
                    0.25718159999999995,
                    0.25718159999999995,
                    0.25718159999999995,
                    0.25718159999999995,
                    0.25720350000000003,
                    0.2571821,
                    0.2567324,
                    0.2567687,
                    0.2567218,
                    0.2567687,
                    0.25673830000000003,
                    0.25673320000000005,
                    0.2547462,
                    0.2547931,
                    0.25474549999999996,
                    0.2551736,
                    0.2547346,
                    0.2571406,
                    0.2551315,
                    0.2571187,
                    0.25714770000000003,
                    0.25714770000000003,
                    0.25714770000000003,
                    0.2571187,
                    0.25717890000000004,
                    0.2571767,
                    0.2571767,
                    0.25717890000000004,
                    0.25522969999999995,
                    0.25715639999999995,
                    0.25717890000000004,
                    0.25522969999999995,
                    0.25715639999999995,
                    0.25522969999999995,
                    0.25522969999999995,
                    0.2569247,
                    0.25526819999999995,
                    0.2571932,
                    0.2571932,
                    0.2571932,
                    0.2572239,
                    0.2572217,
                    0.24988799999999997
                  ]
                },
                {
                  "name": "Best Value",
                  "type": "scatter",
                  "x": [
                    0,
                    1,
                    2,
                    3,
                    4,
                    5,
                    6,
                    7,
                    8,
                    9,
                    10,
                    11,
                    12,
                    13,
                    14,
                    15,
                    16,
                    17,
                    18,
                    19,
                    23,
                    24,
                    25,
                    26,
                    27,
                    28,
                    29,
                    30,
                    31,
                    32,
                    33,
                    34,
                    35,
                    36,
                    37,
                    38,
                    39,
                    41,
                    43,
                    44,
                    45,
                    46,
                    47,
                    48,
                    49,
                    50,
                    51,
                    52,
                    53,
                    54,
                    55,
                    56,
                    57,
                    58,
                    59,
                    60,
                    62,
                    63,
                    64,
                    65,
                    66,
                    67,
                    68,
                    69,
                    70,
                    71,
                    72,
                    73,
                    74,
                    75,
                    76,
                    77,
                    78,
                    79,
                    80,
                    81,
                    82,
                    83,
                    84,
                    85,
                    86,
                    87,
                    88,
                    89,
                    90,
                    91,
                    92,
                    93,
                    94,
                    95,
                    96,
                    97,
                    98,
                    99,
                    102,
                    103,
                    104,
                    105,
                    106,
                    107,
                    108,
                    109,
                    110,
                    111,
                    112,
                    113,
                    114,
                    115,
                    116,
                    117,
                    118,
                    119,
                    122,
                    124,
                    125,
                    126,
                    127,
                    128,
                    129,
                    130,
                    131,
                    132,
                    133,
                    134,
                    135,
                    136,
                    137,
                    138,
                    139,
                    141,
                    142,
                    143,
                    145,
                    146,
                    147,
                    148,
                    149,
                    150,
                    151,
                    152,
                    153,
                    154,
                    155,
                    156,
                    157,
                    158,
                    159,
                    160,
                    161,
                    162,
                    163,
                    164,
                    165,
                    166,
                    167,
                    168,
                    169,
                    170,
                    171,
                    172,
                    173,
                    174,
                    175,
                    176,
                    177,
                    178,
                    179,
                    180,
                    181,
                    182,
                    183,
                    184,
                    185,
                    186,
                    187,
                    188,
                    189,
                    190,
                    191,
                    192,
                    193,
                    194,
                    195,
                    196,
                    197,
                    198,
                    199,
                    200,
                    201,
                    202,
                    203,
                    204,
                    205,
                    206,
                    207,
                    208,
                    209,
                    210,
                    211,
                    212,
                    213,
                    214,
                    215,
                    216,
                    217,
                    218,
                    219,
                    220,
                    221,
                    222,
                    223,
                    224,
                    225,
                    226,
                    227,
                    228,
                    229,
                    230,
                    231,
                    232,
                    233,
                    234,
                    235,
                    236,
                    237,
                    238,
                    239,
                    240,
                    241,
                    242,
                    243,
                    244,
                    245,
                    246,
                    247,
                    248,
                    249,
                    250,
                    251,
                    252,
                    253,
                    254,
                    255,
                    256,
                    257,
                    258,
                    259,
                    260,
                    261,
                    262,
                    263,
                    264,
                    265,
                    266,
                    267,
                    269,
                    270,
                    271,
                    272,
                    273,
                    275,
                    276,
                    277,
                    278,
                    279,
                    280,
                    281,
                    282,
                    283,
                    284,
                    285,
                    286,
                    287,
                    288,
                    289,
                    290,
                    291,
                    293,
                    294,
                    295,
                    296,
                    297,
                    298,
                    299,
                    300,
                    301,
                    302,
                    303,
                    305,
                    306,
                    307,
                    308,
                    309,
                    310,
                    311,
                    312,
                    313,
                    314,
                    316,
                    317,
                    318,
                    319,
                    320,
                    321,
                    322,
                    323,
                    324,
                    325,
                    326,
                    327,
                    328,
                    329,
                    330,
                    331,
                    332,
                    333,
                    334,
                    335,
                    336,
                    337,
                    338,
                    339,
                    340,
                    341,
                    342,
                    343,
                    344,
                    345,
                    346,
                    347,
                    348,
                    349,
                    350,
                    351,
                    352,
                    353,
                    354,
                    355,
                    356,
                    357,
                    358,
                    359,
                    360,
                    361,
                    362,
                    363,
                    364,
                    365,
                    366,
                    367,
                    368,
                    369,
                    370,
                    371,
                    372,
                    374,
                    375,
                    376,
                    377,
                    378,
                    379,
                    380,
                    381,
                    382,
                    383,
                    384,
                    385,
                    386,
                    387,
                    388,
                    389,
                    390,
                    391,
                    393,
                    394,
                    395,
                    396,
                    397,
                    398,
                    399
                  ],
                  "y": [
                    0.24309599999999998,
                    0.24818389999999999,
                    0.24818389999999999,
                    0.256212,
                    0.256212,
                    0.256212,
                    0.256212,
                    0.256212,
                    0.256212,
                    0.25648119999999996,
                    0.25648119999999996,
                    0.25648119999999996,
                    0.25648119999999996,
                    0.25648119999999996,
                    0.25648119999999996,
                    0.25648119999999996,
                    0.25648119999999996,
                    0.25648119999999996,
                    0.25648119999999996,
                    0.25648119999999996,
                    0.25648119999999996,
                    0.25648119999999996,
                    0.25648119999999996,
                    0.25648119999999996,
                    0.25648119999999996,
                    0.25648119999999996,
                    0.25648119999999996,
                    0.25648119999999996,
                    0.25648119999999996,
                    0.25648119999999996,
                    0.25648119999999996,
                    0.25648119999999996,
                    0.2567946,
                    0.2567946,
                    0.2567946,
                    0.2567946,
                    0.2567946,
                    0.2567946,
                    0.2571392,
                    0.2571392,
                    0.2571392,
                    0.2571392,
                    0.2571392,
                    0.2571392,
                    0.2571392,
                    0.2571392,
                    0.2571392,
                    0.2571392,
                    0.2571392,
                    0.2571392,
                    0.2571392,
                    0.2571392,
                    0.2571392,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571526,
                    0.2571847,
                    0.2571847,
                    0.2571847,
                    0.2571847,
                    0.2571847,
                    0.2571847,
                    0.2571847,
                    0.2571847,
                    0.2571847,
                    0.2571847,
                    0.2571847,
                    0.2571847,
                    0.2571847,
                    0.2571847,
                    0.2571847,
                    0.2571847,
                    0.2571847,
                    0.2571847,
                    0.2571847,
                    0.2571847,
                    0.2571847,
                    0.2571847,
                    0.2571847,
                    0.2571847,
                    0.2571847,
                    0.2571847,
                    0.2571847,
                    0.2571847,
                    0.2571847,
                    0.2571847,
                    0.2571847,
                    0.2571847,
                    0.257187,
                    0.257187,
                    0.257187,
                    0.257187,
                    0.257187,
                    0.257187,
                    0.257187,
                    0.257187,
                    0.257187,
                    0.257187,
                    0.257187,
                    0.257187,
                    0.257187,
                    0.257187,
                    0.257187,
                    0.257187,
                    0.257187,
                    0.257187,
                    0.257187,
                    0.257187,
                    0.257187,
                    0.257187,
                    0.257187,
                    0.257187,
                    0.257187,
                    0.257187,
                    0.257187,
                    0.257187,
                    0.257187,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572217,
                    0.2572239,
                    0.2572239,
                    0.2572239
                  ]
                }
              ],
              "layout": {
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "heatmapgl": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmapgl"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                },
                "title": {
                  "text": "Optimization History Plot"
                },
                "xaxis": {
                  "title": {
                    "text": "#Trials"
                  }
                },
                "yaxis": {
                  "title": {
                    "text": "Objective Value"
                  }
                }
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "opt.visualization.plot_optimization_history(xgb_study)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "mode": "lines",
                  "name": "xgboost-reduced",
                  "type": "scatter",
                  "x": [
                    0.24309599999999998,
                    0.24323870606060605,
                    0.2433814121212121,
                    0.24352411818181816,
                    0.24366682424242422,
                    0.2438095303030303,
                    0.24395223636363633,
                    0.2440949424242424,
                    0.24423764848484847,
                    0.24438035454545454,
                    0.24452306060606058,
                    0.24466576666666665,
                    0.2448084727272727,
                    0.24495117878787878,
                    0.24509388484848482,
                    0.2452365909090909,
                    0.24537929696969696,
                    0.24552200303030303,
                    0.24566470909090907,
                    0.24580741515151514,
                    0.2459501212121212,
                    0.24609282727272724,
                    0.2462355333333333,
                    0.24637823939393938,
                    0.24652094545454545,
                    0.2466636515151515,
                    0.24680635757575756,
                    0.24694906363636362,
                    0.2470917696969697,
                    0.24723447575757573,
                    0.2473771818181818,
                    0.24751988787878787,
                    0.24766259393939394,
                    0.24780529999999998,
                    0.24794800606060605,
                    0.24809071212121211,
                    0.24823341818181818,
                    0.24837612424242422,
                    0.2485188303030303,
                    0.24866153636363636,
                    0.24880424242424243,
                    0.24894694848484847,
                    0.24908965454545454,
                    0.2492323606060606,
                    0.24937506666666664,
                    0.2495177727272727,
                    0.24966047878787878,
                    0.24980318484848485,
                    0.2499458909090909,
                    0.250088596969697,
                    0.250231303030303,
                    0.25037400909090907,
                    0.25051671515151513,
                    0.2506594212121212,
                    0.25080212727272727,
                    0.25094483333333334,
                    0.2510875393939394,
                    0.2512302454545454,
                    0.2513729515151515,
                    0.25151565757575756,
                    0.2516583636363636,
                    0.2518010696969697,
                    0.25194377575757576,
                    0.25208648181818183,
                    0.2522291878787879,
                    0.2523718939393939,
                    0.2525146,
                    0.25265730606060605,
                    0.2528000121212121,
                    0.2529427181818182,
                    0.25308542424242425,
                    0.2532281303030303,
                    0.2533708363636364,
                    0.2535135424242424,
                    0.25365624848484847,
                    0.25379895454545454,
                    0.2539416606060606,
                    0.2540843666666667,
                    0.25422707272727274,
                    0.2543697787878788,
                    0.2545124848484849,
                    0.2546551909090909,
                    0.25479789696969696,
                    0.254940603030303,
                    0.2550833090909091,
                    0.25522601515151516,
                    0.25536872121212123,
                    0.2555114272727273,
                    0.2556541333333333,
                    0.2557968393939394,
                    0.25593954545454545,
                    0.2560822515151515,
                    0.2562249575757576,
                    0.25636766363636365,
                    0.2565103696969697,
                    0.2566530757575758,
                    0.2567957818181818,
                    0.25693848787878787,
                    0.25708119393939394,
                    0.2572239
                  ],
                  "y": [
                    0.002631578947368421,
                    0.002631578947368421,
                    0.002631578947368421,
                    0.002631578947368421,
                    0.002631578947368421,
                    0.002631578947368421,
                    0.002631578947368421,
                    0.002631578947368421,
                    0.002631578947368421,
                    0.005263157894736842,
                    0.005263157894736842,
                    0.005263157894736842,
                    0.005263157894736842,
                    0.007894736842105263,
                    0.007894736842105263,
                    0.007894736842105263,
                    0.007894736842105263,
                    0.007894736842105263,
                    0.007894736842105263,
                    0.007894736842105263,
                    0.007894736842105263,
                    0.007894736842105263,
                    0.010526315789473684,
                    0.010526315789473684,
                    0.013157894736842105,
                    0.013157894736842105,
                    0.013157894736842105,
                    0.013157894736842105,
                    0.013157894736842105,
                    0.013157894736842105,
                    0.013157894736842105,
                    0.013157894736842105,
                    0.015789473684210527,
                    0.02368421052631579,
                    0.02368421052631579,
                    0.02368421052631579,
                    0.031578947368421054,
                    0.034210526315789476,
                    0.034210526315789476,
                    0.034210526315789476,
                    0.034210526315789476,
                    0.034210526315789476,
                    0.039473684210526314,
                    0.039473684210526314,
                    0.04473684210526316,
                    0.04473684210526316,
                    0.04473684210526316,
                    0.04473684210526316,
                    0.04736842105263158,
                    0.05,
                    0.05,
                    0.05,
                    0.05,
                    0.05263157894736842,
                    0.05789473684210526,
                    0.060526315789473685,
                    0.060526315789473685,
                    0.060526315789473685,
                    0.060526315789473685,
                    0.06315789473684211,
                    0.06315789473684211,
                    0.06578947368421052,
                    0.06842105263157895,
                    0.06842105263157895,
                    0.06842105263157895,
                    0.06842105263157895,
                    0.06842105263157895,
                    0.06842105263157895,
                    0.07368421052631578,
                    0.07368421052631578,
                    0.07894736842105263,
                    0.0868421052631579,
                    0.09736842105263158,
                    0.10263157894736842,
                    0.10526315789473684,
                    0.10789473684210527,
                    0.10789473684210527,
                    0.10789473684210527,
                    0.11842105263157894,
                    0.11842105263157894,
                    0.12105263157894737,
                    0.12631578947368421,
                    0.18421052631578946,
                    0.1868421052631579,
                    0.19736842105263158,
                    0.25526315789473686,
                    0.28421052631578947,
                    0.2868421052631579,
                    0.3026315789473684,
                    0.3131578947368421,
                    0.3236842105263158,
                    0.33157894736842103,
                    0.34210526315789475,
                    0.3447368421052632,
                    0.3526315789473684,
                    0.3868421052631579,
                    0.5526315789473685,
                    0.5921052631578947,
                    0.6289473684210526,
                    1
                  ]
                }
              ],
              "layout": {
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "heatmapgl": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmapgl"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                },
                "title": {
                  "text": "Empirical Distribution Function Plot"
                },
                "xaxis": {
                  "title": {
                    "text": "Objective Value"
                  }
                },
                "yaxis": {
                  "range": [
                    0,
                    1
                  ],
                  "title": {
                    "text": "Cumulative Probability"
                  }
                }
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "opt.visualization.plot_edf(xgb_study)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "cliponaxis": false,
                  "hovertemplate": [
                    "alpha (UniformDistribution): 0.011711765931635863<extra></extra>",
                    "colsample_bytree (UniformDistribution): 0.012236129861957178<extra></extra>",
                    "gamma (UniformDistribution): 0.06326297838416395<extra></extra>",
                    "scale_pos_weight (UniformDistribution): 0.07193908747177238<extra></extra>",
                    "eta (UniformDistribution): 0.07713876700463707<extra></extra>",
                    "subsample (UniformDistribution): 0.7637112713458336<extra></extra>"
                  ],
                  "marker": {
                    "color": "rgb(66,146,198)"
                  },
                  "orientation": "h",
                  "text": [
                    "0.011711765931635863",
                    "0.012236129861957178",
                    "0.06326297838416395",
                    "0.07193908747177238",
                    "0.07713876700463707",
                    "0.7637112713458336"
                  ],
                  "textposition": "outside",
                  "texttemplate": "%{text:.2f}",
                  "type": "bar",
                  "x": [
                    0.011711765931635863,
                    0.012236129861957178,
                    0.06326297838416395,
                    0.07193908747177238,
                    0.07713876700463707,
                    0.7637112713458336
                  ],
                  "y": [
                    "alpha",
                    "colsample_bytree",
                    "gamma",
                    "scale_pos_weight",
                    "eta",
                    "subsample"
                  ]
                }
              ],
              "layout": {
                "showlegend": false,
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "heatmapgl": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmapgl"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                },
                "title": {
                  "text": "Hyperparameter Importances"
                },
                "xaxis": {
                  "title": {
                    "text": "Importance for Objective Value"
                  }
                },
                "yaxis": {
                  "title": {
                    "text": "Hyperparameter"
                  }
                }
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "opt.visualization.plot_param_importances(xgb_study)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "dimensions": [
                    {
                      "label": "Objective Value",
                      "range": [
                        0.24309599999999998,
                        0.2572239
                      ],
                      "values": [
                        0.24309599999999998,
                        0.24818389999999999,
                        0.24435959999999998,
                        0.256212,
                        0.2555163,
                        0.2464995,
                        0.25545389999999996,
                        0.24905049999999998,
                        0.2548641,
                        0.25648119999999996,
                        0.2558698,
                        0.24780459999999999,
                        0.2477465,
                        0.24833249999999998,
                        0.25473920000000005,
                        0.24775509999999995,
                        0.2505895,
                        0.25473789999999996,
                        0.2547096,
                        0.2448719,
                        0.2516613,
                        0.25311239999999996,
                        0.25467589999999996,
                        0.253307,
                        0.24996430000000003,
                        0.2556667,
                        0.25070549999999997,
                        0.2507082,
                        0.2550057,
                        0.2556131,
                        0.2550865,
                        0.2556131,
                        0.2567946,
                        0.25560499999999997,
                        0.2546059,
                        0.2533031,
                        0.2546889,
                        0.24616310000000002,
                        0.2571392,
                        0.25704049999999995,
                        0.2570628,
                        0.25710390000000005,
                        0.2570731,
                        0.25704439999999995,
                        0.2555306,
                        0.25553879999999995,
                        0.2565786,
                        0.2570731,
                        0.2570578,
                        0.2570198,
                        0.2532803,
                        0.24752110000000002,
                        0.25571079999999996,
                        0.2571526,
                        0.2550972,
                        0.2550105,
                        0.251436,
                        0.24811100000000003,
                        0.25268229999999997,
                        0.25472929999999994,
                        0.2529772,
                        0.25307799999999997,
                        0.25477059999999996,
                        0.25472989999999995,
                        0.2550596,
                        0.25319769999999997,
                        0.2567672,
                        0.2541135,
                        0.25625390000000003,
                        0.25672740000000005,
                        0.25674270000000005,
                        0.25477740000000004,
                        0.25665759999999993,
                        0.2567666,
                        0.2567825,
                        0.2571437,
                        0.2541133,
                        0.2570405,
                        0.2556736,
                        0.2559516,
                        0.2549704,
                        0.25710520000000003,
                        0.25712749999999995,
                        0.25594589999999995,
                        0.25650200000000006,
                        0.2535493,
                        0.25665879999999996,
                        0.25673450000000003,
                        0.2567359,
                        0.25673450000000003,
                        0.25662219999999997,
                        0.2547356,
                        0.25673450000000003,
                        0.25658259999999994,
                        0.24811029999999995,
                        0.2565795,
                        0.2492701,
                        0.25657729999999995,
                        0.2565707,
                        0.2545136,
                        0.256613,
                        0.25657729999999995,
                        0.2565415999999999,
                        0.25713010000000003,
                        0.25703919999999997,
                        0.2551085,
                        0.2560518,
                        0.2550975,
                        0.25665249999999995,
                        0.25512729999999995,
                        0.2570198,
                        0.25703919999999997,
                        0.2546713,
                        0.25268519999999994,
                        0.25477059999999996,
                        0.2565277,
                        0.2564938,
                        0.25672819999999996,
                        0.2565415999999999,
                        0.2567638,
                        0.2567104,
                        0.25592079999999995,
                        0.25709360000000003,
                        0.2567097,
                        0.2567747,
                        0.25182119999999997,
                        0.25709360000000003,
                        0.2560942,
                        0.2569352,
                        0.25366809999999995,
                        0.2571847,
                        0.2570494,
                        0.2571681,
                        0.2571794,
                        0.25715869999999996,
                        0.2571681,
                        0.25665760000000004,
                        0.25676439999999995,
                        0.2570578,
                        0.2551037,
                        0.25705370000000005,
                        0.25716680000000003,
                        0.25716680000000003,
                        0.25715639999999995,
                        0.25715639999999995,
                        0.2571548,
                        0.2571523,
                        0.25715869999999996,
                        0.257151,
                        0.25438510000000003,
                        0.255105,
                        0.257151,
                        0.25513479999999994,
                        0.2534262,
                        0.25509889999999996,
                        0.2534262,
                        0.2551042,
                        0.25509889999999996,
                        0.25509889999999996,
                        0.2541022,
                        0.2540864,
                        0.25513359999999996,
                        0.257187,
                        0.257187,
                        0.2561664,
                        0.25620539999999997,
                        0.255899,
                        0.257187,
                        0.257187,
                        0.2569225,
                        0.2571629,
                        0.257187,
                        0.2571848,
                        0.2571629,
                        0.2571848,
                        0.25717890000000004,
                        0.2571629,
                        0.2571548,
                        0.2571767,
                        0.2571767,
                        0.25659529999999997,
                        0.25692029999999993,
                        0.25692029999999993,
                        0.25692029999999993,
                        0.2569225,
                        0.2569225,
                        0.24924519999999997,
                        0.2569225,
                        0.25718159999999995,
                        0.2571838,
                        0.25516869999999997,
                        0.2572217,
                        0.2572217,
                        0.25718159999999995,
                        0.2547674999999999,
                        0.2571794,
                        0.2571838,
                        0.2571794,
                        0.2571806,
                        0.257151,
                        0.257151,
                        0.2571911,
                        0.2571911,
                        0.25716710000000004,
                        0.257151,
                        0.2571911,
                        0.2571911,
                        0.2571911,
                        0.2571911,
                        0.2571911,
                        0.2571911,
                        0.2571911,
                        0.2571911,
                        0.257091,
                        0.25672459999999997,
                        0.2571237,
                        0.25672459999999997,
                        0.25672459999999997,
                        0.25672459999999997,
                        0.25672740000000005,
                        0.25669410000000004,
                        0.25673070000000003,
                        0.25669410000000004,
                        0.2566733,
                        0.2567088,
                        0.25711349999999994,
                        0.2571129,
                        0.257091,
                        0.257091,
                        0.257091,
                        0.2571237,
                        0.25712149999999995,
                        0.25712149999999995,
                        0.2572217,
                        0.2572217,
                        0.2572217,
                        0.25718159999999995,
                        0.257151,
                        0.25717890000000004,
                        0.25717890000000004,
                        0.2571806,
                        0.2571786,
                        0.2571806,
                        0.2571742,
                        0.2571806,
                        0.2571742,
                        0.2571742,
                        0.2567405,
                        0.25671960000000005,
                        0.2532991,
                        0.2567007,
                        0.2531245,
                        0.25669410000000004,
                        0.25669410000000004,
                        0.25669410000000004,
                        0.2568919,
                        0.2568919,
                        0.2568919,
                        0.2569225,
                        0.2556653,
                        0.257187,
                        0.2558753,
                        0.2569225,
                        0.2569225,
                        0.2572217,
                        0.2572217,
                        0.2572217,
                        0.2571844,
                        0.25718159999999995,
                        0.2572217,
                        0.25712149999999995,
                        0.25712149999999995,
                        0.2551721,
                        0.25717890000000004,
                        0.25715930000000004,
                        0.2547511,
                        0.2547931,
                        0.25470859999999995,
                        0.2547462,
                        0.25475180000000003,
                        0.25669580000000003,
                        0.25667389999999995,
                        0.256714,
                        0.25669410000000004,
                        0.25667389999999995,
                        0.25672680000000003,
                        0.2571483,
                        0.2571483,
                        0.2490541,
                        0.25522969999999995,
                        0.2552482,
                        0.25522969999999995,
                        0.25526249999999995,
                        0.25526249999999995,
                        0.2572217,
                        0.25721950000000005,
                        0.2550935,
                        0.2550935,
                        0.2550913,
                        0.2572217,
                        0.25721950000000005,
                        0.2571794,
                        0.2572217,
                        0.2508721,
                        0.25721950000000005,
                        0.25721950000000005,
                        0.2572217,
                        0.2552301,
                        0.2567405,
                        0.25718159999999995,
                        0.25715930000000004,
                        0.25519440000000004,
                        0.25715420000000005,
                        0.2551714,
                        0.25674850000000005,
                        0.2567276,
                        0.257147,
                        0.2567283,
                        0.2567283,
                        0.25671960000000005,
                        0.2567218,
                        0.2567672,
                        0.25671960000000005,
                        0.25671960000000005,
                        0.25671960000000005,
                        0.25671960000000005,
                        0.2567405,
                        0.2567405,
                        0.2572217,
                        0.2572217,
                        0.2567405,
                        0.25674270000000005,
                        0.25718159999999995,
                        0.2572217,
                        0.25718159999999995,
                        0.25718159999999995,
                        0.2572217,
                        0.25718159999999995,
                        0.25718159999999995,
                        0.25718159999999995,
                        0.25718159999999995,
                        0.25720350000000003,
                        0.2571821,
                        0.2567324,
                        0.2567687,
                        0.2567218,
                        0.2567687,
                        0.25673830000000003,
                        0.25673320000000005,
                        0.2547462,
                        0.2547931,
                        0.25474549999999996,
                        0.2551736,
                        0.2547346,
                        0.2571406,
                        0.2551315,
                        0.2571187,
                        0.25714770000000003,
                        0.25714770000000003,
                        0.25714770000000003,
                        0.2571187,
                        0.25717890000000004,
                        0.2571767,
                        0.2571767,
                        0.25717890000000004,
                        0.25522969999999995,
                        0.25715639999999995,
                        0.25717890000000004,
                        0.25522969999999995,
                        0.25715639999999995,
                        0.25522969999999995,
                        0.25522969999999995,
                        0.2569247,
                        0.25526819999999995,
                        0.2571932,
                        0.2571932,
                        0.2571932,
                        0.2572239,
                        0.2572217,
                        0.24988799999999997
                      ]
                    },
                    {
                      "label": "alpha",
                      "range": [
                        0.005009889800691488,
                        0.009991370754711404
                      ],
                      "values": [
                        0.008589594627760263,
                        0.005285618654081135,
                        0.005107422085956695,
                        0.006477978498703813,
                        0.0055253963019286,
                        0.009591110997023316,
                        0.007946879314458949,
                        0.008947850986193185,
                        0.009795527468761587,
                        0.0075274213110723565,
                        0.007052071559783096,
                        0.007560164713839888,
                        0.009991370754711404,
                        0.009081222642015257,
                        0.007356318096841587,
                        0.006757302458500524,
                        0.006888857711625368,
                        0.0070010137148578495,
                        0.0067464227191909275,
                        0.006607775247460767,
                        0.006209530714738974,
                        0.00607592399007404,
                        0.005900518553346126,
                        0.0059387743959257505,
                        0.005741452054713312,
                        0.0059388138816638715,
                        0.005980845076330009,
                        0.006038537018722019,
                        0.005903726494703698,
                        0.008025422396839715,
                        0.008068587164614543,
                        0.007670222511007804,
                        0.007991047517789701,
                        0.008092254364329492,
                        0.008140244463357243,
                        0.008074743917907126,
                        0.008142900222398218,
                        0.007302830765211219,
                        0.005267318562108731,
                        0.008388400933269284,
                        0.007129548333846737,
                        0.008592132118643684,
                        0.008340550045952515,
                        0.00859740762331929,
                        0.00843351004283165,
                        0.007672284282399858,
                        0.008547650959303153,
                        0.008645787511758806,
                        0.008800539290057032,
                        0.008738789587781936,
                        0.008562490781867129,
                        0.008863303034783266,
                        0.008935704927250432,
                        0.00888870398223739,
                        0.008855979839036587,
                        0.009055038716028783,
                        0.009291440449080148,
                        0.00925423960009603,
                        0.009469420362243151,
                        0.009311686323343085,
                        0.009278652754510173,
                        0.009266498194940092,
                        0.009447318447750591,
                        0.009309645145063005,
                        0.009269127267665106,
                        0.009425449377377855,
                        0.00826739938032732,
                        0.008294176476212035,
                        0.008300073898083762,
                        0.005018654052147158,
                        0.005041739715668515,
                        0.008308338903553395,
                        0.00504938465204752,
                        0.00838398704039256,
                        0.00873808731944745,
                        0.005009889800691488,
                        0.005034850432470685,
                        0.008688470014011256,
                        0.008677076003579556,
                        0.009855269941162714,
                        0.009722957880478495,
                        0.008669335789919415,
                        0.008716862741018629,
                        0.007862300085042281,
                        0.005290263310170902,
                        0.005490503906014262,
                        0.005516679664567518,
                        0.005662083498545819,
                        0.005525062023396311,
                        0.005297618254416269,
                        0.007720498864924512,
                        0.00575800068566575,
                        0.005630091990878659,
                        0.0052109399065069974,
                        0.00912554437502042,
                        0.005196601548124624,
                        0.008491091037673978,
                        0.009111078963979504,
                        0.009133863141040583,
                        0.009139034228703092,
                        0.008478717712713846,
                        0.008515725901470157,
                        0.008491113664998003,
                        0.008591794880091578,
                        0.008550106826739911,
                        0.00861854175228725,
                        0.008633387980733315,
                        0.008948752647324193,
                        0.008615404375946068,
                        0.008628056084760756,
                        0.008711299253981444,
                        0.008662828100438271,
                        0.008927220548432773,
                        0.00877696714766037,
                        0.008211779010357741,
                        0.008785716760316403,
                        0.008790539761669252,
                        0.008722383512883168,
                        0.008202617409947452,
                        0.008802891501294936,
                        0.008210584111625625,
                        0.008210563565998323,
                        0.008197318864259107,
                        0.00835941209299509,
                        0.00833492263367497,
                        0.008393649422575783,
                        0.00838393801676543,
                        0.008374276759999617,
                        0.008415827746409373,
                        0.006351112622150849,
                        0.007912013448058435,
                        0.00841061832644361,
                        0.0070877621734125595,
                        0.007362390471447967,
                        0.007936387923845632,
                        0.006312611057690573,
                        0.00796517348787346,
                        0.007916507557671353,
                        0.007981161199167638,
                        0.007867865993893582,
                        0.00713231110265431,
                        0.007333850382890857,
                        0.007943808917324687,
                        0.007408203897576187,
                        0.007371815203837804,
                        0.007629151633245951,
                        0.007775008688059383,
                        0.007492099054559658,
                        0.007448030378659717,
                        0.007414046891505809,
                        0.0074813521172377336,
                        0.007545855862889212,
                        0.007364888977631442,
                        0.007357016441497898,
                        0.00750531112946989,
                        0.007411172196792117,
                        0.007517770882113254,
                        0.0075284750907962175,
                        0.00760113458009918,
                        0.007591289437391763,
                        0.007583645414699951,
                        0.007577857034169708,
                        0.007627228133326711,
                        0.0077501472892089925,
                        0.007665571996242534,
                        0.00771466995048432,
                        0.007737302296565905,
                        0.00775034273355659,
                        0.0077378503877180696,
                        0.007755926648499696,
                        0.0072352547689069294,
                        0.007745244106548568,
                        0.007745124106712494,
                        0.007238533455074232,
                        0.007243271052534206,
                        0.007173647151382449,
                        0.007246782158410562,
                        0.007298418084467172,
                        0.007827119509227013,
                        0.00723174786109974,
                        0.007185887207767419,
                        0.007243900932205527,
                        0.007246621579538853,
                        0.007220368239061969,
                        0.007230633423371809,
                        0.007202059097488749,
                        0.007174484087032065,
                        0.007121875816303545,
                        0.007243026193018393,
                        0.007079857358595158,
                        0.0069822590872850145,
                        0.006970520075664316,
                        0.006921726299338945,
                        0.006965592954489379,
                        0.007010327136568321,
                        0.007018859622995736,
                        0.006986062434302996,
                        0.007837139077750854,
                        0.007039457762709656,
                        0.007022729238887831,
                        0.007020032754278989,
                        0.006595980160642961,
                        0.00665653864680183,
                        0.006715090640501162,
                        0.0065247063845679425,
                        0.00661014282694712,
                        0.006683132387465882,
                        0.006762469763495614,
                        0.006774318922452027,
                        0.00673379918817534,
                        0.006736923045283333,
                        0.006880004105726992,
                        0.00660284018545741,
                        0.006518448137798235,
                        0.006743162351629159,
                        0.006799193225767692,
                        0.0067966161475819685,
                        0.0067055335606416655,
                        0.006799692153546336,
                        0.00676477826878973,
                        0.0067603398117646145,
                        0.006803454430970397,
                        0.006593754485558881,
                        0.006615620806621881,
                        0.00660174129054028,
                        0.006615726103788079,
                        0.006898885677141209,
                        0.006600749678420652,
                        0.006628991026519314,
                        0.0066141445301188245,
                        0.006908401744522984,
                        0.006893921201086935,
                        0.006912337308072522,
                        0.006882179392003975,
                        0.006683870034297295,
                        0.006442776717788709,
                        0.006422532393564967,
                        0.006448869517956435,
                        0.006400753598777036,
                        0.006401421498831545,
                        0.006483727885342858,
                        0.0065039166464735156,
                        0.006462153189880854,
                        0.006482884646913113,
                        0.006477514773354453,
                        0.006680639762541448,
                        0.0066941689844490235,
                        0.0066937394161027865,
                        0.0061543492359060585,
                        0.006826914651817819,
                        0.006843966937331373,
                        0.00669299342774783,
                        0.006214907419739542,
                        0.006749954754825008,
                        0.006853870422735109,
                        0.00687151185205498,
                        0.006837701237606492,
                        0.006864803695235252,
                        0.007792361089477349,
                        0.007807239104333079,
                        0.0077431399550505035,
                        0.007778483736033926,
                        0.00766485699673497,
                        0.00781847374032242,
                        0.007724025822866058,
                        0.007735942914726618,
                        0.007698428403888268,
                        0.007701367007770667,
                        0.007690029977676086,
                        0.0076585349445590775,
                        0.007895307188614102,
                        0.007683538267083718,
                        0.007677441528308381,
                        0.007675824189671825,
                        0.007720798525779953,
                        0.007689672560502907,
                        0.007623692275535668,
                        0.007665054209043452,
                        0.0065647368968096,
                        0.006559690909251902,
                        0.006602931671022326,
                        0.00654464458656988,
                        0.00665330112770141,
                        0.006536544268541659,
                        0.006617230261255228,
                        0.006633044095631534,
                        0.006654516395732438,
                        0.006634392862012253,
                        0.0067064527885017464,
                        0.006721690863954764,
                        0.006755594481623722,
                        0.006754104555666492,
                        0.006750942547760347,
                        0.007863090227846885,
                        0.007866017988746282,
                        0.0067641000678347295,
                        0.007855568901628104,
                        0.007888783953186238,
                        0.007859023646394464,
                        0.007525532632076615,
                        0.00755242187379748,
                        0.007514940840635229,
                        0.007828645923882122,
                        0.006321705880839772,
                        0.006353809727385175,
                        0.006345948171253658,
                        0.006963064168022867,
                        0.006936048211262013,
                        0.006960162966413956,
                        0.006362946402277978,
                        0.006336972568052757,
                        0.006930101425118931,
                        0.00636577701007989,
                        0.00612255343133111,
                        0.006205286780129795,
                        0.006328065420299109,
                        0.006045217538207302,
                        0.006336128072210632,
                        0.006161640805072339,
                        0.006115019040866761,
                        0.006058383092733453,
                        0.006049256762725532,
                        0.0068377661770214725,
                        0.0064292532585599315,
                        0.006860964064539553,
                        0.006472578167700068,
                        0.00681112186832921,
                        0.0068218571104764906,
                        0.006858213880383808,
                        0.006859383207037545,
                        0.006524792628162556,
                        0.007086306044045569,
                        0.00745733289773379,
                        0.007497137050123547,
                        0.007485953118225405,
                        0.007543980675802965,
                        0.007024221934566094,
                        0.007045260686584481,
                        0.0070604637287306525,
                        0.006984278377838938,
                        0.006998703110063497,
                        0.008045772369534658,
                        0.008108978849002666,
                        0.007024619471698204,
                        0.006939257357029973,
                        0.0069564389544856855,
                        0.00803662722056305,
                        0.00803246442737647,
                        0.008024102582473873,
                        0.008073021628128185,
                        0.007985889957568717,
                        0.006943000052108813,
                        0.007947130616464284,
                        0.006898568873241663,
                        0.008079756458985517,
                        0.00739238439835303,
                        0.007114398852231134,
                        0.007572337010800473,
                        0.007574077430954089,
                        0.007584061694258853,
                        0.007591556843462017,
                        0.007548075020808694,
                        0.007591539450302367,
                        0.007568413336413031,
                        0.007587778540429357,
                        0.00754929764034406,
                        0.006869985657164009,
                        0.007855989583114254,
                        0.007926210921844687,
                        0.007783337943475856,
                        0.006271315389195447,
                        0.006862859455088666,
                        0.006857223823916469,
                        0.007806182234302102,
                        0.007805640542764216,
                        0.006830679133298649,
                        0.006749141915343987,
                        0.0062545614364426,
                        0.0064862477131847045,
                        0.00709301377600877
                      ]
                    },
                    {
                      "label": "colsample_bytree",
                      "range": [
                        0.9300909829307847,
                        0.9595833840180262
                      ],
                      "values": [
                        0.9385307314445429,
                        0.9579596008501592,
                        0.9557079800716425,
                        0.9325101545078358,
                        0.9322714717280214,
                        0.942612085816292,
                        0.9545420728919836,
                        0.9526716031147863,
                        0.9587392417902044,
                        0.9327253907505669,
                        0.9370455575176508,
                        0.9339445146926441,
                        0.9317607903901185,
                        0.9432924473760561,
                        0.9529317762630338,
                        0.9463142730161558,
                        0.9526108961946157,
                        0.9479178895143713,
                        0.9301145331967765,
                        0.9455150333473841,
                        0.9300909829307847,
                        0.9301964440889269,
                        0.9368435524616539,
                        0.9383157777009044,
                        0.9371195474109223,
                        0.9363518861834793,
                        0.9366210400770529,
                        0.9352760704233138,
                        0.9368511340828427,
                        0.9361728597190786,
                        0.9360121770282931,
                        0.9349082360657537,
                        0.9348846132042606,
                        0.9343428004507004,
                        0.9345342171723747,
                        0.9407043155434823,
                        0.9406649501522173,
                        0.9335165774054649,
                        0.9404753023591609,
                        0.933576393581177,
                        0.9327587854706855,
                        0.932864330906498,
                        0.9327561832780369,
                        0.9324369748664796,
                        0.9326732688863902,
                        0.9327532231296537,
                        0.9323684624284896,
                        0.932557736007427,
                        0.9322784004634026,
                        0.932072180770208,
                        0.9318331767162579,
                        0.9318724539778018,
                        0.9316903436141791,
                        0.931681737928292,
                        0.9313184591483825,
                        0.931246791329993,
                        0.9313263637421739,
                        0.931098291986485,
                        0.9385539537325719,
                        0.943550681362027,
                        0.9431333669045286,
                        0.9505068221257024,
                        0.9433808521523733,
                        0.9381875429475904,
                        0.937998680069702,
                        0.9384929216968565,
                        0.9504092943445066,
                        0.9338165956102679,
                        0.9335481633240708,
                        0.9335968051425158,
                        0.9334763567227642,
                        0.9564434907684519,
                        0.9340609039236243,
                        0.9332885362045051,
                        0.933408958967126,
                        0.9337271130078468,
                        0.9328853438743822,
                        0.9354324048810446,
                        0.9567976463188171,
                        0.9354851934558582,
                        0.9357556133531549,
                        0.9358125469119793,
                        0.9354008282802848,
                        0.935134808047183,
                        0.9356404572779073,
                        0.9308396151253646,
                        0.935614803407497,
                        0.9305649712068279,
                        0.9306692450265518,
                        0.9344613927410358,
                        0.9305191590201545,
                        0.9373219718320817,
                        0.9345944635473509,
                        0.930367105136231,
                        0.9374439536433674,
                        0.9374256050956298,
                        0.9344940270531296,
                        0.9326629931721572,
                        0.9372698589035147,
                        0.9393295412199095,
                        0.9323903084669494,
                        0.9324412975354691,
                        0.9325671025132771,
                        0.9324883669264307,
                        0.9323055876859988,
                        0.9325236256310613,
                        0.9322452836727949,
                        0.9394306628182627,
                        0.9364272646946384,
                        0.9319127141618964,
                        0.9419600907484292,
                        0.9419572216159681,
                        0.9330784718666665,
                        0.9318060186888144,
                        0.9595833840180262,
                        0.9331491182858558,
                        0.9331458431755169,
                        0.9330613899443335,
                        0.9330754869327313,
                        0.9330589551007769,
                        0.9341024274673093,
                        0.9338277466810795,
                        0.9340000907712607,
                        0.9338781303057284,
                        0.9340465875666055,
                        0.9339955150819318,
                        0.9340244419358517,
                        0.9339376506733894,
                        0.9360583415275062,
                        0.9361459056277814,
                        0.9349209100537451,
                        0.9349244696273761,
                        0.9359813797109534,
                        0.9364219072815347,
                        0.9361932688943728,
                        0.9352402141762528,
                        0.9309715877453886,
                        0.9442509282568162,
                        0.9349546316027513,
                        0.9349027802231435,
                        0.9450541697948751,
                        0.9363986419351364,
                        0.936818520003286,
                        0.9365203011139593,
                        0.9367585813827893,
                        0.9363393583303193,
                        0.9369456003117023,
                        0.9368839295568576,
                        0.9362269259782607,
                        0.9366375198291517,
                        0.9367700821370043,
                        0.9367771678353336,
                        0.936830468546246,
                        0.9366113145820097,
                        0.9368245665412422,
                        0.9368493840588564,
                        0.9367098876573233,
                        0.9380902558028151,
                        0.9379696932713306,
                        0.9379796341010799,
                        0.938745122183225,
                        0.9379874417178587,
                        0.9378475020357221,
                        0.9378418494572006,
                        0.9377671821188777,
                        0.9378824537003385,
                        0.9378843538615579,
                        0.9361306662289385,
                        0.9376004906553532,
                        0.9359609668151774,
                        0.9361884169203735,
                        0.9360741136270423,
                        0.9362257342326362,
                        0.9359531818624035,
                        0.9389468605568898,
                        0.9357965653364796,
                        0.9360735045081054,
                        0.9373513930729875,
                        0.9390157020861903,
                        0.9388102738863024,
                        0.9387894085002124,
                        0.9387073699391092,
                        0.9355633612354312,
                        0.9389369211811555,
                        0.9386607418057117,
                        0.9355816524344897,
                        0.9387232628677985,
                        0.9387556881043279,
                        0.9399835957306353,
                        0.9399453711152419,
                        0.939488690749592,
                        0.935495431642134,
                        0.9398029467751952,
                        0.9398736951106977,
                        0.9399745913695197,
                        0.9395171294052846,
                        0.9398065558053313,
                        0.9373611553559625,
                        0.9399671162304294,
                        0.9404401565567705,
                        0.9403515728332338,
                        0.940218251575329,
                        0.9402836695588738,
                        0.9410764921848082,
                        0.9403961349987378,
                        0.9415768813398987,
                        0.9412127656498902,
                        0.9411136403091798,
                        0.941144707988193,
                        0.9411153441785843,
                        0.9414833878956992,
                        0.9417102883222874,
                        0.941564428751354,
                        0.941322995382999,
                        0.9415511285330697,
                        0.9412063855739196,
                        0.9413922204180497,
                        0.9414561908207915,
                        0.9414442017286588,
                        0.9417121860996865,
                        0.9416826431192451,
                        0.9420829267191806,
                        0.9422337496347816,
                        0.9422339543146661,
                        0.9426184087993245,
                        0.942444183756586,
                        0.94226390889869,
                        0.9427838789273465,
                        0.943041228497843,
                        0.9408497080103855,
                        0.9426622871257356,
                        0.9409303682251833,
                        0.9408393866032119,
                        0.9409320339665984,
                        0.9408660290374692,
                        0.940661786073528,
                        0.9399791259767775,
                        0.939966291769624,
                        0.9397056156032642,
                        0.9400793301906584,
                        0.9399966112016808,
                        0.9399154118929349,
                        0.940149298172004,
                        0.9405314972700245,
                        0.9407017387512354,
                        0.9408535189682359,
                        0.9407459927639139,
                        0.9408258238959426,
                        0.9406876599641585,
                        0.9408175414263144,
                        0.9407460113035312,
                        0.9408103470377334,
                        0.9410845055250054,
                        0.9409494115018604,
                        0.9393125603107179,
                        0.9417678709614842,
                        0.9439501705966682,
                        0.9436637963690797,
                        0.9393440637396585,
                        0.9417351264074563,
                        0.9417181660117897,
                        0.943749342759868,
                        0.9394002098881952,
                        0.9415654642504745,
                        0.941710655802752,
                        0.9414124043640071,
                        0.939370519984805,
                        0.9413185538340119,
                        0.9418119202349737,
                        0.9416736856155757,
                        0.9420257986321999,
                        0.9417431829247179,
                        0.9420436445997282,
                        0.9420492540911305,
                        0.9421326974567944,
                        0.9418448834190069,
                        0.94232440426788,
                        0.9426989821751552,
                        0.9426553484920124,
                        0.9424011844496899,
                        0.9426587588104137,
                        0.942909736238688,
                        0.9430731889090088,
                        0.9425670276086981,
                        0.9428098236737225,
                        0.9413980864298157,
                        0.9412928463742054,
                        0.9413535230617465,
                        0.9411614298886419,
                        0.9412568270841227,
                        0.9544143194021838,
                        0.941342103209767,
                        0.9413560374468365,
                        0.9402200394088065,
                        0.9460186152914338,
                        0.9404046103311063,
                        0.9404099584461443,
                        0.9404070785834739,
                        0.9404567578951858,
                        0.9404280810618996,
                        0.940316157033483,
                        0.9404407321004413,
                        0.9467561224657001,
                        0.9402141709135876,
                        0.9456816746805475,
                        0.9472458834513457,
                        0.9395271749028521,
                        0.9449655167640862,
                        0.9457745524741875,
                        0.9393612219344947,
                        0.9461355226201675,
                        0.940947860809054,
                        0.9458281399417163,
                        0.9469883577897783,
                        0.9467814457843597,
                        0.9470569533108922,
                        0.9465089360719436,
                        0.9474462821891815,
                        0.9485319817132603,
                        0.947214273930322,
                        0.9397848878861123,
                        0.947149565915273,
                        0.9476770601605786,
                        0.9485876475704443,
                        0.9483845774524646,
                        0.9487630177051379,
                        0.9484809519391949,
                        0.9481684321289303,
                        0.9452687110081327,
                        0.944484675227464,
                        0.9463548712029249,
                        0.9483647514440966,
                        0.9491579429795378,
                        0.94480154777867,
                        0.9448528251903618,
                        0.9462769072349508,
                        0.9464417871484135,
                        0.9449179040887055,
                        0.9451869722252045,
                        0.9444263933577802,
                        0.9449377804747062,
                        0.9441760611744606,
                        0.9443676395806962,
                        0.9451949098267232,
                        0.9452894788486097,
                        0.9453915345571954,
                        0.9442843932273571,
                        0.9457072311607491,
                        0.9453922116669374,
                        0.9455119261329055,
                        0.9460128093605955,
                        0.9456511647284678,
                        0.94592238029099,
                        0.945962519956507,
                        0.9459954632106345,
                        0.9462413454806863,
                        0.9458378926130447,
                        0.9463940450431825,
                        0.9441564714107358,
                        0.9467458302929479,
                        0.946694263041543,
                        0.9443940706073132,
                        0.9474918402345258,
                        0.944586753405946,
                        0.9445899050833251,
                        0.9467239703054531,
                        0.943376983639095,
                        0.9434323823656939,
                        0.9434697495382167,
                        0.9436542291848318,
                        0.9434262324874153,
                        0.9437779553504975,
                        0.9477775568211606,
                        0.939596676564523,
                        0.943397426084893,
                        0.9436938558258321,
                        0.9393653686895015,
                        0.9395599414116251,
                        0.9477767406895474,
                        0.9478871563624949
                      ]
                    },
                    {
                      "label": "eta",
                      "range": [
                        0.20591800940998461,
                        0.2149445306643157
                      ],
                      "values": [
                        0.20836006255735828,
                        0.2076328239227961,
                        0.20922355853882413,
                        0.20892729969256307,
                        0.20969689096154429,
                        0.21341819631571582,
                        0.21217248129248145,
                        0.21289664885331044,
                        0.20648107011316402,
                        0.2098336146388696,
                        0.20974630466663327,
                        0.21003987768840895,
                        0.21105212334965917,
                        0.21196190893667513,
                        0.20772722656638096,
                        0.21170396871488353,
                        0.21310823357723827,
                        0.21139301007864406,
                        0.21145775606983028,
                        0.20591800940998461,
                        0.2149445306643157,
                        0.21462097428075838,
                        0.21077013559480975,
                        0.21079760873527814,
                        0.2145996866974866,
                        0.21040347323058492,
                        0.21481857834850593,
                        0.21484426965638592,
                        0.21037598124328463,
                        0.20874566252057203,
                        0.20887098334598164,
                        0.2089742108443338,
                        0.20885022342576445,
                        0.2088303066526164,
                        0.20889428730128595,
                        0.2082486879521577,
                        0.2088490746108834,
                        0.20784524192100984,
                        0.20953508437337448,
                        0.20953428367026788,
                        0.20971057516994723,
                        0.2098136726781213,
                        0.20967434607838023,
                        0.20956951095596738,
                        0.20958972002298248,
                        0.20959295838442085,
                        0.20959419539399204,
                        0.209629143632365,
                        0.20947377939284764,
                        0.20945249667448743,
                        0.20688399805791888,
                        0.20952804403116482,
                        0.207192552964503,
                        0.21005508884095359,
                        0.21003769034026393,
                        0.2072653724439593,
                        0.2101279200923025,
                        0.21021312394419178,
                        0.21013348055730982,
                        0.2101896983803809,
                        0.2101041217753779,
                        0.21019066609008932,
                        0.21045855441015032,
                        0.21002327277929578,
                        0.21092500507554007,
                        0.21072288011362406,
                        0.21068878520950374,
                        0.21079615741385038,
                        0.2091870583772791,
                        0.21106620170239954,
                        0.2110776884543835,
                        0.21097911221119758,
                        0.20920088025586003,
                        0.2112376632337586,
                        0.2092792542420501,
                        0.20922503153884575,
                        0.20919642191195065,
                        0.20923425899358378,
                        0.208490900292633,
                        0.20854255611524816,
                        0.20925863791429825,
                        0.20985558699585113,
                        0.20989862341366583,
                        0.20849161472555408,
                        0.20860355728499572,
                        0.20981172537195095,
                        0.2097688377654665,
                        0.20986423307705382,
                        0.20988693356504506,
                        0.2098016739323429,
                        0.20987969410814641,
                        0.20984828284567789,
                        0.20983903085561523,
                        0.2097892823128339,
                        0.20807396638262976,
                        0.2104395966552188,
                        0.2089846525960839,
                        0.21051511996114705,
                        0.20937255765819915,
                        0.21045765497992636,
                        0.21042170592502812,
                        0.21047096753668482,
                        0.20938818774233325,
                        0.20940176556596818,
                        0.20943613045858608,
                        0.20950365773155818,
                        0.20902926707085087,
                        0.2095102089916373,
                        0.20900088486446833,
                        0.20964572033827253,
                        0.20957126804321008,
                        0.20956688814404864,
                        0.2096209783345439,
                        0.21025143865380946,
                        0.21026493005294247,
                        0.20875891098747548,
                        0.20876024615106456,
                        0.2100507034986861,
                        0.20932752832816479,
                        0.21029413681465034,
                        0.21002975225373158,
                        0.21250847729902977,
                        0.2100330701632101,
                        0.2100391956096816,
                        0.21003864191461386,
                        0.21373928256687066,
                        0.21006642479240087,
                        0.21247728522496326,
                        0.20929614524229997,
                        0.2138307671306405,
                        0.20927891921824257,
                        0.20923661459706902,
                        0.20929569812168342,
                        0.2105977680877294,
                        0.21066091267986817,
                        0.20966118831117903,
                        0.20964685196492586,
                        0.21065959120391153,
                        0.20973422487833596,
                        0.20968926009905403,
                        0.20969561137350243,
                        0.21064136798917424,
                        0.2107537773434914,
                        0.21147243866983909,
                        0.21141569158926043,
                        0.21078967826064188,
                        0.2117742779286233,
                        0.21063167589976603,
                        0.2113760120382558,
                        0.21170941668963278,
                        0.21147061845772208,
                        0.21160425140331007,
                        0.21134674951418356,
                        0.21187242250336827,
                        0.21142509709541296,
                        0.21171670458950043,
                        0.21149810714622122,
                        0.21151449231690572,
                        0.21177681775210008,
                        0.21189528813007474,
                        0.21196792795454597,
                        0.21121471741435918,
                        0.21118624989045484,
                        0.2111780219250121,
                        0.21206360627467957,
                        0.21212555486819062,
                        0.21202013331575228,
                        0.21113393489420326,
                        0.21110855889015862,
                        0.21120382653130768,
                        0.21094134356976788,
                        0.21097034545309512,
                        0.2109317579937233,
                        0.21093269786024876,
                        0.2109125435138493,
                        0.21109271811428165,
                        0.2109054494643582,
                        0.21088737375559705,
                        0.21093455942388636,
                        0.21103693613829866,
                        0.21094104922941928,
                        0.21102528412164331,
                        0.21097297742230087,
                        0.21094421003102629,
                        0.21094443573093036,
                        0.2110197212874356,
                        0.2109855218296618,
                        0.2110833434563816,
                        0.21117058565252006,
                        0.21120625317087519,
                        0.21114020636683012,
                        0.21110806838050414,
                        0.21116092411232582,
                        0.21117704966299353,
                        0.21066213263742808,
                        0.21061255102948684,
                        0.21120611055610605,
                        0.21062304747682092,
                        0.21076679981391708,
                        0.21121174264869078,
                        0.21121220695984969,
                        0.21127697745081056,
                        0.2112133862203816,
                        0.2111889554462233,
                        0.21126430461734877,
                        0.21119460195354378,
                        0.21122300391495097,
                        0.21127377834473934,
                        0.21125050175898483,
                        0.2112144940106103,
                        0.21129344705699254,
                        0.211316293354912,
                        0.21131377453300854,
                        0.21136214070604306,
                        0.2112850774028023,
                        0.21129758346265684,
                        0.21134437698016936,
                        0.21132100056222117,
                        0.21132528831703074,
                        0.2113491977210432,
                        0.2115652256084601,
                        0.21151826495122636,
                        0.2115968587155931,
                        0.2115544400121897,
                        0.2114862964362308,
                        0.21163982676971213,
                        0.21157862434181687,
                        0.2114810486185562,
                        0.2116283474743856,
                        0.2115926511808577,
                        0.21116651044957002,
                        0.21113863426588889,
                        0.2111477851343666,
                        0.21114958452594731,
                        0.21108679437067765,
                        0.21111978213529328,
                        0.21111929119069123,
                        0.2111899001123254,
                        0.2111106436565746,
                        0.21112346762893747,
                        0.21076507398538616,
                        0.21113003266824748,
                        0.2108159854526692,
                        0.21084558551556826,
                        0.2108225694564076,
                        0.210829266917227,
                        0.2108274675998525,
                        0.21080265205785723,
                        0.21085292410152967,
                        0.21081608420101725,
                        0.21136206368880442,
                        0.2113709778978869,
                        0.2113845972166928,
                        0.2113958814327769,
                        0.21137241651083374,
                        0.2113699452954162,
                        0.21135020508748667,
                        0.21137853864522116,
                        0.2110215870853989,
                        0.21181626343264617,
                        0.21114789981084098,
                        0.21182947717100534,
                        0.21104311325704814,
                        0.2110299161433806,
                        0.21102161187762772,
                        0.21103168478508824,
                        0.2110519025292412,
                        0.21107893693534005,
                        0.21103120225873634,
                        0.2110538824680202,
                        0.21103564905573047,
                        0.2110145289106145,
                        0.21053400496789879,
                        0.21099873506117509,
                        0.21050990403297704,
                        0.2104727938961832,
                        0.21049059650372212,
                        0.21169411263537405,
                        0.21051155923033693,
                        0.21050014552877083,
                        0.21164178950806856,
                        0.2116539872233884,
                        0.2116961828986039,
                        0.21155202416727778,
                        0.2116660867767039,
                        0.21123048587886858,
                        0.21123241315309924,
                        0.21155184857629067,
                        0.2112737142274454,
                        0.21126448582470056,
                        0.21233568982225362,
                        0.211254909087075,
                        0.2112336551759653,
                        0.2112334341774436,
                        0.21072986521404433,
                        0.21072591004536295,
                        0.2107403827382347,
                        0.21079089474452245,
                        0.21071194134243149,
                        0.21077518016973198,
                        0.21072378054112492,
                        0.2107228652545446,
                        0.2107859241820559,
                        0.21067556980056648,
                        0.2107159895804203,
                        0.21070258953760235,
                        0.21093884085913678,
                        0.21093593806053493,
                        0.21065284880118376,
                        0.21027397252593102,
                        0.2103101026005075,
                        0.21088670459487968,
                        0.21037546085046316,
                        0.2104055441422164,
                        0.21020519522728828,
                        0.21039968673339263,
                        0.2106018163556779,
                        0.2103057656753898,
                        0.2103304641425127,
                        0.2106711102742661,
                        0.2106568139816781,
                        0.2107485550211112,
                        0.21067332386033674,
                        0.21081381930949103,
                        0.2107946467121563,
                        0.2107973429262528,
                        0.2108056422735722,
                        0.21086234796710338,
                        0.21086290783263398,
                        0.21089079701997276,
                        0.21087907377960005,
                        0.21094073801039395,
                        0.2109122863716097,
                        0.21097740898898548,
                        0.21095536609225748,
                        0.21098517252997454,
                        0.2109583700814671,
                        0.21097332550964515,
                        0.21100505930055194,
                        0.21101733185953073,
                        0.2105572169641442,
                        0.21099624339735906,
                        0.21059546831438955,
                        0.21053112893242718,
                        0.2106060383128591,
                        0.2105589593175356,
                        0.21065230678011368,
                        0.21051218563283874,
                        0.21044840743447854,
                        0.21056623281066641,
                        0.21056165799770724,
                        0.21061430941219914,
                        0.2106939385870455,
                        0.21079935579578743,
                        0.2110379164479231,
                        0.21102250352208624,
                        0.2109916855556684,
                        0.21083089321766135,
                        0.21082998329799732,
                        0.21080505084179899,
                        0.21088338632885847,
                        0.2110318921375686,
                        0.2108744303515034,
                        0.21086060687737773,
                        0.21082980774516338,
                        0.21145488163359208,
                        0.21142100965870986,
                        0.211055613674533,
                        0.2114858672437119,
                        0.21142853836135653,
                        0.21142981487785562,
                        0.21145458339071027,
                        0.21110931343427908,
                        0.2110902533189999,
                        0.21022619982562574,
                        0.21028665079752126,
                        0.21021635582195497,
                        0.21111474540305314,
                        0.21111433674707453,
                        0.21020883156290152
                      ]
                    },
                    {
                      "label": "gamma",
                      "range": [
                        0.008055458876769951,
                        0.02999597387628421
                      ],
                      "values": [
                        0.013646090786889345,
                        0.025510642575480906,
                        0.015534894901756356,
                        0.019987069001167937,
                        0.016250253244916957,
                        0.021805722416554138,
                        0.029054965778990634,
                        0.025547819214339358,
                        0.012840817763425041,
                        0.01046465538305304,
                        0.012477482275246674,
                        0.016982713100363957,
                        0.008996326054273458,
                        0.0290246871161828,
                        0.02139629831593335,
                        0.010239011244634994,
                        0.019317991369759088,
                        0.008684434651039437,
                        0.008055458876769951,
                        0.019929716318160297,
                        0.019962607103801357,
                        0.017950109205445586,
                        0.018932916133420453,
                        0.018113592970090624,
                        0.025398565321569047,
                        0.011763499628149028,
                        0.011088988550994626,
                        0.011366379832855255,
                        0.011607039316295403,
                        0.012132401859424331,
                        0.011555504061826509,
                        0.01158104548013641,
                        0.011802419103099863,
                        0.014667202437829024,
                        0.014425255083324819,
                        0.01357085591799859,
                        0.01438265790920884,
                        0.01428952573101427,
                        0.014474959797431214,
                        0.013762732591409732,
                        0.022898576182084827,
                        0.02357942712834634,
                        0.022899083674191544,
                        0.009830575492501091,
                        0.010121355451780282,
                        0.023220898226334656,
                        0.00968331345540792,
                        0.016300066599813524,
                        0.022936857811758485,
                        0.0231574703762468,
                        0.023307729835276687,
                        0.02308593710748954,
                        0.023310456290551177,
                        0.023053904891983217,
                        0.02314825489350549,
                        0.023397952931283657,
                        0.024636497837893182,
                        0.024737270741220146,
                        0.02496534037730698,
                        0.02810166065747066,
                        0.026349196781370172,
                        0.027156191743005962,
                        0.02695881438558006,
                        0.02682264571504016,
                        0.027106683459777535,
                        0.02732149921623625,
                        0.026449051553412418,
                        0.026246329325960886,
                        0.016023911012324067,
                        0.016050242177972775,
                        0.022156837206243007,
                        0.015450958144461333,
                        0.022019244732502316,
                        0.022090375007264882,
                        0.016065401485352977,
                        0.022367202424326296,
                        0.02127718202988605,
                        0.022131908259902966,
                        0.022055029558733702,
                        0.024105717715337496,
                        0.020688748021496665,
                        0.02124508279061624,
                        0.01730339434545881,
                        0.017411863889762295,
                        0.017542669148905274,
                        0.020539358735728017,
                        0.024038215888231573,
                        0.02086863821813495,
                        0.02405842845135786,
                        0.017205590687810232,
                        0.01756352900100012,
                        0.01919746104415076,
                        0.019113043888950312,
                        0.023977581295498245,
                        0.01839523586507354,
                        0.022799027304045698,
                        0.02263626442442984,
                        0.0153700238347871,
                        0.02131388877269201,
                        0.022665198391198783,
                        0.022443927901077028,
                        0.022433243006642137,
                        0.02265380536180103,
                        0.022726901438324613,
                        0.01678323226705188,
                        0.021354266876589544,
                        0.012993956460620496,
                        0.01991075551153421,
                        0.012736251075112651,
                        0.016451177291759374,
                        0.012842681648344217,
                        0.01994320924344572,
                        0.01988216242270916,
                        0.02375812108686844,
                        0.02365385141222315,
                        0.023617757369170003,
                        0.02368847880670466,
                        0.023719649974896416,
                        0.023624428737932517,
                        0.023567564955788697,
                        0.02372980102250248,
                        0.02350958599995436,
                        0.0256276034255795,
                        0.024535133553282816,
                        0.025535870967960263,
                        0.00921849361110653,
                        0.024439771918823266,
                        0.011025538579138575,
                        0.02444341521799192,
                        0.01359573765415461,
                        0.025453499846945726,
                        0.02435463107045356,
                        0.022823821018507596,
                        0.024320642674562805,
                        0.024396570763063685,
                        0.024338828247805647,
                        0.02491442720518204,
                        0.025895937655022534,
                        0.025980307452979405,
                        0.025159302259939564,
                        0.025783633046599246,
                        0.024865029328088775,
                        0.02595090051513148,
                        0.026157033471995734,
                        0.02583714072574628,
                        0.025113254215391335,
                        0.024941761433204097,
                        0.015066914862829073,
                        0.02532336114463114,
                        0.025285185907426868,
                        0.025484469679270445,
                        0.02532472573287807,
                        0.0249580963589055,
                        0.02744301623780569,
                        0.026649390524614604,
                        0.027810716536874742,
                        0.02771703523561855,
                        0.02802010324327296,
                        0.026334981532336994,
                        0.02781334306034147,
                        0.026487830496455284,
                        0.02667638137938978,
                        0.02627048769193617,
                        0.02625989041870047,
                        0.026250110360307125,
                        0.02492405728947659,
                        0.026008588739015334,
                        0.025998788648274603,
                        0.024763566469086628,
                        0.024822425086274726,
                        0.02597363310374756,
                        0.025974728912328833,
                        0.024834806310528267,
                        0.025784516625564184,
                        0.02581874947240347,
                        0.0253743961340404,
                        0.02521400251527843,
                        0.025271326174839,
                        0.025655788779119466,
                        0.02698258255513927,
                        0.025808887746615806,
                        0.025874793767993242,
                        0.026997223876783008,
                        0.026990178949997515,
                        0.02694248858424343,
                        0.025906899447900263,
                        0.02703352031796937,
                        0.02702968991569078,
                        0.026934641757908336,
                        0.026838621162675873,
                        0.0243393603659028,
                        0.024447131510588027,
                        0.02892249945024649,
                        0.024347360025838847,
                        0.025537355670443417,
                        0.024199016422664688,
                        0.02855620738437317,
                        0.028635462030973686,
                        0.028454902597227966,
                        0.026660077267120545,
                        0.0296408482014678,
                        0.026499007846075326,
                        0.028776188328052413,
                        0.029122651549919325,
                        0.029646874835480914,
                        0.02834088293879909,
                        0.0287443054458947,
                        0.029313737208931778,
                        0.02848321862093026,
                        0.028930442193709396,
                        0.028701207738561066,
                        0.028199668358786966,
                        0.028580457965887523,
                        0.028623097764522893,
                        0.02842943655321202,
                        0.028451949426468958,
                        0.028501047492760313,
                        0.02857188102403316,
                        0.028492385056586227,
                        0.029023476874657776,
                        0.029219649683503872,
                        0.028990118360406908,
                        0.029133864810553366,
                        0.029058251887028597,
                        0.029110577770283946,
                        0.02922025095332241,
                        0.029217203380282702,
                        0.029167426896660357,
                        0.029371328246356868,
                        0.029685105852504414,
                        0.02980921060502087,
                        0.029931093371941112,
                        0.02960072749390825,
                        0.027450625873434196,
                        0.028085604742608454,
                        0.029911553828847755,
                        0.02772638322621283,
                        0.028074087120559935,
                        0.027896655468950583,
                        0.02798245244986702,
                        0.027980479554901995,
                        0.027486617414072538,
                        0.027456698696949503,
                        0.028124832031556385,
                        0.02753452442262428,
                        0.027933124659471408,
                        0.028284169964928517,
                        0.027600006608776734,
                        0.027464420033807547,
                        0.028771852703179033,
                        0.02866819718685121,
                        0.028721319290986896,
                        0.028597722907299214,
                        0.0287929152878909,
                        0.028798133131401657,
                        0.02881735141533259,
                        0.028877167236967323,
                        0.02641628783132807,
                        0.026348776735623632,
                        0.02644912095026132,
                        0.026433091559096424,
                        0.026540464263679463,
                        0.028167713539502925,
                        0.02999597387628421,
                        0.026386289074383628,
                        0.029972379727848344,
                        0.02822381060598781,
                        0.029930830946604668,
                        0.029859327742955136,
                        0.029959963351190406,
                        0.027274287066384417,
                        0.0293756159124548,
                        0.027316036988389216,
                        0.029523776549873867,
                        0.02966177509094367,
                        0.02948606743924183,
                        0.02937427268804766,
                        0.029440671086853814,
                        0.029344572883904952,
                        0.029424365249868873,
                        0.029520750053185787,
                        0.029477327953983643,
                        0.029149380694864176,
                        0.028171219017952383,
                        0.02820864588716397,
                        0.028198837293856794,
                        0.028265548035263523,
                        0.028204997407225835,
                        0.028277331425229205,
                        0.028174923157879655,
                        0.028200181770621745,
                        0.02998454754070056,
                        0.028122934257140405,
                        0.027929659413942518,
                        0.027676003820711035,
                        0.027800814937919777,
                        0.028961127070849753,
                        0.027697213404476298,
                        0.027726035535003486,
                        0.02762821142205821,
                        0.02764000658677876,
                        0.027525568620848834,
                        0.027387006390672233,
                        0.027592122497948367,
                        0.02755218048079458,
                        0.027321206576421654,
                        0.027331996983828752,
                        0.02729709664956599,
                        0.027453830151863017,
                        0.027377295421443675,
                        0.027336411799428327,
                        0.027263121561703324,
                        0.02718951180727542,
                        0.0272015104157097,
                        0.027288620332350664,
                        0.027235727787494796,
                        0.027195453200536877,
                        0.027150293658394543,
                        0.027081952068218167,
                        0.02779218200303551,
                        0.027738594600201106,
                        0.02777089527926771,
                        0.02788652744163095,
                        0.027777854614512237,
                        0.027837990969761136,
                        0.02788795639422333,
                        0.027905160749772985,
                        0.027805683043441862,
                        0.027823658715002947,
                        0.02787986957363947,
                        0.02888852470848853,
                        0.028794921049946895,
                        0.02854807943697492,
                        0.028740391319127194,
                        0.028538634690189777,
                        0.028568628142424585,
                        0.02678493392132992,
                        0.026765881845812675,
                        0.02677480031147627,
                        0.0285663451993154,
                        0.028235165140926874,
                        0.026809816021562766,
                        0.02673320672478215,
                        0.026871138905233224,
                        0.029981881819994914,
                        0.029130287081983,
                        0.026990537891411225,
                        0.029867918181110682,
                        0.029856029590411285,
                        0.026803341651114594,
                        0.026825256650754165,
                        0.027594284895915082,
                        0.02692938102715826,
                        0.02754957105349953,
                        0.027428438682660535,
                        0.0275965334974417,
                        0.02756689735995033,
                        0.02754364399590406,
                        0.027509165434166448,
                        0.02752249005991369,
                        0.027531685235985252,
                        0.02808360740568786,
                        0.02806154524976328,
                        0.028252189937052134,
                        0.029170022187455097,
                        0.02814495732604533,
                        0.028121524258866906,
                        0.028110201245256868,
                        0.028216294182378417,
                        0.028207420792006062,
                        0.028303591345894663,
                        0.028225515578901315,
                        0.0265264550779504,
                        0.029037743377745746,
                        0.028462219417182917,
                        0.027036986212016403,
                        0.02897010761295469,
                        0.008068642975245555,
                        0.026295215445433773,
                        0.027120253117413364
                      ]
                    },
                    {
                      "label": "scale_pos_weight",
                      "range": [
                        1.5301231620400317,
                        1.549243022311114
                      ],
                      "values": [
                        1.5334618417524855,
                        1.539676638478191,
                        1.5488829614194435,
                        1.5452518586417758,
                        1.5354472651931557,
                        1.549243022311114,
                        1.5306078783981292,
                        1.5307380066441212,
                        1.5392391385794857,
                        1.5434995652966343,
                        1.534415173133456,
                        1.5314191636586745,
                        1.5345680269074744,
                        1.5417853906923924,
                        1.544517419275331,
                        1.5481315751009312,
                        1.546847062274494,
                        1.5434524541962595,
                        1.5452946320552028,
                        1.5447764194833224,
                        1.5452274720645993,
                        1.545290540196808,
                        1.5421327241486604,
                        1.5416201452904699,
                        1.5419737312068091,
                        1.5374578438038555,
                        1.5373020223900178,
                        1.5374181350071199,
                        1.5372163991429526,
                        1.538115663140904,
                        1.5417125287692381,
                        1.5384182300330203,
                        1.5372158662409219,
                        1.5369688388299834,
                        1.5468457915514782,
                        1.5324150091644895,
                        1.5324178454364297,
                        1.5352536418899747,
                        1.5355602713697742,
                        1.5355072521167257,
                        1.5349253452826273,
                        1.5402399388603272,
                        1.5358117660264383,
                        1.5350361000890393,
                        1.535621451758342,
                        1.5357411349613463,
                        1.5400633664628267,
                        1.5358338356689991,
                        1.5360647615534622,
                        1.536054753641849,
                        1.536114759708228,
                        1.536098097025564,
                        1.5404331756420802,
                        1.540350853521867,
                        1.5341657368711294,
                        1.5345152636740707,
                        1.5342960027849724,
                        1.5344682012645905,
                        1.534089139712349,
                        1.5392252501702326,
                        1.5340826058007206,
                        1.5410124877452829,
                        1.538455419495004,
                        1.5388996916884894,
                        1.5392301401179307,
                        1.5390947620666853,
                        1.539046756089369,
                        1.5408701530248075,
                        1.5405600865751539,
                        1.5407721627577124,
                        1.5392967866266272,
                        1.5425411927761168,
                        1.5365780144323846,
                        1.5365399766672354,
                        1.5426951465411745,
                        1.5350475507632237,
                        1.5301231620400317,
                        1.5366388393732306,
                        1.5431496434069358,
                        1.5366226131144438,
                        1.5313215052618434,
                        1.537922753893052,
                        1.5349918978372536,
                        1.5350680257545306,
                        1.5353093477062851,
                        1.5350222700113543,
                        1.5350884958000797,
                        1.5350153827408477,
                        1.5350331882342938,
                        1.5380134252904496,
                        1.5378685071742748,
                        1.5335866603373247,
                        1.5380861815308227,
                        1.5380902980326592,
                        1.5397687231991193,
                        1.5398483978152473,
                        1.537721393152204,
                        1.5359100645973212,
                        1.540086432934546,
                        1.532680036900656,
                        1.5399124537254874,
                        1.535976626593068,
                        1.5359363423756967,
                        1.535940679617531,
                        1.535880837092094,
                        1.5325757734786138,
                        1.534657955414332,
                        1.5323772481303206,
                        1.5369619285798883,
                        1.5336650960362677,
                        1.5368797745225076,
                        1.5369438593769698,
                        1.5336985439347866,
                        1.5337259433724537,
                        1.541228018536704,
                        1.535559106555219,
                        1.5355599575409828,
                        1.5362339280076331,
                        1.535542783581175,
                        1.5363005797047855,
                        1.5355417685175272,
                        1.5354395243389456,
                        1.5363207209443697,
                        1.5363779343679802,
                        1.5385949998984134,
                        1.5385820681211508,
                        1.5362486372791702,
                        1.536452566748857,
                        1.5345871329387997,
                        1.5347798887138848,
                        1.5385183017626884,
                        1.5347200103353653,
                        1.5374400323267396,
                        1.5374736636565003,
                        1.5373487706270734,
                        1.5375305360307918,
                        1.5352686759595522,
                        1.5374482674197454,
                        1.5376277534178044,
                        1.5341972160252606,
                        1.5374456670404046,
                        1.5376219985587056,
                        1.5374611435361278,
                        1.537462874995137,
                        1.5374719981218414,
                        1.5374441803376575,
                        1.5373330138634802,
                        1.5375060690632152,
                        1.5383521210303432,
                        1.5386533503049922,
                        1.5384317250313264,
                        1.5387848037185021,
                        1.5382535136769282,
                        1.5383329002461892,
                        1.5384188119448605,
                        1.5382823369283245,
                        1.5382955753990122,
                        1.5382816554098575,
                        1.5374795628527353,
                        1.5372751097886108,
                        1.5394599617607139,
                        1.53722873071085,
                        1.5373054933634454,
                        1.5373436336325907,
                        1.5373948015521417,
                        1.537175870838878,
                        1.5372242531853944,
                        1.5393464591998876,
                        1.5377741642621783,
                        1.5388373859408035,
                        1.5377066703479998,
                        1.53890910391906,
                        1.5389053826192791,
                        1.5377759833595082,
                        1.5389525102375594,
                        1.5387876068693807,
                        1.5377688048409426,
                        1.537727643764285,
                        1.5378456161322198,
                        1.5378613791687228,
                        1.5377056816620087,
                        1.5377393022790753,
                        1.5378104906058903,
                        1.5378601109814214,
                        1.5395517620236008,
                        1.5395077729084898,
                        1.5393729854911378,
                        1.5388987079641265,
                        1.5392778466791668,
                        1.5394463064936463,
                        1.5391305241313338,
                        1.5389210174364985,
                        1.5390022003464374,
                        1.5390941673308505,
                        1.5390367509839102,
                        1.5388500274589823,
                        1.539159842373928,
                        1.5388108953476418,
                        1.5388827706076076,
                        1.5388975339522215,
                        1.5387993346774107,
                        1.5398447254212586,
                        1.540272979976081,
                        1.5400073677418535,
                        1.539885953520639,
                        1.5399715260748998,
                        1.539871464740689,
                        1.5399671789069,
                        1.5396994510619433,
                        1.5397425485144876,
                        1.5401227265309487,
                        1.5404513856940598,
                        1.540307316839254,
                        1.5402620297496734,
                        1.540494276063179,
                        1.5405009133637697,
                        1.5397053842809658,
                        1.5405805415860572,
                        1.5403684964041149,
                        1.540509371285683,
                        1.5405907772715042,
                        1.54131191208876,
                        1.5411025079263607,
                        1.5409782282520255,
                        1.5413689720410408,
                        1.5409829225208993,
                        1.54129087309536,
                        1.5413649063412802,
                        1.53965527343084,
                        1.5396267588486436,
                        1.5396105705308416,
                        1.5397956344957968,
                        1.5396636855253294,
                        1.5395727131121344,
                        1.5397452893436387,
                        1.5397028576512257,
                        1.5392698689547912,
                        1.5393235716046505,
                        1.539337535621359,
                        1.5392568355045093,
                        1.5392344821452946,
                        1.5401115477723977,
                        1.5401350807254452,
                        1.5401000744720952,
                        1.5401303692399047,
                        1.5400712254548325,
                        1.5401019121799708,
                        1.5400329005791895,
                        1.5399650348611165,
                        1.5401003118744996,
                        1.5398112532794814,
                        1.5400104888972919,
                        1.5397579019816658,
                        1.5396779131253988,
                        1.5395223473174968,
                        1.5398721755813272,
                        1.5396279718286123,
                        1.5396918038883374,
                        1.5395340451846948,
                        1.540711628662482,
                        1.5406238986181817,
                        1.5407791825550927,
                        1.5404894768032553,
                        1.540556391343747,
                        1.5407709311656435,
                        1.540730331802296,
                        1.5406336474645295,
                        1.5386433717947314,
                        1.5407497105038734,
                        1.5405087383856018,
                        1.5386554974515796,
                        1.5385839805609682,
                        1.5416886484629246,
                        1.5408996712221295,
                        1.5408308257615275,
                        1.5419062681733313,
                        1.542004135557865,
                        1.5420743605497584,
                        1.542088309397299,
                        1.542050384850715,
                        1.5420072536139982,
                        1.5404397898305144,
                        1.5403286646989278,
                        1.5403921903435747,
                        1.5404314486301747,
                        1.54028384681747,
                        1.5403551424551165,
                        1.5404022203524927,
                        1.5471546808376202,
                        1.540351489948944,
                        1.5403594510312713,
                        1.5414599510191471,
                        1.5413578447644836,
                        1.5412327301652688,
                        1.5413600661646663,
                        1.5414917261050964,
                        1.5410238423331388,
                        1.5412178435058699,
                        1.5408879071194272,
                        1.5409871099568246,
                        1.5399073215882737,
                        1.5409325899061235,
                        1.5410438793213423,
                        1.540980167685914,
                        1.5408673474654464,
                        1.5408922180227898,
                        1.5398548045099292,
                        1.5442517412036183,
                        1.5408746904796897,
                        1.5398650608443816,
                        1.5415106433066705,
                        1.5428679639845009,
                        1.5424421433218258,
                        1.5425758204024365,
                        1.541542520312799,
                        1.5416032972492584,
                        1.5415592399577032,
                        1.5416228317062446,
                        1.5424961777492117,
                        1.5415249595761935,
                        1.5415512003582748,
                        1.5415887512553947,
                        1.54072221615755,
                        1.539950952749247,
                        1.540769987393429,
                        1.540723223397911,
                        1.5407482994105777,
                        1.5407198216348108,
                        1.540841541230825,
                        1.5407897891352111,
                        1.5400027823138838,
                        1.5407038271804556,
                        1.541047798732269,
                        1.5410472674795024,
                        1.5401863474319746,
                        1.5402467066405394,
                        1.5411691963305862,
                        1.5411922028818026,
                        1.5411180140216652,
                        1.541043912180281,
                        1.5412099297091948,
                        1.541111598289166,
                        1.5404588433447444,
                        1.5411593996595228,
                        1.541156879363863,
                        1.5411822325848537,
                        1.5410030026359671,
                        1.541123502455342,
                        1.541817608271037,
                        1.5418821993428422,
                        1.5419579394130998,
                        1.5418704302552264,
                        1.5419672485865477,
                        1.5417732315392105,
                        1.5407862568650055,
                        1.5419123417911431,
                        1.5405047783554677,
                        1.5406243773846193,
                        1.540655729025219,
                        1.5406540514065203,
                        1.5405678171773942,
                        1.540628244491059,
                        1.5392767710854782,
                        1.5394276541173972,
                        1.5405551533465986,
                        1.5404356909505434,
                        1.5402478721889914,
                        1.5400785562716568,
                        1.540201804317702,
                        1.5413260830590276,
                        1.5412903335858246,
                        1.5413726596963673,
                        1.5414070069667474,
                        1.5413240807918118,
                        1.541249861579541,
                        1.5413168469208307,
                        1.5395216567367522,
                        1.5413490995959842,
                        1.539650465063064,
                        1.5458765583616385
                      ]
                    },
                    {
                      "label": "subsample",
                      "range": [
                        0.9430230654140817,
                        0.9459988006303498
                      ],
                      "values": [
                        0.9453296181482255,
                        0.9455053223232528,
                        0.9459988006303498,
                        0.9438771308511329,
                        0.9433063836320635,
                        0.9451880620199111,
                        0.9443031018770578,
                        0.9448201956644691,
                        0.9434159805780364,
                        0.9440527359428611,
                        0.9437802509162949,
                        0.9443594504020336,
                        0.9455784180695651,
                        0.9447699962056549,
                        0.9432466551900003,
                        0.944299742579834,
                        0.9431750071294857,
                        0.9440840329336343,
                        0.9441080555373369,
                        0.9440952945891955,
                        0.9438020944532961,
                        0.9438195384887759,
                        0.9436615393190555,
                        0.9430230654140817,
                        0.9446161869082254,
                        0.943609558436519,
                        0.9436330794592137,
                        0.9436055823313348,
                        0.9435222548413704,
                        0.9435571291144325,
                        0.943639215532526,
                        0.9435802295788911,
                        0.9436673955116351,
                        0.9435835284582746,
                        0.9434842928989612,
                        0.9434759193745964,
                        0.9440612672179819,
                        0.9445262538951339,
                        0.9441255308843788,
                        0.9441220319691357,
                        0.9441862560000946,
                        0.9442187468432255,
                        0.9442222172788111,
                        0.9441544050013282,
                        0.94335591985275,
                        0.9433646744817017,
                        0.9442982717202176,
                        0.9442225924863286,
                        0.9442771819144716,
                        0.9442448115647246,
                        0.9442773547846582,
                        0.9449637510449588,
                        0.9442727070115136,
                        0.9442612009726581,
                        0.9442145976722806,
                        0.9442375543585556,
                        0.9449228069405787,
                        0.945057540928685,
                        0.9444237557532479,
                        0.9444225648177368,
                        0.9447058043111204,
                        0.9446907987990313,
                        0.9444440996898757,
                        0.9443668622253106,
                        0.9443930902739884,
                        0.9446866285803898,
                        0.9440065520450398,
                        0.9447267125770614,
                        0.9440148164111459,
                        0.9439920660017851,
                        0.943967821802263,
                        0.9439639089318205,
                        0.9440428037470283,
                        0.9439924847192449,
                        0.9441686295247557,
                        0.9441487631660943,
                        0.9441643939359079,
                        0.9441358294051257,
                        0.9441659688086868,
                        0.944149454159261,
                        0.9441471591066578,
                        0.9441540653573042,
                        0.9441606778259046,
                        0.944150844037863,
                        0.9438415179409465,
                        0.9445827462773142,
                        0.9438540419630829,
                        0.9438465702241883,
                        0.9437250435803752,
                        0.94384993057527,
                        0.9437326560179142,
                        0.9438430167044306,
                        0.9438345365773609,
                        0.9443204147188141,
                        0.9443328256000996,
                        0.9443039118582017,
                        0.9443390945775831,
                        0.9443202297077714,
                        0.9443171525307595,
                        0.9443107411466233,
                        0.9443446571185894,
                        0.9443456404110107,
                        0.9440742414628341,
                        0.9442111116916532,
                        0.9442182714601866,
                        0.9442224434355379,
                        0.9442144973928258,
                        0.944223888288738,
                        0.9440894516033962,
                        0.9442267228264783,
                        0.9442041197986157,
                        0.9442242208762223,
                        0.9439300246702854,
                        0.9444783106621728,
                        0.9444514854550579,
                        0.944069254354662,
                        0.9439145395924108,
                        0.9439172073315456,
                        0.9440797886980913,
                        0.9440983098137483,
                        0.944086209301897,
                        0.9440720390820442,
                        0.9441223239090138,
                        0.9441130272569621,
                        0.9440538223255401,
                        0.9441067461792136,
                        0.9441250886715842,
                        0.9441279780734714,
                        0.9441309448427074,
                        0.9440191122701337,
                        0.9441584418083023,
                        0.9441502781770478,
                        0.9442727488642683,
                        0.944170930661371,
                        0.9442567453259881,
                        0.9442700096965685,
                        0.944011341966188,
                        0.9440052877015548,
                        0.9442796457026561,
                        0.9442742205115704,
                        0.9442557400524307,
                        0.9442727802615428,
                        0.9442646429107531,
                        0.9442630961497284,
                        0.9442631055376085,
                        0.9442555156916548,
                        0.9442766863168093,
                        0.944259361456306,
                        0.944191679452166,
                        0.9445523780956128,
                        0.9446004872345639,
                        0.9441933262768689,
                        0.9445660090971786,
                        0.944608906416778,
                        0.9443870813516266,
                        0.9445726311415104,
                        0.944564882593365,
                        0.9443905021033924,
                        0.9443821208318299,
                        0.9443928481410516,
                        0.9443905661041305,
                        0.9443918680539384,
                        0.9442701674499747,
                        0.9442787847208512,
                        0.944283728462179,
                        0.9442754816790603,
                        0.9442942102649466,
                        0.9442842264563033,
                        0.9442677566599502,
                        0.9443069204543808,
                        0.9442817691496519,
                        0.9442733090263319,
                        0.9442637797129361,
                        0.9442625373005382,
                        0.9442746332025044,
                        0.9442488700176688,
                        0.944261515929444,
                        0.9442478232637123,
                        0.94425027556747,
                        0.9442508232950433,
                        0.9443449042762118,
                        0.9443396052509554,
                        0.9443384878278903,
                        0.9443406650038852,
                        0.9443354469360256,
                        0.9443381540446522,
                        0.9452896833119693,
                        0.9443386000403636,
                        0.9441861302584821,
                        0.9441889824696628,
                        0.9444390161493964,
                        0.9441832990159295,
                        0.944184989706611,
                        0.9441862902119127,
                        0.9444351253040636,
                        0.944177459549636,
                        0.9441958528033678,
                        0.9441944079889945,
                        0.9442090678855593,
                        0.9441929437598361,
                        0.9441875406534632,
                        0.9441793909592525,
                        0.9441851640576957,
                        0.944186366326079,
                        0.9441972153438344,
                        0.9441821251611258,
                        0.9441760201585162,
                        0.9441802567489995,
                        0.9441707703955624,
                        0.944183937074191,
                        0.9441729368370833,
                        0.9441759241393259,
                        0.9441660278343739,
                        0.9441550340966374,
                        0.9440714458541068,
                        0.9441496363330758,
                        0.9440778193874911,
                        0.944070985920474,
                        0.9440613313478546,
                        0.944032741337384,
                        0.9440959212373158,
                        0.944039002771086,
                        0.9441138392977748,
                        0.9440399809554904,
                        0.9440253360279196,
                        0.9441246572335931,
                        0.9441236789892319,
                        0.9441254736484345,
                        0.9441553759338066,
                        0.9441312967296562,
                        0.944144616507472,
                        0.9441405319119324,
                        0.9441500305505492,
                        0.9441655758291675,
                        0.9441780061408603,
                        0.9441732468400297,
                        0.944200529291739,
                        0.9442006007384287,
                        0.9442077985222102,
                        0.944207923291505,
                        0.9442114781755321,
                        0.9442179686587163,
                        0.9442095774925637,
                        0.9442197733373612,
                        0.9442106899025698,
                        0.9442175437094708,
                        0.9442268608151513,
                        0.9439521412807956,
                        0.9441026243013562,
                        0.9430412134487897,
                        0.943981097925685,
                        0.9431554172477618,
                        0.9440997545396879,
                        0.9441039869908451,
                        0.9440900900309057,
                        0.9443079625726303,
                        0.9443127402353749,
                        0.9443064999336206,
                        0.9443097238316637,
                        0.9443049487974342,
                        0.9442865553251085,
                        0.9443106451254362,
                        0.9443150465855905,
                        0.9443078544319373,
                        0.9441621760837908,
                        0.9441644919280325,
                        0.9441652947194663,
                        0.9441569424489088,
                        0.9441578396190339,
                        0.944167004956982,
                        0.9441402010789256,
                        0.9441477942509436,
                        0.9441490475814519,
                        0.9442559076149062,
                        0.9441546030045953,
                        0.9440364639649956,
                        0.9440282782477234,
                        0.9440497436430328,
                        0.9440572409612245,
                        0.9440413091136297,
                        0.9440980735320826,
                        0.9440443352976404,
                        0.9440446827537193,
                        0.9440858441629495,
                        0.9440596121745786,
                        0.9440942390129244,
                        0.9442425969586133,
                        0.9442418768423941,
                        0.9442465886685081,
                        0.9442275373106299,
                        0.9442441735805182,
                        0.9442351900672351,
                        0.9442346004990778,
                        0.9442284208815431,
                        0.9441750475876739,
                        0.9441793244663099,
                        0.9443716528260214,
                        0.9443737527702698,
                        0.9443789259270202,
                        0.944181027060091,
                        0.9441713769230459,
                        0.9441574669369988,
                        0.9441621882447624,
                        0.944837333919363,
                        0.9441692823536251,
                        0.944159009006782,
                        0.9441644048163115,
                        0.9441657159918114,
                        0.9439609787838287,
                        0.9441622125398791,
                        0.9441540974017225,
                        0.9441626518806775,
                        0.9441449689874577,
                        0.9441271933427631,
                        0.9439836400759832,
                        0.944119960806216,
                        0.9441258772297945,
                        0.9441075486281194,
                        0.944112604064852,
                        0.9441019074739495,
                        0.9440864561467393,
                        0.9439914595374733,
                        0.9441074939083002,
                        0.944089775171572,
                        0.9440809897548531,
                        0.9440830945798814,
                        0.9439837779630612,
                        0.9439346732740177,
                        0.944178425891511,
                        0.9441837133346551,
                        0.9439018538409637,
                        0.9439071691543046,
                        0.9441858265130227,
                        0.9441815319567416,
                        0.9441908173814023,
                        0.9441942947984261,
                        0.9441807733821153,
                        0.9441953693777142,
                        0.9442005674517171,
                        0.9441936130578197,
                        0.9442008533844167,
                        0.9441934803874028,
                        0.9442062128759997,
                        0.9440342741869353,
                        0.9440310642451585,
                        0.9440621933200818,
                        0.9440257026069352,
                        0.9440380813171582,
                        0.9440462848395748,
                        0.944055955437481,
                        0.9440152578533689,
                        0.9441173861631107,
                        0.944120560540105,
                        0.9441119845135498,
                        0.9441283702977907,
                        0.9441400730695735,
                        0.9441358480557546,
                        0.9441290565822991,
                        0.9441314013695818,
                        0.9441429912532754,
                        0.9441451115074824,
                        0.9442498149260685,
                        0.9442552436581098,
                        0.944249692841048,
                        0.9442552828010948,
                        0.9442401803075193,
                        0.9442801718857707,
                        0.9442484403496727,
                        0.9442296155945178,
                        0.9442649896410428,
                        0.9442410339691538,
                        0.9442220726507641,
                        0.9443116308497475,
                        0.9442096262584192,
                        0.9441951573533408,
                        0.9441874270994761,
                        0.9441775753270542,
                        0.9441851457784306,
                        0.944185468136847,
                        0.9441765944891672
                      ]
                    }
                  ],
                  "labelangle": 30,
                  "labelside": "bottom",
                  "line": {
                    "color": [
                      0.24309599999999998,
                      0.24818389999999999,
                      0.24435959999999998,
                      0.256212,
                      0.2555163,
                      0.2464995,
                      0.25545389999999996,
                      0.24905049999999998,
                      0.2548641,
                      0.25648119999999996,
                      0.2558698,
                      0.24780459999999999,
                      0.2477465,
                      0.24833249999999998,
                      0.25473920000000005,
                      0.24775509999999995,
                      0.2505895,
                      0.25473789999999996,
                      0.2547096,
                      0.2448719,
                      0.2516613,
                      0.25311239999999996,
                      0.25467589999999996,
                      0.253307,
                      0.24996430000000003,
                      0.2556667,
                      0.25070549999999997,
                      0.2507082,
                      0.2550057,
                      0.2556131,
                      0.2550865,
                      0.2556131,
                      0.2567946,
                      0.25560499999999997,
                      0.2546059,
                      0.2533031,
                      0.2546889,
                      0.24616310000000002,
                      0.2571392,
                      0.25704049999999995,
                      0.2570628,
                      0.25710390000000005,
                      0.2570731,
                      0.25704439999999995,
                      0.2555306,
                      0.25553879999999995,
                      0.2565786,
                      0.2570731,
                      0.2570578,
                      0.2570198,
                      0.2532803,
                      0.24752110000000002,
                      0.25571079999999996,
                      0.2571526,
                      0.2550972,
                      0.2550105,
                      0.251436,
                      0.24811100000000003,
                      0.25268229999999997,
                      0.25472929999999994,
                      0.2529772,
                      0.25307799999999997,
                      0.25477059999999996,
                      0.25472989999999995,
                      0.2550596,
                      0.25319769999999997,
                      0.2567672,
                      0.2541135,
                      0.25625390000000003,
                      0.25672740000000005,
                      0.25674270000000005,
                      0.25477740000000004,
                      0.25665759999999993,
                      0.2567666,
                      0.2567825,
                      0.2571437,
                      0.2541133,
                      0.2570405,
                      0.2556736,
                      0.2559516,
                      0.2549704,
                      0.25710520000000003,
                      0.25712749999999995,
                      0.25594589999999995,
                      0.25650200000000006,
                      0.2535493,
                      0.25665879999999996,
                      0.25673450000000003,
                      0.2567359,
                      0.25673450000000003,
                      0.25662219999999997,
                      0.2547356,
                      0.25673450000000003,
                      0.25658259999999994,
                      0.24811029999999995,
                      0.2565795,
                      0.2492701,
                      0.25657729999999995,
                      0.2565707,
                      0.2545136,
                      0.256613,
                      0.25657729999999995,
                      0.2565415999999999,
                      0.25713010000000003,
                      0.25703919999999997,
                      0.2551085,
                      0.2560518,
                      0.2550975,
                      0.25665249999999995,
                      0.25512729999999995,
                      0.2570198,
                      0.25703919999999997,
                      0.2546713,
                      0.25268519999999994,
                      0.25477059999999996,
                      0.2565277,
                      0.2564938,
                      0.25672819999999996,
                      0.2565415999999999,
                      0.2567638,
                      0.2567104,
                      0.25592079999999995,
                      0.25709360000000003,
                      0.2567097,
                      0.2567747,
                      0.25182119999999997,
                      0.25709360000000003,
                      0.2560942,
                      0.2569352,
                      0.25366809999999995,
                      0.2571847,
                      0.2570494,
                      0.2571681,
                      0.2571794,
                      0.25715869999999996,
                      0.2571681,
                      0.25665760000000004,
                      0.25676439999999995,
                      0.2570578,
                      0.2551037,
                      0.25705370000000005,
                      0.25716680000000003,
                      0.25716680000000003,
                      0.25715639999999995,
                      0.25715639999999995,
                      0.2571548,
                      0.2571523,
                      0.25715869999999996,
                      0.257151,
                      0.25438510000000003,
                      0.255105,
                      0.257151,
                      0.25513479999999994,
                      0.2534262,
                      0.25509889999999996,
                      0.2534262,
                      0.2551042,
                      0.25509889999999996,
                      0.25509889999999996,
                      0.2541022,
                      0.2540864,
                      0.25513359999999996,
                      0.257187,
                      0.257187,
                      0.2561664,
                      0.25620539999999997,
                      0.255899,
                      0.257187,
                      0.257187,
                      0.2569225,
                      0.2571629,
                      0.257187,
                      0.2571848,
                      0.2571629,
                      0.2571848,
                      0.25717890000000004,
                      0.2571629,
                      0.2571548,
                      0.2571767,
                      0.2571767,
                      0.25659529999999997,
                      0.25692029999999993,
                      0.25692029999999993,
                      0.25692029999999993,
                      0.2569225,
                      0.2569225,
                      0.24924519999999997,
                      0.2569225,
                      0.25718159999999995,
                      0.2571838,
                      0.25516869999999997,
                      0.2572217,
                      0.2572217,
                      0.25718159999999995,
                      0.2547674999999999,
                      0.2571794,
                      0.2571838,
                      0.2571794,
                      0.2571806,
                      0.257151,
                      0.257151,
                      0.2571911,
                      0.2571911,
                      0.25716710000000004,
                      0.257151,
                      0.2571911,
                      0.2571911,
                      0.2571911,
                      0.2571911,
                      0.2571911,
                      0.2571911,
                      0.2571911,
                      0.2571911,
                      0.257091,
                      0.25672459999999997,
                      0.2571237,
                      0.25672459999999997,
                      0.25672459999999997,
                      0.25672459999999997,
                      0.25672740000000005,
                      0.25669410000000004,
                      0.25673070000000003,
                      0.25669410000000004,
                      0.2566733,
                      0.2567088,
                      0.25711349999999994,
                      0.2571129,
                      0.257091,
                      0.257091,
                      0.257091,
                      0.2571237,
                      0.25712149999999995,
                      0.25712149999999995,
                      0.2572217,
                      0.2572217,
                      0.2572217,
                      0.25718159999999995,
                      0.257151,
                      0.25717890000000004,
                      0.25717890000000004,
                      0.2571806,
                      0.2571786,
                      0.2571806,
                      0.2571742,
                      0.2571806,
                      0.2571742,
                      0.2571742,
                      0.2567405,
                      0.25671960000000005,
                      0.2532991,
                      0.2567007,
                      0.2531245,
                      0.25669410000000004,
                      0.25669410000000004,
                      0.25669410000000004,
                      0.2568919,
                      0.2568919,
                      0.2568919,
                      0.2569225,
                      0.2556653,
                      0.257187,
                      0.2558753,
                      0.2569225,
                      0.2569225,
                      0.2572217,
                      0.2572217,
                      0.2572217,
                      0.2571844,
                      0.25718159999999995,
                      0.2572217,
                      0.25712149999999995,
                      0.25712149999999995,
                      0.2551721,
                      0.25717890000000004,
                      0.25715930000000004,
                      0.2547511,
                      0.2547931,
                      0.25470859999999995,
                      0.2547462,
                      0.25475180000000003,
                      0.25669580000000003,
                      0.25667389999999995,
                      0.256714,
                      0.25669410000000004,
                      0.25667389999999995,
                      0.25672680000000003,
                      0.2571483,
                      0.2571483,
                      0.2490541,
                      0.25522969999999995,
                      0.2552482,
                      0.25522969999999995,
                      0.25526249999999995,
                      0.25526249999999995,
                      0.2572217,
                      0.25721950000000005,
                      0.2550935,
                      0.2550935,
                      0.2550913,
                      0.2572217,
                      0.25721950000000005,
                      0.2571794,
                      0.2572217,
                      0.2508721,
                      0.25721950000000005,
                      0.25721950000000005,
                      0.2572217,
                      0.2552301,
                      0.2567405,
                      0.25718159999999995,
                      0.25715930000000004,
                      0.25519440000000004,
                      0.25715420000000005,
                      0.2551714,
                      0.25674850000000005,
                      0.2567276,
                      0.257147,
                      0.2567283,
                      0.2567283,
                      0.25671960000000005,
                      0.2567218,
                      0.2567672,
                      0.25671960000000005,
                      0.25671960000000005,
                      0.25671960000000005,
                      0.25671960000000005,
                      0.2567405,
                      0.2567405,
                      0.2572217,
                      0.2572217,
                      0.2567405,
                      0.25674270000000005,
                      0.25718159999999995,
                      0.2572217,
                      0.25718159999999995,
                      0.25718159999999995,
                      0.2572217,
                      0.25718159999999995,
                      0.25718159999999995,
                      0.25718159999999995,
                      0.25718159999999995,
                      0.25720350000000003,
                      0.2571821,
                      0.2567324,
                      0.2567687,
                      0.2567218,
                      0.2567687,
                      0.25673830000000003,
                      0.25673320000000005,
                      0.2547462,
                      0.2547931,
                      0.25474549999999996,
                      0.2551736,
                      0.2547346,
                      0.2571406,
                      0.2551315,
                      0.2571187,
                      0.25714770000000003,
                      0.25714770000000003,
                      0.25714770000000003,
                      0.2571187,
                      0.25717890000000004,
                      0.2571767,
                      0.2571767,
                      0.25717890000000004,
                      0.25522969999999995,
                      0.25715639999999995,
                      0.25717890000000004,
                      0.25522969999999995,
                      0.25715639999999995,
                      0.25522969999999995,
                      0.25522969999999995,
                      0.2569247,
                      0.25526819999999995,
                      0.2571932,
                      0.2571932,
                      0.2571932,
                      0.2572239,
                      0.2572217,
                      0.24988799999999997
                    ],
                    "colorbar": {
                      "title": {
                        "text": "Objective Value"
                      }
                    },
                    "colorscale": [
                      [
                        0,
                        "rgb(247,251,255)"
                      ],
                      [
                        0.125,
                        "rgb(222,235,247)"
                      ],
                      [
                        0.25,
                        "rgb(198,219,239)"
                      ],
                      [
                        0.375,
                        "rgb(158,202,225)"
                      ],
                      [
                        0.5,
                        "rgb(107,174,214)"
                      ],
                      [
                        0.625,
                        "rgb(66,146,198)"
                      ],
                      [
                        0.75,
                        "rgb(33,113,181)"
                      ],
                      [
                        0.875,
                        "rgb(8,81,156)"
                      ],
                      [
                        1,
                        "rgb(8,48,107)"
                      ]
                    ],
                    "reversescale": false,
                    "showscale": true
                  },
                  "type": "parcoords"
                }
              ],
              "layout": {
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "heatmapgl": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmapgl"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                },
                "title": {
                  "text": "Parallel Coordinate Plot"
                }
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "opt.visualization.plot_parallel_coordinate(xgb_study)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 139, number of negative: 2722\n",
            "[LightGBM] [Info] Total Bins 540\n",
            "[LightGBM] [Info] Number of data points in the train set: 2861, number of used features: 8\n",
            "[LightGBM] [Info] Using GOSS\n",
            "[LightGBM] [Info] Number of positive: 139, number of negative: 2722\n",
            "[LightGBM] [Info] Total Bins 540\n",
            "[LightGBM] [Info] Number of data points in the train set: 2861, number of used features: 8\n",
            "[LightGBM] [Info] Using GOSS\n",
            "[LightGBM] [Info] Number of positive: 139, number of negative: 2722\n",
            "[LightGBM] [Info] Total Bins 540\n",
            "[LightGBM] [Info] Number of data points in the train set: 2861, number of used features: 8\n",
            "[LightGBM] [Info] Using GOSS\n",
            "[LightGBM] [Info] Number of positive: 139, number of negative: 2722\n",
            "[LightGBM] [Info] Total Bins 540\n",
            "[LightGBM] [Info] Number of data points in the train set: 2861, number of used features: 8\n",
            "[LightGBM] [Info] Using GOSS\n",
            "[LightGBM] [Info] Number of positive: 139, number of negative: 2722\n",
            "[LightGBM] [Info] Total Bins 540\n",
            "[LightGBM] [Info] Number of data points in the train set: 2861, number of used features: 8\n",
            "[LightGBM] [Info] Using GOSS\n",
            "[LightGBM] [Info] Number of positive: 139, number of negative: 2722\n",
            "[LightGBM] [Info] Total Bins 540\n",
            "[LightGBM] [Info] Number of data points in the train set: 2861, number of used features: 8\n",
            "[LightGBM] [Info] Using GOSS\n",
            "[LightGBM] [Info] Number of positive: 139, number of negative: 2722\n",
            "[LightGBM] [Info] Total Bins 540\n",
            "[LightGBM] [Info] Number of data points in the train set: 2861, number of used features: 8\n",
            "[LightGBM] [Info] Using GOSS\n",
            "[LightGBM] [Info] Number of positive: 139, number of negative: 2722\n",
            "[LightGBM] [Info] Total Bins 540\n",
            "[LightGBM] [Info] Number of data points in the train set: 2861, number of used features: 8\n",
            "[LightGBM] [Info] Using GOSS\n",
            "[LightGBM] [Info] Number of positive: 139, number of negative: 2722\n",
            "[LightGBM] [Info] Total Bins 540\n",
            "[LightGBM] [Info] Number of data points in the train set: 2861, number of used features: 8\n",
            "[LightGBM] [Info] Using GOSS\n",
            "[LightGBM] [Info] Number of positive: 139, number of negative: 2722\n",
            "[LightGBM] [Info] Total Bins 540\n",
            "[LightGBM] [Info] Number of data points in the train set: 2861, number of used features: 8\n",
            "[LightGBM] [Info] Using GOSS\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048584 -> initscore=-2.974648\n",
            "[LightGBM] [Info] Start training from score -2.974648\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048584 -> initscore=-2.974648\n",
            "[LightGBM] [Info] Start training from score -2.974648\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048584 -> initscore=-2.974648\n",
            "[LightGBM] [Info] Start training from score -2.974648\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048584 -> initscore=-2.974648\n",
            "[LightGBM] [Info] Start training from score -2.974648\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048584 -> initscore=-2.974648\n",
            "[LightGBM] [Info] Start training from score -2.974648\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048584 -> initscore=-2.974648\n",
            "[LightGBM] [Info] Start training from score -2.974648\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048584 -> initscore=-2.974648\n",
            "[LightGBM] [Info] Start training from score -2.974648\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048584 -> initscore=-2.974648\n",
            "[LightGBM] [Info] Start training from score -2.974648\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048584 -> initscore=-2.974648\n",
            "[LightGBM] [Info] Start training from score -2.974648\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048584 -> initscore=-2.974648\n",
            "[LightGBM] [Info] Start training from score -2.974648\n",
            "Training until validation scores don't improve for 30 rounds\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[32]\tcv_agg's average_precision: 0.209069 + 0.0263007\n",
            "Best validation precision-recall AUC 0.21 at iteration 31\n",
            "Last validation precision-recall AUC 0.21 at iteration 31\n"
          ]
        }
      ],
      "source": [
        "dset = lgb.Dataset(data=X, label=y, \n",
        "                   #categorical_feature=['age','hypertension','heart_disease','ever_married','work_type','smoking_status']\n",
        "                   )\n",
        "lgb_params = {\n",
        "    'metric':'average_precision',\n",
        "    'objective':'binary', \n",
        "    'is_unbalance': True,\n",
        "    'force_col_wise':True,\n",
        "    'boosting_type': 'goss'\n",
        "}\n",
        "\n",
        "\n",
        "lgb_cv_res = lgb.cv(params=lgb_params,\n",
        "                    train_set=dset,\n",
        "                    num_boost_round=50,\n",
        "                    folds=StratifiedShuffleSplit(n_splits=10, test_size=0.3, random_state=0),\n",
        "                    metrics='average_precision',\n",
        "                    callbacks=[lgb.early_stopping(30)]\n",
        "                    )\n",
        "\n",
        "lgb_cv_res_df = pd.DataFrame(lgb_cv_res)\n",
        "\n",
        "print(f'Best validation precision-recall AUC {round(lgb_cv_res_df[\"average_precision-mean\"].max(), 2)} at iteration {lgb_cv_res_df[\"average_precision-mean\"].idxmax()}')\n",
        "print(f'Last validation precision-recall AUC {round(lgb_cv_res_df.loc[len(lgb_cv_res_df) - 1,\"average_precision-mean\"], 2)} at iteration {len(lgb_cv_res_df) - 1}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Model performance without specifying categories seems to be better, but there are related HP to tune using Optuna  \n",
        "However the difference among optimizers is not significant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div><div id=d81b2e75-283f-4b77-ab18-10252f9b0ad6 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('d81b2e75-283f-4b77-ab18-10252f9b0ad6').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>average_precision-mean</th>\n",
              "      <th>average_precision-stdv</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.145334</td>\n",
              "      <td>0.024636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.167569</td>\n",
              "      <td>0.027445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.174953</td>\n",
              "      <td>0.028324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.179029</td>\n",
              "      <td>0.027405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.182255</td>\n",
              "      <td>0.027885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.187835</td>\n",
              "      <td>0.026680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.191697</td>\n",
              "      <td>0.025448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.193907</td>\n",
              "      <td>0.027768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.193765</td>\n",
              "      <td>0.028647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.195590</td>\n",
              "      <td>0.028482</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.202155</td>\n",
              "      <td>0.033837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.200937</td>\n",
              "      <td>0.031809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.201073</td>\n",
              "      <td>0.031222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.201002</td>\n",
              "      <td>0.027007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.199543</td>\n",
              "      <td>0.021616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.203583</td>\n",
              "      <td>0.022029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.204646</td>\n",
              "      <td>0.022890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.206317</td>\n",
              "      <td>0.023099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.202906</td>\n",
              "      <td>0.023374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.205015</td>\n",
              "      <td>0.025820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.205835</td>\n",
              "      <td>0.026302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.204874</td>\n",
              "      <td>0.025701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.205475</td>\n",
              "      <td>0.025953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.204718</td>\n",
              "      <td>0.025285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.206672</td>\n",
              "      <td>0.026841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.206919</td>\n",
              "      <td>0.026338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.206288</td>\n",
              "      <td>0.025994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.207625</td>\n",
              "      <td>0.025045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.207797</td>\n",
              "      <td>0.023640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.207220</td>\n",
              "      <td>0.024143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.208017</td>\n",
              "      <td>0.024990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.209069</td>\n",
              "      <td>0.026301</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table></div>"
            ],
            "text/plain": [
              "    average_precision-mean  average_precision-stdv\n",
              "0                 0.145334                0.024636\n",
              "1                 0.167569                0.027445\n",
              "2                 0.174953                0.028324\n",
              "3                 0.179029                0.027405\n",
              "4                 0.182255                0.027885\n",
              "5                 0.187835                0.026680\n",
              "6                 0.191697                0.025448\n",
              "7                 0.193907                0.027768\n",
              "8                 0.193765                0.028647\n",
              "9                 0.195590                0.028482\n",
              "10                0.202155                0.033837\n",
              "11                0.200937                0.031809\n",
              "12                0.201073                0.031222\n",
              "13                0.201002                0.027007\n",
              "14                0.199543                0.021616\n",
              "15                0.203583                0.022029\n",
              "16                0.204646                0.022890\n",
              "17                0.206317                0.023099\n",
              "18                0.202906                0.023374\n",
              "19                0.205015                0.025820\n",
              "20                0.205835                0.026302\n",
              "21                0.204874                0.025701\n",
              "22                0.205475                0.025953\n",
              "23                0.204718                0.025285\n",
              "24                0.206672                0.026841\n",
              "25                0.206919                0.026338\n",
              "26                0.206288                0.025994\n",
              "27                0.207625                0.025045\n",
              "28                0.207797                0.023640\n",
              "29                0.207220                0.024143\n",
              "30                0.208017                0.024990\n",
              "31                0.209069                0.026301"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lgb_cv_res_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "clf = lgb.LGBMClassifier(**lgb_params)\n",
        "clf.fit(X, y)\n",
        "lgb.plot_importance(clf)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "LGB_DB_URL = os.getenv('LGB_DB_URL')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-10-23 18:11:55,890]\u001b[0m A new study created in RDB with name: goss-cat\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "def objective(trial,data=X,target=y, boosting_type='gbdt'):\n",
        "    \n",
        "    clf_params ={\n",
        "        'metric':'average_precision',\n",
        "        'is_unbalance': True,\n",
        "        'objective': 'binary',\n",
        "        'verbose': -1,\n",
        "        'min_child_weight': 17,\n",
        "        'max_bin': 58,\n",
        "        'boosting_type': trial.suggest_categorical('booster', [boosting_type]), # trial.suggest_categorical('booster', ['gbdt', 'dart', 'goss']),\n",
        "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.4, 0.8),\n",
        "        'lambda_l1': trial.suggest_uniform('lambda_l1', 0.07, 0.11),\n",
        "    \n",
        "        \n",
        "        'cat_l2': trial.suggest_uniform('cat_l2', 2e-3, 0.0035),\n",
        "        'min_data_per_group': trial.suggest_int('min_data_per_group', 5, 15),\n",
        "        'max_cat_threshold': trial.suggest_int('max_cat_threshold',12,25),\n",
        "        'cat_smooth': trial.suggest_uniform('cat_smooth', 2.0, 6.5)\n",
        "    }\n",
        "    \n",
        "    \n",
        "    if clf_params[\"boosting_type\"] in ['gbdt', 'rf', 'dart', 'goss']:\n",
        "        #clf_params['max_bin'] = trial.suggest_int('max_bin', 55, 65)\n",
        "        clf_params['num_leaves'] = trial.suggest_int('num_leaves', 38, 60)\n",
        "        clf_params[\"max_depth\"] = trial.suggest_int(\"max_depth\", 5, 8)\n",
        "        clf_params[\"eta\"] = trial.suggest_uniform(\"eta\", 0.07, 0.08)\n",
        "        clf_params[\"min_split_gain\"] = trial.suggest_uniform(\"min_split_gain\", 0.013, 0.015)\n",
        "        #clf_params['min_child_weight'] = trial.suggest_int('min_child_weight', 15, 19)\n",
        "        clf_params['min_data_in_leaf'] = trial.suggest_int('min_data_in_leaf', 1, 8)        \n",
        "        clf_params['feature_fraction'] = trial.suggest_uniform('feature_fraction', 0.9435, 0.945)\n",
        "        \n",
        "    if clf_params['boosting_type'] in ['gbdt', 'rf', 'dart']:\n",
        "        clf_params['bagging_freq'] = trial.suggest_int('bagging_freq', 1, 16)\n",
        "        clf_params['bagging_fraction'] = 0.9\n",
        "        clf_params['pos_bagging_fraction'] = trial.suggest_uniform('pos_bagging_fraction', 0.8, 1.0)\n",
        "        clf_params['neg_bagging_fraction'] = trial.suggest_uniform('neg_bagging_fraction', 0.5, 0.7)      \n",
        "                \n",
        "    if clf_params[\"boosting_type\"] == \"dart\":\n",
        "        clf_params[\"uniform_drop\"] = False\n",
        "        clf_params[\"rate_drop\"] = trial.suggest_loguniform(\"rate_drop\", 1e-2, 1e-1)\n",
        "        clf_params[\"skip_drop\"] = trial.suggest_loguniform(\"skip_drop\", 1e-1, 1.0)    \n",
        "        clf_params[\"max_drop\"] = trial.suggest_int(\"max_drop\", 30, 60)  \n",
        "        \n",
        "        \n",
        "    if clf_params['boosting_type'] == 'goss':\n",
        "        clf_params['top_rate'] = round(trial.suggest_uniform('top_rate', 0.3, 0.5), 5)\n",
        "        clf_params['other_rate'] =  round(trial.suggest_uniform('other_rate', 0, 1 - clf_params['top_rate']), 5)\n",
        "        \n",
        "    \n",
        "    \n",
        "    dmatrix = lgb.Dataset(data=data, label=target, categorical_feature=['age','hypertension','heart_disease','ever_married','work_type','smoking_status'])\n",
        "    \n",
        "    pruning_callback = opt.integration.LightGBMPruningCallback(trial, 'average_precision')\n",
        "    \n",
        "    #try:\n",
        "    lgb_cv_res = lgb.cv(params=clf_params, train_set=dmatrix, num_boost_round=50 if clf_params['boosting_type'] == 'dart' else 100,\n",
        "                        folds=StratifiedShuffleSplit(n_splits=10, test_size=0.3, random_state=0), \n",
        "                        metrics='average_precision',\n",
        "                        callbacks=[pruning_callback, lgb.log_evaluation(period=0)] if clf_params['boosting_type'] == 'dart' else\n",
        "                        [lgb.log_evaluation(period=0), pruning_callback, lgb.early_stopping(30, verbose=False)])\n",
        "    \n",
        "    #except lgb.basic.LightGBMError:\n",
        "    #    print('-!'*50+f'\\n{clf_params[\"boosting_type\"]} params are: top rate={clf_params.get(\"top_rate\")}, other rate={clf_params.get(\"other_rate\")}\\n'+'-!'*50)\n",
        "        \n",
        "    df = pd.DataFrame(lgb_cv_res)\n",
        "    \n",
        "    aucpr = df[\"average_precision-mean\"].max()\n",
        "    trial.set_user_attr('n_estimators', df[\"average_precision-mean\"].idxmax() + 1)\n",
        "    \n",
        "    return aucpr\n",
        "\n",
        "def create_study(name):\n",
        "    return opt.create_study(\n",
        "        pruner=opt.pruners.MedianPruner(n_warmup_steps=10),\n",
        "        direction='maximize',\n",
        "        study_name=name,\n",
        "        storage=LGB_DB_URL)\n",
        "    \n",
        "boosters = ['goss']\n",
        "postfix = '-cat'\n",
        "    \n",
        "lgb_study = {booster: create_study(name=booster+postfix) for booster in boosters}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\study\\study.py:393: FutureWarning:\n",
            "\n",
            "`n_jobs` argument has been deprecated in v2.7.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.7.0.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:12:07,878]\u001b[0m Trial 4 finished with value: 0.22118355006291165 and parameters: {'booster': 'goss', 'lambda_l2': 0.6783662330693259, 'lambda_l1': 0.03688255695266242, 'cat_l2': 0.003078867371690268, 'min_data_per_group': 15, 'max_cat_threshold': 18, 'cat_smooth': 2.944081300144676, 'max_bin': 60, 'num_leaves': 54, 'max_depth': 5, 'eta': 0.07730713237684239, 'min_split_gain': 0.007556660623378714, 'min_child_weight': 17, 'min_data_in_leaf': 4, 'feature_fraction': 0.9407254059739092, 'top_rate': 0.10794472036374592, 'other_rate': 0.5538729065194656}. Best is trial 4 with value: 0.22118355006291165.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:12:10,653]\u001b[0m Trial 2 finished with value: 0.23607234921980993 and parameters: {'booster': 'goss', 'lambda_l2': 0.4492056768407942, 'lambda_l1': 0.10411468439030888, 'cat_l2': 0.0028417675464967682, 'min_data_per_group': 13, 'max_cat_threshold': 20, 'cat_smooth': 5.044862784912935, 'max_bin': 55, 'num_leaves': 48, 'max_depth': 7, 'eta': 0.07058638823742382, 'min_split_gain': 0.011231968606259975, 'min_child_weight': 18, 'min_data_in_leaf': 4, 'feature_fraction': 0.9420446763960327, 'top_rate': 0.0823217077694812, 'other_rate': 0.48302049937801217}. Best is trial 2 with value: 0.23607234921980993.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:12:12,025]\u001b[0m Trial 6 finished with value: 0.2368054863573365 and parameters: {'booster': 'goss', 'lambda_l2': 0.6760833986087861, 'lambda_l1': 0.18461152490702432, 'cat_l2': 0.002289983971803947, 'min_data_per_group': 9, 'max_cat_threshold': 15, 'cat_smooth': 3.736469991415106, 'max_bin': 64, 'num_leaves': 60, 'max_depth': 7, 'eta': 0.07771538203098736, 'min_split_gain': 0.005437373568205178, 'min_child_weight': 19, 'min_data_in_leaf': 8, 'feature_fraction': 0.9417224142032081, 'top_rate': 0.43394128708019863, 'other_rate': 0.06960619687330734}. Best is trial 6 with value: 0.2368054863573365.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:12:13,336]\u001b[0m Trial 3 finished with value: 0.23351004392260122 and parameters: {'booster': 'goss', 'lambda_l2': 0.6376555421777106, 'lambda_l1': 0.14811556142695492, 'cat_l2': 0.0026838345277320017, 'min_data_per_group': 9, 'max_cat_threshold': 25, 'cat_smooth': 2.8776718573188838, 'max_bin': 55, 'num_leaves': 42, 'max_depth': 8, 'eta': 0.07110220635117667, 'min_split_gain': 0.009200792757828145, 'min_child_weight': 17, 'min_data_in_leaf': 8, 'feature_fraction': 0.9452095639238848, 'top_rate': 0.15626097164939207, 'other_rate': 0.08443558996829727}. Best is trial 6 with value: 0.2368054863573365.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:12:14,950]\u001b[0m Trial 7 finished with value: 0.23467817578951994 and parameters: {'booster': 'goss', 'lambda_l2': 0.48895794971398515, 'lambda_l1': 0.023969505546166652, 'cat_l2': 0.0024132102767287396, 'min_data_per_group': 11, 'max_cat_threshold': 25, 'cat_smooth': 2.2464577801344174, 'max_bin': 62, 'num_leaves': 56, 'max_depth': 8, 'eta': 0.07276700259078742, 'min_split_gain': 0.005017428330678744, 'min_child_weight': 15, 'min_data_in_leaf': 4, 'feature_fraction': 0.9423642843770372, 'top_rate': 0.24529709898328295, 'other_rate': 0.5567467957001528}. Best is trial 6 with value: 0.2368054863573365.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:12:16,621]\u001b[0m Trial 1 finished with value: 0.25257026611385686 and parameters: {'booster': 'goss', 'lambda_l2': 0.740072876978086, 'lambda_l1': 0.1069720298059572, 'cat_l2': 0.0021101658783661873, 'min_data_per_group': 8, 'max_cat_threshold': 25, 'cat_smooth': 5.875657935636863, 'max_bin': 58, 'num_leaves': 44, 'max_depth': 7, 'eta': 0.0720988004858504, 'min_split_gain': 0.013153959907061918, 'min_child_weight': 19, 'min_data_in_leaf': 1, 'feature_fraction': 0.9439595924991366, 'top_rate': 0.2417591915436597, 'other_rate': 0.3643323896398874}. Best is trial 1 with value: 0.25257026611385686.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:12:17,131]\u001b[0m Trial 5 pruned. Trial was pruned at iteration 57.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:12:18,760]\u001b[0m Trial 12 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:12:20,358]\u001b[0m Trial 14 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:12:25,207]\u001b[0m Trial 10 finished with value: 0.2508034667728444 and parameters: {'booster': 'goss', 'lambda_l2': 0.7758977574265233, 'lambda_l1': 0.14415448139624953, 'cat_l2': 0.0030349370503348133, 'min_data_per_group': 13, 'max_cat_threshold': 14, 'cat_smooth': 4.346751175619485, 'max_bin': 57, 'num_leaves': 44, 'max_depth': 5, 'eta': 0.07956437764919257, 'min_split_gain': 0.009207032189715223, 'min_child_weight': 18, 'min_data_in_leaf': 2, 'feature_fraction': 0.9403774989323315, 'top_rate': 0.6386858211977333, 'other_rate': 0.24360607418992206}. Best is trial 1 with value: 0.25257026611385686.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:12:26,581]\u001b[0m Trial 0 finished with value: 0.23799384286273395 and parameters: {'booster': 'goss', 'lambda_l2': 0.5470290993632491, 'lambda_l1': 0.05287568167782561, 'cat_l2': 0.0023770012915399963, 'min_data_per_group': 11, 'max_cat_threshold': 17, 'cat_smooth': 5.925189282006059, 'max_bin': 57, 'num_leaves': 45, 'max_depth': 8, 'eta': 0.07395544662518917, 'min_split_gain': 0.00641548012914274, 'min_child_weight': 15, 'min_data_in_leaf': 1, 'feature_fraction': 0.9415137111205462, 'top_rate': 0.662424956392463, 'other_rate': 0.12398565280403889}. Best is trial 1 with value: 0.25257026611385686.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\sampler.py:459: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:12:27,355]\u001b[0m Trial 8 pruned. Trial was pruned at iteration 48.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:12:32,466]\u001b[0m Trial 9 finished with value: 0.2492183617272187 and parameters: {'booster': 'goss', 'lambda_l2': 0.49852339921912286, 'lambda_l1': 0.1299797492927787, 'cat_l2': 0.0027841725706150653, 'min_data_per_group': 12, 'max_cat_threshold': 20, 'cat_smooth': 5.187656278492092, 'max_bin': 58, 'num_leaves': 50, 'max_depth': 7, 'eta': 0.07373155565023351, 'min_split_gain': 0.011947820673926812, 'min_child_weight': 16, 'min_data_in_leaf': 8, 'feature_fraction': 0.9403474036258785, 'top_rate': 0.6675398982325833, 'other_rate': 0.26255617429836337}. Best is trial 1 with value: 0.25257026611385686.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:12:33,995]\u001b[0m Trial 11 finished with value: 0.24444355146697733 and parameters: {'booster': 'goss', 'lambda_l2': 0.47028819795530813, 'lambda_l1': 0.13067134538222594, 'cat_l2': 0.003212274301469588, 'min_data_per_group': 7, 'max_cat_threshold': 18, 'cat_smooth': 4.440252864489608, 'max_bin': 60, 'num_leaves': 41, 'max_depth': 7, 'eta': 0.07691775286557866, 'min_split_gain': 0.00854933452182206, 'min_child_weight': 16, 'min_data_in_leaf': 6, 'feature_fraction': 0.9459381269746069, 'top_rate': 0.45822071686286814, 'other_rate': 0.2983178041810645}. Best is trial 1 with value: 0.25257026611385686.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\sampler.py:459: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:12:36,312]\u001b[0m Trial 13 finished with value: 0.24638441809695522 and parameters: {'booster': 'goss', 'lambda_l2': 0.5766344773516032, 'lambda_l1': 0.1972885063536018, 'cat_l2': 0.0030896682216095496, 'min_data_per_group': 12, 'max_cat_threshold': 25, 'cat_smooth': 5.570368080724998, 'max_bin': 59, 'num_leaves': 38, 'max_depth': 6, 'eta': 0.07483709578465891, 'min_split_gain': 0.006439380150239569, 'min_child_weight': 16, 'min_data_in_leaf': 5, 'feature_fraction': 0.9405884074092368, 'top_rate': 0.8693863661636576, 'other_rate': 0.11290622891653651}. Best is trial 1 with value: 0.25257026611385686.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:12:38,603]\u001b[0m Trial 16 finished with value: 0.2500992724128512 and parameters: {'booster': 'goss', 'lambda_l2': 0.40128095846425205, 'lambda_l1': 0.023281366526247706, 'cat_l2': 0.0025623541992967954, 'min_data_per_group': 12, 'max_cat_threshold': 18, 'cat_smooth': 3.9121341538579193, 'max_bin': 57, 'num_leaves': 59, 'max_depth': 6, 'eta': 0.07006072359699109, 'min_split_gain': 0.009001306786304418, 'min_child_weight': 15, 'min_data_in_leaf': 3, 'feature_fraction': 0.9450486219397145, 'top_rate': 0.3820644786484645, 'other_rate': 0.1126966512145427}. Best is trial 1 with value: 0.25257026611385686.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:12:39,541]\u001b[0m Trial 18 finished with value: 0.24780014207800183 and parameters: {'booster': 'goss', 'lambda_l2': 0.7999148665874735, 'lambda_l1': 0.1283292050072638, 'cat_l2': 0.003344324549329337, 'min_data_per_group': 5, 'max_cat_threshold': 12, 'cat_smooth': 6.407852102823963, 'max_bin': 58, 'num_leaves': 39, 'max_depth': 5, 'eta': 0.07954016546939274, 'min_split_gain': 0.013787997291057594, 'min_child_weight': 19, 'min_data_in_leaf': 2, 'feature_fraction': 0.9437776416778267, 'top_rate': 0.9637993577494786, 'other_rate': 0.0023419598052110864}. Best is trial 1 with value: 0.25257026611385686.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:12:40,174]\u001b[0m Trial 19 finished with value: 0.24345589003523718 and parameters: {'booster': 'goss', 'lambda_l2': 0.7944853976275992, 'lambda_l1': 0.13076183763829186, 'cat_l2': 0.002983034241671877, 'min_data_per_group': 5, 'max_cat_threshold': 12, 'cat_smooth': 6.352798997057539, 'max_bin': 58, 'num_leaves': 38, 'max_depth': 5, 'eta': 0.0792773095833003, 'min_split_gain': 0.00993641272752868, 'min_child_weight': 19, 'min_data_in_leaf': 1, 'feature_fraction': 0.9440786801509444, 'top_rate': 0.9193807282583628, 'other_rate': 0.0645964141112893}. Best is trial 1 with value: 0.25257026611385686.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:12:40,327]\u001b[0m Trial 15 finished with value: 0.24066073110273717 and parameters: {'booster': 'goss', 'lambda_l2': 0.6838237706834563, 'lambda_l1': 0.020401664538530335, 'cat_l2': 0.0026298611632777085, 'min_data_per_group': 6, 'max_cat_threshold': 15, 'cat_smooth': 2.878248625647796, 'max_bin': 55, 'num_leaves': 44, 'max_depth': 8, 'eta': 0.07768871648759197, 'min_split_gain': 0.00879679118385826, 'min_child_weight': 15, 'min_data_in_leaf': 3, 'feature_fraction': 0.9454961473364355, 'top_rate': 0.515005878090238, 'other_rate': 0.2142501115960387}. Best is trial 1 with value: 0.25257026611385686.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:12:42,133]\u001b[0m Trial 20 finished with value: 0.24950559698288596 and parameters: {'booster': 'goss', 'lambda_l2': 0.7972532344472658, 'lambda_l1': 0.1016495872938764, 'cat_l2': 0.0034781507601363867, 'min_data_per_group': 5, 'max_cat_threshold': 12, 'cat_smooth': 6.176726233656675, 'max_bin': 58, 'num_leaves': 38, 'max_depth': 5, 'eta': 0.07545285129999298, 'min_split_gain': 0.009543492348254407, 'min_child_weight': 19, 'min_data_in_leaf': 1, 'feature_fraction': 0.9439958428631502, 'top_rate': 0.8930484324524175, 'other_rate': 0.09237284066514034}. Best is trial 1 with value: 0.25257026611385686.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:12:42,469]\u001b[0m Trial 23 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:12:43,376]\u001b[0m Trial 21 finished with value: 0.2512468585781459 and parameters: {'booster': 'goss', 'lambda_l2': 0.7763482371073576, 'lambda_l1': 0.09374178916042976, 'cat_l2': 0.0034552543744967136, 'min_data_per_group': 5, 'max_cat_threshold': 12, 'cat_smooth': 6.465247323023476, 'max_bin': 58, 'num_leaves': 38, 'max_depth': 5, 'eta': 0.07965514268941513, 'min_split_gain': 0.01389329323175148, 'min_child_weight': 19, 'min_data_in_leaf': 1, 'feature_fraction': 0.9442502108322101, 'top_rate': 0.97995354975591, 'other_rate': 0.019871739949229084}. Best is trial 1 with value: 0.25257026611385686.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:12:43,874]\u001b[0m Trial 24 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:12:43,915]\u001b[0m Trial 17 finished with value: 0.2512497389906705 and parameters: {'booster': 'goss', 'lambda_l2': 0.5576265371862321, 'lambda_l1': 0.0792027200627457, 'cat_l2': 0.003338568514331944, 'min_data_per_group': 5, 'max_cat_threshold': 12, 'cat_smooth': 6.484259040403243, 'max_bin': 58, 'num_leaves': 38, 'max_depth': 8, 'eta': 0.072507482537094, 'min_split_gain': 0.013895874546504722, 'min_child_weight': 19, 'min_data_in_leaf': 1, 'feature_fraction': 0.944203138749004, 'top_rate': 0.9584775458436678, 'other_rate': 0.03360417082866407}. Best is trial 1 with value: 0.25257026611385686.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:12:44,925]\u001b[0m Trial 26 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:12:45,094]\u001b[0m Trial 25 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:12:46,003]\u001b[0m Trial 22 finished with value: 0.24966547399488767 and parameters: {'booster': 'goss', 'lambda_l2': 0.766418373776335, 'lambda_l1': 0.09621760814525737, 'cat_l2': 0.003492744665085241, 'min_data_per_group': 5, 'max_cat_threshold': 12, 'cat_smooth': 6.4373170065380725, 'max_bin': 58, 'num_leaves': 43, 'max_depth': 5, 'eta': 0.07944034482025142, 'min_split_gain': 0.01371434321711355, 'min_child_weight': 19, 'min_data_in_leaf': 1, 'feature_fraction': 0.9435502266573403, 'top_rate': 0.848970221709236, 'other_rate': 0.05637552482880098}. Best is trial 1 with value: 0.25257026611385686.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\sampler.py:459: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\sampler.py:459: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:12:47,056]\u001b[0m Trial 27 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:12:47,701]\u001b[0m Trial 28 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\sampler.py:459: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\sampler.py:459: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:12:49,284]\u001b[0m Trial 30 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\sampler.py:459: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:12:51,404]\u001b[0m Trial 31 pruned. Trial was pruned at iteration 20.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:12:52,437]\u001b[0m Trial 36 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:12:54,608]\u001b[0m Trial 38 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:12:55,592]\u001b[0m Trial 29 finished with value: 0.2527316371024155 and parameters: {'booster': 'goss', 'lambda_l2': 0.7313113926637566, 'lambda_l1': 0.07417053931106543, 'cat_l2': 0.003476462365499494, 'min_data_per_group': 7, 'max_cat_threshold': 22, 'cat_smooth': 5.780442094305964, 'max_bin': 59, 'num_leaves': 40, 'max_depth': 8, 'eta': 0.07597134824437608, 'min_split_gain': 0.013949180170676577, 'min_child_weight': 19, 'min_data_in_leaf': 2, 'feature_fraction': 0.9467647127684768, 'top_rate': 0.9818498174623076, 'other_rate': 0.010113713176376058}. Best is trial 29 with value: 0.2527316371024155.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:12:55,957]\u001b[0m Trial 39 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:12:56,820]\u001b[0m Trial 32 finished with value: 0.2514909232994099 and parameters: {'booster': 'goss', 'lambda_l2': 0.5982462592750669, 'lambda_l1': 0.06527346797919638, 'cat_l2': 0.003329412172458045, 'min_data_per_group': 6, 'max_cat_threshold': 14, 'cat_smooth': 5.727930650844502, 'max_bin': 59, 'num_leaves': 41, 'max_depth': 8, 'eta': 0.07627348307845115, 'min_split_gain': 0.01285334330005792, 'min_child_weight': 19, 'min_data_in_leaf': 2, 'feature_fraction': 0.9468083914769451, 'top_rate': 0.014054026518375673, 'other_rate': 0.8885389061606181}. Best is trial 29 with value: 0.2527316371024155.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:12:57,801]\u001b[0m Trial 40 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:12:57,857]\u001b[0m Trial 34 finished with value: 0.2586352644702073 and parameters: {'booster': 'goss', 'lambda_l2': 0.5921899895050626, 'lambda_l1': 0.0657841003343484, 'cat_l2': 0.0032772023694486565, 'min_data_per_group': 6, 'max_cat_threshold': 14, 'cat_smooth': 5.746801066352235, 'max_bin': 59, 'num_leaves': 40, 'max_depth': 8, 'eta': 0.07275648093566002, 'min_split_gain': 0.012879216406469166, 'min_child_weight': 17, 'min_data_in_leaf': 2, 'feature_fraction': 0.9427388749973236, 'top_rate': 0.995561894590299, 'other_rate': 0.003827578966132305}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:13:00,058]\u001b[0m Trial 33 finished with value: 0.2511396047960298 and parameters: {'booster': 'goss', 'lambda_l2': 0.5889899840843474, 'lambda_l1': 0.06775623436094128, 'cat_l2': 0.0033028337208436637, 'min_data_per_group': 6, 'max_cat_threshold': 14, 'cat_smooth': 5.792291372653756, 'max_bin': 59, 'num_leaves': 40, 'max_depth': 8, 'eta': 0.07283711809575052, 'min_split_gain': 0.013007414000697099, 'min_child_weight': 19, 'min_data_in_leaf': 2, 'feature_fraction': 0.9469335729454961, 'top_rate': 0.9986952733465, 'other_rate': 0.0012895929947922338}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:00,677]\u001b[0m Trial 42 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:13:01,422]\u001b[0m Trial 35 finished with value: 0.2527264459805575 and parameters: {'booster': 'goss', 'lambda_l2': 0.5363954088907854, 'lambda_l1': 0.05834986526337527, 'cat_l2': 0.0033354851799437123, 'min_data_per_group': 6, 'max_cat_threshold': 16, 'cat_smooth': 5.986799330377028, 'max_bin': 59, 'num_leaves': 41, 'max_depth': 8, 'eta': 0.07427751470155212, 'min_split_gain': 0.012793019282888464, 'min_child_weight': 17, 'min_data_in_leaf': 1, 'feature_fraction': 0.9432727932497229, 'top_rate': 0.9980628546273331, 'other_rate': 0.0019280140023790332}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:01,430]\u001b[0m Trial 37 finished with value: 0.25572363816910854 and parameters: {'booster': 'goss', 'lambda_l2': 0.5233537022019892, 'lambda_l1': 0.05089345156079397, 'cat_l2': 0.0029309545449726, 'min_data_per_group': 6, 'max_cat_threshold': 16, 'cat_smooth': 5.38516095101839, 'max_bin': 59, 'num_leaves': 40, 'max_depth': 8, 'eta': 0.0746189977207041, 'min_split_gain': 0.01272033407831791, 'min_child_weight': 17, 'min_data_in_leaf': 1, 'feature_fraction': 0.9426037945222383, 'top_rate': 0.7196459084687541, 'other_rate': 0.032400464639335}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:01,941]\u001b[0m Trial 43 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:02,680]\u001b[0m Trial 45 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:02,987]\u001b[0m Trial 44 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:13:05,024]\u001b[0m Trial 46 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:13:05,932]\u001b[0m Trial 47 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:13:06,585]\u001b[0m Trial 48 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:06,686]\u001b[0m Trial 49 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:06,726]\u001b[0m Trial 41 finished with value: 0.25022635152072403 and parameters: {'booster': 'goss', 'lambda_l2': 0.6264556852133835, 'lambda_l1': 0.1117419902175392, 'cat_l2': 0.0031884562876432574, 'min_data_per_group': 8, 'max_cat_threshold': 20, 'cat_smooth': 5.344419589449092, 'max_bin': 59, 'num_leaves': 41, 'max_depth': 8, 'eta': 0.07096403107920296, 'min_split_gain': 0.011286745038995896, 'min_child_weight': 17, 'min_data_in_leaf': 2, 'feature_fraction': 0.9469448244284111, 'top_rate': 0.19707392690877576, 'other_rate': 0.6123562234012887}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:06,968]\u001b[0m Trial 50 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:07,677]\u001b[0m Trial 52 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:08,029]\u001b[0m Trial 51 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:13:09,755]\u001b[0m Trial 53 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\sampler.py:459: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:13:11,750]\u001b[0m Trial 54 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:12,346]\u001b[0m Trial 57 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:12,404]\u001b[0m Trial 56 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:12,575]\u001b[0m Trial 55 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:13:13,100]\u001b[0m Trial 59 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:13,147]\u001b[0m Trial 60 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:13,643]\u001b[0m Trial 58 pruned. Trial was pruned at iteration 19.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\sampler.py:459: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\sampler.py:459: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:13:17,495]\u001b[0m Trial 62 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:18,551]\u001b[0m Trial 63 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:18,835]\u001b[0m Trial 64 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:19,036]\u001b[0m Trial 68 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:19,209]\u001b[0m Trial 65 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\sampler.py:459: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:13:19,675]\u001b[0m Trial 66 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:19,827]\u001b[0m Trial 67 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:20,141]\u001b[0m Trial 61 finished with value: 0.24556031408083032 and parameters: {'booster': 'goss', 'lambda_l2': 0.5668992800788932, 'lambda_l1': 0.07813759133786363, 'cat_l2': 0.0032661167542221313, 'min_data_per_group': 7, 'max_cat_threshold': 15, 'cat_smooth': 5.874726257609183, 'max_bin': 59, 'num_leaves': 56, 'max_depth': 8, 'eta': 0.07674499055078729, 'min_split_gain': 0.007827609006557545, 'min_child_weight': 17, 'min_data_in_leaf': 2, 'feature_fraction': 0.9433788433579184, 'top_rate': 0.0509444310236783, 'other_rate': 0.17442824430615286}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:20,472]\u001b[0m Trial 69 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\sampler.py:459: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\sampler.py:459: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:13:23,272]\u001b[0m Trial 70 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\sampler.py:459: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:13:24,013]\u001b[0m Trial 71 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:24,824]\u001b[0m Trial 74 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:24,999]\u001b[0m Trial 75 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:25,226]\u001b[0m Trial 77 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\sampler.py:459: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\sampler.py:459: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\sampler.py:459: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\sampler.py:459: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:13:28,553]\u001b[0m Trial 79 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:29,864]\u001b[0m Trial 80 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:30,176]\u001b[0m Trial 82 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:30,176]\u001b[0m Trial 81 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\sampler.py:459: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:13:31,300]\u001b[0m Trial 72 finished with value: 0.24675938835375505 and parameters: {'booster': 'goss', 'lambda_l2': 0.6123635863250945, 'lambda_l1': 0.10632592569054983, 'cat_l2': 0.0033328921732779923, 'min_data_per_group': 5, 'max_cat_threshold': 16, 'cat_smooth': 6.498855316542055, 'max_bin': 57, 'num_leaves': 40, 'max_depth': 8, 'eta': 0.07791136796938136, 'min_split_gain': 0.0129558712732162, 'min_child_weight': 18, 'min_data_in_leaf': 3, 'feature_fraction': 0.9437040426784132, 'top_rate': 0.9997565521187126, 'other_rate': 0.00023986322449376374}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:32,175]\u001b[0m Trial 83 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:32,571]\u001b[0m Trial 73 finished with value: 0.2517645801757151 and parameters: {'booster': 'goss', 'lambda_l2': 0.6072775399960783, 'lambda_l1': 0.07162549757163639, 'cat_l2': 0.003360391952229691, 'min_data_per_group': 5, 'max_cat_threshold': 16, 'cat_smooth': 2.0108351504842106, 'max_bin': 57, 'num_leaves': 40, 'max_depth': 8, 'eta': 0.07765377805294285, 'min_split_gain': 0.012444090778562362, 'min_child_weight': 18, 'min_data_in_leaf': 5, 'feature_fraction': 0.9448913416234085, 'top_rate': 0.9976232821210037, 'other_rate': 0.0023669952896334667}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:32,972]\u001b[0m Trial 76 finished with value: 0.2538164492920105 and parameters: {'booster': 'goss', 'lambda_l2': 0.6143644176346983, 'lambda_l1': 0.07215369321263775, 'cat_l2': 0.0021402991830204113, 'min_data_per_group': 5, 'max_cat_threshold': 16, 'cat_smooth': 3.3366251614319733, 'max_bin': 57, 'num_leaves': 40, 'max_depth': 8, 'eta': 0.07583453376853479, 'min_split_gain': 0.013964996824074448, 'min_child_weight': 18, 'min_data_in_leaf': 3, 'feature_fraction': 0.9438029824579859, 'top_rate': 0.7433851971657084, 'other_rate': 0.11329532421385798}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\sampler.py:459: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:13:34,942]\u001b[0m Trial 78 finished with value: 0.2525943989047087 and parameters: {'booster': 'goss', 'lambda_l2': 0.7714833215273397, 'lambda_l1': 0.09545838190273329, 'cat_l2': 0.0034524300466538347, 'min_data_per_group': 5, 'max_cat_threshold': 16, 'cat_smooth': 6.486189937213192, 'max_bin': 58, 'num_leaves': 40, 'max_depth': 8, 'eta': 0.0741476559122299, 'min_split_gain': 0.012987849370552178, 'min_child_weight': 19, 'min_data_in_leaf': 1, 'feature_fraction': 0.9442379948601007, 'top_rate': 0.9938955642798943, 'other_rate': 0.0013294990630620832}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:13:38,551]\u001b[0m Trial 89 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:38,785]\u001b[0m Trial 88 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:39,137]\u001b[0m Trial 90 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:39,534]\u001b[0m Trial 91 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\sampler.py:459: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:13:43,192]\u001b[0m Trial 86 finished with value: 0.25582444275876653 and parameters: {'booster': 'goss', 'lambda_l2': 0.7534138141826383, 'lambda_l1': 0.06247874231038167, 'cat_l2': 0.0022903591385164917, 'min_data_per_group': 6, 'max_cat_threshold': 23, 'cat_smooth': 2.084180290308832, 'max_bin': 58, 'num_leaves': 43, 'max_depth': 7, 'eta': 0.07310487072999278, 'min_split_gain': 0.012177546004933464, 'min_child_weight': 19, 'min_data_in_leaf': 6, 'feature_fraction': 0.9455945625932812, 'top_rate': 0.8549913327794346, 'other_rate': 0.03920193631024744}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:43,559]\u001b[0m Trial 85 finished with value: 0.2532202192933685 and parameters: {'booster': 'goss', 'lambda_l2': 0.7267297962472132, 'lambda_l1': 0.061745867553807156, 'cat_l2': 0.0022947457545105993, 'min_data_per_group': 11, 'max_cat_threshold': 21, 'cat_smooth': 2.0071509287497813, 'max_bin': 58, 'num_leaves': 43, 'max_depth': 7, 'eta': 0.07287362144407807, 'min_split_gain': 0.0121196616534019, 'min_child_weight': 19, 'min_data_in_leaf': 5, 'feature_fraction': 0.9466029998266224, 'top_rate': 0.6779723062516939, 'other_rate': 0.2165358247094431}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:43,828]\u001b[0m Trial 92 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:43,961]\u001b[0m Trial 84 finished with value: 0.24974231033993394 and parameters: {'booster': 'goss', 'lambda_l2': 0.722134197294781, 'lambda_l1': 0.06069616052479685, 'cat_l2': 0.0032287757715720906, 'min_data_per_group': 11, 'max_cat_threshold': 23, 'cat_smooth': 5.951127791103988, 'max_bin': 58, 'num_leaves': 45, 'max_depth': 7, 'eta': 0.07040917286130823, 'min_split_gain': 0.005992990610973262, 'min_child_weight': 19, 'min_data_in_leaf': 6, 'feature_fraction': 0.9455413894783746, 'top_rate': 0.9153707709235651, 'other_rate': 0.012615342963951346}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:44,867]\u001b[0m Trial 95 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:44,992]\u001b[0m Trial 87 finished with value: 0.2529551831471422 and parameters: {'booster': 'goss', 'lambda_l2': 0.750495424333197, 'lambda_l1': 0.06158796538717164, 'cat_l2': 0.0022927906399337096, 'min_data_per_group': 6, 'max_cat_threshold': 21, 'cat_smooth': 6.061688130175775, 'max_bin': 59, 'num_leaves': 43, 'max_depth': 8, 'eta': 0.07585476273654156, 'min_split_gain': 0.00571984012338116, 'min_child_weight': 17, 'min_data_in_leaf': 5, 'feature_fraction': 0.9429447164928703, 'top_rate': 0.40743237144604644, 'other_rate': 0.10860864090569675}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:13:49,023]\u001b[0m Trial 96 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:49,241]\u001b[0m Trial 97 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:49,604]\u001b[0m Trial 98 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:49,655]\u001b[0m Trial 93 finished with value: 0.24839273295219666 and parameters: {'booster': 'goss', 'lambda_l2': 0.5818869379088069, 'lambda_l1': 0.04867602334437442, 'cat_l2': 0.002132515532332704, 'min_data_per_group': 6, 'max_cat_threshold': 16, 'cat_smooth': 2.5032511955491348, 'max_bin': 59, 'num_leaves': 42, 'max_depth': 7, 'eta': 0.0752856139887967, 'min_split_gain': 0.012631572939938978, 'min_child_weight': 18, 'min_data_in_leaf': 2, 'feature_fraction': 0.946671999291752, 'top_rate': 0.6691727374491132, 'other_rate': 0.046971445207276794}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:50,056]\u001b[0m Trial 94 finished with value: 0.2527985746283016 and parameters: {'booster': 'goss', 'lambda_l2': 0.6841756214760563, 'lambda_l1': 0.04839473636747205, 'cat_l2': 0.003230957908797958, 'min_data_per_group': 6, 'max_cat_threshold': 23, 'cat_smooth': 2.7074375998474802, 'max_bin': 59, 'num_leaves': 45, 'max_depth': 7, 'eta': 0.07635194997003142, 'min_split_gain': 0.012689647127594421, 'min_child_weight': 18, 'min_data_in_leaf': 2, 'feature_fraction': 0.946590053985628, 'top_rate': 0.670969582460196, 'other_rate': 0.2231675953902646}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:50,196]\u001b[0m Trial 100 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:50,213]\u001b[0m Trial 101 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:13:52,630]\u001b[0m Trial 99 finished with value: 0.25097194701688813 and parameters: {'booster': 'goss', 'lambda_l2': 0.7490647898211251, 'lambda_l1': 0.04981316103001927, 'cat_l2': 0.002003953513231411, 'min_data_per_group': 12, 'max_cat_threshold': 23, 'cat_smooth': 2.0967219751531543, 'max_bin': 58, 'num_leaves': 45, 'max_depth': 7, 'eta': 0.07523739009197762, 'min_split_gain': 0.01263801470465526, 'min_child_weight': 17, 'min_data_in_leaf': 6, 'feature_fraction': 0.9465632952057391, 'top_rate': 0.8013787681340113, 'other_rate': 0.0629616002612598}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:14:00,910]\u001b[0m Trial 106 finished with value: 0.2470559585496679 and parameters: {'booster': 'goss', 'lambda_l2': 0.7567918808028149, 'lambda_l1': 0.12428945059633975, 'cat_l2': 0.002327901446649067, 'min_data_per_group': 10, 'max_cat_threshold': 20, 'cat_smooth': 2.354578328618746, 'max_bin': 58, 'num_leaves': 44, 'max_depth': 7, 'eta': 0.0726786261297619, 'min_split_gain': 0.013399757943412107, 'min_child_weight': 19, 'min_data_in_leaf': 5, 'feature_fraction': 0.9440105128441246, 'top_rate': 0.565248757966691, 'other_rate': 0.055686553116797634}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:01,143]\u001b[0m Trial 103 finished with value: 0.2510635252106125 and parameters: {'booster': 'goss', 'lambda_l2': 0.7349098904741994, 'lambda_l1': 0.12509212281025933, 'cat_l2': 0.002355522227842682, 'min_data_per_group': 10, 'max_cat_threshold': 20, 'cat_smooth': 2.269132121020348, 'max_bin': 58, 'num_leaves': 44, 'max_depth': 7, 'eta': 0.07645134664701417, 'min_split_gain': 0.013429609722606069, 'min_child_weight': 19, 'min_data_in_leaf': 5, 'feature_fraction': 0.9439324513516905, 'top_rate': 0.5772654611178946, 'other_rate': 0.21643127265629855}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:01,436]\u001b[0m Trial 105 finished with value: 0.24684229713746925 and parameters: {'booster': 'goss', 'lambda_l2': 0.7841127718167303, 'lambda_l1': 0.05922112942592192, 'cat_l2': 0.0024007292255140457, 'min_data_per_group': 10, 'max_cat_threshold': 20, 'cat_smooth': 2.3257581432369987, 'max_bin': 58, 'num_leaves': 44, 'max_depth': 7, 'eta': 0.07269922075803918, 'min_split_gain': 0.011517583968658651, 'min_child_weight': 19, 'min_data_in_leaf': 5, 'feature_fraction': 0.9440226515012602, 'top_rate': 0.6469364510345094, 'other_rate': 0.09696798383987176}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:01,596]\u001b[0m Trial 104 finished with value: 0.2514807436210522 and parameters: {'booster': 'goss', 'lambda_l2': 0.7591989305348154, 'lambda_l1': 0.06023131332971873, 'cat_l2': 0.0023397099447355673, 'min_data_per_group': 7, 'max_cat_threshold': 20, 'cat_smooth': 2.3334991143519717, 'max_bin': 58, 'num_leaves': 44, 'max_depth': 7, 'eta': 0.07650920525383968, 'min_split_gain': 0.011484648774699237, 'min_child_weight': 19, 'min_data_in_leaf': 5, 'feature_fraction': 0.9431566309481706, 'top_rate': 0.6355435321705301, 'other_rate': 0.014854791157456877}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:02,024]\u001b[0m Trial 108 finished with value: 0.25222208388466083 and parameters: {'booster': 'goss', 'lambda_l2': 0.7336554014997335, 'lambda_l1': 0.06705996863504711, 'cat_l2': 0.0023657614024807333, 'min_data_per_group': 10, 'max_cat_threshold': 20, 'cat_smooth': 3.073903411643721, 'max_bin': 58, 'num_leaves': 44, 'max_depth': 7, 'eta': 0.07272250823600593, 'min_split_gain': 0.009638151926423987, 'min_child_weight': 19, 'min_data_in_leaf': 5, 'feature_fraction': 0.9431360963193777, 'top_rate': 0.5555901670637401, 'other_rate': 0.13840881131246724}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:02,449]\u001b[0m Trial 102 finished with value: 0.2556160224341649 and parameters: {'booster': 'goss', 'lambda_l2': 0.7863751376789244, 'lambda_l1': 0.11962112779943551, 'cat_l2': 0.0024357020613995782, 'min_data_per_group': 7, 'max_cat_threshold': 20, 'cat_smooth': 2.3664596307701418, 'max_bin': 58, 'num_leaves': 44, 'max_depth': 7, 'eta': 0.07560345483194802, 'min_split_gain': 0.00847872837383047, 'min_child_weight': 19, 'min_data_in_leaf': 5, 'feature_fraction': 0.9469900241270733, 'top_rate': 0.6573488358060962, 'other_rate': 0.07508401222424338}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:02,571]\u001b[0m Trial 107 finished with value: 0.2502647364386594 and parameters: {'booster': 'goss', 'lambda_l2': 0.7191501272828478, 'lambda_l1': 0.0665882521208902, 'cat_l2': 0.002326397594840918, 'min_data_per_group': 7, 'max_cat_threshold': 20, 'cat_smooth': 2.3201718256527557, 'max_bin': 58, 'num_leaves': 44, 'max_depth': 7, 'eta': 0.07642267509973814, 'min_split_gain': 0.011578488585837586, 'min_child_weight': 19, 'min_data_in_leaf': 5, 'feature_fraction': 0.9439263611952566, 'top_rate': 0.35632862851397107, 'other_rate': 0.3356413663768198}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:03,509]\u001b[0m Trial 109 finished with value: 0.25400125143797925 and parameters: {'booster': 'goss', 'lambda_l2': 0.7319161831766101, 'lambda_l1': 0.12157325013526774, 'cat_l2': 0.002371045508966523, 'min_data_per_group': 7, 'max_cat_threshold': 25, 'cat_smooth': 2.252700344833433, 'max_bin': 59, 'num_leaves': 44, 'max_depth': 7, 'eta': 0.07465147702274161, 'min_split_gain': 0.011489133595383571, 'min_child_weight': 19, 'min_data_in_leaf': 5, 'feature_fraction': 0.9430256688982647, 'top_rate': 0.5734176161869076, 'other_rate': 0.028428353127987766}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:14:07,056]\u001b[0m Trial 111 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:07,367]\u001b[0m Trial 112 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:08,032]\u001b[0m Trial 116 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:08,412]\u001b[0m Trial 117 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:14:13,249]\u001b[0m Trial 120 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:13,432]\u001b[0m Trial 121 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:14,656]\u001b[0m Trial 110 finished with value: 0.2552580905005643 and parameters: {'booster': 'goss', 'lambda_l2': 0.71817215629843, 'lambda_l1': 0.06703028383621616, 'cat_l2': 0.0022140594881332482, 'min_data_per_group': 7, 'max_cat_threshold': 21, 'cat_smooth': 2.75227844430191, 'max_bin': 59, 'num_leaves': 41, 'max_depth': 7, 'eta': 0.07564186750772522, 'min_split_gain': 0.005018994393670229, 'min_child_weight': 17, 'min_data_in_leaf': 4, 'feature_fraction': 0.946988945546699, 'top_rate': 0.6780822515347498, 'other_rate': 0.04806887804343462}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:14,821]\u001b[0m Trial 113 finished with value: 0.2528342014614715 and parameters: {'booster': 'goss', 'lambda_l2': 0.7069577902398776, 'lambda_l1': 0.08965985201500819, 'cat_l2': 0.002460605015055308, 'min_data_per_group': 7, 'max_cat_threshold': 21, 'cat_smooth': 2.748356341303558, 'max_bin': 59, 'num_leaves': 41, 'max_depth': 7, 'eta': 0.0755981253058213, 'min_split_gain': 0.005129850404020865, 'min_child_weight': 17, 'min_data_in_leaf': 4, 'feature_fraction': 0.9468305217617686, 'top_rate': 0.713738356130781, 'other_rate': 0.22586536861659362}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:15,195]\u001b[0m Trial 114 finished with value: 0.2493985001778562 and parameters: {'booster': 'goss', 'lambda_l2': 0.7169153622351664, 'lambda_l1': 0.14235630751120074, 'cat_l2': 0.0024675175494663936, 'min_data_per_group': 7, 'max_cat_threshold': 21, 'cat_smooth': 2.4189267032041584, 'max_bin': 59, 'num_leaves': 46, 'max_depth': 7, 'eta': 0.07565545915906068, 'min_split_gain': 0.005293451818450421, 'min_child_weight': 17, 'min_data_in_leaf': 4, 'feature_fraction': 0.9463258495434955, 'top_rate': 0.7278173465446084, 'other_rate': 0.03656008757316667}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:15,598]\u001b[0m Trial 115 finished with value: 0.2528384528802303 and parameters: {'booster': 'goss', 'lambda_l2': 0.5216924816891988, 'lambda_l1': 0.08961675730865543, 'cat_l2': 0.002452058825434117, 'min_data_per_group': 13, 'max_cat_threshold': 21, 'cat_smooth': 2.4392679703317945, 'max_bin': 59, 'num_leaves': 47, 'max_depth': 7, 'eta': 0.07470288219886123, 'min_split_gain': 0.01090536418344066, 'min_child_weight': 17, 'min_data_in_leaf': 4, 'feature_fraction': 0.9422453945038776, 'top_rate': 0.6808200201262729, 'other_rate': 0.0762321595928299}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:16,858]\u001b[0m Trial 118 finished with value: 0.2550233498938586 and parameters: {'booster': 'goss', 'lambda_l2': 0.7021925137840583, 'lambda_l1': 0.1438418828912233, 'cat_l2': 0.0022632086318053455, 'min_data_per_group': 7, 'max_cat_threshold': 22, 'cat_smooth': 2.7651745843532742, 'max_bin': 59, 'num_leaves': 43, 'max_depth': 8, 'eta': 0.07477121266394847, 'min_split_gain': 0.009223099496876505, 'min_child_weight': 19, 'min_data_in_leaf': 7, 'feature_fraction': 0.9463637955108499, 'top_rate': 0.530475886296434, 'other_rate': 0.010607625879665794}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:14:18,249]\u001b[0m Trial 119 finished with value: 0.2523083029470582 and parameters: {'booster': 'goss', 'lambda_l2': 0.7594033900096877, 'lambda_l1': 0.1330133263218537, 'cat_l2': 0.0022821558718602994, 'min_data_per_group': 7, 'max_cat_threshold': 22, 'cat_smooth': 2.1781462240176546, 'max_bin': 59, 'num_leaves': 45, 'max_depth': 8, 'eta': 0.07458197792417463, 'min_split_gain': 0.008630103123288522, 'min_child_weight': 19, 'min_data_in_leaf': 7, 'feature_fraction': 0.942953135176449, 'top_rate': 0.5291310778058417, 'other_rate': 0.10357269985169873}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:19,190]\u001b[0m Trial 122 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:19,244]\u001b[0m Trial 123 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:14:21,397]\u001b[0m Trial 124 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:21,605]\u001b[0m Trial 125 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:21,732]\u001b[0m Trial 127 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:21,841]\u001b[0m Trial 126 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:22,270]\u001b[0m Trial 128 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:14:23,700]\u001b[0m Trial 129 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:24,424]\u001b[0m Trial 130 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:24,490]\u001b[0m Trial 131 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:14:27,134]\u001b[0m Trial 133 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:27,509]\u001b[0m Trial 132 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:27,738]\u001b[0m Trial 135 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:27,875]\u001b[0m Trial 136 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:14:28,379]\u001b[0m Trial 137 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:14:29,554]\u001b[0m Trial 139 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:29,951]\u001b[0m Trial 138 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:31,543]\u001b[0m Trial 134 finished with value: 0.25483072502545034 and parameters: {'booster': 'goss', 'lambda_l2': 0.6600846137139843, 'lambda_l1': 0.07573893873064633, 'cat_l2': 0.0024003964954334113, 'min_data_per_group': 8, 'max_cat_threshold': 21, 'cat_smooth': 2.824035728097634, 'max_bin': 59, 'num_leaves': 43, 'max_depth': 7, 'eta': 0.07540096560735919, 'min_split_gain': 0.010262252971048866, 'min_child_weight': 19, 'min_data_in_leaf': 3, 'feature_fraction': 0.9467072242204082, 'top_rate': 0.6423100425039453, 'other_rate': 0.011637831144813465}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:14:34,135]\u001b[0m Trial 142 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:34,188]\u001b[0m Trial 140 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:14:34,824]\u001b[0m Trial 144 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:34,975]\u001b[0m Trial 141 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:14:37,704]\u001b[0m Trial 147 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:14:40,105]\u001b[0m Trial 149 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:40,302]\u001b[0m Trial 148 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:40,695]\u001b[0m Trial 150 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:40,846]\u001b[0m Trial 151 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:41,340]\u001b[0m Trial 146 finished with value: 0.25608749134198927 and parameters: {'booster': 'goss', 'lambda_l2': 0.4804029781208209, 'lambda_l1': 0.07405772818153951, 'cat_l2': 0.0021453850250373985, 'min_data_per_group': 6, 'max_cat_threshold': 23, 'cat_smooth': 2.592999505162176, 'max_bin': 58, 'num_leaves': 60, 'max_depth': 7, 'eta': 0.07509887517509724, 'min_split_gain': 0.01063522848408654, 'min_child_weight': 17, 'min_data_in_leaf': 4, 'feature_fraction': 0.9464177033961425, 'top_rate': 0.63419408255435, 'other_rate': 0.07134634003594836}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:41,405]\u001b[0m Trial 143 finished with value: 0.24847497589226655 and parameters: {'booster': 'goss', 'lambda_l2': 0.6976349297342527, 'lambda_l1': 0.07103937398292075, 'cat_l2': 0.0021586525896883234, 'min_data_per_group': 7, 'max_cat_threshold': 22, 'cat_smooth': 2.592036006628838, 'max_bin': 58, 'num_leaves': 39, 'max_depth': 8, 'eta': 0.07510106539875495, 'min_split_gain': 0.009238524651839611, 'min_child_weight': 17, 'min_data_in_leaf': 5, 'feature_fraction': 0.94568533510909, 'top_rate': 0.6178256329371149, 'other_rate': 0.08798829480564659}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:41,666]\u001b[0m Trial 145 finished with value: 0.2574753029167793 and parameters: {'booster': 'goss', 'lambda_l2': 0.7293110973524527, 'lambda_l1': 0.08952298793474704, 'cat_l2': 0.0023029267910544774, 'min_data_per_group': 6, 'max_cat_threshold': 23, 'cat_smooth': 3.4366897115950374, 'max_bin': 58, 'num_leaves': 39, 'max_depth': 7, 'eta': 0.0751545007551665, 'min_split_gain': 0.010763857079891938, 'min_child_weight': 17, 'min_data_in_leaf': 4, 'feature_fraction': 0.9464249991137471, 'top_rate': 0.6348429838829626, 'other_rate': 0.033924710594382415}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:41,830]\u001b[0m Trial 152 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:14:44,634]\u001b[0m Trial 153 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:44,860]\u001b[0m Trial 154 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:14:46,090]\u001b[0m Trial 155 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:46,476]\u001b[0m Trial 156 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:46,477]\u001b[0m Trial 158 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:46,661]\u001b[0m Trial 157 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:46,919]\u001b[0m Trial 160 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:46,941]\u001b[0m Trial 159 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:14:49,334]\u001b[0m Trial 162 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:14:50,272]\u001b[0m Trial 161 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:14:51,861]\u001b[0m Trial 165 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:52,640]\u001b[0m Trial 164 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:52,735]\u001b[0m Trial 167 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:52,851]\u001b[0m Trial 168 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:52,854]\u001b[0m Trial 166 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:14:55,822]\u001b[0m Trial 169 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:56,027]\u001b[0m Trial 163 finished with value: 0.2511703011467725 and parameters: {'booster': 'goss', 'lambda_l2': 0.45069912834834913, 'lambda_l1': 0.08623876425390076, 'cat_l2': 0.00238015344998232, 'min_data_per_group': 5, 'max_cat_threshold': 22, 'cat_smooth': 2.780513474187998, 'max_bin': 59, 'num_leaves': 42, 'max_depth': 7, 'eta': 0.07658927028424573, 'min_split_gain': 0.011419613030875837, 'min_child_weight': 17, 'min_data_in_leaf': 6, 'feature_fraction': 0.9452413033638486, 'top_rate': 0.6776070106263251, 'other_rate': 0.049050846030944326}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:56,314]\u001b[0m Trial 170 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\sampler.py:459: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\sampler.py:459: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\sampler.py:459: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:14:58,688]\u001b[0m Trial 171 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:59,294]\u001b[0m Trial 174 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:59,586]\u001b[0m Trial 175 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:59,587]\u001b[0m Trial 172 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:14:59,588]\u001b[0m Trial 173 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\sampler.py:459: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:15:02,695]\u001b[0m Trial 176 pruned. Trial was pruned at iteration 19.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:15:03,266]\u001b[0m Trial 178 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:15:06,116]\u001b[0m Trial 180 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\sampler.py:459: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:15:08,425]\u001b[0m Trial 184 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:15:08,582]\u001b[0m Trial 177 finished with value: 0.2547536078051821 and parameters: {'booster': 'goss', 'lambda_l2': 0.6558314092025801, 'lambda_l1': 0.09970980961942705, 'cat_l2': 0.003223897555472623, 'min_data_per_group': 7, 'max_cat_threshold': 20, 'cat_smooth': 5.764556530767181, 'max_bin': 58, 'num_leaves': 43, 'max_depth': 8, 'eta': 0.07448115912820229, 'min_split_gain': 0.013053342147685639, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9429039132442488, 'top_rate': 0.7075103754987575, 'other_rate': 0.15054694794675216}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:15:08,942]\u001b[0m Trial 185 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:15:09,660]\u001b[0m Trial 186 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:15:12,960]\u001b[0m Trial 183 finished with value: 0.2548329181498087 and parameters: {'booster': 'goss', 'lambda_l2': 0.5181023250141846, 'lambda_l1': 0.06708335557622647, 'cat_l2': 0.0031811562702252754, 'min_data_per_group': 6, 'max_cat_threshold': 15, 'cat_smooth': 5.975673355833383, 'max_bin': 58, 'num_leaves': 55, 'max_depth': 8, 'eta': 0.07438570313020176, 'min_split_gain': 0.012749675503750895, 'min_child_weight': 17, 'min_data_in_leaf': 3, 'feature_fraction': 0.9435943608114685, 'top_rate': 0.7032989082819909, 'other_rate': 0.045546460590930093}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:15:13,341]\u001b[0m Trial 181 finished with value: 0.25209671945226275 and parameters: {'booster': 'goss', 'lambda_l2': 0.5277756635586995, 'lambda_l1': 0.0693231301048876, 'cat_l2': 0.003175857717234037, 'min_data_per_group': 6, 'max_cat_threshold': 21, 'cat_smooth': 6.112676156722897, 'max_bin': 58, 'num_leaves': 39, 'max_depth': 8, 'eta': 0.07427786952775801, 'min_split_gain': 0.013139327104276838, 'min_child_weight': 17, 'min_data_in_leaf': 3, 'feature_fraction': 0.9436308173799173, 'top_rate': 0.7079622421688677, 'other_rate': 0.03146687427997609}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:15:13,402]\u001b[0m Trial 182 finished with value: 0.2515369929044722 and parameters: {'booster': 'goss', 'lambda_l2': 0.5168211206820692, 'lambda_l1': 0.0661816348990478, 'cat_l2': 0.0032220737084165305, 'min_data_per_group': 6, 'max_cat_threshold': 15, 'cat_smooth': 5.895815260937384, 'max_bin': 58, 'num_leaves': 39, 'max_depth': 8, 'eta': 0.0742704551770835, 'min_split_gain': 0.01314796420145143, 'min_child_weight': 17, 'min_data_in_leaf': 3, 'feature_fraction': 0.9468127140531714, 'top_rate': 0.700817327229001, 'other_rate': 0.04342169930494307}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:15:13,657]\u001b[0m Trial 179 finished with value: 0.2529914277269956 and parameters: {'booster': 'goss', 'lambda_l2': 0.5249638624380449, 'lambda_l1': 0.06676014502228944, 'cat_l2': 0.003311403477336039, 'min_data_per_group': 6, 'max_cat_threshold': 21, 'cat_smooth': 5.932051508153088, 'max_bin': 58, 'num_leaves': 39, 'max_depth': 8, 'eta': 0.0736243489207871, 'min_split_gain': 0.013135808809398476, 'min_child_weight': 17, 'min_data_in_leaf': 3, 'feature_fraction': 0.9435547684216399, 'top_rate': 0.7165189501699015, 'other_rate': 0.06798348848811595}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:15:14,123]\u001b[0m Trial 188 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:15:14,242]\u001b[0m Trial 189 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:15:14,621]\u001b[0m Trial 190 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:15:17,007]\u001b[0m Trial 187 finished with value: 0.25068697393310213 and parameters: {'booster': 'goss', 'lambda_l2': 0.5579947157049525, 'lambda_l1': 0.056463424028943734, 'cat_l2': 0.00321220133744472, 'min_data_per_group': 6, 'max_cat_threshold': 15, 'cat_smooth': 6.148665982073387, 'max_bin': 58, 'num_leaves': 40, 'max_depth': 8, 'eta': 0.07433878687563218, 'min_split_gain': 0.009477913142157257, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9427716489084906, 'top_rate': 0.6594072504651327, 'other_rate': 0.16619283200276658}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:15:19,108]\u001b[0m Trial 191 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:15:19,321]\u001b[0m Trial 193 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:15:19,509]\u001b[0m Trial 192 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:15:20,893]\u001b[0m Trial 197 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:15:23,818]\u001b[0m Trial 198 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:15:25,789]\u001b[0m Trial 196 finished with value: 0.2507047934728426 and parameters: {'booster': 'goss', 'lambda_l2': 0.7794226592545471, 'lambda_l1': 0.07874898121602565, 'cat_l2': 0.00331443522709238, 'min_data_per_group': 6, 'max_cat_threshold': 21, 'cat_smooth': 2.384096893546697, 'max_bin': 58, 'num_leaves': 58, 'max_depth': 7, 'eta': 0.07261235170467163, 'min_split_gain': 0.010519422485754697, 'min_child_weight': 17, 'min_data_in_leaf': 3, 'feature_fraction': 0.9435430517282245, 'top_rate': 0.7263536941218933, 'other_rate': 0.08000794780355087}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:15:25,997]\u001b[0m Trial 194 finished with value: 0.2501431184287837 and parameters: {'booster': 'goss', 'lambda_l2': 0.502731112034774, 'lambda_l1': 0.07851740360857554, 'cat_l2': 0.0032987906927439406, 'min_data_per_group': 6, 'max_cat_threshold': 14, 'cat_smooth': 2.354242229107588, 'max_bin': 58, 'num_leaves': 43, 'max_depth': 7, 'eta': 0.0732658468242701, 'min_split_gain': 0.006539412695721669, 'min_child_weight': 17, 'min_data_in_leaf': 3, 'feature_fraction': 0.9433269793511179, 'top_rate': 0.8004410402415224, 'other_rate': 0.006356754561685013}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:15:26,166]\u001b[0m Trial 195 finished with value: 0.2540030651641933 and parameters: {'booster': 'goss', 'lambda_l2': 0.7167178741932303, 'lambda_l1': 0.05984466652833857, 'cat_l2': 0.0032617971489513685, 'min_data_per_group': 6, 'max_cat_threshold': 14, 'cat_smooth': 2.3807229113311017, 'max_bin': 58, 'num_leaves': 51, 'max_depth': 7, 'eta': 0.07279633713880855, 'min_split_gain': 0.012959090821499552, 'min_child_weight': 17, 'min_data_in_leaf': 3, 'feature_fraction': 0.9425257731357702, 'top_rate': 0.7526226992545223, 'other_rate': 0.04882961313024878}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:15:26,556]\u001b[0m Trial 199 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:15:29,455]\u001b[0m Trial 202 pruned. Trial was pruned at iteration 20.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:15:29,887]\u001b[0m Trial 203 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:15:31,929]\u001b[0m Trial 205 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:15:32,261]\u001b[0m Trial 204 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:15:33,587]\u001b[0m Trial 201 finished with value: 0.25780701625469604 and parameters: {'booster': 'goss', 'lambda_l2': 0.6880999262718187, 'lambda_l1': 0.07764331463395906, 'cat_l2': 0.0032485821984712298, 'min_data_per_group': 12, 'max_cat_threshold': 21, 'cat_smooth': 5.6929916796024385, 'max_bin': 59, 'num_leaves': 43, 'max_depth': 8, 'eta': 0.07581739384727539, 'min_split_gain': 0.012703050285329066, 'min_child_weight': 19, 'min_data_in_leaf': 3, 'feature_fraction': 0.9423750484931597, 'top_rate': 0.6276684214571634, 'other_rate': 0.2040805184508382}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:15:34,493]\u001b[0m Trial 200 finished with value: 0.25641341551762764 and parameters: {'booster': 'goss', 'lambda_l2': 0.73031514835356, 'lambda_l1': 0.07272531878330082, 'cat_l2': 0.003255705324648504, 'min_data_per_group': 12, 'max_cat_threshold': 21, 'cat_smooth': 5.761459288062921, 'max_bin': 59, 'num_leaves': 55, 'max_depth': 8, 'eta': 0.07587436137069126, 'min_split_gain': 0.012890968979222216, 'min_child_weight': 19, 'min_data_in_leaf': 3, 'feature_fraction': 0.9438651009012007, 'top_rate': 0.6243938115465607, 'other_rate': 0.1363949150667549}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:15:36,379]\u001b[0m Trial 209 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:15:37,108]\u001b[0m Trial 206 finished with value: 0.25521824386459036 and parameters: {'booster': 'goss', 'lambda_l2': 0.49354944570770726, 'lambda_l1': 0.072635312722626, 'cat_l2': 0.003236452776233787, 'min_data_per_group': 6, 'max_cat_threshold': 24, 'cat_smooth': 3.4545776212869925, 'max_bin': 58, 'num_leaves': 54, 'max_depth': 6, 'eta': 0.07405005313559547, 'min_split_gain': 0.012952781093621473, 'min_child_weight': 17, 'min_data_in_leaf': 3, 'feature_fraction': 0.9426229025161872, 'top_rate': 0.6820740384610205, 'other_rate': 0.012774032162404404}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:15:38,316]\u001b[0m Trial 207 finished with value: 0.2557960577331986 and parameters: {'booster': 'goss', 'lambda_l2': 0.6864154214013647, 'lambda_l1': 0.07214820197028543, 'cat_l2': 0.003256288941373499, 'min_data_per_group': 13, 'max_cat_threshold': 24, 'cat_smooth': 3.4656599535017945, 'max_bin': 58, 'num_leaves': 60, 'max_depth': 7, 'eta': 0.07225380041380824, 'min_split_gain': 0.012698298784466548, 'min_child_weight': 17, 'min_data_in_leaf': 3, 'feature_fraction': 0.9422817471439568, 'top_rate': 0.6722019572406575, 'other_rate': 0.21657719345846974}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:15:38,759]\u001b[0m Trial 211 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:15:39,753]\u001b[0m Trial 208 finished with value: 0.2534074976345324 and parameters: {'booster': 'goss', 'lambda_l2': 0.686688899158306, 'lambda_l1': 0.06170030306472574, 'cat_l2': 0.003259828937530485, 'min_data_per_group': 6, 'max_cat_threshold': 23, 'cat_smooth': 2.2369692983644067, 'max_bin': 59, 'num_leaves': 51, 'max_depth': 7, 'eta': 0.07299207915092616, 'min_split_gain': 0.013283065840577101, 'min_child_weight': 19, 'min_data_in_leaf': 4, 'feature_fraction': 0.9423017667412207, 'top_rate': 0.669903906920604, 'other_rate': 0.04373986383399029}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:15:41,106]\u001b[0m Trial 212 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:15:41,348]\u001b[0m Trial 213 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:15:43,635]\u001b[0m Trial 210 finished with value: 0.2585956950317595 and parameters: {'booster': 'goss', 'lambda_l2': 0.7280846336087595, 'lambda_l1': 0.061111906638863754, 'cat_l2': 0.003381911446605451, 'min_data_per_group': 6, 'max_cat_threshold': 21, 'cat_smooth': 2.5081754282891353, 'max_bin': 59, 'num_leaves': 44, 'max_depth': 7, 'eta': 0.07288717793715525, 'min_split_gain': 0.013303218217163808, 'min_child_weight': 19, 'min_data_in_leaf': 3, 'feature_fraction': 0.9421936154015322, 'top_rate': 0.5869788172410708, 'other_rate': 0.039703644428098706}. Best is trial 34 with value: 0.2586352644702073.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:15:44,157]\u001b[0m Trial 214 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:15:44,542]\u001b[0m Trial 215 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:15:47,394]\u001b[0m Trial 218 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:15:48,525]\u001b[0m Trial 219 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:15:48,871]\u001b[0m Trial 220 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:15:49,960]\u001b[0m Trial 216 finished with value: 0.25957896568406236 and parameters: {'booster': 'goss', 'lambda_l2': 0.731342247066771, 'lambda_l1': 0.06516654286207302, 'cat_l2': 0.0032652330108267065, 'min_data_per_group': 12, 'max_cat_threshold': 25, 'cat_smooth': 3.3603845258493603, 'max_bin': 58, 'num_leaves': 59, 'max_depth': 8, 'eta': 0.0719376386742061, 'min_split_gain': 0.012591668630521989, 'min_child_weight': 19, 'min_data_in_leaf': 3, 'feature_fraction': 0.9423278975647763, 'top_rate': 0.3626493084151933, 'other_rate': 0.1761962482686374}. Best is trial 216 with value: 0.25957896568406236.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:15:51,014]\u001b[0m Trial 221 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:15:51,357]\u001b[0m Trial 217 finished with value: 0.252325709986834 and parameters: {'booster': 'goss', 'lambda_l2': 0.7320506465008993, 'lambda_l1': 0.0664075853323648, 'cat_l2': 0.003257510026950122, 'min_data_per_group': 12, 'max_cat_threshold': 25, 'cat_smooth': 3.4224007258358733, 'max_bin': 58, 'num_leaves': 60, 'max_depth': 8, 'eta': 0.07228816616685536, 'min_split_gain': 0.012628495866995316, 'min_child_weight': 19, 'min_data_in_leaf': 3, 'feature_fraction': 0.9421688302906167, 'top_rate': 0.584773847390628, 'other_rate': 0.2003957140261911}. Best is trial 216 with value: 0.25957896568406236.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:15:51,560]\u001b[0m Trial 222 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:15:51,676]\u001b[0m Trial 223 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:15:53,199]\u001b[0m Trial 224 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:15:54,566]\u001b[0m Trial 225 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:15:54,914]\u001b[0m Trial 226 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:15:55,334]\u001b[0m Trial 227 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:15:57,053]\u001b[0m Trial 228 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:15:57,343]\u001b[0m Trial 229 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:15:57,752]\u001b[0m Trial 230 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:15:57,807]\u001b[0m Trial 231 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:16:02,353]\u001b[0m Trial 235 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:16:03,715]\u001b[0m Trial 237 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:16:04,240]\u001b[0m Trial 239 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:16:04,267]\u001b[0m Trial 238 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:16:05,615]\u001b[0m Trial 232 finished with value: 0.251712426654483 and parameters: {'booster': 'goss', 'lambda_l2': 0.7159346646430743, 'lambda_l1': 0.0727363315109656, 'cat_l2': 0.003230800965287415, 'min_data_per_group': 12, 'max_cat_threshold': 23, 'cat_smooth': 3.2921980676458196, 'max_bin': 58, 'num_leaves': 54, 'max_depth': 8, 'eta': 0.07341357180948156, 'min_split_gain': 0.013515203418320548, 'min_child_weight': 19, 'min_data_in_leaf': 5, 'feature_fraction': 0.9429083760345671, 'top_rate': 0.6548916468346888, 'other_rate': 0.023218191390784758}. Best is trial 216 with value: 0.25957896568406236.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:16:07,239]\u001b[0m Trial 240 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:16:09,529]\u001b[0m Trial 233 finished with value: 0.25704328332362836 and parameters: {'booster': 'goss', 'lambda_l2': 0.7136124451948773, 'lambda_l1': 0.07511412798691472, 'cat_l2': 0.003232685135269417, 'min_data_per_group': 13, 'max_cat_threshold': 23, 'cat_smooth': 3.1869296577229367, 'max_bin': 58, 'num_leaves': 44, 'max_depth': 8, 'eta': 0.07245454622809752, 'min_split_gain': 0.013493820381814745, 'min_child_weight': 17, 'min_data_in_leaf': 5, 'feature_fraction': 0.9429255347132741, 'top_rate': 0.33437217224658633, 'other_rate': 0.15435132459108197}. Best is trial 216 with value: 0.25957896568406236.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:16:09,598]\u001b[0m Trial 234 finished with value: 0.2586001109656427 and parameters: {'booster': 'goss', 'lambda_l2': 0.6997745312124862, 'lambda_l1': 0.05898390710481083, 'cat_l2': 0.0032388336994090077, 'min_data_per_group': 13, 'max_cat_threshold': 23, 'cat_smooth': 3.179206125401603, 'max_bin': 58, 'num_leaves': 51, 'max_depth': 8, 'eta': 0.07303657204066263, 'min_split_gain': 0.012848352943166183, 'min_child_weight': 17, 'min_data_in_leaf': 5, 'feature_fraction': 0.9430758445769324, 'top_rate': 0.35267664025399126, 'other_rate': 0.15992641856966955}. Best is trial 216 with value: 0.25957896568406236.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:16:11,403]\u001b[0m Trial 236 finished with value: 0.253032392102843 and parameters: {'booster': 'goss', 'lambda_l2': 0.7153950882637246, 'lambda_l1': 0.07548880845765348, 'cat_l2': 0.002238224980914861, 'min_data_per_group': 6, 'max_cat_threshold': 21, 'cat_smooth': 3.2760949079687536, 'max_bin': 59, 'num_leaves': 56, 'max_depth': 8, 'eta': 0.07247627296548721, 'min_split_gain': 0.013224132743120518, 'min_child_weight': 17, 'min_data_in_leaf': 5, 'feature_fraction': 0.9428625158457977, 'top_rate': 0.32664682994382455, 'other_rate': 0.16020266961415391}. Best is trial 216 with value: 0.25957896568406236.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:16:13,587]\u001b[0m Trial 245 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:16:16,637]\u001b[0m Trial 246 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:16:17,454]\u001b[0m Trial 241 finished with value: 0.2582294697836728 and parameters: {'booster': 'goss', 'lambda_l2': 0.6898812151659934, 'lambda_l1': 0.06315698036036954, 'cat_l2': 0.0032126167643749693, 'min_data_per_group': 6, 'max_cat_threshold': 14, 'cat_smooth': 5.50642247112247, 'max_bin': 58, 'num_leaves': 43, 'max_depth': 8, 'eta': 0.07292852996000428, 'min_split_gain': 0.01323316657269211, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9424785472601767, 'top_rate': 0.5150167003432465, 'other_rate': 0.13709084998952661}. Best is trial 216 with value: 0.25957896568406236.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:16:17,658]\u001b[0m Trial 242 finished with value: 0.25615608164991127 and parameters: {'booster': 'goss', 'lambda_l2': 0.6874140423192469, 'lambda_l1': 0.07492878498129048, 'cat_l2': 0.00319707542309611, 'min_data_per_group': 6, 'max_cat_threshold': 14, 'cat_smooth': 5.53841349755831, 'max_bin': 58, 'num_leaves': 43, 'max_depth': 8, 'eta': 0.07299451033183336, 'min_split_gain': 0.0132438943705351, 'min_child_weight': 17, 'min_data_in_leaf': 3, 'feature_fraction': 0.9436961151554689, 'top_rate': 0.6179085140724102, 'other_rate': 0.02514735214178801}. Best is trial 216 with value: 0.25957896568406236.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:16:17,839]\u001b[0m Trial 243 finished with value: 0.2597090938462958 and parameters: {'booster': 'goss', 'lambda_l2': 0.6811155370188435, 'lambda_l1': 0.07521506224941417, 'cat_l2': 0.0028853336888426946, 'min_data_per_group': 6, 'max_cat_threshold': 14, 'cat_smooth': 5.587581124171321, 'max_bin': 58, 'num_leaves': 49, 'max_depth': 8, 'eta': 0.0728941903009486, 'min_split_gain': 0.012728028638364548, 'min_child_weight': 17, 'min_data_in_leaf': 3, 'feature_fraction': 0.9443887826891451, 'top_rate': 0.6215381966348924, 'other_rate': 0.05009413999111768}. Best is trial 243 with value: 0.2597090938462958.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:16:19,756]\u001b[0m Trial 244 finished with value: 0.25817099974935753 and parameters: {'booster': 'goss', 'lambda_l2': 0.6814955089448964, 'lambda_l1': 0.0753928650169046, 'cat_l2': 0.0032037249189971317, 'min_data_per_group': 6, 'max_cat_threshold': 14, 'cat_smooth': 6.01334603724808, 'max_bin': 58, 'num_leaves': 43, 'max_depth': 8, 'eta': 0.07284108917968743, 'min_split_gain': 0.013256571263110736, 'min_child_weight': 17, 'min_data_in_leaf': 3, 'feature_fraction': 0.9437013823269941, 'top_rate': 0.38625958836448065, 'other_rate': 0.17747487596107012}. Best is trial 243 with value: 0.2597090938462958.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:16:22,219]\u001b[0m Trial 247 finished with value: 0.25732394817011095 and parameters: {'booster': 'goss', 'lambda_l2': 0.6919017941633184, 'lambda_l1': 0.07580856515460169, 'cat_l2': 0.0032001733007180518, 'min_data_per_group': 13, 'max_cat_threshold': 24, 'cat_smooth': 3.061779608159832, 'max_bin': 58, 'num_leaves': 51, 'max_depth': 8, 'eta': 0.07297917533529792, 'min_split_gain': 0.013252141204969653, 'min_child_weight': 17, 'min_data_in_leaf': 5, 'feature_fraction': 0.9446804749882249, 'top_rate': 0.37840826194401184, 'other_rate': 0.14703824373781996}. Best is trial 243 with value: 0.2597090938462958.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:16:26,486]\u001b[0m Trial 248 finished with value: 0.251840973701201 and parameters: {'booster': 'goss', 'lambda_l2': 0.6916221097057913, 'lambda_l1': 0.054819694712300256, 'cat_l2': 0.003193411423903983, 'min_data_per_group': 13, 'max_cat_threshold': 24, 'cat_smooth': 3.3480846578895034, 'max_bin': 58, 'num_leaves': 55, 'max_depth': 8, 'eta': 0.07275687122237166, 'min_split_gain': 0.013261476867534153, 'min_child_weight': 17, 'min_data_in_leaf': 5, 'feature_fraction': 0.9444311231757513, 'top_rate': 0.34250168345475773, 'other_rate': 0.15574308137299056}. Best is trial 243 with value: 0.2597090938462958.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:16:28,547]\u001b[0m Trial 255 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:16:29,248]\u001b[0m Trial 249 finished with value: 0.25554155233484255 and parameters: {'booster': 'goss', 'lambda_l2': 0.6873194949343364, 'lambda_l1': 0.07611119341784962, 'cat_l2': 0.0031945555342809645, 'min_data_per_group': 13, 'max_cat_threshold': 24, 'cat_smooth': 3.0621086619876925, 'max_bin': 58, 'num_leaves': 51, 'max_depth': 8, 'eta': 0.07280551978419739, 'min_split_gain': 0.013279971914321377, 'min_child_weight': 17, 'min_data_in_leaf': 5, 'feature_fraction': 0.9430290966639876, 'top_rate': 0.2887239949105229, 'other_rate': 0.15502232511957798}. Best is trial 243 with value: 0.2597090938462958.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:16:33,471]\u001b[0m Trial 253 finished with value: 0.252060534249514 and parameters: {'booster': 'goss', 'lambda_l2': 0.6756039739674287, 'lambda_l1': 0.07598581135973487, 'cat_l2': 0.0032062980771053328, 'min_data_per_group': 13, 'max_cat_threshold': 14, 'cat_smooth': 5.61810724519225, 'max_bin': 58, 'num_leaves': 50, 'max_depth': 8, 'eta': 0.07314116102631814, 'min_split_gain': 0.012675797402176166, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9437407027699835, 'top_rate': 0.5129899422349862, 'other_rate': 0.15727604512738558}. Best is trial 243 with value: 0.2597090938462958.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:16:33,964]\u001b[0m Trial 250 finished with value: 0.2538934288059256 and parameters: {'booster': 'goss', 'lambda_l2': 0.6912172119010038, 'lambda_l1': 0.07454301680132394, 'cat_l2': 0.0022207990954472767, 'min_data_per_group': 13, 'max_cat_threshold': 23, 'cat_smooth': 5.524153377690688, 'max_bin': 58, 'num_leaves': 50, 'max_depth': 8, 'eta': 0.07305691954046083, 'min_split_gain': 0.012681807607281093, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.943715529944724, 'top_rate': 0.37454742817711373, 'other_rate': 0.1813078860774223}. Best is trial 243 with value: 0.2597090938462958.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:16:34,719]\u001b[0m Trial 251 finished with value: 0.2604836395582832 and parameters: {'booster': 'goss', 'lambda_l2': 0.6906317722239904, 'lambda_l1': 0.08235895877458867, 'cat_l2': 0.002829026237298389, 'min_data_per_group': 13, 'max_cat_threshold': 14, 'cat_smooth': 5.505662862511171, 'max_bin': 58, 'num_leaves': 44, 'max_depth': 8, 'eta': 0.07307773261425457, 'min_split_gain': 0.012729968869620408, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9444067884789972, 'top_rate': 0.3912008323952332, 'other_rate': 0.1513476045484385}. Best is trial 251 with value: 0.2604836395582832.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:16:35,032]\u001b[0m Trial 252 finished with value: 0.25924654113987 and parameters: {'booster': 'goss', 'lambda_l2': 0.6912628823294454, 'lambda_l1': 0.07714434640944769, 'cat_l2': 0.003182373495486428, 'min_data_per_group': 13, 'max_cat_threshold': 14, 'cat_smooth': 5.504507108628863, 'max_bin': 58, 'num_leaves': 50, 'max_depth': 8, 'eta': 0.07312489821356793, 'min_split_gain': 0.01276115208502486, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9449932977037597, 'top_rate': 0.3945423719545751, 'other_rate': 0.125747832140301}. Best is trial 251 with value: 0.2604836395582832.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:16:35,502]\u001b[0m Trial 254 finished with value: 0.25873673802174624 and parameters: {'booster': 'goss', 'lambda_l2': 0.6772992172512748, 'lambda_l1': 0.08232768509833689, 'cat_l2': 0.0032205388577900835, 'min_data_per_group': 13, 'max_cat_threshold': 14, 'cat_smooth': 5.489914924041577, 'max_bin': 58, 'num_leaves': 51, 'max_depth': 8, 'eta': 0.07324432591163188, 'min_split_gain': 0.012762733889391354, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9445301036129469, 'top_rate': 0.3957993202814269, 'other_rate': 0.1380319673382643}. Best is trial 251 with value: 0.2604836395582832.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:16:38,265]\u001b[0m Trial 256 finished with value: 0.2544991930599525 and parameters: {'booster': 'goss', 'lambda_l2': 0.6758079230575681, 'lambda_l1': 0.0809313243710677, 'cat_l2': 0.0028823102475582837, 'min_data_per_group': 13, 'max_cat_threshold': 14, 'cat_smooth': 5.316410314391837, 'max_bin': 58, 'num_leaves': 52, 'max_depth': 8, 'eta': 0.07302692840013619, 'min_split_gain': 0.012737949837538145, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9449776155615605, 'top_rate': 0.5117402779080206, 'other_rate': 0.1442196336585917}. Best is trial 251 with value: 0.2604836395582832.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:16:41,292]\u001b[0m Trial 257 finished with value: 0.2555580966475103 and parameters: {'booster': 'goss', 'lambda_l2': 0.6928702706540277, 'lambda_l1': 0.0754435528243108, 'cat_l2': 0.0030873755467589513, 'min_data_per_group': 13, 'max_cat_threshold': 14, 'cat_smooth': 5.595126887470398, 'max_bin': 58, 'num_leaves': 52, 'max_depth': 8, 'eta': 0.0732018340208607, 'min_split_gain': 0.013464426878152073, 'min_child_weight': 17, 'min_data_in_leaf': 3, 'feature_fraction': 0.9447789420628365, 'top_rate': 0.27889167438685086, 'other_rate': 0.14155240975358718}. Best is trial 251 with value: 0.2604836395582832.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:16:41,779]\u001b[0m Trial 258 finished with value: 0.25971665260699334 and parameters: {'booster': 'goss', 'lambda_l2': 0.6824120707782801, 'lambda_l1': 0.07628273257619839, 'cat_l2': 0.0032000458917164232, 'min_data_per_group': 13, 'max_cat_threshold': 13, 'cat_smooth': 5.466511034519699, 'max_bin': 58, 'num_leaves': 50, 'max_depth': 8, 'eta': 0.07300307938121607, 'min_split_gain': 0.012620888142595956, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9443434575774154, 'top_rate': 0.38636864435628965, 'other_rate': 0.1486457479401345}. Best is trial 251 with value: 0.2604836395582832.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:16:48,362]\u001b[0m Trial 259 finished with value: 0.26240806334113453 and parameters: {'booster': 'goss', 'lambda_l2': 0.6925367519021738, 'lambda_l1': 0.08032966066100604, 'cat_l2': 0.003165236552108504, 'min_data_per_group': 13, 'max_cat_threshold': 13, 'cat_smooth': 5.342984404306893, 'max_bin': 58, 'num_leaves': 52, 'max_depth': 8, 'eta': 0.07328084546594568, 'min_split_gain': 0.013502757666193074, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.944670904621495, 'top_rate': 0.38909502254412415, 'other_rate': 0.14971776648390459}. Best is trial 259 with value: 0.26240806334113453.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:16:50,387]\u001b[0m Trial 263 finished with value: 0.26140396995493137 and parameters: {'booster': 'goss', 'lambda_l2': 0.6839880875814651, 'lambda_l1': 0.08139045122638497, 'cat_l2': 0.0028121700036749337, 'min_data_per_group': 13, 'max_cat_threshold': 14, 'cat_smooth': 5.308097139520911, 'max_bin': 58, 'num_leaves': 52, 'max_depth': 8, 'eta': 0.07325397573736867, 'min_split_gain': 0.01348799664109564, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9445110668039536, 'top_rate': 0.38250173111618385, 'other_rate': 0.13302312283258705}. Best is trial 259 with value: 0.26240806334113453.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:16:50,665]\u001b[0m Trial 260 finished with value: 0.25987806370287453 and parameters: {'booster': 'goss', 'lambda_l2': 0.6851372361680281, 'lambda_l1': 0.07818179465283227, 'cat_l2': 0.0031681411832879176, 'min_data_per_group': 13, 'max_cat_threshold': 14, 'cat_smooth': 5.395604892313248, 'max_bin': 58, 'num_leaves': 52, 'max_depth': 8, 'eta': 0.07322955378015196, 'min_split_gain': 0.013469905274900591, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9447124690747711, 'top_rate': 0.37472835473954574, 'other_rate': 0.12866777301501067}. Best is trial 259 with value: 0.26240806334113453.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:16:51,629]\u001b[0m Trial 261 finished with value: 0.2617452826463283 and parameters: {'booster': 'goss', 'lambda_l2': 0.6849913696154888, 'lambda_l1': 0.08314777143892244, 'cat_l2': 0.002813816783319242, 'min_data_per_group': 13, 'max_cat_threshold': 14, 'cat_smooth': 5.332712093786356, 'max_bin': 58, 'num_leaves': 52, 'max_depth': 8, 'eta': 0.07333008761519436, 'min_split_gain': 0.01346889799265096, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9446710309587995, 'top_rate': 0.39529018525404225, 'other_rate': 0.12397379030982497}. Best is trial 259 with value: 0.26240806334113453.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:16:52,244]\u001b[0m Trial 262 finished with value: 0.2588429180727659 and parameters: {'booster': 'goss', 'lambda_l2': 0.6844481366676377, 'lambda_l1': 0.08125352068449537, 'cat_l2': 0.0028865234725149766, 'min_data_per_group': 13, 'max_cat_threshold': 14, 'cat_smooth': 5.307161049706111, 'max_bin': 58, 'num_leaves': 50, 'max_depth': 8, 'eta': 0.07329217401706718, 'min_split_gain': 0.013409121067190756, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9447038243024037, 'top_rate': 0.43095319303772445, 'other_rate': 0.14711759356546494}. Best is trial 259 with value: 0.26240806334113453.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:16:52,975]\u001b[0m Trial 265 finished with value: 0.2552430711790555 and parameters: {'booster': 'goss', 'lambda_l2': 0.685203023332734, 'lambda_l1': 0.08324825024097585, 'cat_l2': 0.0031019048268435124, 'min_data_per_group': 13, 'max_cat_threshold': 13, 'cat_smooth': 5.4657238395228, 'max_bin': 58, 'num_leaves': 50, 'max_depth': 8, 'eta': 0.07333643423121577, 'min_split_gain': 0.013520191170338033, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9448342784158865, 'top_rate': 0.38781340130033776, 'other_rate': 0.12653259181517776}. Best is trial 259 with value: 0.26240806334113453.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:16:54,280]\u001b[0m Trial 264 finished with value: 0.25751223896826564 and parameters: {'booster': 'goss', 'lambda_l2': 0.6856247387819412, 'lambda_l1': 0.0830740146567675, 'cat_l2': 0.003154403613692922, 'min_data_per_group': 13, 'max_cat_threshold': 13, 'cat_smooth': 5.373980898003311, 'max_bin': 58, 'num_leaves': 52, 'max_depth': 8, 'eta': 0.07321032375626775, 'min_split_gain': 0.013502277705870602, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9447301136451495, 'top_rate': 0.38490746660570846, 'other_rate': 0.12785054551314892}. Best is trial 259 with value: 0.26240806334113453.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:16:57,047]\u001b[0m Trial 266 finished with value: 0.25949895623877345 and parameters: {'booster': 'goss', 'lambda_l2': 0.688396895392536, 'lambda_l1': 0.08411798239941712, 'cat_l2': 0.0028452933437894496, 'min_data_per_group': 13, 'max_cat_threshold': 13, 'cat_smooth': 5.382734426908223, 'max_bin': 58, 'num_leaves': 50, 'max_depth': 8, 'eta': 0.07324238889395632, 'min_split_gain': 0.013438404604176609, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9445620652098417, 'top_rate': 0.39270973540098464, 'other_rate': 0.13588167541308593}. Best is trial 259 with value: 0.26240806334113453.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:16:59,993]\u001b[0m Trial 267 finished with value: 0.26532196167545063 and parameters: {'booster': 'goss', 'lambda_l2': 0.6855920985773585, 'lambda_l1': 0.08016922106726923, 'cat_l2': 0.002832945022550406, 'min_data_per_group': 13, 'max_cat_threshold': 13, 'cat_smooth': 5.4111463094755266, 'max_bin': 58, 'num_leaves': 50, 'max_depth': 8, 'eta': 0.07328979517371839, 'min_split_gain': 0.013653991391068496, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9446167822698687, 'top_rate': 0.38895880168990904, 'other_rate': 0.12836337511071985}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:17:05,104]\u001b[0m Trial 269 finished with value: 0.258422205804421 and parameters: {'booster': 'goss', 'lambda_l2': 0.6824955833981854, 'lambda_l1': 0.08344921879692672, 'cat_l2': 0.0028276997899626195, 'min_data_per_group': 13, 'max_cat_threshold': 13, 'cat_smooth': 5.214493603466551, 'max_bin': 58, 'num_leaves': 50, 'max_depth': 8, 'eta': 0.07324435810516755, 'min_split_gain': 0.013669802308194846, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9445880826317901, 'top_rate': 0.44017952939239424, 'other_rate': 0.13031831725655887}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:17:05,297]\u001b[0m Trial 268 finished with value: 0.2635506977103081 and parameters: {'booster': 'goss', 'lambda_l2': 0.6841335855921826, 'lambda_l1': 0.08260152361109961, 'cat_l2': 0.0028281118573913913, 'min_data_per_group': 13, 'max_cat_threshold': 13, 'cat_smooth': 5.2236758042633396, 'max_bin': 58, 'num_leaves': 50, 'max_depth': 8, 'eta': 0.07329544843846406, 'min_split_gain': 0.013642387388530443, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9446208609664822, 'top_rate': 0.4391186525758708, 'other_rate': 0.12967088946961985}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:17:05,904]\u001b[0m Trial 270 finished with value: 0.2607411123181213 and parameters: {'booster': 'goss', 'lambda_l2': 0.6829473642024084, 'lambda_l1': 0.08291530530127093, 'cat_l2': 0.002833654566070066, 'min_data_per_group': 13, 'max_cat_threshold': 13, 'cat_smooth': 5.397757550224098, 'max_bin': 58, 'num_leaves': 49, 'max_depth': 8, 'eta': 0.07320728681697034, 'min_split_gain': 0.013708210748220128, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.944636283549435, 'top_rate': 0.3860124808101124, 'other_rate': 0.12932994713976537}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:17:06,092]\u001b[0m Trial 272 finished with value: 0.2564147969225439 and parameters: {'booster': 'goss', 'lambda_l2': 0.6824793675872958, 'lambda_l1': 0.08246078505471711, 'cat_l2': 0.002824352013629863, 'min_data_per_group': 13, 'max_cat_threshold': 13, 'cat_smooth': 5.253318802571415, 'max_bin': 58, 'num_leaves': 52, 'max_depth': 8, 'eta': 0.07326978769902777, 'min_split_gain': 0.013711177442144897, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9445237993699297, 'top_rate': 0.44085361331486517, 'other_rate': 0.13149402337218447}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:17:08,187]\u001b[0m Trial 271 finished with value: 0.26077220028163106 and parameters: {'booster': 'goss', 'lambda_l2': 0.6812968050061122, 'lambda_l1': 0.08389389504050929, 'cat_l2': 0.002827241194271848, 'min_data_per_group': 13, 'max_cat_threshold': 13, 'cat_smooth': 5.231441645851645, 'max_bin': 58, 'num_leaves': 52, 'max_depth': 8, 'eta': 0.07324433833379973, 'min_split_gain': 0.013821147218071744, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9445891146696554, 'top_rate': 0.38014775720082944, 'other_rate': 0.1315899204068971}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:17:09,794]\u001b[0m Trial 273 finished with value: 0.2618370498319524 and parameters: {'booster': 'goss', 'lambda_l2': 0.6722899555532597, 'lambda_l1': 0.0847381498214769, 'cat_l2': 0.0028250248437695245, 'min_data_per_group': 13, 'max_cat_threshold': 13, 'cat_smooth': 5.229860169885731, 'max_bin': 58, 'num_leaves': 49, 'max_depth': 8, 'eta': 0.07332544548522159, 'min_split_gain': 0.013791988805598588, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9446475823881454, 'top_rate': 0.38647426843926713, 'other_rate': 0.12985101359892168}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:17:10,119]\u001b[0m Trial 275 finished with value: 0.256073589906999 and parameters: {'booster': 'goss', 'lambda_l2': 0.6689195832639196, 'lambda_l1': 0.0839596002468457, 'cat_l2': 0.002818198072705453, 'min_data_per_group': 13, 'max_cat_threshold': 13, 'cat_smooth': 5.244107349472462, 'max_bin': 58, 'num_leaves': 49, 'max_depth': 8, 'eta': 0.07335106103682354, 'min_split_gain': 0.013632981270840696, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.944618087196114, 'top_rate': 0.38445771960266506, 'other_rate': 0.1264021433298589}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:17:11,570]\u001b[0m Trial 274 finished with value: 0.2574255385529174 and parameters: {'booster': 'goss', 'lambda_l2': 0.667822189332364, 'lambda_l1': 0.08391848684726419, 'cat_l2': 0.003140134506661768, 'min_data_per_group': 13, 'max_cat_threshold': 13, 'cat_smooth': 5.26330859663257, 'max_bin': 58, 'num_leaves': 49, 'max_depth': 8, 'eta': 0.0733372675748052, 'min_split_gain': 0.013729161272244755, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9446211104903387, 'top_rate': 0.4429177804914554, 'other_rate': 0.13178778142118203}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:17:17,507]\u001b[0m Trial 276 finished with value: 0.26231410783114406 and parameters: {'booster': 'goss', 'lambda_l2': 0.6747259039235673, 'lambda_l1': 0.08545857818227251, 'cat_l2': 0.002822478906702202, 'min_data_per_group': 13, 'max_cat_threshold': 13, 'cat_smooth': 5.131454924407051, 'max_bin': 58, 'num_leaves': 49, 'max_depth': 8, 'eta': 0.07349747726013228, 'min_split_gain': 0.013814507652801945, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9443865509685772, 'top_rate': 0.3986618620209448, 'other_rate': 0.11771315893061211}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:17:19,874]\u001b[0m Trial 277 finished with value: 0.25693832431455654 and parameters: {'booster': 'goss', 'lambda_l2': 0.6665237115489633, 'lambda_l1': 0.08452301340562819, 'cat_l2': 0.0028257769656412734, 'min_data_per_group': 13, 'max_cat_threshold': 13, 'cat_smooth': 5.397524896132993, 'max_bin': 58, 'num_leaves': 49, 'max_depth': 8, 'eta': 0.07354483785704184, 'min_split_gain': 0.013858962524821118, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9444154469087261, 'top_rate': 0.3942530827065226, 'other_rate': 0.12307931558849775}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:17:20,941]\u001b[0m Trial 278 finished with value: 0.26010458097199834 and parameters: {'booster': 'goss', 'lambda_l2': 0.6687502182837123, 'lambda_l1': 0.08524870342050722, 'cat_l2': 0.0028347149885760243, 'min_data_per_group': 13, 'max_cat_threshold': 13, 'cat_smooth': 5.367053281606707, 'max_bin': 58, 'num_leaves': 50, 'max_depth': 8, 'eta': 0.07350965660905269, 'min_split_gain': 0.013855382013551078, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9446458859801974, 'top_rate': 0.42503333378826, 'other_rate': 0.1145459921222903}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:17:22,251]\u001b[0m Trial 284 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:17:22,949]\u001b[0m Trial 279 finished with value: 0.25641098202249235 and parameters: {'booster': 'goss', 'lambda_l2': 0.6686056327618317, 'lambda_l1': 0.0855286824761255, 'cat_l2': 0.00283368043193138, 'min_data_per_group': 13, 'max_cat_threshold': 13, 'cat_smooth': 5.131855015226831, 'max_bin': 58, 'num_leaves': 49, 'max_depth': 8, 'eta': 0.0735265978534604, 'min_split_gain': 0.013811393596584813, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9446541049970814, 'top_rate': 0.3963389214587115, 'other_rate': 0.1177455097484729}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:17:23,636]\u001b[0m Trial 280 finished with value: 0.26214657077906367 and parameters: {'booster': 'goss', 'lambda_l2': 0.6707670640203415, 'lambda_l1': 0.08606011752180966, 'cat_l2': 0.00284295733715014, 'min_data_per_group': 13, 'max_cat_threshold': 13, 'cat_smooth': 5.153043239908081, 'max_bin': 58, 'num_leaves': 49, 'max_depth': 8, 'eta': 0.07358936866785358, 'min_split_gain': 0.01382180014091455, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.944318087164798, 'top_rate': 0.4040141233261718, 'other_rate': 0.11692561653575634}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:17:24,592]\u001b[0m Trial 281 finished with value: 0.25970132700171716 and parameters: {'booster': 'goss', 'lambda_l2': 0.6701692826931787, 'lambda_l1': 0.0858118236522936, 'cat_l2': 0.002854828630523567, 'min_data_per_group': 13, 'max_cat_threshold': 13, 'cat_smooth': 5.3910995734233635, 'max_bin': 58, 'num_leaves': 50, 'max_depth': 8, 'eta': 0.07361294100125289, 'min_split_gain': 0.013855647560776443, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9444749979260957, 'top_rate': 0.4008819152091167, 'other_rate': 0.12205914572039908}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:17:26,563]\u001b[0m Trial 282 finished with value: 0.2612381465463163 and parameters: {'booster': 'goss', 'lambda_l2': 0.6662031884155353, 'lambda_l1': 0.08552298989798118, 'cat_l2': 0.002848247384919744, 'min_data_per_group': 13, 'max_cat_threshold': 13, 'cat_smooth': 5.103191441723849, 'max_bin': 58, 'num_leaves': 50, 'max_depth': 8, 'eta': 0.07350987083434218, 'min_split_gain': 0.013927583561370284, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9444059072450924, 'top_rate': 0.40165421616085134, 'other_rate': 0.11496304760097945}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:17:27,150]\u001b[0m Trial 283 finished with value: 0.25838319112920943 and parameters: {'booster': 'goss', 'lambda_l2': 0.6737143175502184, 'lambda_l1': 0.08703282828244946, 'cat_l2': 0.0028463478936136535, 'min_data_per_group': 13, 'max_cat_threshold': 13, 'cat_smooth': 5.380566495108466, 'max_bin': 58, 'num_leaves': 50, 'max_depth': 8, 'eta': 0.07360378559790363, 'min_split_gain': 0.013942901659409266, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9443864213664868, 'top_rate': 0.40307569919584174, 'other_rate': 0.11515120490976048}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:17:29,463]\u001b[0m Trial 285 finished with value: 0.26193894135573725 and parameters: {'booster': 'goss', 'lambda_l2': 0.6764246711625529, 'lambda_l1': 0.08841507354897404, 'cat_l2': 0.0028641932563058157, 'min_data_per_group': 13, 'max_cat_threshold': 13, 'cat_smooth': 5.0462916199176995, 'max_bin': 58, 'num_leaves': 50, 'max_depth': 8, 'eta': 0.07352590773132658, 'min_split_gain': 0.01397998085221002, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9444236342738981, 'top_rate': 0.41427247262946015, 'other_rate': 0.11091609740560365}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:17:30,143]\u001b[0m Trial 287 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:17:31,300]\u001b[0m Trial 289 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:17:32,083]\u001b[0m Trial 290 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:17:32,423]\u001b[0m Trial 286 finished with value: 0.2607055197450044 and parameters: {'booster': 'goss', 'lambda_l2': 0.6744865818815412, 'lambda_l1': 0.087638790177697, 'cat_l2': 0.0027691319786029333, 'min_data_per_group': 13, 'max_cat_threshold': 13, 'cat_smooth': 5.075700300674777, 'max_bin': 58, 'num_leaves': 50, 'max_depth': 8, 'eta': 0.07351647809772985, 'min_split_gain': 0.0139874285126242, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9450500582384367, 'top_rate': 0.4575662083519294, 'other_rate': 0.10861552156980346}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:17:33,988]\u001b[0m Trial 291 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:17:34,495]\u001b[0m Trial 288 finished with value: 0.2558238819843697 and parameters: {'booster': 'goss', 'lambda_l2': 0.6787136301162204, 'lambda_l1': 0.08026206228106918, 'cat_l2': 0.002803076562919697, 'min_data_per_group': 13, 'max_cat_threshold': 12, 'cat_smooth': 5.008612960084298, 'max_bin': 58, 'num_leaves': 50, 'max_depth': 8, 'eta': 0.07350067558718627, 'min_split_gain': 0.013972453464831877, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9441825138837207, 'top_rate': 0.42056638230996424, 'other_rate': 0.11040142185982728}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:17:37,734]\u001b[0m Trial 293 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:17:37,868]\u001b[0m Trial 294 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:17:39,337]\u001b[0m Trial 292 finished with value: 0.26039411892238445 and parameters: {'booster': 'goss', 'lambda_l2': 0.6590121205521048, 'lambda_l1': 0.09119428855330125, 'cat_l2': 0.002740287782138739, 'min_data_per_group': 13, 'max_cat_threshold': 12, 'cat_smooth': 5.025398868459798, 'max_bin': 58, 'num_leaves': 49, 'max_depth': 8, 'eta': 0.07375889331673605, 'min_split_gain': 0.013756396136881129, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9441234399811937, 'top_rate': 0.42299789190600673, 'other_rate': 0.10410494338635662}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:17:47,388]\u001b[0m Trial 296 finished with value: 0.25672325638029103 and parameters: {'booster': 'goss', 'lambda_l2': 0.6639733064345705, 'lambda_l1': 0.08713161996811185, 'cat_l2': 0.0027425458687300856, 'min_data_per_group': 14, 'max_cat_threshold': 13, 'cat_smooth': 5.073612978045959, 'max_bin': 58, 'num_leaves': 49, 'max_depth': 8, 'eta': 0.07335234901431807, 'min_split_gain': 0.013735333858937793, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9448743887191106, 'top_rate': 0.3648933550688487, 'other_rate': 0.14356862426087014}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:17:48,707]\u001b[0m Trial 295 finished with value: 0.2596285073734872 and parameters: {'booster': 'goss', 'lambda_l2': 0.6624347145563281, 'lambda_l1': 0.09146740980196899, 'cat_l2': 0.002735770580978544, 'min_data_per_group': 13, 'max_cat_threshold': 13, 'cat_smooth': 5.054132471345144, 'max_bin': 58, 'num_leaves': 49, 'max_depth': 8, 'eta': 0.07335665960935879, 'min_split_gain': 0.013747804562813808, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9444970032749445, 'top_rate': 0.3728597590663147, 'other_rate': 0.09652647917344459}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:17:48,851]\u001b[0m Trial 297 finished with value: 0.25835134322104664 and parameters: {'booster': 'goss', 'lambda_l2': 0.6589640840127486, 'lambda_l1': 0.08748299711723087, 'cat_l2': 0.0027371720175186722, 'min_data_per_group': 14, 'max_cat_threshold': 13, 'cat_smooth': 5.4383223736568915, 'max_bin': 58, 'num_leaves': 49, 'max_depth': 8, 'eta': 0.07331023311261092, 'min_split_gain': 0.01373545732038142, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9448514461484783, 'top_rate': 0.3666877982587064, 'other_rate': 0.14502271914393794}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:17:51,006]\u001b[0m Trial 298 finished with value: 0.25779739913631283 and parameters: {'booster': 'goss', 'lambda_l2': 0.6602964774736422, 'lambda_l1': 0.08811390205181989, 'cat_l2': 0.0027311280366707482, 'min_data_per_group': 14, 'max_cat_threshold': 13, 'cat_smooth': 5.174309473874068, 'max_bin': 58, 'num_leaves': 49, 'max_depth': 8, 'eta': 0.07338612957009763, 'min_split_gain': 0.013749889808845159, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9443231249498174, 'top_rate': 0.42817440570449944, 'other_rate': 0.1430621917240082}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:17:51,405]\u001b[0m Trial 299 finished with value: 0.2616895893152762 and parameters: {'booster': 'goss', 'lambda_l2': 0.6602152687257162, 'lambda_l1': 0.08667745087848891, 'cat_l2': 0.002731803102376289, 'min_data_per_group': 14, 'max_cat_threshold': 13, 'cat_smooth': 4.777910079023194, 'max_bin': 58, 'num_leaves': 49, 'max_depth': 8, 'eta': 0.07335294055086532, 'min_split_gain': 0.013746505558692662, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9443387691785412, 'top_rate': 0.4278025634948973, 'other_rate': 0.11952583621074798}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:17:52,761]\u001b[0m Trial 301 finished with value: 0.2560462182784489 and parameters: {'booster': 'goss', 'lambda_l2': 0.6691661328285362, 'lambda_l1': 0.08603433342227758, 'cat_l2': 0.002879959364226462, 'min_data_per_group': 14, 'max_cat_threshold': 13, 'cat_smooth': 5.07118906567914, 'max_bin': 58, 'num_leaves': 48, 'max_depth': 8, 'eta': 0.07336185466253103, 'min_split_gain': 0.013627347456373028, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.944306517223667, 'top_rate': 0.4260827603384368, 'other_rate': 0.11742180291023842}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:17:53,184]\u001b[0m Trial 302 finished with value: 0.25273645729321736 and parameters: {'booster': 'goss', 'lambda_l2': 0.6707141569853232, 'lambda_l1': 0.08515125948549422, 'cat_l2': 0.0028828874055813183, 'min_data_per_group': 14, 'max_cat_threshold': 13, 'cat_smooth': 4.845472558300112, 'max_bin': 58, 'num_leaves': 48, 'max_depth': 8, 'eta': 0.07333046943170753, 'min_split_gain': 0.013646035145009826, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9445118102719731, 'top_rate': 0.4253202501908303, 'other_rate': 0.11916553607065207}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:17:53,367]\u001b[0m Trial 300 finished with value: 0.25981441847356196 and parameters: {'booster': 'goss', 'lambda_l2': 0.6700415278971343, 'lambda_l1': 0.08678191379850285, 'cat_l2': 0.0028701950825657943, 'min_data_per_group': 13, 'max_cat_threshold': 13, 'cat_smooth': 5.069770257184889, 'max_bin': 58, 'num_leaves': 49, 'max_depth': 8, 'eta': 0.07335822382872904, 'min_split_gain': 0.013681199697081852, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.944368403441815, 'top_rate': 0.4288878868622799, 'other_rate': 0.1445739118500403}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:17:55,754]\u001b[0m Trial 305 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:17:57,214]\u001b[0m Trial 303 finished with value: 0.2618738353401766 and parameters: {'booster': 'goss', 'lambda_l2': 0.6683414489048929, 'lambda_l1': 0.08043133221292467, 'cat_l2': 0.002699647054836767, 'min_data_per_group': 13, 'max_cat_threshold': 13, 'cat_smooth': 5.426807477800371, 'max_bin': 58, 'num_leaves': 48, 'max_depth': 8, 'eta': 0.07356907223792158, 'min_split_gain': 0.013578292129222453, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9443198153142761, 'top_rate': 0.42390696687840645, 'other_rate': 0.11711050335740081}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:17:58,120]\u001b[0m Trial 306 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:17:58,603]\u001b[0m Trial 307 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:17:59,878]\u001b[0m Trial 304 finished with value: 0.2577028990584764 and parameters: {'booster': 'goss', 'lambda_l2': 0.6696768139576044, 'lambda_l1': 0.09432815127812526, 'cat_l2': 0.0028780642981563066, 'min_data_per_group': 13, 'max_cat_threshold': 13, 'cat_smooth': 5.196840238844837, 'max_bin': 58, 'num_leaves': 48, 'max_depth': 8, 'eta': 0.0736110955239096, 'min_split_gain': 0.013605891474682878, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9441565303999019, 'top_rate': 0.40837553370384644, 'other_rate': 0.09849203963844301}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:18:00,199]\u001b[0m Trial 308 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:18:00,719]\u001b[0m Trial 309 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:18:01,091]\u001b[0m Trial 310 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:18:02,528]\u001b[0m Trial 311 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:18:03,821]\u001b[0m Trial 312 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:18:04,447]\u001b[0m Trial 313 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:18:05,419]\u001b[0m Trial 314 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:18:06,525]\u001b[0m Trial 315 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:18:06,968]\u001b[0m Trial 316 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:18:07,291]\u001b[0m Trial 317 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:18:07,685]\u001b[0m Trial 318 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:18:09,157]\u001b[0m Trial 319 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:18:10,356]\u001b[0m Trial 320 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:18:12,690]\u001b[0m Trial 322 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:18:14,364]\u001b[0m Trial 324 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:18:15,740]\u001b[0m Trial 326 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:18:17,181]\u001b[0m Trial 321 finished with value: 0.25564175186673194 and parameters: {'booster': 'goss', 'lambda_l2': 0.6796779234703457, 'lambda_l1': 0.0800191692936784, 'cat_l2': 0.0028075455313584415, 'min_data_per_group': 13, 'max_cat_threshold': 12, 'cat_smooth': 5.0911277709613225, 'max_bin': 58, 'num_leaves': 50, 'max_depth': 8, 'eta': 0.07314661947028794, 'min_split_gain': 0.013806201955243019, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9442204634372529, 'top_rate': 0.42715835295154125, 'other_rate': 0.13456606452575923}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:18:17,391]\u001b[0m Trial 328 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:18:19,008]\u001b[0m Trial 329 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:18:19,955]\u001b[0m Trial 323 finished with value: 0.25320855897174505 and parameters: {'booster': 'goss', 'lambda_l2': 0.6814116354948361, 'lambda_l1': 0.0891204429933413, 'cat_l2': 0.0029251883128576903, 'min_data_per_group': 15, 'max_cat_threshold': 13, 'cat_smooth': 5.434278320287494, 'max_bin': 58, 'num_leaves': 51, 'max_depth': 8, 'eta': 0.07347170403948904, 'min_split_gain': 0.013794896312334284, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9448146758212786, 'top_rate': 0.4346571540061495, 'other_rate': 0.1133413144722044}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:18:20,349]\u001b[0m Trial 325 finished with value: 0.2538377838640009 and parameters: {'booster': 'goss', 'lambda_l2': 0.6767032917517061, 'lambda_l1': 0.0883275832782111, 'cat_l2': 0.0028475792849144243, 'min_data_per_group': 15, 'max_cat_threshold': 13, 'cat_smooth': 5.416886477568411, 'max_bin': 58, 'num_leaves': 51, 'max_depth': 8, 'eta': 0.0734291291972317, 'min_split_gain': 0.013772375636530774, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9447705050760884, 'top_rate': 0.4381696454435389, 'other_rate': 0.11527501937099191}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:18:22,023]\u001b[0m Trial 327 finished with value: 0.2526526964817669 and parameters: {'booster': 'goss', 'lambda_l2': 0.6795533984577523, 'lambda_l1': 0.08890762599812811, 'cat_l2': 0.0028477525046346555, 'min_data_per_group': 15, 'max_cat_threshold': 13, 'cat_smooth': 5.419039233421348, 'max_bin': 58, 'num_leaves': 51, 'max_depth': 8, 'eta': 0.0734576434845879, 'min_split_gain': 0.01344816076206537, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9440055021772944, 'top_rate': 0.4308277544486695, 'other_rate': 0.1313207375032623}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:18:25,192]\u001b[0m Trial 332 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:18:25,444]\u001b[0m Trial 333 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:18:25,685]\u001b[0m Trial 330 finished with value: 0.2569033566900406 and parameters: {'booster': 'goss', 'lambda_l2': 0.70032947337393, 'lambda_l1': 0.08867690755288125, 'cat_l2': 0.0028495849622859294, 'min_data_per_group': 13, 'max_cat_threshold': 13, 'cat_smooth': 4.926958717377864, 'max_bin': 58, 'num_leaves': 50, 'max_depth': 8, 'eta': 0.07341829392199688, 'min_split_gain': 0.013460637337932098, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9444059089635751, 'top_rate': 0.46054757604368557, 'other_rate': 0.10377567065124153}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:18:27,203]\u001b[0m Trial 334 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:18:27,506]\u001b[0m Trial 331 finished with value: 0.25799946734201123 and parameters: {'booster': 'goss', 'lambda_l2': 0.6953811299696192, 'lambda_l1': 0.08875562538348551, 'cat_l2': 0.0027640883703447627, 'min_data_per_group': 13, 'max_cat_threshold': 13, 'cat_smooth': 4.926632607576773, 'max_bin': 58, 'num_leaves': 50, 'max_depth': 8, 'eta': 0.07340047698673181, 'min_split_gain': 0.013606971693259222, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9444046959143529, 'top_rate': 0.40754610609593955, 'other_rate': 0.14218931372984275}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:18:27,603]\u001b[0m Trial 335 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:18:31,656]\u001b[0m Trial 336 finished with value: 0.2534882015509653 and parameters: {'booster': 'goss', 'lambda_l2': 0.6675172449827521, 'lambda_l1': 0.08567577359334447, 'cat_l2': 0.0027642235350393593, 'min_data_per_group': 13, 'max_cat_threshold': 14, 'cat_smooth': 4.920750720367718, 'max_bin': 58, 'num_leaves': 48, 'max_depth': 8, 'eta': 0.0732108057719012, 'min_split_gain': 0.013593236024522634, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9444049818554732, 'top_rate': 0.4046506382090514, 'other_rate': 0.14789978726995126}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:18:33,437]\u001b[0m Trial 339 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:18:33,461]\u001b[0m Trial 338 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:18:33,693]\u001b[0m Trial 340 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:18:34,328]\u001b[0m Trial 337 finished with value: 0.25968570363497123 and parameters: {'booster': 'goss', 'lambda_l2': 0.6624370788566639, 'lambda_l1': 0.0844326012161547, 'cat_l2': 0.0027242627325861153, 'min_data_per_group': 13, 'max_cat_threshold': 14, 'cat_smooth': 5.163756804321824, 'max_bin': 58, 'num_leaves': 48, 'max_depth': 8, 'eta': 0.07322305755843667, 'min_split_gain': 0.013890740101335532, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9446259645660073, 'top_rate': 0.38984927592735746, 'other_rate': 0.12354163164946227}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:18:34,973]\u001b[0m Trial 341 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:18:35,166]\u001b[0m Trial 342 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:18:35,530]\u001b[0m Trial 343 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:18:37,690]\u001b[0m Trial 344 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:18:39,508]\u001b[0m Trial 346 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:18:39,727]\u001b[0m Trial 345 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:18:40,089]\u001b[0m Trial 347 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:18:40,528]\u001b[0m Trial 348 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:18:41,111]\u001b[0m Trial 350 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:18:41,280]\u001b[0m Trial 351 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:18:44,138]\u001b[0m Trial 349 finished with value: 0.256679453449559 and parameters: {'booster': 'goss', 'lambda_l2': 0.690085695228926, 'lambda_l1': 0.07935264920132136, 'cat_l2': 0.002900748297866823, 'min_data_per_group': 13, 'max_cat_threshold': 13, 'cat_smooth': 5.623731298258112, 'max_bin': 58, 'num_leaves': 52, 'max_depth': 8, 'eta': 0.0729750476408374, 'min_split_gain': 0.013427918729668345, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9442515913988768, 'top_rate': 0.46062589597589937, 'other_rate': 0.10486807120280016}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:18:45,186]\u001b[0m Trial 352 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:18:47,012]\u001b[0m Trial 354 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:18:47,560]\u001b[0m Trial 355 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:18:47,919]\u001b[0m Trial 356 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:18:48,489]\u001b[0m Trial 357 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:18:48,610]\u001b[0m Trial 358 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:18:51,716]\u001b[0m Trial 359 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:18:52,786]\u001b[0m Trial 353 finished with value: 0.2592257173283327 and parameters: {'booster': 'goss', 'lambda_l2': 0.6879685239450976, 'lambda_l1': 0.09151613418494578, 'cat_l2': 0.0028265584852396135, 'min_data_per_group': 13, 'max_cat_threshold': 14, 'cat_smooth': 5.04746517896592, 'max_bin': 58, 'num_leaves': 49, 'max_depth': 8, 'eta': 0.0733486641272294, 'min_split_gain': 0.013698495250402131, 'min_child_weight': 17, 'min_data_in_leaf': 8, 'feature_fraction': 0.9453611686302514, 'top_rate': 0.4091183631873835, 'other_rate': 0.1501229255631525}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:18:55,795]\u001b[0m Trial 363 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:18:59,875]\u001b[0m Trial 360 finished with value: 0.26163534353357887 and parameters: {'booster': 'goss', 'lambda_l2': 0.6722803799617455, 'lambda_l1': 0.09098287382321481, 'cat_l2': 0.002788236962411542, 'min_data_per_group': 13, 'max_cat_threshold': 14, 'cat_smooth': 5.21251643699789, 'max_bin': 58, 'num_leaves': 48, 'max_depth': 8, 'eta': 0.07314453193211143, 'min_split_gain': 0.013975287992919196, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9442953008093866, 'top_rate': 0.3678087146667334, 'other_rate': 0.1394255584505628}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:19:03,936]\u001b[0m Trial 364 finished with value: 0.2613736175677654 and parameters: {'booster': 'goss', 'lambda_l2': 0.6740980430075768, 'lambda_l1': 0.08563900589903273, 'cat_l2': 0.0027816684029561586, 'min_data_per_group': 12, 'max_cat_threshold': 15, 'cat_smooth': 5.241292994917008, 'max_bin': 58, 'num_leaves': 48, 'max_depth': 8, 'eta': 0.07352836504600674, 'min_split_gain': 0.01398901244252187, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9444874000843012, 'top_rate': 0.4330685607956135, 'other_rate': 0.11245785819914773}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:19:04,338]\u001b[0m Trial 361 finished with value: 0.2599259310342126 and parameters: {'booster': 'goss', 'lambda_l2': 0.6729158681687971, 'lambda_l1': 0.0918494833449019, 'cat_l2': 0.002724654556618487, 'min_data_per_group': 12, 'max_cat_threshold': 12, 'cat_smooth': 5.234173687142705, 'max_bin': 58, 'num_leaves': 48, 'max_depth': 8, 'eta': 0.07312101262808465, 'min_split_gain': 0.013843405756735991, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9445181083211426, 'top_rate': 0.429491186447481, 'other_rate': 0.11475575676120729}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:19:05,148]\u001b[0m Trial 362 finished with value: 0.2548622979379641 and parameters: {'booster': 'goss', 'lambda_l2': 0.6756334365111765, 'lambda_l1': 0.08674263232048687, 'cat_l2': 0.002870879281768578, 'min_data_per_group': 12, 'max_cat_threshold': 12, 'cat_smooth': 5.236460349426332, 'max_bin': 58, 'num_leaves': 48, 'max_depth': 8, 'eta': 0.07311117997343133, 'min_split_gain': 0.0139975122198246, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9444590370464818, 'top_rate': 0.43431037821301316, 'other_rate': 0.1361846410751506}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:19:06,467]\u001b[0m Trial 365 finished with value: 0.26220709023889477 and parameters: {'booster': 'goss', 'lambda_l2': 0.6728584510627262, 'lambda_l1': 0.08560591726956487, 'cat_l2': 0.0028683970662144423, 'min_data_per_group': 12, 'max_cat_threshold': 12, 'cat_smooth': 5.23174909140096, 'max_bin': 58, 'num_leaves': 48, 'max_depth': 8, 'eta': 0.07348833620074897, 'min_split_gain': 0.01399217124463141, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9445140378269268, 'top_rate': 0.4243499957421048, 'other_rate': 0.1146153537802001}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:19:06,502]\u001b[0m Trial 367 finished with value: 0.25695966823922817 and parameters: {'booster': 'goss', 'lambda_l2': 0.6727324500541336, 'lambda_l1': 0.0860957258200076, 'cat_l2': 0.0026708222848927403, 'min_data_per_group': 12, 'max_cat_threshold': 12, 'cat_smooth': 5.266715953497639, 'max_bin': 58, 'num_leaves': 47, 'max_depth': 8, 'eta': 0.07354367114324648, 'min_split_gain': 0.013960077932840438, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9451086181420651, 'top_rate': 0.36430820164015576, 'other_rate': 0.4442160637092818}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:19:07,083]\u001b[0m Trial 366 finished with value: 0.256967005043854 and parameters: {'booster': 'goss', 'lambda_l2': 0.6724845081933186, 'lambda_l1': 0.08699260689134207, 'cat_l2': 0.0028756617356547466, 'min_data_per_group': 12, 'max_cat_threshold': 12, 'cat_smooth': 5.261405265978644, 'max_bin': 58, 'num_leaves': 50, 'max_depth': 8, 'eta': 0.07354864711191293, 'min_split_gain': 0.013952395588371646, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9442863881902004, 'top_rate': 0.3686737802375082, 'other_rate': 0.08544035041271793}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:19:07,416]\u001b[0m Trial 368 finished with value: 0.2579806183913517 and parameters: {'booster': 'goss', 'lambda_l2': 0.6704024090916342, 'lambda_l1': 0.08249335249090478, 'cat_l2': 0.0028656244978029796, 'min_data_per_group': 13, 'max_cat_threshold': 13, 'cat_smooth': 5.335584246461105, 'max_bin': 58, 'num_leaves': 47, 'max_depth': 8, 'eta': 0.07356033872853357, 'min_split_gain': 0.01390296668518959, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.944314356367432, 'top_rate': 0.3734925969784769, 'other_rate': 0.09788747322897887}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:19:09,208]\u001b[0m Trial 369 finished with value: 0.26008790595455256 and parameters: {'booster': 'goss', 'lambda_l2': 0.6724310059714568, 'lambda_l1': 0.08209907522489737, 'cat_l2': 0.002876983485159428, 'min_data_per_group': 12, 'max_cat_threshold': 15, 'cat_smooth': 5.327396368870891, 'max_bin': 58, 'num_leaves': 50, 'max_depth': 8, 'eta': 0.07351755267398272, 'min_split_gain': 0.013958856660323326, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9440925216413896, 'top_rate': 0.49144346433295205, 'other_rate': 0.13297355000293518}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:19:10,416]\u001b[0m Trial 370 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:19:10,866]\u001b[0m Trial 371 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:19:11,879]\u001b[0m Trial 372 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:19:13,474]\u001b[0m Trial 373 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:19:14,002]\u001b[0m Trial 374 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:19:14,158]\u001b[0m Trial 376 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:19:14,253]\u001b[0m Trial 375 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:19:17,596]\u001b[0m Trial 378 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:19:18,160]\u001b[0m Trial 379 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:19:18,960]\u001b[0m Trial 380 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:19:19,523]\u001b[0m Trial 377 finished with value: 0.2542587612681432 and parameters: {'booster': 'goss', 'lambda_l2': 0.6571872984101732, 'lambda_l1': 0.08155422333167053, 'cat_l2': 0.00278895276534613, 'min_data_per_group': 12, 'max_cat_threshold': 12, 'cat_smooth': 5.188385220901673, 'max_bin': 58, 'num_leaves': 48, 'max_depth': 8, 'eta': 0.0734913297534854, 'min_split_gain': 0.013804940390042918, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9441988278796859, 'top_rate': 0.42313645145146606, 'other_rate': 0.11242984927940503}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:19:20,907]\u001b[0m Trial 381 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:19:21,499]\u001b[0m Trial 384 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:19:21,613]\u001b[0m Trial 383 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:19:24,911]\u001b[0m Trial 382 finished with value: 0.25510121711750094 and parameters: {'booster': 'goss', 'lambda_l2': 0.6586308595300153, 'lambda_l1': 0.08825210955730642, 'cat_l2': 0.002822254570311552, 'min_data_per_group': 14, 'max_cat_threshold': 12, 'cat_smooth': 5.234022277602582, 'max_bin': 58, 'num_leaves': 48, 'max_depth': 8, 'eta': 0.07347222378957637, 'min_split_gain': 0.013798033689184261, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9445746835080756, 'top_rate': 0.32813180535820846, 'other_rate': 0.08648004303980751}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:19:25,532]\u001b[0m Trial 385 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:19:25,977]\u001b[0m Trial 386 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:19:27,316]\u001b[0m Trial 387 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:19:27,583]\u001b[0m Trial 388 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:19:28,838]\u001b[0m Trial 389 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:19:33,887]\u001b[0m Trial 392 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:19:34,528]\u001b[0m Trial 390 finished with value: 0.2557056361980953 and parameters: {'booster': 'goss', 'lambda_l2': 0.6827622297003509, 'lambda_l1': 0.0935982335410157, 'cat_l2': 0.002747387253511683, 'min_data_per_group': 13, 'max_cat_threshold': 13, 'cat_smooth': 5.26816568652192, 'max_bin': 58, 'num_leaves': 51, 'max_depth': 8, 'eta': 0.07314558091238538, 'min_split_gain': 0.01398818572450445, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.944338011145654, 'top_rate': 0.39629297668262203, 'other_rate': 0.11898508831388714}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:19:34,955]\u001b[0m Trial 394 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:19:37,045]\u001b[0m Trial 391 finished with value: 0.2559235751087734 and parameters: {'booster': 'goss', 'lambda_l2': 0.6831320219214597, 'lambda_l1': 0.1044365608797947, 'cat_l2': 0.0027433262678651206, 'min_data_per_group': 13, 'max_cat_threshold': 13, 'cat_smooth': 5.291452942692799, 'max_bin': 58, 'num_leaves': 51, 'max_depth': 8, 'eta': 0.07318360770883368, 'min_split_gain': 0.013991861473696817, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9444122459282787, 'top_rate': 0.3934088803368483, 'other_rate': 0.12164005008597732}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:19:39,928]\u001b[0m Trial 393 finished with value: 0.2588756602797714 and parameters: {'booster': 'goss', 'lambda_l2': 0.6823811992837774, 'lambda_l1': 0.09280511356064611, 'cat_l2': 0.0028645353010103374, 'min_data_per_group': 13, 'max_cat_threshold': 13, 'cat_smooth': 5.2960435785097815, 'max_bin': 58, 'num_leaves': 50, 'max_depth': 8, 'eta': 0.0733121577090069, 'min_split_gain': 0.013566759033653083, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9446556378098887, 'top_rate': 0.3992901060368256, 'other_rate': 0.11977375201515705}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:19:42,963]\u001b[0m Trial 395 finished with value: 0.26361563888417805 and parameters: {'booster': 'goss', 'lambda_l2': 0.6834466881529311, 'lambda_l1': 0.10339954332157973, 'cat_l2': 0.00286247895908472, 'min_data_per_group': 13, 'max_cat_threshold': 13, 'cat_smooth': 5.110380873711029, 'max_bin': 58, 'num_leaves': 50, 'max_depth': 8, 'eta': 0.07330632128467589, 'min_split_gain': 0.013495081847623156, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9439842191399, 'top_rate': 0.3960589263451436, 'other_rate': 0.13543174738758187}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:19:43,127]\u001b[0m Trial 396 finished with value: 0.2629685046632935 and parameters: {'booster': 'goss', 'lambda_l2': 0.6725226358212615, 'lambda_l1': 0.09295714370206046, 'cat_l2': 0.002859503976637491, 'min_data_per_group': 13, 'max_cat_threshold': 13, 'cat_smooth': 5.2711531642420155, 'max_bin': 58, 'num_leaves': 50, 'max_depth': 8, 'eta': 0.07327678549360754, 'min_split_gain': 0.013277410920610482, 'min_child_weight': 17, 'min_data_in_leaf': 6, 'feature_fraction': 0.9440152780204027, 'top_rate': 0.3460628440632084, 'other_rate': 0.13706397210049978}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:19:43,512]\u001b[0m Trial 398 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:19:43,745]\u001b[0m Trial 399 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:19:43,779]\u001b[0m Trial 397 finished with value: 0.26430512690245644 and parameters: {'booster': 'goss', 'lambda_l2': 0.6682969144944985, 'lambda_l1': 0.09167690382922887, 'cat_l2': 0.002870937681183348, 'min_data_per_group': 13, 'max_cat_threshold': 13, 'cat_smooth': 5.305339407042878, 'max_bin': 58, 'num_leaves': 46, 'max_depth': 8, 'eta': 0.07332079653241379, 'min_split_gain': 0.013321257857702936, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.944038705901864, 'top_rate': 0.41300543638626896, 'other_rate': 0.13609778095611683}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:19:44,028]\u001b[0m Trial 400 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:19:45,358]\u001b[0m Trial 401 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:19:47,273]\u001b[0m Trial 402 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:19:50,230]\u001b[0m Trial 406 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:19:50,660]\u001b[0m Trial 405 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:19:50,818]\u001b[0m Trial 407 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:19:50,928]\u001b[0m Trial 408 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:19:51,383]\u001b[0m Trial 409 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:19:54,188]\u001b[0m Trial 410 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:19:54,504]\u001b[0m Trial 404 finished with value: 0.25844180234975545 and parameters: {'booster': 'goss', 'lambda_l2': 0.6723930312170301, 'lambda_l1': 0.10321302184030491, 'cat_l2': 0.0029167805895193312, 'min_data_per_group': 13, 'max_cat_threshold': 13, 'cat_smooth': 5.486593455370894, 'max_bin': 58, 'num_leaves': 50, 'max_depth': 8, 'eta': 0.07364219055550456, 'min_split_gain': 0.013249549332150844, 'min_child_weight': 17, 'min_data_in_leaf': 6, 'feature_fraction': 0.9440954447476751, 'top_rate': 0.37785046048661225, 'other_rate': 0.13754038642788918}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:19:54,566]\u001b[0m Trial 403 finished with value: 0.25818162361334757 and parameters: {'booster': 'goss', 'lambda_l2': 0.6716992315198934, 'lambda_l1': 0.08588740935795848, 'cat_l2': 0.003015538253026762, 'min_data_per_group': 13, 'max_cat_threshold': 13, 'cat_smooth': 5.476010753648876, 'max_bin': 58, 'num_leaves': 50, 'max_depth': 8, 'eta': 0.07368233711506994, 'min_split_gain': 0.013148751974216437, 'min_child_weight': 17, 'min_data_in_leaf': 6, 'feature_fraction': 0.9440762327666165, 'top_rate': 0.36398096743665226, 'other_rate': 0.1374817259340593}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:19:57,265]\u001b[0m Trial 411 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:19:57,471]\u001b[0m Trial 413 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:19:57,896]\u001b[0m Trial 414 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:19:58,078]\u001b[0m Trial 412 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:19:58,526]\u001b[0m Trial 415 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:20:00,608]\u001b[0m Trial 416 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:20:00,648]\u001b[0m Trial 417 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:20:00,893]\u001b[0m Trial 418 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:20:03,269]\u001b[0m Trial 419 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:20:04,249]\u001b[0m Trial 422 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:20:04,278]\u001b[0m Trial 420 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:20:04,973]\u001b[0m Trial 423 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:20:08,026]\u001b[0m Trial 421 finished with value: 0.2618657322486643 and parameters: {'booster': 'goss', 'lambda_l2': 0.6785949509515755, 'lambda_l1': 0.09038887519141166, 'cat_l2': 0.0028369848128228826, 'min_data_per_group': 13, 'max_cat_threshold': 13, 'cat_smooth': 5.192204019796349, 'max_bin': 58, 'num_leaves': 49, 'max_depth': 8, 'eta': 0.07342374931424954, 'min_split_gain': 0.013819169579363532, 'min_child_weight': 17, 'min_data_in_leaf': 8, 'feature_fraction': 0.9439165852825135, 'top_rate': 0.4381708586529318, 'other_rate': 0.1261343900888008}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:20:08,067]\u001b[0m Trial 424 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:20:08,152]\u001b[0m Trial 425 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:20:08,298]\u001b[0m Trial 426 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:20:12,498]\u001b[0m Trial 430 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:20:15,900]\u001b[0m Trial 432 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:20:16,067]\u001b[0m Trial 431 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:20:16,278]\u001b[0m Trial 427 finished with value: 0.258159260340855 and parameters: {'booster': 'goss', 'lambda_l2': 0.679091192680136, 'lambda_l1': 0.08209297431678908, 'cat_l2': 0.002807430015290493, 'min_data_per_group': 13, 'max_cat_threshold': 14, 'cat_smooth': 4.966713716577458, 'max_bin': 58, 'num_leaves': 46, 'max_depth': 8, 'eta': 0.07326522090157447, 'min_split_gain': 0.013366872425254049, 'min_child_weight': 17, 'min_data_in_leaf': 8, 'feature_fraction': 0.9452555607477136, 'top_rate': 0.4297515730363585, 'other_rate': 0.11098931216437281}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:20:16,444]\u001b[0m Trial 433 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:20:16,479]\u001b[0m Trial 434 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:20:17,353]\u001b[0m Trial 429 finished with value: 0.25513589733560715 and parameters: {'booster': 'goss', 'lambda_l2': 0.6805664372517349, 'lambda_l1': 0.08270965702636188, 'cat_l2': 0.0028064107411250967, 'min_data_per_group': 13, 'max_cat_threshold': 14, 'cat_smooth': 4.948523793546177, 'max_bin': 58, 'num_leaves': 51, 'max_depth': 8, 'eta': 0.07301314664937794, 'min_split_gain': 0.013412134040729964, 'min_child_weight': 17, 'min_data_in_leaf': 8, 'feature_fraction': 0.9452491746050363, 'top_rate': 0.42858978547250154, 'other_rate': 0.10429427271170776}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:20:17,981]\u001b[0m Trial 428 finished with value: 0.2560703510169188 and parameters: {'booster': 'goss', 'lambda_l2': 0.6815584457397714, 'lambda_l1': 0.08171922530196737, 'cat_l2': 0.002969665957676158, 'min_data_per_group': 13, 'max_cat_threshold': 14, 'cat_smooth': 4.97162682217146, 'max_bin': 58, 'num_leaves': 46, 'max_depth': 8, 'eta': 0.07303719540079578, 'min_split_gain': 0.01339677300859515, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9447668427897958, 'top_rate': 0.41882723982127995, 'other_rate': 0.10701215649782325}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:20:19,087]\u001b[0m Trial 435 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:20:22,710]\u001b[0m Trial 437 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:20:22,970]\u001b[0m Trial 438 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:20:23,145]\u001b[0m Trial 439 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:20:23,396]\u001b[0m Trial 440 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:20:24,007]\u001b[0m Trial 441 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:20:24,648]\u001b[0m Trial 442 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:20:26,945]\u001b[0m Trial 443 pruned. Trial was pruned at iteration 19.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:20:27,298]\u001b[0m Trial 436 finished with value: 0.2603661126674567 and parameters: {'booster': 'goss', 'lambda_l2': 0.6850232859983876, 'lambda_l1': 0.08721467660549209, 'cat_l2': 0.0028544171254900248, 'min_data_per_group': 14, 'max_cat_threshold': 13, 'cat_smooth': 5.097819845606036, 'max_bin': 58, 'num_leaves': 49, 'max_depth': 8, 'eta': 0.07383656888839549, 'min_split_gain': 0.013704310384522201, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9445829341758266, 'top_rate': 0.3628525877493982, 'other_rate': 0.12354626496322935}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:20:30,188]\u001b[0m Trial 444 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:20:30,727]\u001b[0m Trial 445 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:20:30,925]\u001b[0m Trial 447 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:20:31,027]\u001b[0m Trial 448 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:20:31,600]\u001b[0m Trial 449 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:20:33,787]\u001b[0m Trial 446 finished with value: 0.2609181723092779 and parameters: {'booster': 'goss', 'lambda_l2': 0.6643413595430115, 'lambda_l1': 0.0921094236853509, 'cat_l2': 0.0027126297438006823, 'min_data_per_group': 13, 'max_cat_threshold': 13, 'cat_smooth': 5.277706198344079, 'max_bin': 58, 'num_leaves': 50, 'max_depth': 8, 'eta': 0.07347530100979499, 'min_split_gain': 0.013792302456214621, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9443654853952944, 'top_rate': 0.37657526840412153, 'other_rate': 0.09677067428730636}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:20:34,275]\u001b[0m Trial 450 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:20:34,594]\u001b[0m Trial 451 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:20:37,329]\u001b[0m Trial 452 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:20:37,840]\u001b[0m Trial 453 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:20:38,044]\u001b[0m Trial 454 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:20:38,148]\u001b[0m Trial 455 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:20:38,676]\u001b[0m Trial 456 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:20:40,613]\u001b[0m Trial 457 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:20:41,032]\u001b[0m Trial 458 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:20:45,903]\u001b[0m Trial 460 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:20:46,506]\u001b[0m Trial 463 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:20:46,635]\u001b[0m Trial 459 finished with value: 0.25602619550937156 and parameters: {'booster': 'goss', 'lambda_l2': 0.6765807207767419, 'lambda_l1': 0.07639672238447236, 'cat_l2': 0.00265774074333722, 'min_data_per_group': 13, 'max_cat_threshold': 12, 'cat_smooth': 5.168986226138609, 'max_bin': 58, 'num_leaves': 45, 'max_depth': 8, 'eta': 0.07320190514684231, 'min_split_gain': 0.013799986504482421, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9442989400398913, 'top_rate': 0.4605949311160203, 'other_rate': 0.16493085202900487}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:20:46,798]\u001b[0m Trial 462 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:20:46,902]\u001b[0m Trial 461 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:20:46,936]\u001b[0m Trial 464 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:20:48,676]\u001b[0m Trial 465 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:20:48,776]\u001b[0m Trial 466 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:20:53,076]\u001b[0m Trial 469 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:20:53,322]\u001b[0m Trial 471 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:20:53,399]\u001b[0m Trial 472 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:20:53,486]\u001b[0m Trial 468 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:20:53,516]\u001b[0m Trial 470 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:20:55,630]\u001b[0m Trial 473 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:20:56,639]\u001b[0m Trial 467 finished with value: 0.2583086996205922 and parameters: {'booster': 'goss', 'lambda_l2': 0.6776740380871413, 'lambda_l1': 0.08880250315327551, 'cat_l2': 0.0027652600615917715, 'min_data_per_group': 13, 'max_cat_threshold': 13, 'cat_smooth': 5.029251753970411, 'max_bin': 58, 'num_leaves': 51, 'max_depth': 8, 'eta': 0.07293760327809319, 'min_split_gain': 0.013319102799183387, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.944491204291397, 'top_rate': 0.35495725028828995, 'other_rate': 0.08141318425112735}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:20:59,592]\u001b[0m Trial 474 finished with value: 0.25882218456222217 and parameters: {'booster': 'goss', 'lambda_l2': 0.6647202072030418, 'lambda_l1': 0.0803697441079558, 'cat_l2': 0.002772142825801889, 'min_data_per_group': 12, 'max_cat_threshold': 13, 'cat_smooth': 5.052214346464238, 'max_bin': 58, 'num_leaves': 51, 'max_depth': 8, 'eta': 0.07335124816329085, 'min_split_gain': 0.013291228012198914, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9444842614448419, 'top_rate': 0.4409529437037529, 'other_rate': 0.13240569413491798}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:21:02,046]\u001b[0m Trial 477 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:21:02,341]\u001b[0m Trial 479 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:21:02,510]\u001b[0m Trial 476 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:21:04,224]\u001b[0m Trial 480 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:21:05,658]\u001b[0m Trial 481 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:21:05,928]\u001b[0m Trial 478 finished with value: 0.26155620250780726 and parameters: {'booster': 'goss', 'lambda_l2': 0.664964661190318, 'lambda_l1': 0.09461449867119316, 'cat_l2': 0.002913297573556813, 'min_data_per_group': 12, 'max_cat_threshold': 13, 'cat_smooth': 5.320249339720423, 'max_bin': 58, 'num_leaves': 48, 'max_depth': 8, 'eta': 0.07333240356714393, 'min_split_gain': 0.013701241506673258, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9442506751947493, 'top_rate': 0.40817126115175106, 'other_rate': 0.11622892806150749}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:21:06,126]\u001b[0m Trial 475 finished with value: 0.2602180736801283 and parameters: {'booster': 'goss', 'lambda_l2': 0.6647664518919552, 'lambda_l1': 0.08910463760342356, 'cat_l2': 0.0028324053852776163, 'min_data_per_group': 12, 'max_cat_threshold': 13, 'cat_smooth': 5.299663803574919, 'max_bin': 58, 'num_leaves': 49, 'max_depth': 8, 'eta': 0.0733511926737537, 'min_split_gain': 0.013687181822923361, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9450979575950853, 'top_rate': 0.41312164517007005, 'other_rate': 0.10736223721125503}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:21:07,994]\u001b[0m Trial 482 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:21:09,832]\u001b[0m Trial 484 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:21:09,877]\u001b[0m Trial 485 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:21:10,029]\u001b[0m Trial 483 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:21:10,966]\u001b[0m Trial 486 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:21:12,020]\u001b[0m Trial 487 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:21:12,904]\u001b[0m Trial 488 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:21:13,072]\u001b[0m Trial 489 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:21:14,857]\u001b[0m Trial 490 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:21:16,829]\u001b[0m Trial 492 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:21:16,931]\u001b[0m Trial 491 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:21:17,263]\u001b[0m Trial 493 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:21:20,070]\u001b[0m Trial 496 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\optuna\\samplers\\_tpe\\parzen_estimator.py:188: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning:\n",
            "\n",
            "Using categorical_feature in Dataset.\n",
            "\n",
            "\u001b[32m[I 2021-10-23 18:21:21,608]\u001b[0m Trial 498 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:21:23,350]\u001b[0m Trial 494 finished with value: 0.26080104715505814 and parameters: {'booster': 'goss', 'lambda_l2': 0.6866076207522818, 'lambda_l1': 0.10529077216435216, 'cat_l2': 0.0029515723592510976, 'min_data_per_group': 12, 'max_cat_threshold': 14, 'cat_smooth': 5.419594362075896, 'max_bin': 58, 'num_leaves': 50, 'max_depth': 8, 'eta': 0.07352752345563295, 'min_split_gain': 0.013495109547555277, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9442709763239417, 'top_rate': 0.33848243326108723, 'other_rate': 0.14236632656727014}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:21:24,162]\u001b[0m Trial 497 finished with value: 0.25705983134166244 and parameters: {'booster': 'goss', 'lambda_l2': 0.685402616679251, 'lambda_l1': 0.0952246505665014, 'cat_l2': 0.0028745506667827952, 'min_data_per_group': 12, 'max_cat_threshold': 14, 'cat_smooth': 5.414109949046793, 'max_bin': 58, 'num_leaves': 47, 'max_depth': 8, 'eta': 0.073494836622022, 'min_split_gain': 0.013479184437265722, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9443854266361361, 'top_rate': 0.45996849379000737, 'other_rate': 0.4316509866942603}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:21:24,490]\u001b[0m Trial 495 finished with value: 0.257790014753141 and parameters: {'booster': 'goss', 'lambda_l2': 0.6874635513069256, 'lambda_l1': 0.094900359842856, 'cat_l2': 0.002960832412384209, 'min_data_per_group': 10, 'max_cat_threshold': 14, 'cat_smooth': 5.162967968265273, 'max_bin': 58, 'num_leaves': 47, 'max_depth': 8, 'eta': 0.07357462734208528, 'min_split_gain': 0.01381521201234868, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9442946655195432, 'top_rate': 0.4179776966794441, 'other_rate': 0.11827740813020779}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n",
            "\u001b[32m[I 2021-10-23 18:21:25,013]\u001b[0m Trial 499 finished with value: 0.25906326121060286 and parameters: {'booster': 'goss', 'lambda_l2': 0.6726389052292463, 'lambda_l1': 0.09513804888393097, 'cat_l2': 0.0028298976170453437, 'min_data_per_group': 12, 'max_cat_threshold': 13, 'cat_smooth': 5.141881886968699, 'max_bin': 58, 'num_leaves': 50, 'max_depth': 8, 'eta': 0.07341648891551313, 'min_split_gain': 0.013805570387664121, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'feature_fraction': 0.9448368575664324, 'top_rate': 0.43027072199230304, 'other_rate': 0.1231426609891079}. Best is trial 267 with value: 0.26532196167545063.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "for booster, study in lgb_study.items():\n",
        "    study.optimize(lambda t: objective(t, boosting_type=booster), n_trials=500, n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Value 0.26532196167545063\n",
            "{'booster': 'goss', 'cat_l2': 0.002832945022550406, 'cat_smooth': 5.4111463094755266, 'eta': 0.07328979517371839, 'feature_fraction': 0.9446167822698687, 'lambda_l1': 0.08016922106726923, 'lambda_l2': 0.6855920985773585, 'max_bin': 58, 'max_cat_threshold': 13, 'max_depth': 8, 'min_child_weight': 17, 'min_data_in_leaf': 7, 'min_data_per_group': 13, 'min_split_gain': 0.013653991391068496, 'num_leaves': 50, 'other_rate': 0.12836337511071985, 'top_rate': 0.38895880168990904}\n",
            "{'n_estimators': 23}\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    lgb_study\n",
        "except NameError:\n",
        "    lgb_study = {booster+postfix: opt.load_study(study_name=booster+postfix, storage=LGB_DB_URL) for booster in boosters}\n",
        "    \n",
        "for study in lgb_study.values():\n",
        "    best = study.best_trial\n",
        "    print(f'Value {best.value}')\n",
        "    print(best.params)\n",
        "    print(best.user_attrs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "mode": "markers",
                  "name": "Objective Value",
                  "type": "scatter",
                  "x": [
                    0,
                    1,
                    2,
                    3,
                    4,
                    6,
                    7,
                    9,
                    10,
                    11,
                    13,
                    15,
                    16,
                    17,
                    18,
                    19,
                    20,
                    21,
                    22,
                    29,
                    32,
                    33,
                    34,
                    35,
                    37,
                    41,
                    61,
                    72,
                    73,
                    76,
                    78,
                    84,
                    85,
                    86,
                    87,
                    93,
                    94,
                    99,
                    102,
                    103,
                    104,
                    105,
                    106,
                    107,
                    108,
                    109,
                    110,
                    113,
                    114,
                    115,
                    118,
                    119,
                    134,
                    143,
                    145,
                    146,
                    163,
                    177,
                    179,
                    181,
                    182,
                    183,
                    187,
                    194,
                    195,
                    196,
                    200,
                    201,
                    206,
                    207,
                    208,
                    210,
                    216,
                    217,
                    232,
                    233,
                    234,
                    236,
                    241,
                    242,
                    243,
                    244,
                    247,
                    248,
                    249,
                    250,
                    251,
                    252,
                    253,
                    254,
                    256,
                    257,
                    258,
                    259,
                    260,
                    261,
                    262,
                    263,
                    264,
                    265,
                    266,
                    267,
                    268,
                    269,
                    270,
                    271,
                    272,
                    273,
                    274,
                    275,
                    276,
                    277,
                    278,
                    279,
                    280,
                    281,
                    282,
                    283,
                    285,
                    286,
                    288,
                    292,
                    295,
                    296,
                    297,
                    298,
                    299,
                    300,
                    301,
                    302,
                    303,
                    304,
                    321,
                    323,
                    325,
                    327,
                    330,
                    331,
                    336,
                    337,
                    349,
                    353,
                    360,
                    361,
                    362,
                    364,
                    365,
                    366,
                    367,
                    368,
                    369,
                    377,
                    382,
                    390,
                    391,
                    393,
                    395,
                    396,
                    397,
                    403,
                    404,
                    421,
                    427,
                    428,
                    429,
                    436,
                    446,
                    459,
                    467,
                    474,
                    475,
                    478,
                    494,
                    495,
                    497,
                    499
                  ],
                  "y": [
                    0.23799384286273395,
                    0.25257026611385686,
                    0.23607234921980993,
                    0.23351004392260122,
                    0.22118355006291165,
                    0.2368054863573365,
                    0.23467817578951994,
                    0.2492183617272187,
                    0.2508034667728444,
                    0.24444355146697733,
                    0.24638441809695522,
                    0.24066073110273717,
                    0.2500992724128512,
                    0.2512497389906705,
                    0.24780014207800183,
                    0.24345589003523718,
                    0.24950559698288596,
                    0.2512468585781459,
                    0.24966547399488767,
                    0.2527316371024155,
                    0.2514909232994099,
                    0.2511396047960298,
                    0.2586352644702073,
                    0.2527264459805575,
                    0.25572363816910854,
                    0.25022635152072403,
                    0.24556031408083032,
                    0.24675938835375505,
                    0.2517645801757151,
                    0.2538164492920105,
                    0.2525943989047087,
                    0.24974231033993394,
                    0.2532202192933685,
                    0.25582444275876653,
                    0.2529551831471422,
                    0.24839273295219666,
                    0.2527985746283016,
                    0.25097194701688813,
                    0.2556160224341649,
                    0.2510635252106125,
                    0.2514807436210522,
                    0.24684229713746925,
                    0.2470559585496679,
                    0.2502647364386594,
                    0.25222208388466083,
                    0.25400125143797925,
                    0.2552580905005643,
                    0.2528342014614715,
                    0.2493985001778562,
                    0.2528384528802303,
                    0.2550233498938586,
                    0.2523083029470582,
                    0.25483072502545034,
                    0.24847497589226655,
                    0.2574753029167793,
                    0.25608749134198927,
                    0.2511703011467725,
                    0.2547536078051821,
                    0.2529914277269956,
                    0.25209671945226275,
                    0.2515369929044722,
                    0.2548329181498087,
                    0.25068697393310213,
                    0.2501431184287837,
                    0.2540030651641933,
                    0.2507047934728426,
                    0.25641341551762764,
                    0.25780701625469604,
                    0.25521824386459036,
                    0.2557960577331986,
                    0.2534074976345324,
                    0.2585956950317595,
                    0.25957896568406236,
                    0.252325709986834,
                    0.251712426654483,
                    0.25704328332362836,
                    0.2586001109656427,
                    0.253032392102843,
                    0.2582294697836728,
                    0.25615608164991127,
                    0.2597090938462958,
                    0.25817099974935753,
                    0.25732394817011095,
                    0.251840973701201,
                    0.25554155233484255,
                    0.2538934288059256,
                    0.2604836395582832,
                    0.25924654113987,
                    0.252060534249514,
                    0.25873673802174624,
                    0.2544991930599525,
                    0.2555580966475103,
                    0.25971665260699334,
                    0.26240806334113453,
                    0.25987806370287453,
                    0.2617452826463283,
                    0.2588429180727659,
                    0.26140396995493137,
                    0.25751223896826564,
                    0.2552430711790555,
                    0.25949895623877345,
                    0.26532196167545063,
                    0.2635506977103081,
                    0.258422205804421,
                    0.2607411123181213,
                    0.26077220028163106,
                    0.2564147969225439,
                    0.2618370498319524,
                    0.2574255385529174,
                    0.256073589906999,
                    0.26231410783114406,
                    0.25693832431455654,
                    0.26010458097199834,
                    0.25641098202249235,
                    0.26214657077906367,
                    0.25970132700171716,
                    0.2612381465463163,
                    0.25838319112920943,
                    0.26193894135573725,
                    0.2607055197450044,
                    0.2558238819843697,
                    0.26039411892238445,
                    0.2596285073734872,
                    0.25672325638029103,
                    0.25835134322104664,
                    0.25779739913631283,
                    0.2616895893152762,
                    0.25981441847356196,
                    0.2560462182784489,
                    0.25273645729321736,
                    0.2618738353401766,
                    0.2577028990584764,
                    0.25564175186673194,
                    0.25320855897174505,
                    0.2538377838640009,
                    0.2526526964817669,
                    0.2569033566900406,
                    0.25799946734201123,
                    0.2534882015509653,
                    0.25968570363497123,
                    0.256679453449559,
                    0.2592257173283327,
                    0.26163534353357887,
                    0.2599259310342126,
                    0.2548622979379641,
                    0.2613736175677654,
                    0.26220709023889477,
                    0.256967005043854,
                    0.25695966823922817,
                    0.2579806183913517,
                    0.26008790595455256,
                    0.2542587612681432,
                    0.25510121711750094,
                    0.2557056361980953,
                    0.2559235751087734,
                    0.2588756602797714,
                    0.26361563888417805,
                    0.2629685046632935,
                    0.26430512690245644,
                    0.25818162361334757,
                    0.25844180234975545,
                    0.2618657322486643,
                    0.258159260340855,
                    0.2560703510169188,
                    0.25513589733560715,
                    0.2603661126674567,
                    0.2609181723092779,
                    0.25602619550937156,
                    0.2583086996205922,
                    0.25882218456222217,
                    0.2602180736801283,
                    0.26155620250780726,
                    0.26080104715505814,
                    0.257790014753141,
                    0.25705983134166244,
                    0.25906326121060286
                  ]
                },
                {
                  "name": "Best Value",
                  "type": "scatter",
                  "x": [
                    0,
                    1,
                    2,
                    3,
                    4,
                    6,
                    7,
                    9,
                    10,
                    11,
                    13,
                    15,
                    16,
                    17,
                    18,
                    19,
                    20,
                    21,
                    22,
                    29,
                    32,
                    33,
                    34,
                    35,
                    37,
                    41,
                    61,
                    72,
                    73,
                    76,
                    78,
                    84,
                    85,
                    86,
                    87,
                    93,
                    94,
                    99,
                    102,
                    103,
                    104,
                    105,
                    106,
                    107,
                    108,
                    109,
                    110,
                    113,
                    114,
                    115,
                    118,
                    119,
                    134,
                    143,
                    145,
                    146,
                    163,
                    177,
                    179,
                    181,
                    182,
                    183,
                    187,
                    194,
                    195,
                    196,
                    200,
                    201,
                    206,
                    207,
                    208,
                    210,
                    216,
                    217,
                    232,
                    233,
                    234,
                    236,
                    241,
                    242,
                    243,
                    244,
                    247,
                    248,
                    249,
                    250,
                    251,
                    252,
                    253,
                    254,
                    256,
                    257,
                    258,
                    259,
                    260,
                    261,
                    262,
                    263,
                    264,
                    265,
                    266,
                    267,
                    268,
                    269,
                    270,
                    271,
                    272,
                    273,
                    274,
                    275,
                    276,
                    277,
                    278,
                    279,
                    280,
                    281,
                    282,
                    283,
                    285,
                    286,
                    288,
                    292,
                    295,
                    296,
                    297,
                    298,
                    299,
                    300,
                    301,
                    302,
                    303,
                    304,
                    321,
                    323,
                    325,
                    327,
                    330,
                    331,
                    336,
                    337,
                    349,
                    353,
                    360,
                    361,
                    362,
                    364,
                    365,
                    366,
                    367,
                    368,
                    369,
                    377,
                    382,
                    390,
                    391,
                    393,
                    395,
                    396,
                    397,
                    403,
                    404,
                    421,
                    427,
                    428,
                    429,
                    436,
                    446,
                    459,
                    467,
                    474,
                    475,
                    478,
                    494,
                    495,
                    497,
                    499
                  ],
                  "y": [
                    0.23799384286273395,
                    0.25257026611385686,
                    0.25257026611385686,
                    0.25257026611385686,
                    0.25257026611385686,
                    0.25257026611385686,
                    0.25257026611385686,
                    0.25257026611385686,
                    0.25257026611385686,
                    0.25257026611385686,
                    0.25257026611385686,
                    0.25257026611385686,
                    0.25257026611385686,
                    0.25257026611385686,
                    0.25257026611385686,
                    0.25257026611385686,
                    0.25257026611385686,
                    0.25257026611385686,
                    0.25257026611385686,
                    0.2527316371024155,
                    0.2527316371024155,
                    0.2527316371024155,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.2586352644702073,
                    0.25957896568406236,
                    0.25957896568406236,
                    0.25957896568406236,
                    0.25957896568406236,
                    0.25957896568406236,
                    0.25957896568406236,
                    0.25957896568406236,
                    0.25957896568406236,
                    0.2597090938462958,
                    0.2597090938462958,
                    0.2597090938462958,
                    0.2597090938462958,
                    0.2597090938462958,
                    0.2597090938462958,
                    0.2604836395582832,
                    0.2604836395582832,
                    0.2604836395582832,
                    0.2604836395582832,
                    0.2604836395582832,
                    0.2604836395582832,
                    0.2604836395582832,
                    0.26240806334113453,
                    0.26240806334113453,
                    0.26240806334113453,
                    0.26240806334113453,
                    0.26240806334113453,
                    0.26240806334113453,
                    0.26240806334113453,
                    0.26240806334113453,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063,
                    0.26532196167545063
                  ]
                }
              ],
              "layout": {
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "heatmapgl": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmapgl"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                },
                "title": {
                  "text": "Optimization History Plot"
                },
                "xaxis": {
                  "title": {
                    "text": "#Trials"
                  }
                },
                "yaxis": {
                  "title": {
                    "text": "Objective Value"
                  }
                }
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "opt.visualization.plot_optimization_history(lgb_study.get(boosters[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "mode": "lines",
                  "name": "goss-cat",
                  "type": "scatter",
                  "x": [
                    0.22118355006291165,
                    0.22162939260445244,
                    0.22207523514599325,
                    0.22252107768753404,
                    0.22296692022907486,
                    0.22341276277061564,
                    0.22385860531215643,
                    0.22430444785369724,
                    0.22475029039523803,
                    0.22519613293677884,
                    0.22564197547831963,
                    0.22608781801986044,
                    0.22653366056140123,
                    0.22697950310294202,
                    0.22742534564448283,
                    0.22787118818602362,
                    0.22831703072756443,
                    0.22876287326910522,
                    0.229208715810646,
                    0.22965455835218682,
                    0.2301004008937276,
                    0.23054624343526842,
                    0.2309920859768092,
                    0.23143792851835,
                    0.2318837710598908,
                    0.2323296136014316,
                    0.2327754561429724,
                    0.2332212986845132,
                    0.233667141226054,
                    0.2341129837675948,
                    0.23455882630913558,
                    0.2350046688506764,
                    0.23545051139221718,
                    0.235896353933758,
                    0.23634219647529878,
                    0.2367880390168396,
                    0.23723388155838038,
                    0.23767972409992116,
                    0.23812556664146198,
                    0.23857140918300276,
                    0.23901725172454358,
                    0.23946309426608436,
                    0.23990893680762515,
                    0.24035477934916596,
                    0.24080062189070675,
                    0.24124646443224756,
                    0.24169230697378835,
                    0.24213814951532914,
                    0.24258399205686995,
                    0.24302983459841074,
                    0.24347567713995155,
                    0.24392151968149234,
                    0.24436736222303312,
                    0.24481320476457394,
                    0.24525904730611472,
                    0.24570488984765554,
                    0.24615073238919633,
                    0.24659657493073714,
                    0.24704241747227793,
                    0.2474882600138187,
                    0.24793410255535953,
                    0.2483799450969003,
                    0.24882578763844113,
                    0.2492716301799819,
                    0.24971747272152273,
                    0.2501633152630635,
                    0.2506091578046043,
                    0.2510550003461451,
                    0.2515008428876859,
                    0.2519466854292267,
                    0.2523925279707675,
                    0.2528383705123083,
                    0.25328421305384907,
                    0.2537300555953899,
                    0.2541758981369307,
                    0.2546217406784715,
                    0.2550675832200123,
                    0.2555134257615531,
                    0.2559592683030939,
                    0.2564051108446347,
                    0.2568509533861755,
                    0.25729679592771626,
                    0.25774263846925705,
                    0.2581884810107979,
                    0.2586343235523387,
                    0.25908016609387946,
                    0.25952600863542025,
                    0.2599718511769611,
                    0.2604176937185019,
                    0.26086353626004266,
                    0.26130937880158345,
                    0.26175522134312423,
                    0.262201063884665,
                    0.26264690642620586,
                    0.26309274896774665,
                    0.26353859150928743,
                    0.2639844340508282,
                    0.26443027659236906,
                    0.26487611913390985,
                    0.26532196167545063
                  ],
                  "y": [
                    0.005681818181818182,
                    0.005681818181818182,
                    0.005681818181818182,
                    0.005681818181818182,
                    0.005681818181818182,
                    0.005681818181818182,
                    0.005681818181818182,
                    0.005681818181818182,
                    0.005681818181818182,
                    0.005681818181818182,
                    0.005681818181818182,
                    0.005681818181818182,
                    0.005681818181818182,
                    0.005681818181818182,
                    0.005681818181818182,
                    0.005681818181818182,
                    0.005681818181818182,
                    0.005681818181818182,
                    0.005681818181818182,
                    0.005681818181818182,
                    0.005681818181818182,
                    0.005681818181818182,
                    0.005681818181818182,
                    0.005681818181818182,
                    0.005681818181818182,
                    0.005681818181818182,
                    0.005681818181818182,
                    0.005681818181818182,
                    0.011363636363636364,
                    0.011363636363636364,
                    0.011363636363636364,
                    0.017045454545454544,
                    0.017045454545454544,
                    0.017045454545454544,
                    0.022727272727272728,
                    0.022727272727272728,
                    0.028409090909090908,
                    0.028409090909090908,
                    0.03409090909090909,
                    0.03409090909090909,
                    0.03409090909090909,
                    0.03409090909090909,
                    0.03409090909090909,
                    0.03409090909090909,
                    0.03977272727272727,
                    0.03977272727272727,
                    0.03977272727272727,
                    0.03977272727272727,
                    0.03977272727272727,
                    0.03977272727272727,
                    0.045454545454545456,
                    0.045454545454545456,
                    0.045454545454545456,
                    0.05113636363636364,
                    0.05113636363636364,
                    0.056818181818181816,
                    0.056818181818181816,
                    0.0625,
                    0.07386363636363637,
                    0.07954545454545454,
                    0.08522727272727272,
                    0.08522727272727272,
                    0.09659090909090909,
                    0.10227272727272728,
                    0.11931818181818182,
                    0.13636363636363635,
                    0.14772727272727273,
                    0.17045454545454544,
                    0.21022727272727273,
                    0.23295454545454544,
                    0.26136363636363635,
                    0.3068181818181818,
                    0.3409090909090909,
                    0.3522727272727273,
                    0.3806818181818182,
                    0.39204545454545453,
                    0.42045454545454547,
                    0.44886363636363635,
                    0.5056818181818182,
                    0.5397727272727273,
                    0.5681818181818182,
                    0.6022727272727273,
                    0.6306818181818182,
                    0.6761363636363636,
                    0.7215909090909091,
                    0.7556818181818182,
                    0.7727272727272727,
                    0.8238636363636364,
                    0.8522727272727273,
                    0.8806818181818182,
                    0.8920454545454546,
                    0.9261363636363636,
                    0.9545454545454546,
                    0.9715909090909091,
                    0.9772727272727273,
                    0.9772727272727273,
                    0.9886363636363636,
                    0.9943181818181818,
                    0.9943181818181818,
                    1
                  ]
                }
              ],
              "layout": {
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "heatmapgl": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmapgl"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                },
                "title": {
                  "text": "Empirical Distribution Function Plot"
                },
                "xaxis": {
                  "title": {
                    "text": "Objective Value"
                  }
                },
                "yaxis": {
                  "range": [
                    0,
                    1
                  ],
                  "title": {
                    "text": "Cumulative Probability"
                  }
                }
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "opt.visualization.plot_edf(list(lgb_study.values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "mode": "lines",
                  "name": "gbdt-cat",
                  "type": "scatter",
                  "x": [
                    0.18432587042658996,
                    0.18502476527755568,
                    0.18572366012852137,
                    0.1864225549794871,
                    0.1871214498304528,
                    0.1878203446814185,
                    0.18851923953238423,
                    0.18921813438334992,
                    0.18991702923431564,
                    0.19061592408528136,
                    0.19131481893624705,
                    0.19201371378721277,
                    0.1927126086381785,
                    0.19341150348914418,
                    0.1941103983401099,
                    0.19480929319107562,
                    0.19550818804204131,
                    0.19620708289300703,
                    0.19690597774397273,
                    0.19760487259493845,
                    0.19830376744590417,
                    0.19900266229686986,
                    0.19970155714783558,
                    0.2004004519988013,
                    0.201099346849767,
                    0.2017982417007327,
                    0.20249713655169843,
                    0.20319603140266412,
                    0.20389492625362984,
                    0.20459382110459556,
                    0.20529271595556126,
                    0.20599161080652698,
                    0.20669050565749267,
                    0.2073894005084584,
                    0.2080882953594241,
                    0.2087871902103898,
                    0.20948608506135552,
                    0.2101849799123212,
                    0.21088387476328693,
                    0.21158276961425265,
                    0.21228166446521834,
                    0.21298055931618406,
                    0.21367945416714978,
                    0.21437834901811548,
                    0.2150772438690812,
                    0.21577613872004692,
                    0.2164750335710126,
                    0.21717392842197833,
                    0.21787282327294405,
                    0.21857171812390974,
                    0.21927061297487546,
                    0.21996950782584118,
                    0.22066840267680687,
                    0.2213672975277726,
                    0.22206619237873831,
                    0.222765087229704,
                    0.22346398208066973,
                    0.22416287693163542,
                    0.22486177178260114,
                    0.22556066663356683,
                    0.22625956148453255,
                    0.22695845633549827,
                    0.22765735118646396,
                    0.22835624603742968,
                    0.2290551408883954,
                    0.2297540357393611,
                    0.23045293059032682,
                    0.23115182544129254,
                    0.23185072029225823,
                    0.23254961514322395,
                    0.23324850999418967,
                    0.23394740484515536,
                    0.23464629969612108,
                    0.2353451945470868,
                    0.2360440893980525,
                    0.2367429842490182,
                    0.23744187909998393,
                    0.23814077395094962,
                    0.23883966880191534,
                    0.23953856365288104,
                    0.24023745850384676,
                    0.24093635335481245,
                    0.24163524820577817,
                    0.2423341430567439,
                    0.24303303790770958,
                    0.2437319327586753,
                    0.24443082760964102,
                    0.2451297224606067,
                    0.24582861731157243,
                    0.24652751216253815,
                    0.24722640701350385,
                    0.24792530186446957,
                    0.24862419671543529,
                    0.24932309156640098,
                    0.2500219864173667,
                    0.2507208812683324,
                    0.2514197761192981,
                    0.25211867097026386,
                    0.25281756582122955,
                    0.25351646067219524
                  ],
                  "y": [
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0.0064516129032258064,
                    0.0064516129032258064,
                    0.0064516129032258064,
                    0.01935483870967742,
                    0.01935483870967742,
                    0.01935483870967742,
                    0.01935483870967742,
                    0.01935483870967742,
                    0.01935483870967742,
                    0.01935483870967742,
                    0.025806451612903226,
                    0.025806451612903226,
                    0.03225806451612903,
                    0.03225806451612903,
                    0.04516129032258064,
                    0.05161290322580645,
                    0.06451612903225806,
                    0.07096774193548387,
                    0.07741935483870968,
                    0.08387096774193549,
                    0.11612903225806452,
                    0.12258064516129032,
                    0.14193548387096774,
                    0.16129032258064516,
                    0.16774193548387098,
                    0.18064516129032257,
                    0.2,
                    0.23225806451612904,
                    0.2967741935483871,
                    0.36129032258064514,
                    0.432258064516129,
                    0.45806451612903226,
                    0.4967741935483871,
                    0.5096774193548387,
                    0.5806451612903226,
                    0.6193548387096774,
                    0.6774193548387096,
                    0.7096774193548387,
                    0.7677419354838709,
                    0.8193548387096774,
                    0.8387096774193549,
                    0.8709677419354839,
                    0.896774193548387,
                    0.9225806451612903,
                    0.9419354838709677,
                    0.9483870967741935,
                    0.9612903225806452,
                    0.9741935483870968,
                    0.9806451612903225,
                    0.9870967741935484,
                    0.9935483870967742,
                    0.9935483870967742,
                    0.9935483870967742,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1
                  ]
                },
                {
                  "mode": "lines",
                  "name": "dart-cat",
                  "type": "scatter",
                  "x": [
                    0.18432587042658996,
                    0.18502476527755568,
                    0.18572366012852137,
                    0.1864225549794871,
                    0.1871214498304528,
                    0.1878203446814185,
                    0.18851923953238423,
                    0.18921813438334992,
                    0.18991702923431564,
                    0.19061592408528136,
                    0.19131481893624705,
                    0.19201371378721277,
                    0.1927126086381785,
                    0.19341150348914418,
                    0.1941103983401099,
                    0.19480929319107562,
                    0.19550818804204131,
                    0.19620708289300703,
                    0.19690597774397273,
                    0.19760487259493845,
                    0.19830376744590417,
                    0.19900266229686986,
                    0.19970155714783558,
                    0.2004004519988013,
                    0.201099346849767,
                    0.2017982417007327,
                    0.20249713655169843,
                    0.20319603140266412,
                    0.20389492625362984,
                    0.20459382110459556,
                    0.20529271595556126,
                    0.20599161080652698,
                    0.20669050565749267,
                    0.2073894005084584,
                    0.2080882953594241,
                    0.2087871902103898,
                    0.20948608506135552,
                    0.2101849799123212,
                    0.21088387476328693,
                    0.21158276961425265,
                    0.21228166446521834,
                    0.21298055931618406,
                    0.21367945416714978,
                    0.21437834901811548,
                    0.2150772438690812,
                    0.21577613872004692,
                    0.2164750335710126,
                    0.21717392842197833,
                    0.21787282327294405,
                    0.21857171812390974,
                    0.21927061297487546,
                    0.21996950782584118,
                    0.22066840267680687,
                    0.2213672975277726,
                    0.22206619237873831,
                    0.222765087229704,
                    0.22346398208066973,
                    0.22416287693163542,
                    0.22486177178260114,
                    0.22556066663356683,
                    0.22625956148453255,
                    0.22695845633549827,
                    0.22765735118646396,
                    0.22835624603742968,
                    0.2290551408883954,
                    0.2297540357393611,
                    0.23045293059032682,
                    0.23115182544129254,
                    0.23185072029225823,
                    0.23254961514322395,
                    0.23324850999418967,
                    0.23394740484515536,
                    0.23464629969612108,
                    0.2353451945470868,
                    0.2360440893980525,
                    0.2367429842490182,
                    0.23744187909998393,
                    0.23814077395094962,
                    0.23883966880191534,
                    0.23953856365288104,
                    0.24023745850384676,
                    0.24093635335481245,
                    0.24163524820577817,
                    0.2423341430567439,
                    0.24303303790770958,
                    0.2437319327586753,
                    0.24443082760964102,
                    0.2451297224606067,
                    0.24582861731157243,
                    0.24652751216253815,
                    0.24722640701350385,
                    0.24792530186446957,
                    0.24862419671543529,
                    0.24932309156640098,
                    0.2500219864173667,
                    0.2507208812683324,
                    0.2514197761192981,
                    0.25211867097026386,
                    0.25281756582122955,
                    0.25351646067219524
                  ],
                  "y": [
                    0.006289308176100629,
                    0.006289308176100629,
                    0.006289308176100629,
                    0.006289308176100629,
                    0.006289308176100629,
                    0.006289308176100629,
                    0.006289308176100629,
                    0.006289308176100629,
                    0.006289308176100629,
                    0.006289308176100629,
                    0.006289308176100629,
                    0.006289308176100629,
                    0.006289308176100629,
                    0.006289308176100629,
                    0.006289308176100629,
                    0.006289308176100629,
                    0.006289308176100629,
                    0.012578616352201259,
                    0.012578616352201259,
                    0.012578616352201259,
                    0.012578616352201259,
                    0.012578616352201259,
                    0.012578616352201259,
                    0.012578616352201259,
                    0.012578616352201259,
                    0.018867924528301886,
                    0.018867924528301886,
                    0.018867924528301886,
                    0.018867924528301886,
                    0.018867924528301886,
                    0.018867924528301886,
                    0.025157232704402517,
                    0.025157232704402517,
                    0.025157232704402517,
                    0.025157232704402517,
                    0.025157232704402517,
                    0.03773584905660377,
                    0.03773584905660377,
                    0.03773584905660377,
                    0.03773584905660377,
                    0.050314465408805034,
                    0.050314465408805034,
                    0.06289308176100629,
                    0.06918238993710692,
                    0.11949685534591195,
                    0.1320754716981132,
                    0.1509433962264151,
                    0.18238993710691823,
                    0.2138364779874214,
                    0.27044025157232704,
                    0.33962264150943394,
                    0.36477987421383645,
                    0.389937106918239,
                    0.44025157232704404,
                    0.48427672955974843,
                    0.5408805031446541,
                    0.610062893081761,
                    0.6352201257861635,
                    0.6666666666666666,
                    0.7232704402515723,
                    0.7547169811320755,
                    0.7672955974842768,
                    0.7861635220125787,
                    0.8238993710691824,
                    0.8616352201257862,
                    0.8805031446540881,
                    0.8867924528301887,
                    0.8930817610062893,
                    0.9056603773584906,
                    0.9182389937106918,
                    0.9371069182389937,
                    0.9433962264150944,
                    0.9622641509433962,
                    0.9874213836477987,
                    0.9874213836477987,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1,
                    1
                  ]
                },
                {
                  "mode": "lines",
                  "name": "goss-cat",
                  "type": "scatter",
                  "x": [
                    0.18432587042658996,
                    0.18502476527755568,
                    0.18572366012852137,
                    0.1864225549794871,
                    0.1871214498304528,
                    0.1878203446814185,
                    0.18851923953238423,
                    0.18921813438334992,
                    0.18991702923431564,
                    0.19061592408528136,
                    0.19131481893624705,
                    0.19201371378721277,
                    0.1927126086381785,
                    0.19341150348914418,
                    0.1941103983401099,
                    0.19480929319107562,
                    0.19550818804204131,
                    0.19620708289300703,
                    0.19690597774397273,
                    0.19760487259493845,
                    0.19830376744590417,
                    0.19900266229686986,
                    0.19970155714783558,
                    0.2004004519988013,
                    0.201099346849767,
                    0.2017982417007327,
                    0.20249713655169843,
                    0.20319603140266412,
                    0.20389492625362984,
                    0.20459382110459556,
                    0.20529271595556126,
                    0.20599161080652698,
                    0.20669050565749267,
                    0.2073894005084584,
                    0.2080882953594241,
                    0.2087871902103898,
                    0.20948608506135552,
                    0.2101849799123212,
                    0.21088387476328693,
                    0.21158276961425265,
                    0.21228166446521834,
                    0.21298055931618406,
                    0.21367945416714978,
                    0.21437834901811548,
                    0.2150772438690812,
                    0.21577613872004692,
                    0.2164750335710126,
                    0.21717392842197833,
                    0.21787282327294405,
                    0.21857171812390974,
                    0.21927061297487546,
                    0.21996950782584118,
                    0.22066840267680687,
                    0.2213672975277726,
                    0.22206619237873831,
                    0.222765087229704,
                    0.22346398208066973,
                    0.22416287693163542,
                    0.22486177178260114,
                    0.22556066663356683,
                    0.22625956148453255,
                    0.22695845633549827,
                    0.22765735118646396,
                    0.22835624603742968,
                    0.2290551408883954,
                    0.2297540357393611,
                    0.23045293059032682,
                    0.23115182544129254,
                    0.23185072029225823,
                    0.23254961514322395,
                    0.23324850999418967,
                    0.23394740484515536,
                    0.23464629969612108,
                    0.2353451945470868,
                    0.2360440893980525,
                    0.2367429842490182,
                    0.23744187909998393,
                    0.23814077395094962,
                    0.23883966880191534,
                    0.23953856365288104,
                    0.24023745850384676,
                    0.24093635335481245,
                    0.24163524820577817,
                    0.2423341430567439,
                    0.24303303790770958,
                    0.2437319327586753,
                    0.24443082760964102,
                    0.2451297224606067,
                    0.24582861731157243,
                    0.24652751216253815,
                    0.24722640701350385,
                    0.24792530186446957,
                    0.24862419671543529,
                    0.24932309156640098,
                    0.2500219864173667,
                    0.2507208812683324,
                    0.2514197761192981,
                    0.25211867097026386,
                    0.25281756582122955,
                    0.25351646067219524
                  ],
                  "y": [
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0,
                    0.005813953488372093,
                    0.005813953488372093,
                    0.005813953488372093,
                    0.005813953488372093,
                    0.005813953488372093,
                    0.005813953488372093,
                    0.005813953488372093,
                    0.005813953488372093,
                    0.005813953488372093,
                    0.005813953488372093,
                    0.011627906976744186,
                    0.011627906976744186,
                    0.011627906976744186,
                    0.011627906976744186,
                    0.011627906976744186,
                    0.011627906976744186,
                    0.011627906976744186,
                    0.011627906976744186,
                    0.01744186046511628,
                    0.023255813953488372,
                    0.023255813953488372,
                    0.023255813953488372,
                    0.023255813953488372,
                    0.023255813953488372,
                    0.023255813953488372,
                    0.029069767441860465,
                    0.029069767441860465,
                    0.029069767441860465,
                    0.029069767441860465,
                    0.03488372093023256,
                    0.03488372093023256,
                    0.046511627906976744,
                    0.046511627906976744,
                    0.05813953488372093,
                    0.06976744186046512,
                    0.09302325581395349,
                    0.10465116279069768,
                    0.11046511627906977,
                    0.11627906976744186,
                    0.12209302325581395,
                    0.13372093023255813,
                    0.14534883720930233,
                    0.1511627906976744,
                    0.1511627906976744,
                    0.1511627906976744,
                    0.1569767441860465,
                    0.1686046511627907,
                    0.19767441860465115,
                    0.22674418604651161,
                    0.2616279069767442,
                    0.27906976744186046,
                    0.31976744186046513,
                    0.3488372093023256,
                    0.38372093023255816,
                    0.436046511627907,
                    0.46511627906976744,
                    0.5290697674418605,
                    0.5581395348837209,
                    0.5930232558139535,
                    0.6627906976744186,
                    0.6976744186046512,
                    0.7267441860465116,
                    0.7558139534883721,
                    0.7965116279069767,
                    0.8081395348837209,
                    0.8372093023255814,
                    0.872093023255814,
                    0.8837209302325582,
                    0.8895348837209303,
                    0.8895348837209303,
                    0.9011627906976745,
                    0.9418604651162791,
                    0.9534883720930233,
                    0.9534883720930233,
                    0.9709302325581395,
                    0.9767441860465116,
                    0.9767441860465116,
                    0.9825581395348837,
                    0.9825581395348837,
                    0.9883720930232558,
                    0.9883720930232558,
                    0.9883720930232558,
                    0.9883720930232558,
                    0.9883720930232558,
                    0.9941860465116279,
                    0.9941860465116279,
                    0.9941860465116279,
                    1
                  ]
                }
              ],
              "layout": {
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "heatmapgl": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmapgl"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                },
                "title": {
                  "text": "Empirical Distribution Function Plot"
                },
                "xaxis": {
                  "title": {
                    "text": "Objective Value"
                  }
                },
                "yaxis": {
                  "range": [
                    0,
                    1
                  ],
                  "title": {
                    "text": "Cumulative Probability"
                  }
                }
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "opt.visualization.plot_edf(list(lgb_study.values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "cliponaxis": false,
                  "hovertemplate": [
                    "booster (CategoricalDistribution): 0.0<extra></extra>",
                    "lambda_l2 (LogUniformDistribution): 0.004131105621980473<extra></extra>",
                    "lambda_l1 (LogUniformDistribution): 0.00456791333814768<extra></extra>",
                    "cat_smooth (LogUniformDistribution): 0.009437680074281434<extra></extra>",
                    "max_cat_threshold (IntUniformDistribution): 0.01448373020394374<extra></extra>",
                    "bagging_freq (IntUniformDistribution): 0.015474060651871945<extra></extra>",
                    "neg_bagging_fraction (UniformDistribution): 0.01620067148873719<extra></extra>",
                    "max_bin (IntUniformDistribution): 0.021791746602051396<extra></extra>",
                    "min_split_gain (LogUniformDistribution): 0.02755261105122519<extra></extra>",
                    "max_depth (IntUniformDistribution): 0.02830761363229281<extra></extra>",
                    "min_data_in_leaf (IntUniformDistribution): 0.028602388489757373<extra></extra>",
                    "pos_bagging_fraction (UniformDistribution): 0.028666828736472715<extra></extra>",
                    "min_data_per_group (IntUniformDistribution): 0.030142915452044727<extra></extra>",
                    "min_child_weight (IntUniformDistribution): 0.032655758240784746<extra></extra>",
                    "num_leaves (IntUniformDistribution): 0.04235179934079292<extra></extra>",
                    "cat_l2 (LogUniformDistribution): 0.049830438060585014<extra></extra>",
                    "feature_fraction (UniformDistribution): 0.31711698874433186<extra></extra>",
                    "eta (UniformDistribution): 0.3286857502706988<extra></extra>"
                  ],
                  "marker": {
                    "color": "rgb(66,146,198)"
                  },
                  "orientation": "h",
                  "text": [
                    "0.0",
                    "0.004131105621980473",
                    "0.00456791333814768",
                    "0.009437680074281434",
                    "0.01448373020394374",
                    "0.015474060651871945",
                    "0.01620067148873719",
                    "0.021791746602051396",
                    "0.02755261105122519",
                    "0.02830761363229281",
                    "0.028602388489757373",
                    "0.028666828736472715",
                    "0.030142915452044727",
                    "0.032655758240784746",
                    "0.04235179934079292",
                    "0.049830438060585014",
                    "0.31711698874433186",
                    "0.3286857502706988"
                  ],
                  "textposition": "outside",
                  "texttemplate": "%{text:.2f}",
                  "type": "bar",
                  "x": [
                    0,
                    0.004131105621980473,
                    0.00456791333814768,
                    0.009437680074281434,
                    0.01448373020394374,
                    0.015474060651871945,
                    0.01620067148873719,
                    0.021791746602051396,
                    0.02755261105122519,
                    0.02830761363229281,
                    0.028602388489757373,
                    0.028666828736472715,
                    0.030142915452044727,
                    0.032655758240784746,
                    0.04235179934079292,
                    0.049830438060585014,
                    0.31711698874433186,
                    0.3286857502706988
                  ],
                  "y": [
                    "booster",
                    "lambda_l2",
                    "lambda_l1",
                    "cat_smooth",
                    "max_cat_threshold",
                    "bagging_freq",
                    "neg_bagging_fraction",
                    "max_bin",
                    "min_split_gain",
                    "max_depth",
                    "min_data_in_leaf",
                    "pos_bagging_fraction",
                    "min_data_per_group",
                    "min_child_weight",
                    "num_leaves",
                    "cat_l2",
                    "feature_fraction",
                    "eta"
                  ]
                }
              ],
              "layout": {
                "showlegend": false,
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "heatmapgl": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmapgl"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                },
                "title": {
                  "text": "Hyperparameter Importances"
                },
                "xaxis": {
                  "title": {
                    "text": "Importance for Objective Value"
                  }
                },
                "yaxis": {
                  "title": {
                    "text": "Hyperparameter"
                  }
                }
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "opt.visualization.plot_param_importances(lgb_study.get(boosters[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "dimensions": [
                    {
                      "label": "Objective Value",
                      "range": [
                        0.19888805382418956,
                        0.2354243080384983
                      ],
                      "values": [
                        0.19888805382418956,
                        0.20047569992077774,
                        0.20910185756296046,
                        0.22165194968520385,
                        0.20970582024004153,
                        0.20863535973025496,
                        0.205976042590228,
                        0.20072255938848146,
                        0.2103079845706956,
                        0.2082985236682758,
                        0.21432517239424106,
                        0.21878117433376693,
                        0.2171693482536861,
                        0.21744984150524466,
                        0.21223280984567508,
                        0.20701355958284187,
                        0.2124105635259939,
                        0.21972758597118455,
                        0.2115279512436663,
                        0.2206719340465987,
                        0.2136362753770463,
                        0.21504335218917753,
                        0.219367839636719,
                        0.21917870795179634,
                        0.2099963135598782,
                        0.21926905086157428,
                        0.21706161173331057,
                        0.22025535374120073,
                        0.22105592330869378,
                        0.2173713170067751,
                        0.21254599780388825,
                        0.21480241419196652,
                        0.21594933153827361,
                        0.21785422628097742,
                        0.21974227932369578,
                        0.21274360169405634,
                        0.23314606567455867,
                        0.2192691433693866,
                        0.21854547144728062,
                        0.21377048461040146,
                        0.21231545457583656,
                        0.21887410402252386,
                        0.21284436224085082,
                        0.21425871851356298,
                        0.21844640583975203,
                        0.21845549212461385,
                        0.22272155286404435,
                        0.2225100289438891,
                        0.2197372150192915,
                        0.2285882480344056,
                        0.2194083599945341,
                        0.22545448474364949,
                        0.2178789103116569,
                        0.22255595776964582,
                        0.21983167400169473,
                        0.2206255952537568,
                        0.2259114551939681,
                        0.22365116298472398,
                        0.2232476706747813,
                        0.22894540347169273,
                        0.21675187803904522,
                        0.21957476825069247,
                        0.2278646342582419,
                        0.21940233805299977,
                        0.22219866961511364,
                        0.22231879935074422,
                        0.22520719713550513,
                        0.22028065792862903,
                        0.22273779782394346,
                        0.2256436475251682,
                        0.21465205360605882,
                        0.2240640457565551,
                        0.21643501555704575,
                        0.22118252962649287,
                        0.21557410259449755,
                        0.2191717129962579,
                        0.2199342033441925,
                        0.22327581810790212,
                        0.22610994938283943,
                        0.2194953451323268,
                        0.22536110405144086,
                        0.2269258806198457,
                        0.2225469710499784,
                        0.22439513690754592,
                        0.2251968093636263,
                        0.21892491394620697,
                        0.21899534438087712,
                        0.2183193014291162,
                        0.22542895876437136,
                        0.23152049915846246,
                        0.2237970224051163,
                        0.2206845190111905,
                        0.21839216906937806,
                        0.22127277204793963,
                        0.23067532309960379,
                        0.2174017090545512,
                        0.23367174900617624,
                        0.22763072024138684,
                        0.22713827451790009,
                        0.22759824939539527,
                        0.22948493785167515,
                        0.2257929136719123,
                        0.2264516346460796,
                        0.21773180506881268,
                        0.22353217206589054,
                        0.22229253103025104,
                        0.22477455544499322,
                        0.22360552729287703,
                        0.22345027167342674,
                        0.22496800377207804,
                        0.21807878478825157,
                        0.22488788531533524,
                        0.2193430925950625,
                        0.2257406607535481,
                        0.22866092788175552,
                        0.22757211024013255,
                        0.2186433522154036,
                        0.22759589639051298,
                        0.23228023262772504,
                        0.22457417094223162,
                        0.22300294591381736,
                        0.22095556719543813,
                        0.21793276504562545,
                        0.22491583928229325,
                        0.2267351287658333,
                        0.22295099509959598,
                        0.218973927658516,
                        0.22261392364072,
                        0.23132508389565426,
                        0.21837467814044825,
                        0.22891527098872158,
                        0.23047209370615757,
                        0.22625374212884686,
                        0.22322070118176113,
                        0.2245906481976566,
                        0.2249146747264104,
                        0.22945358233210045,
                        0.22371852394603792,
                        0.22346884107091292,
                        0.223961262887281,
                        0.223734579459415,
                        0.22576745370130555,
                        0.22786977988957163,
                        0.22258749154909094,
                        0.2217642213271664,
                        0.22259346232066396,
                        0.22801331830049792,
                        0.22444358402071923,
                        0.22801604062148018,
                        0.2181848612078116,
                        0.22940172795364155,
                        0.22605456243319338,
                        0.2354243080384983,
                        0.2204803739656675,
                        0.22978889493403423
                      ]
                    },
                    {
                      "label": "bagging_freq",
                      "range": [
                        1,
                        16
                      ],
                      "values": [
                        11,
                        9,
                        2,
                        5,
                        7,
                        4,
                        8,
                        6,
                        8,
                        13,
                        16,
                        1,
                        1,
                        7,
                        2,
                        14,
                        5,
                        11,
                        3,
                        1,
                        2,
                        3,
                        6,
                        11,
                        3,
                        6,
                        6,
                        6,
                        11,
                        4,
                        10,
                        1,
                        1,
                        1,
                        1,
                        13,
                        2,
                        2,
                        6,
                        6,
                        6,
                        6,
                        7,
                        1,
                        11,
                        11,
                        1,
                        1,
                        1,
                        6,
                        7,
                        7,
                        7,
                        2,
                        1,
                        2,
                        1,
                        2,
                        1,
                        1,
                        1,
                        1,
                        2,
                        2,
                        2,
                        2,
                        2,
                        2,
                        2,
                        15,
                        2,
                        2,
                        2,
                        2,
                        3,
                        3,
                        2,
                        2,
                        2,
                        3,
                        3,
                        15,
                        2,
                        2,
                        2,
                        2,
                        2,
                        14,
                        2,
                        2,
                        2,
                        3,
                        3,
                        2,
                        2,
                        1,
                        2,
                        9,
                        2,
                        2,
                        2,
                        2,
                        2,
                        4,
                        2,
                        2,
                        2,
                        3,
                        3,
                        15,
                        3,
                        2,
                        9,
                        9,
                        2,
                        13,
                        2,
                        2,
                        15,
                        15,
                        9,
                        15,
                        1,
                        1,
                        2,
                        2,
                        2,
                        2,
                        15,
                        8,
                        2,
                        2,
                        9,
                        2,
                        2,
                        16,
                        16,
                        3,
                        1,
                        2,
                        2,
                        2,
                        16,
                        16,
                        16,
                        16,
                        16,
                        16,
                        16,
                        2,
                        2,
                        2,
                        2,
                        3,
                        4
                      ]
                    },
                    {
                      "label": "booster",
                      "range": [
                        0,
                        0
                      ],
                      "ticktext": [
                        "gbdt"
                      ],
                      "tickvals": [
                        0
                      ],
                      "values": [
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0
                      ]
                    },
                    {
                      "label": "cat_l2",
                      "range": [
                        -2.9972441862630568,
                        -1.000164066865862
                      ],
                      "ticktext": [
                        "0.00101",
                        "0.01",
                        "0.1"
                      ],
                      "tickvals": [
                        -2.9972441862630568,
                        -2,
                        -1.000164066865862
                      ],
                      "values": [
                        -1.369041238810118,
                        -1.500146160407524,
                        -2.567244826987588,
                        -1.3372974799721538,
                        -2.9670371235479327,
                        -1.5953591502612088,
                        -2.9080897541583344,
                        -1.2619961175843033,
                        -2.058796295876863,
                        -2.0291886164033386,
                        -1.9678132394865824,
                        -1.0044529376636264,
                        -1.0486387595797602,
                        -1.0277917912554795,
                        -2.94609060930213,
                        -1.7516451433918476,
                        -2.6707771834946374,
                        -2.736470319111475,
                        -1.3592762802756153,
                        -1.3803828224229577,
                        -1.192520417702182,
                        -1.0030589066423081,
                        -1.1482507759088383,
                        -1.155784738846589,
                        -1.4304904727567886,
                        -1.4453218296396904,
                        -1.6051419027112441,
                        -1.5262403029357716,
                        -1.2606136069730058,
                        -1.4389940749985246,
                        -1.6332113461272717,
                        -1.0815082129602984,
                        -1.0928390196812479,
                        -1.2174048928593788,
                        -1.227346585751482,
                        -1.1954753291716091,
                        -1.3571773459302463,
                        -1.377735573834337,
                        -1.0424636606569282,
                        -1.304434299329697,
                        -2.9972441862630568,
                        -1.23281097458499,
                        -1.3312280149372715,
                        -2.5739265270926053,
                        -1.3343537220193564,
                        -1.3378815356866958,
                        -1.0536215643714384,
                        -1.0554875902942171,
                        -1.2489556388949488,
                        -1.244221886581481,
                        -1.0665624150778208,
                        -1.056455273433997,
                        -1.2552275809260582,
                        -1.1725831300323,
                        -1.2834482312623723,
                        -1.4725571647610876,
                        -1.2373825152226963,
                        -1.1998840250183305,
                        -1.0655462540382379,
                        -1.0756179200519145,
                        -1.2836009277848268,
                        -1.1238444613906178,
                        -1.0244447904300558,
                        -1.2502646087675182,
                        -1.0240302561977952,
                        -1.2559752424218047,
                        -1.2600614593612836,
                        -1.2610722959380376,
                        -1.2565874325456368,
                        -1.3672582837823728,
                        -1.235909323133397,
                        -1.2507696329329188,
                        -1.233500831089157,
                        -1.2190953738782118,
                        -1.082255257552329,
                        -1.0878041978683868,
                        -1.0949779400520583,
                        -1.0867705803443353,
                        -1.195846547912992,
                        -1.1681383528742728,
                        -1.002191924529469,
                        -1.3251620513110807,
                        -1.0020557487588948,
                        -1.2742592673025899,
                        -1.2747589418590306,
                        -1.271531337262126,
                        -1.0037677662049052,
                        -1.0043132886089348,
                        -1.0003242944091464,
                        -1.1265264937503408,
                        -1.1254660873924311,
                        -1.001041658274556,
                        -1.0609352191288277,
                        -1.1349907152380785,
                        -1.147964601377288,
                        -1.2016691299428264,
                        -1.03993655510403,
                        -1.312300151862217,
                        -2.1647216971220815,
                        -1.297063315278807,
                        -1.176691343618921,
                        -1.000164066865862,
                        -1.7499667755550303,
                        -1.7681644795075298,
                        -2.0921836754875547,
                        -2.0601629367715337,
                        -2.054967662120598,
                        -1.3310976545319342,
                        -1.3198428976216738,
                        -1.3254289384633955,
                        -2.2256392162413148,
                        -2.3689280721788926,
                        -1.8290859501027885,
                        -2.045330932157249,
                        -2.2167904821667177,
                        -2.620040916440114,
                        -2.431358841187525,
                        -2.6455278227232313,
                        -2.453823810230058,
                        -2.3310609119699364,
                        -2.9518525166254244,
                        -2.638101332980255,
                        -1.9002977381947612,
                        -1.0016070800210959,
                        -2.096320610754681,
                        -2.1005524093028853,
                        -2.77367088362717,
                        -2.0448612698740103,
                        -2.043150599361566,
                        -2.0711893471718277,
                        -2.045696033784449,
                        -2.192534904322048,
                        -2.476133113944549,
                        -2.224323632985374,
                        -2.4877167467689554,
                        -2.315856488941922,
                        -2.486134755445589,
                        -2.1483579240478985,
                        -2.170150117308968,
                        -1.959220540097815,
                        -2.5917172772094625,
                        -2.0134326125278763,
                        -2.420431345496672,
                        -2.5052433585398624,
                        -1.1520245570132315,
                        -2.465608893633425,
                        -2.4934410022995586,
                        -2.397717184571211,
                        -2.2024605259344585,
                        -2.3650038634267476,
                        -2.204327064388223,
                        -2.4120107358353544,
                        -2.3503781169967914,
                        -2.3083081585657212,
                        -2.440825271072437
                      ]
                    },
                    {
                      "label": "cat_smooth",
                      "range": [
                        -1.9771606256585021,
                        0.9999031977696683
                      ],
                      "ticktext": [
                        "0.0105",
                        "0.1",
                        "1",
                        "10"
                      ],
                      "tickvals": [
                        -1.9771606256585021,
                        -1,
                        0,
                        0.9999031977696683
                      ],
                      "values": [
                        -0.1751630066495506,
                        -0.40057346751201584,
                        -1.205131609449183,
                        -0.7613074659221996,
                        0.7136906978063912,
                        -1.8692362023885496,
                        0.3389476749268739,
                        -0.05521312833576292,
                        -1.6807091597153636,
                        0.25198939629161854,
                        0.9998189658683577,
                        -1.0290529837563949,
                        -0.9244162901877732,
                        -0.7039740957893619,
                        -0.7117488606367084,
                        -0.5481423351081369,
                        0.16245115606596788,
                        0.18906480660316946,
                        0.23744047994271877,
                        -1.4655351945318293,
                        -0.31727468836525236,
                        -0.7883568963193444,
                        -1.1447442432109214,
                        -0.5203859709421199,
                        -1.4396111531254943,
                        -1.4321016088039162,
                        -1.4693434878171816,
                        -1.3500131320563868,
                        -0.458456940392282,
                        -1.6054960059378258,
                        -1.6720746604880816,
                        -1.0955207765230675,
                        -1.0400007660621757,
                        -1.032405941465198,
                        -1.0529196832140042,
                        -1.0884192211822947,
                        -0.8495861163575296,
                        -0.8059250749150426,
                        -0.26512225750604645,
                        -1.4289235253036807,
                        -1.1642127005184102,
                        0.3439305390881841,
                        -0.27302385170067267,
                        -0.8762904834326282,
                        -0.5262897497900636,
                        -0.13650712318673688,
                        0.2155702048589599,
                        -0.8570188130936804,
                        0.39669044384367347,
                        0.12282855435740805,
                        0.8570758778933969,
                        0.28200926853634306,
                        -0.37509967121075993,
                        0.2710599211912167,
                        0.5016268591178713,
                        0.25529961708960364,
                        0.9116449108810218,
                        0.7778726953846204,
                        0.13970399337358314,
                        0.9109217640791617,
                        0.7328177788697935,
                        0.7422738012477238,
                        0.20999022549273835,
                        0.48046702331573343,
                        0.3458239118662442,
                        0.3478108216880181,
                        0.3442116706612901,
                        0.4646785471854161,
                        0.05944897119621797,
                        0.30726568794193265,
                        0.31938634203199334,
                        0.3758135670208579,
                        0.3323459821153272,
                        0.348975202563775,
                        0.16086502483433038,
                        0.16433297658940602,
                        0.13133184779310803,
                        0.1643299352999079,
                        0.2822468088297486,
                        0.2743667867881413,
                        0.284723421123364,
                        0.26253490965738885,
                        0.28698518182786953,
                        0.3584378740683852,
                        0.44612318289923925,
                        0.3894065800563577,
                        0.20284956558160877,
                        0.3172247163409111,
                        0.20989783965475392,
                        0.2250826728350452,
                        0.205196432558177,
                        0.18880194295792205,
                        0.9824595776695432,
                        0.17603408060906242,
                        0.08191126436383939,
                        0.2586162404424764,
                        0.11559775049603828,
                        0.8107718439986491,
                        0.3088544291910209,
                        0.22136233481792997,
                        0.22763057984831883,
                        0.23203194874357666,
                        -0.06437707560509026,
                        0.7783367598962524,
                        0.8363516608476371,
                        0.09331813236519015,
                        0.826982018247466,
                        0.7823658650119383,
                        0.8746980045802534,
                        0.3741003019348707,
                        0.3522351980958164,
                        0.33163396759931585,
                        0.3188026202706618,
                        -0.17553182734139886,
                        0.26353459046069827,
                        0.2521794340310471,
                        0.25505378336585516,
                        0.2720758507173689,
                        -0.05577170861905398,
                        -0.19680873320064335,
                        -0.04359034796136584,
                        0.1625351288884882,
                        0.09273711540043786,
                        0.9455093247292918,
                        0.30822450143007696,
                        0.2990320380632,
                        0.3091414307159601,
                        -0.6112302557061428,
                        0.2128331554778906,
                        -0.6331872267687875,
                        0.0354829104316596,
                        0.040859394955504544,
                        -0.09006546942287262,
                        0.03966168285729818,
                        0.02894499040870094,
                        -0.06631030487127004,
                        0.06721978768759702,
                        -0.059201444742643924,
                        0.1264910090775603,
                        0.14094615191805263,
                        0.1506195193291089,
                        0.07190389976126878,
                        0.05153406918262403,
                        0.05662457754082424,
                        0.9999031977696683,
                        -0.017560531481213254,
                        0.6868903040246619,
                        -0.0060662417332460195,
                        0.24546262338869793,
                        -0.19448506870447246,
                        0.1938030755833465,
                        0.18905657386844751,
                        -1.8815573046648584,
                        -1.9771606256585021,
                        -1.3216002909668516
                      ]
                    },
                    {
                      "label": "eta",
                      "range": [
                        0.0064254669818258996,
                        0.18049840193681446
                      ],
                      "values": [
                        0.1536083419219755,
                        0.0064254669818258996,
                        0.049341403752650385,
                        0.05060334701856248,
                        0.07853247743862907,
                        0.14771675112335117,
                        0.12049376924563349,
                        0.18049840193681446,
                        0.037060089647682544,
                        0.08230825300106884,
                        0.07741419856264338,
                        0.060887295376960665,
                        0.05860290868060306,
                        0.05392965063793336,
                        0.05590591170077409,
                        0.027971729776060536,
                        0.07807920748733926,
                        0.032543899515703044,
                        0.03539796695922504,
                        0.058000449935832504,
                        0.017893606136193237,
                        0.03727795264270525,
                        0.008862125658751809,
                        0.03849186865443496,
                        0.009975922297479574,
                        0.028588205354055485,
                        0.026826624226054772,
                        0.02441877272317829,
                        0.06848017093176181,
                        0.01843608925414706,
                        0.018967275862722077,
                        0.06247255987730225,
                        0.06132501800221414,
                        0.05337319381633017,
                        0.05394033694988215,
                        0.12488710759893848,
                        0.03873601537636003,
                        0.04132624618807466,
                        0.029254897573987172,
                        0.02918466747750877,
                        0.08220936524164846,
                        0.04208742802273957,
                        0.0651496455297331,
                        0.034966559848438994,
                        0.04306135550924602,
                        0.042592337739565105,
                        0.05743351887118081,
                        0.05740350260289521,
                        0.04046944992657865,
                        0.015950734928616414,
                        0.05803427586689378,
                        0.025548629830097543,
                        0.04837737754085847,
                        0.051218296329828085,
                        0.061918738185164184,
                        0.05406851724849384,
                        0.013009761666989177,
                        0.06261039464043441,
                        0.06343746633176972,
                        0.05958544337113844,
                        0.05435442477242567,
                        0.06841024630008222,
                        0.02155585692689732,
                        0.024905894854587378,
                        0.020620807979195906,
                        0.022008752711289874,
                        0.02176520857041561,
                        0.022119600889578685,
                        0.02430249777150339,
                        0.04614117932520974,
                        0.021080814284362658,
                        0.02138099676670524,
                        0.01955421765173111,
                        0.022344316837910314,
                        0.01714440516286252,
                        0.01844552238612198,
                        0.025512530673924994,
                        0.02565939787447798,
                        0.011449266286943089,
                        0.012659544282932176,
                        0.012274409246241553,
                        0.011957946430358463,
                        0.013885686542477297,
                        0.021029270828276676,
                        0.02075306622825366,
                        0.012725611930028292,
                        0.011626821652733533,
                        0.013775852602189482,
                        0.014461196560940984,
                        0.017358631764369525,
                        0.020141652422275207,
                        0.010262935915110393,
                        0.010545095327814988,
                        0.010811765646646723,
                        0.030161895985869734,
                        0.024067015254248814,
                        0.01927898980848923,
                        0.018194972692920724,
                        0.027550143056533805,
                        0.0232757076281207,
                        0.021838178972508383,
                        0.012394432624238262,
                        0.014000687233267951,
                        0.03605048980512252,
                        0.03491009413665039,
                        0.03284776724383888,
                        0.03475879871786579,
                        0.02140011537302495,
                        0.02160843747119946,
                        0.021310301436378035,
                        0.021179223702954608,
                        0.016892211005596226,
                        0.03128000896693074,
                        0.029684643670473028,
                        0.015892102606812737,
                        0.016155073305546754,
                        0.0157553244244199,
                        0.015432387048873628,
                        0.011825007594107954,
                        0.010282327435628876,
                        0.0125024354327861,
                        0.015897419190691247,
                        0.024225244475973844,
                        0.023887851823330027,
                        0.017670118556136455,
                        0.017549434814279914,
                        0.01825259745519665,
                        0.029042864789790228,
                        0.02943046504800684,
                        0.03341942645612512,
                        0.027891292128050894,
                        0.015212618412121534,
                        0.015508835328565942,
                        0.02022664417377068,
                        0.009684962460145241,
                        0.01582045645148292,
                        0.015212839206792086,
                        0.015310532099203128,
                        0.015541927650579828,
                        0.022751853188048447,
                        0.021121731628905863,
                        0.026077577073666102,
                        0.025395298112489036,
                        0.02580023624909557,
                        0.02648976731310557,
                        0.03311147605738989,
                        0.03356480907024846,
                        0.032972942961201596,
                        0.03774086775191207,
                        0.01895162887576871,
                        0.01887173444444191,
                        0.018134224380611186,
                        0.0183808254625467,
                        0.02670155724176173,
                        0.03152576806857356
                      ]
                    },
                    {
                      "label": "feature_fraction",
                      "range": [
                        0.9053342225197529,
                        0.9996440939751365
                      ],
                      "values": [
                        0.9240870466623126,
                        0.9112667608080904,
                        0.9624347799070285,
                        0.9405368527942464,
                        0.9903360610794585,
                        0.9053342225197529,
                        0.9380231743418843,
                        0.9264786006748952,
                        0.9570301158733999,
                        0.9807752853480781,
                        0.9958765731943061,
                        0.9619191008586309,
                        0.9618274027662276,
                        0.9523007217766438,
                        0.950779098018684,
                        0.9408602979704592,
                        0.9590154945105193,
                        0.9719114265948433,
                        0.9741686317344246,
                        0.9681622623157861,
                        0.9710628241239023,
                        0.9674917003903455,
                        0.96579288549062,
                        0.9678199584775479,
                        0.9463629483885071,
                        0.9465611377657064,
                        0.9479824857304704,
                        0.9483260519202564,
                        0.9780729485235669,
                        0.9404630824616789,
                        0.9590400977821041,
                        0.9542769501030826,
                        0.9699700148456549,
                        0.9531729849590129,
                        0.970398275574767,
                        0.9644089392020362,
                        0.9449478576811305,
                        0.9444652113449483,
                        0.9655953083704251,
                        0.9724510338556819,
                        0.9519498059840835,
                        0.9571401302360831,
                        0.967100148694027,
                        0.967717944937053,
                        0.967736113519117,
                        0.9473054545342274,
                        0.9759734041955122,
                        0.9625959464998758,
                        0.948503558261893,
                        0.9650401335956037,
                        0.9396145239453351,
                        0.9651957856734174,
                        0.9475035218951181,
                        0.9713864523854915,
                        0.9712979006903888,
                        0.9724761166553487,
                        0.9778595618896396,
                        0.9816651651986121,
                        0.9755600936640726,
                        0.973297577566865,
                        0.9854221346730144,
                        0.9788646879998976,
                        0.9723832504992049,
                        0.9732151042281315,
                        0.9737554063886559,
                        0.9701186400287506,
                        0.9691568574363963,
                        0.9699455157735736,
                        0.9732911739005969,
                        0.969049702154585,
                        0.9692091777241273,
                        0.9693802876979933,
                        0.9692055874051132,
                        0.9689864892864977,
                        0.968372215821383,
                        0.976922642046612,
                        0.9731433616220085,
                        0.972508627643226,
                        0.9723215869449797,
                        0.9724352807324841,
                        0.9726289114401988,
                        0.973566172685921,
                        0.9717500809909886,
                        0.9709352799771133,
                        0.9698857543834785,
                        0.9704288434891518,
                        0.9746650578698081,
                        0.9747192133386436,
                        0.9755454798924458,
                        0.9670638418197497,
                        0.9742221529124735,
                        0.9723559139581369,
                        0.9720424525866562,
                        0.9729248726709956,
                        0.9681547054407039,
                        0.9667659866454679,
                        0.9789251959732035,
                        0.9705118647765266,
                        0.9705517371450557,
                        0.9825493388217182,
                        0.9821931718956419,
                        0.9749168042832986,
                        0.978562891668534,
                        0.9824206234786437,
                        0.9776481235007659,
                        0.9837813688807293,
                        0.97857159944988,
                        0.9842995656798251,
                        0.9887605630472807,
                        0.966408839329607,
                        0.9846670909246955,
                        0.9657901793140016,
                        0.9808273434300907,
                        0.9812713343109032,
                        0.9796412193151028,
                        0.9794714546373108,
                        0.9665687302500249,
                        0.9800480596752962,
                        0.9634712460085971,
                        0.9633887231947633,
                        0.9801151050260077,
                        0.9767945877370366,
                        0.9687076620882579,
                        0.9687856250547072,
                        0.9814833880043932,
                        0.9728391426171844,
                        0.9726300799633142,
                        0.9840249515370221,
                        0.9830388289697051,
                        0.9814863384605859,
                        0.981086285389019,
                        0.9814936817619839,
                        0.9785300523011968,
                        0.9900573980407686,
                        0.9791163030128058,
                        0.9821719785982171,
                        0.9850833025381361,
                        0.986053931306381,
                        0.9813198604933294,
                        0.9774121885699559,
                        0.9776633597402604,
                        0.9423873975648439,
                        0.984148834537416,
                        0.987752520140082,
                        0.9831294342469213,
                        0.9864213035835829,
                        0.985904418743301,
                        0.9911583294335571,
                        0.9865229658827374,
                        0.9818798146845265,
                        0.9704428793893956,
                        0.9380690001978843,
                        0.9977078598628034,
                        0.9996440939751365,
                        0.9700230480437197
                      ]
                    },
                    {
                      "label": "lambda_l1",
                      "range": [
                        -1.9969321560739888,
                        -0.0168275962777265
                      ],
                      "ticktext": [
                        "0.0101",
                        "0.1",
                        "0.962"
                      ],
                      "tickvals": [
                        -1.9969321560739888,
                        -1,
                        -0.0168275962777265
                      ],
                      "values": [
                        -1.9582281806659783,
                        -0.8248491310956446,
                        -1.454224063407643,
                        -0.5839904670379366,
                        -0.908052259679128,
                        -0.6117503384176031,
                        -1.1436951385278316,
                        -0.8126417825907162,
                        -0.6390923369868481,
                        -0.6859162887966943,
                        -0.08361771188158193,
                        -1.4905934990494598,
                        -1.5346222732133652,
                        -1.5050888759262266,
                        -0.39632041918307515,
                        -0.37825130787702843,
                        -0.09208593724142398,
                        -0.018766125462104332,
                        -1.9743591859659633,
                        -1.9822085223849037,
                        -1.942969998650373,
                        -1.9969321560739888,
                        -1.6987872650805331,
                        -1.7151183668158558,
                        -1.982861386319762,
                        -0.7639116081089637,
                        -1.1033848120259102,
                        -0.8030539969597494,
                        -0.77829885530571,
                        -0.5833117900075021,
                        -0.5943370313051564,
                        -0.9275789579870688,
                        -0.8704319416216528,
                        -0.19731840118767202,
                        -0.23682540371289149,
                        -1.0718918808957958,
                        -0.0952999798954919,
                        -0.0168275962777265,
                        -0.293204083832708,
                        -0.33033805340191663,
                        -0.4270731586138089,
                        -0.43385937457537094,
                        -1.7708538561296057,
                        -0.19231863830612048,
                        -1.0111706067762136,
                        -0.7777661287175749,
                        -0.7221307793170902,
                        -0.2618503142051211,
                        -1.0107137066220822,
                        -1.5656586047488155,
                        -1.575183874740079,
                        -0.8609791392890259,
                        -0.8595079172829238,
                        -0.7068946569556497,
                        -0.6385307978847768,
                        -0.5282466399433783,
                        -0.6275583629512373,
                        -0.6518731587694507,
                        -0.6311391556305137,
                        -0.6441324926092733,
                        -0.7018932244623589,
                        -0.5227049025808802,
                        -0.7029470233720561,
                        -0.6853807481757456,
                        -0.6679652830603812,
                        -0.7759143336501557,
                        -0.9630280618986632,
                        -0.7840486566063952,
                        -0.7580240972235153,
                        -0.74994489532232,
                        -0.6599542442884079,
                        -0.6633120836946204,
                        -0.9015782706572187,
                        -0.9499027922628583,
                        -0.6636465753312447,
                        -0.7564663581783155,
                        -0.7469324420663574,
                        -0.7409321677020881,
                        -1.074203288863817,
                        -0.6995295097199419,
                        -1.089927616040096,
                        -0.7107653899968503,
                        -0.6732106628036538,
                        -0.7778428020579651,
                        -0.7729231951392537,
                        -1.045093104929641,
                        -0.9885870434382276,
                        -0.7527701597736561,
                        -0.7598789591779811,
                        -0.7131756586680932,
                        -0.9778705109027828,
                        -1.1582009684139525,
                        -1.1279307876397753,
                        -1.0562426194224794,
                        -0.793081073468662,
                        -1.0390184511955278,
                        -0.6015914249803779,
                        -0.6156275870868557,
                        -0.6216673911430212,
                        -0.6151301131184468,
                        -0.6719712324827705,
                        -0.729957009077353,
                        -0.7193878762585699,
                        -0.5610022900243646,
                        -0.5678607446004962,
                        -0.5622381545508565,
                        -0.5699161543298098,
                        -0.610230528462863,
                        -0.6391811056574263,
                        -0.6789040755176166,
                        -0.8325628859532149,
                        -0.837233642941706,
                        -0.6768336998775755,
                        -0.6355215497049013,
                        -0.7864242717484355,
                        -0.8213436784508303,
                        -0.7879364557326269,
                        -0.776948137070751,
                        -0.7146376222309724,
                        -0.6961789315144776,
                        -0.8207623742622113,
                        -0.627375546796359,
                        -0.7709723578861939,
                        -0.7821896214408887,
                        -0.7751714231104104,
                        -0.5878952206315448,
                        -0.5999835920217046,
                        -0.7091657187991246,
                        -1.640671846406944,
                        -0.8523450101776897,
                        -0.7692492442766028,
                        -0.8565833639465299,
                        -0.7529184541229734,
                        -0.6682338884637521,
                        -1.6353405328259025,
                        -1.7352189105269005,
                        -0.8363233719967261,
                        -1.861080844119627,
                        -0.7882778276728132,
                        -0.8260988712255402,
                        -0.8327855733342776,
                        -0.7303474665699615,
                        -0.8432826310044513,
                        -0.850754577346596,
                        -0.8515517817257441,
                        -0.6538734125976972,
                        -0.9356666559507896,
                        -0.8472952773048978,
                        -0.8089696223286298,
                        -1.9515522215725984,
                        -0.41953137175188676,
                        -0.6882899564634484,
                        -1.3027161642033143,
                        -0.2998534551252979,
                        -0.2865135235296715
                      ]
                    },
                    {
                      "label": "lambda_l2",
                      "range": [
                        -2.9909834953281487,
                        0.5596955524967226
                      ],
                      "ticktext": [
                        "0.00102",
                        "0.01",
                        "0.1",
                        "1",
                        "3.63"
                      ],
                      "tickvals": [
                        -2.9909834953281487,
                        -2,
                        -1,
                        0,
                        0.5596955524967226
                      ],
                      "values": [
                        0.13771151959024502,
                        -2.7427188504943656,
                        0.5596955524967226,
                        -1.905070994601991,
                        -1.7055900288359593,
                        -0.47534091003854845,
                        -0.6261803662718799,
                        -1.5676569197029844,
                        -1.5107611898116404,
                        0.27665994280090217,
                        -2.002479777798327,
                        -1.8687843344771082,
                        -1.8692031074904911,
                        -2.9869895498731585,
                        -2.941256254099102,
                        -2.9706730956393455,
                        -1.3670002839675315,
                        -2.6209099290397555,
                        -1.781782549780245,
                        -2.4466449200952853,
                        -2.6787299143066208,
                        -2.464888764895025,
                        -2.3978815697726805,
                        -2.491162154614378,
                        -2.7830694896154613,
                        -2.206160431271273,
                        -2.7833655943801063,
                        -2.2187234136667833,
                        -2.8220258303151633,
                        -2.0257419162386685,
                        -2.040941757886679,
                        -2.571097700070173,
                        -2.553821390523544,
                        -2.347497474659174,
                        -2.3432648127267943,
                        -2.3304335632330564,
                        -2.304457754172338,
                        -1.9109418225228234,
                        -2.891516748592367,
                        -1.9198115278101393,
                        -2.157543273852154,
                        -0.6066136095541961,
                        -2.979839450532814,
                        -2.407159600912781,
                        -1.627631640073693,
                        -2.900111479952069,
                        -2.7504219448184704,
                        -2.723287599028341,
                        -0.7167700155796152,
                        -2.305182715677058,
                        -1.1204174336293915,
                        -2.364445949000413,
                        -1.4583090952367481,
                        -2.6177786370205194,
                        -2.0795737916193433,
                        -2.606871892200031,
                        -2.581579775642565,
                        -2.7181320575446795,
                        -2.6913747074525096,
                        -2.6856834650161203,
                        -2.379181786892952,
                        -2.332795514639988,
                        -2.421506261688079,
                        -2.325817741469703,
                        -2.6564313382277054,
                        -2.4354411757700025,
                        -2.640492657459402,
                        -2.2362766587809286,
                        -2.674758215951638,
                        -2.206524017047476,
                        -2.1968166704085874,
                        -2.2012670759383,
                        -2.1903601192393616,
                        -2.4651210532559196,
                        -2.6522217999893125,
                        -2.660157325571514,
                        -2.7462752880622063,
                        -2.745995020719756,
                        -2.5718312777156775,
                        -2.578828454563109,
                        -2.5584029684380396,
                        -2.5921051040919294,
                        -2.5925587000600876,
                        -2.2711777339864323,
                        -2.282551365089802,
                        -2.3024791539972043,
                        -2.524178078642458,
                        -2.4970874268571257,
                        -2.734072049808675,
                        -2.6809181981978947,
                        -2.5455818380255693,
                        -2.5747580258752025,
                        -2.5529925182110813,
                        -2.571223375381162,
                        -2.4412055662274312,
                        -2.408876763002495,
                        -2.9121602498586787,
                        -2.6697118273500977,
                        -2.154974895463011,
                        -2.6624049459672374,
                        -2.7275411434357473,
                        -2.737899435486204,
                        -2.9909834953281487,
                        -2.9724344587626175,
                        -2.187666460772283,
                        -2.1848162172370813,
                        -2.2094579651915645,
                        -2.3102233011215434,
                        -2.273733078499426,
                        -2.5003931836162034,
                        -2.4992944275139606,
                        -2.512710597990008,
                        -2.358673669732527,
                        -2.0063825744309836,
                        -2.458829520900113,
                        -2.4348869124695116,
                        -2.466079228336539,
                        -2.44383377402341,
                        -2.443749832854984,
                        -2.4447419463546476,
                        -2.9055478510254877,
                        -2.357480029012163,
                        -2.680226564555645,
                        -2.657042499622385,
                        -2.48844701381089,
                        -2.455105881544497,
                        -2.841282545355318,
                        -2.83404331225187,
                        -2.3188670205254045,
                        -2.3327573789719214,
                        -2.418459352983092,
                        -2.390988457921055,
                        -2.2549450527465664,
                        -2.1182650282897106,
                        -2.4343474826417495,
                        -2.4397482236731385,
                        -2.430284917112806,
                        -2.511728205254816,
                        -2.6202466696391253,
                        -2.2669541133294073,
                        -2.2600975278858493,
                        -2.269394412020018,
                        -2.2849776229775016,
                        -2.263738012002583,
                        -2.3947745946261945,
                        -2.537666445971629,
                        -2.3407369767505393,
                        -0.9307761591882041,
                        -2.3271096356429224,
                        -2.216519638862388,
                        -2.440575642153143,
                        -2.3536815484441407,
                        -2.3494124295211583,
                        -2.335526502641918,
                        -2.163972926623368
                      ]
                    },
                    {
                      "label": "max_bin",
                      "range": [
                        20,
                        180
                      ],
                      "values": [
                        119,
                        70,
                        172,
                        23,
                        33,
                        97,
                        57,
                        49,
                        101,
                        180,
                        25,
                        23,
                        25,
                        25,
                        29,
                        36,
                        68,
                        117,
                        20,
                        20,
                        63,
                        61,
                        132,
                        124,
                        156,
                        150,
                        106,
                        108,
                        122,
                        144,
                        165,
                        115,
                        137,
                        136,
                        136,
                        40,
                        24,
                        79,
                        77,
                        109,
                        130,
                        109,
                        30,
                        132,
                        93,
                        92,
                        22,
                        20,
                        20,
                        21,
                        99,
                        140,
                        65,
                        98,
                        25,
                        24,
                        112,
                        25,
                        25,
                        24,
                        29,
                        29,
                        24,
                        23,
                        25,
                        24,
                        24,
                        113,
                        112,
                        44,
                        20,
                        21,
                        20,
                        25,
                        24,
                        112,
                        113,
                        24,
                        24,
                        23,
                        24,
                        24,
                        24,
                        23,
                        24,
                        23,
                        23,
                        20,
                        23,
                        24,
                        20,
                        23,
                        50,
                        23,
                        59,
                        35,
                        24,
                        24,
                        24,
                        24,
                        24,
                        57,
                        25,
                        26,
                        59,
                        60,
                        43,
                        62,
                        71,
                        23,
                        31,
                        54,
                        45,
                        38,
                        54,
                        56,
                        55,
                        43,
                        43,
                        45,
                        46,
                        40,
                        39,
                        23,
                        84,
                        20,
                        23,
                        67,
                        59,
                        82,
                        83,
                        89,
                        52,
                        42,
                        74,
                        59,
                        79,
                        84,
                        59,
                        58,
                        53,
                        51,
                        85,
                        80,
                        88,
                        79,
                        82,
                        88,
                        25,
                        23,
                        24,
                        85,
                        70,
                        73,
                        20
                      ]
                    },
                    {
                      "label": "max_cat_threshold",
                      "range": [
                        6,
                        50
                      ],
                      "values": [
                        8,
                        19,
                        30,
                        35,
                        26,
                        11,
                        11,
                        35,
                        43,
                        40,
                        47,
                        26,
                        28,
                        28,
                        50,
                        50,
                        25,
                        41,
                        18,
                        18,
                        19,
                        16,
                        18,
                        39,
                        17,
                        15,
                        38,
                        38,
                        37,
                        13,
                        13,
                        37,
                        37,
                        37,
                        37,
                        33,
                        41,
                        40,
                        20,
                        40,
                        36,
                        6,
                        23,
                        38,
                        44,
                        16,
                        18,
                        18,
                        38,
                        11,
                        18,
                        34,
                        18,
                        18,
                        41,
                        44,
                        18,
                        44,
                        44,
                        44,
                        47,
                        47,
                        43,
                        43,
                        41,
                        41,
                        43,
                        41,
                        41,
                        41,
                        41,
                        41,
                        41,
                        42,
                        45,
                        43,
                        42,
                        42,
                        43,
                        43,
                        40,
                        40,
                        40,
                        40,
                        41,
                        46,
                        40,
                        41,
                        41,
                        41,
                        41,
                        41,
                        40,
                        43,
                        43,
                        39,
                        12,
                        24,
                        40,
                        19,
                        45,
                        38,
                        11,
                        38,
                        38,
                        38,
                        38,
                        10,
                        12,
                        40,
                        14,
                        13,
                        26,
                        25,
                        38,
                        13,
                        14,
                        11,
                        25,
                        11,
                        31,
                        21,
                        10,
                        45,
                        11,
                        23,
                        32,
                        12,
                        14,
                        14,
                        14,
                        10,
                        10,
                        44,
                        9,
                        16,
                        16,
                        13,
                        14,
                        14,
                        13,
                        9,
                        18,
                        17,
                        17,
                        10,
                        13,
                        13,
                        10,
                        44,
                        44,
                        43,
                        19,
                        18,
                        22
                      ]
                    },
                    {
                      "label": "max_depth",
                      "range": [
                        4,
                        15
                      ],
                      "values": [
                        10,
                        9,
                        5,
                        9,
                        7,
                        4,
                        11,
                        13,
                        15,
                        5,
                        7,
                        7,
                        7,
                        7,
                        12,
                        12,
                        9,
                        11,
                        6,
                        6,
                        6,
                        10,
                        11,
                        11,
                        5,
                        5,
                        5,
                        5,
                        13,
                        4,
                        14,
                        6,
                        6,
                        6,
                        6,
                        11,
                        8,
                        7,
                        10,
                        10,
                        5,
                        12,
                        12,
                        9,
                        11,
                        11,
                        11,
                        11,
                        13,
                        6,
                        7,
                        7,
                        11,
                        11,
                        12,
                        13,
                        13,
                        13,
                        13,
                        14,
                        13,
                        13,
                        15,
                        15,
                        12,
                        12,
                        12,
                        12,
                        15,
                        12,
                        12,
                        6,
                        12,
                        12,
                        15,
                        15,
                        15,
                        15,
                        15,
                        11,
                        14,
                        11,
                        14,
                        12,
                        12,
                        12,
                        12,
                        12,
                        15,
                        15,
                        15,
                        14,
                        14,
                        15,
                        15,
                        14,
                        11,
                        11,
                        14,
                        14,
                        14,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        14,
                        14,
                        14,
                        14,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        14,
                        14,
                        8,
                        14,
                        14,
                        14,
                        6,
                        13,
                        6,
                        6,
                        6,
                        15,
                        15,
                        15,
                        11,
                        10,
                        5,
                        15,
                        15,
                        15,
                        6,
                        6,
                        6,
                        10,
                        15,
                        15,
                        15,
                        15,
                        15,
                        15,
                        15,
                        11,
                        5,
                        14,
                        5,
                        5,
                        8
                      ]
                    },
                    {
                      "label": "min_child_weight",
                      "range": [
                        6,
                        40
                      ],
                      "values": [
                        19,
                        36,
                        12,
                        29,
                        7,
                        24,
                        20,
                        27,
                        6,
                        39,
                        31,
                        9,
                        9,
                        11,
                        13,
                        31,
                        35,
                        16,
                        17,
                        17,
                        16,
                        16,
                        23,
                        22,
                        18,
                        13,
                        13,
                        14,
                        19,
                        24,
                        18,
                        7,
                        8,
                        8,
                        9,
                        38,
                        11,
                        12,
                        23,
                        23,
                        6,
                        9,
                        33,
                        33,
                        21,
                        22,
                        25,
                        10,
                        16,
                        19,
                        27,
                        19,
                        20,
                        29,
                        18,
                        17,
                        29,
                        17,
                        17,
                        31,
                        18,
                        19,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        15,
                        16,
                        16,
                        28,
                        16,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        18,
                        17,
                        17,
                        17,
                        19,
                        17,
                        20,
                        16,
                        19,
                        16,
                        17,
                        19,
                        16,
                        18,
                        18,
                        19,
                        17,
                        17,
                        17,
                        14,
                        17,
                        16,
                        14,
                        16,
                        14,
                        16,
                        40,
                        18,
                        18,
                        18,
                        15,
                        14,
                        17,
                        17,
                        18,
                        20,
                        18,
                        12,
                        16,
                        16,
                        11,
                        21,
                        14,
                        14,
                        18,
                        14,
                        14,
                        16,
                        15,
                        16,
                        16,
                        19,
                        15,
                        16,
                        16,
                        16,
                        13,
                        14,
                        14,
                        18,
                        17,
                        17,
                        17,
                        17,
                        17,
                        16,
                        16,
                        6,
                        10,
                        15,
                        15,
                        10,
                        16
                      ]
                    },
                    {
                      "label": "min_data_in_leaf",
                      "range": [
                        2,
                        88
                      ],
                      "values": [
                        3,
                        88,
                        10,
                        2,
                        26,
                        39,
                        37,
                        56,
                        11,
                        42,
                        64,
                        17,
                        4,
                        22,
                        24,
                        72,
                        54,
                        31,
                        13,
                        19,
                        17,
                        31,
                        32,
                        31,
                        21,
                        29,
                        29,
                        38,
                        36,
                        34,
                        34,
                        20,
                        20,
                        19,
                        19,
                        6,
                        24,
                        23,
                        28,
                        28,
                        32,
                        32,
                        17,
                        22,
                        82,
                        30,
                        34,
                        25,
                        30,
                        22,
                        35,
                        35,
                        35,
                        33,
                        26,
                        33,
                        24,
                        27,
                        27,
                        33,
                        23,
                        25,
                        31,
                        18,
                        31,
                        19,
                        19,
                        27,
                        31,
                        27,
                        33,
                        15,
                        15,
                        15,
                        16,
                        31,
                        31,
                        31,
                        22,
                        22,
                        22,
                        22,
                        23,
                        27,
                        28,
                        34,
                        28,
                        18,
                        28,
                        28,
                        28,
                        27,
                        26,
                        26,
                        22,
                        22,
                        32,
                        24,
                        23,
                        24,
                        21,
                        35,
                        32,
                        20,
                        35,
                        20,
                        20,
                        20,
                        17,
                        17,
                        17,
                        22,
                        17,
                        22,
                        22,
                        22,
                        22,
                        22,
                        22,
                        22,
                        24,
                        52,
                        42,
                        27,
                        30,
                        19,
                        33,
                        29,
                        29,
                        47,
                        29,
                        35,
                        32,
                        36,
                        33,
                        31,
                        31,
                        31,
                        26,
                        38,
                        18,
                        24,
                        29,
                        29,
                        26,
                        34,
                        29,
                        33,
                        28,
                        30,
                        16,
                        16,
                        16,
                        13,
                        14
                      ]
                    },
                    {
                      "label": "min_data_per_group",
                      "range": [
                        5,
                        200
                      ],
                      "values": [
                        165,
                        11,
                        156,
                        170,
                        187,
                        113,
                        68,
                        138,
                        54,
                        52,
                        200,
                        198,
                        199,
                        199,
                        197,
                        173,
                        199,
                        170,
                        175,
                        172,
                        170,
                        162,
                        161,
                        106,
                        144,
                        105,
                        183,
                        144,
                        183,
                        125,
                        154,
                        143,
                        158,
                        167,
                        191,
                        178,
                        187,
                        186,
                        97,
                        63,
                        119,
                        151,
                        166,
                        172,
                        188,
                        190,
                        195,
                        197,
                        181,
                        81,
                        156,
                        154,
                        82,
                        180,
                        179,
                        177,
                        149,
                        177,
                        176,
                        176,
                        184,
                        181,
                        170,
                        169,
                        170,
                        169,
                        169,
                        170,
                        169,
                        177,
                        171,
                        172,
                        167,
                        168,
                        165,
                        162,
                        164,
                        160,
                        166,
                        165,
                        174,
                        173,
                        175,
                        169,
                        169,
                        167,
                        157,
                        173,
                        158,
                        46,
                        173,
                        174,
                        173,
                        179,
                        19,
                        35,
                        165,
                        164,
                        48,
                        30,
                        66,
                        172,
                        171,
                        49,
                        45,
                        19,
                        45,
                        30,
                        29,
                        5,
                        19,
                        40,
                        52,
                        5,
                        44,
                        40,
                        51,
                        50,
                        5,
                        48,
                        5,
                        12,
                        19,
                        163,
                        45,
                        47,
                        23,
                        37,
                        39,
                        45,
                        17,
                        42,
                        76,
                        75,
                        76,
                        26,
                        81,
                        42,
                        31,
                        46,
                        31,
                        46,
                        81,
                        86,
                        57,
                        81,
                        80,
                        73,
                        67,
                        50,
                        50,
                        51,
                        17,
                        24,
                        15
                      ]
                    },
                    {
                      "label": "min_split_gain",
                      "range": [
                        -2.6274076933819814,
                        -0.007346704299238945
                      ],
                      "ticktext": [
                        "0.00236",
                        "0.01",
                        "0.1",
                        "0.983"
                      ],
                      "tickvals": [
                        -2.6274076933819814,
                        -2,
                        -1,
                        -0.007346704299238945
                      ],
                      "values": [
                        -1.9450658267805176,
                        -2.514748276800334,
                        -1.6573488621591785,
                        -1.6268495298442829,
                        -0.5715242081107696,
                        -1.811819097641842,
                        -0.2958733514805712,
                        -0.5795769109557355,
                        -0.11546259932047809,
                        -1.4590139303689598,
                        -1.0268525962576467,
                        -1.1389359951952305,
                        -1.2270573971187395,
                        -1.1213359215829555,
                        -0.007346704299238945,
                        -0.02848858735995191,
                        -0.9337517252033859,
                        -0.9126952566417266,
                        -1.1275597706020482,
                        -1.7211766800814254,
                        -1.5335490941342205,
                        -1.3352216383379925,
                        -1.409334244556053,
                        -1.401045409792868,
                        -1.7730628148969938,
                        -2.478645426999453,
                        -2.563107451422672,
                        -1.956048777192066,
                        -1.3973330297576465,
                        -2.6274076933819814,
                        -2.302951745671047,
                        -1.271503332695988,
                        -1.2629191535497362,
                        -1.0718252742668308,
                        -0.8436567902044927,
                        -1.2607714322047074,
                        -1.5717395172320174,
                        -0.6027497546277115,
                        -1.741644431139826,
                        -2.0260895852356353,
                        -1.1533029936223813,
                        -0.8531040299209016,
                        -1.127610780667013,
                        -1.7210966630194255,
                        -1.858504155937566,
                        -1.7164320983190575,
                        -1.7421696719134208,
                        -1.7395996475343263,
                        -0.7426218488119375,
                        -1.6115552661082668,
                        -1.6234824305505002,
                        -1.6282509674785446,
                        -1.634191804455244,
                        -1.5945095898894126,
                        -2.2150769243462203,
                        -2.2024322960284315,
                        -1.9392567854035168,
                        -2.2418047265451584,
                        -2.108393573245763,
                        -1.79826003877897,
                        -2.0926629148529976,
                        -1.9831476063071634,
                        -1.902407689855017,
                        -1.9015245158392213,
                        -1.909028816718914,
                        -1.801955030262163,
                        -1.6663131729310798,
                        -1.6808663781316844,
                        -2.0638630392342616,
                        -1.7443744553584317,
                        -1.583351154257143,
                        -1.6628283313241314,
                        -1.6884293056824329,
                        -1.6790474431723579,
                        -1.6229688787695054,
                        -1.6614771167768303,
                        -1.6572377978552506,
                        -1.6588852570850305,
                        -1.6101761269204284,
                        -1.6330823692961347,
                        -1.6329567558011377,
                        -1.632781598602968,
                        -1.5152404213015906,
                        -1.534786014756207,
                        -1.6425350733367712,
                        -1.6079953452338682,
                        -1.7144311349626693,
                        -1.4433067505758352,
                        -1.4513724476859922,
                        -1.7217630904181767,
                        -1.7050104914159978,
                        -1.6413532318664008,
                        -1.939496436973591,
                        -1.929038409708696,
                        -1.5638659548010596,
                        -1.4929516255797683,
                        -1.5230360019928448,
                        -1.6812102795539106,
                        -1.68724275516659,
                        -1.6582776453450554,
                        -1.699570730748797,
                        -1.5767448635117207,
                        -1.598198079531955,
                        -1.6161477310348877,
                        -2.04186430387344,
                        -1.5689188398631595,
                        -2.026593368552404,
                        -1.7190207735232725,
                        -1.702345004381971,
                        -1.5572593366312601,
                        -1.6319923846584066,
                        -1.6466507949903757,
                        -1.6400211473985662,
                        -1.641341317821442,
                        -1.5005298170602703,
                        -1.4997026171900447,
                        -1.6065043855853487,
                        -1.5891477879436706,
                        -1.7720725610970278,
                        -1.7701975826822822,
                        -1.527006006404441,
                        -1.8691951101370456,
                        -0.1829019777847067,
                        -1.5262797761452302,
                        -1.9010859901654689,
                        -1.6240779530925895,
                        -1.7523695235949115,
                        -1.92380474211477,
                        -1.9374859725116036,
                        -1.7729582179331989,
                        -1.9601509430681803,
                        -1.771881449611617,
                        -1.5206976178514326,
                        -1.558390133258784,
                        -2.0226554968138273,
                        -1.8670825343287394,
                        -1.8801080962197638,
                        -1.8986927299276504,
                        -1.8196870060397967,
                        -1.5300509845157868,
                        -1.3918096791684171,
                        -1.5973246111021762,
                        -1.7403528004555595,
                        -1.7475993495508244,
                        -1.947342485416287,
                        -1.663279972395279,
                        -1.641114863784954,
                        -1.4749981881999328,
                        -1.809995238178085,
                        -1.802554680992807,
                        -1.8004291712114728,
                        -1.7342252656632389,
                        -1.7491808516275895,
                        -1.75754612574063,
                        -1.6724970110670998
                      ]
                    },
                    {
                      "label": "neg_bagging_fract...",
                      "range": [
                        0.5054795359106322,
                        0.6969480646897743
                      ],
                      "values": [
                        0.5546386085258754,
                        0.688862426624121,
                        0.5785897893387217,
                        0.5766378600667106,
                        0.6224450911687968,
                        0.6572198379553307,
                        0.6106292806968148,
                        0.6787589106242584,
                        0.6468260395915408,
                        0.5129716816654502,
                        0.5220170196441285,
                        0.561678717819255,
                        0.5671465158683087,
                        0.5751483453882975,
                        0.6223947610141592,
                        0.5054795359106322,
                        0.5889668593468954,
                        0.587283782463565,
                        0.5875730888184244,
                        0.5540809095444067,
                        0.5871109094725316,
                        0.5844916436046106,
                        0.5872317666299102,
                        0.5820571801220444,
                        0.601725492044594,
                        0.5457624633611085,
                        0.5459875011734009,
                        0.5750413233854301,
                        0.5434734667687927,
                        0.5146531002819444,
                        0.5645993862196917,
                        0.6060764206637659,
                        0.5806058965889452,
                        0.5765831253819401,
                        0.578098186742546,
                        0.6091165555966126,
                        0.5707815370271244,
                        0.5725945435166336,
                        0.5550622035151859,
                        0.6658016024153626,
                        0.5414229602494923,
                        0.5301610481488476,
                        0.5763622178874892,
                        0.5930168742222556,
                        0.5518254703040577,
                        0.5493250446933311,
                        0.5611032792214977,
                        0.5596884786750759,
                        0.5212640080611619,
                        0.5813947213889258,
                        0.5811589833504348,
                        0.5809061178326798,
                        0.5738589232702549,
                        0.5743789207712343,
                        0.5092308426560134,
                        0.5876719408311274,
                        0.5744973793440606,
                        0.5769488982081331,
                        0.568642726478373,
                        0.5695317165926366,
                        0.576651579973359,
                        0.5768868070811818,
                        0.5632168437746368,
                        0.5635024901515739,
                        0.5842375858908258,
                        0.5846977029518928,
                        0.5882468605834885,
                        0.5886556784533975,
                        0.5589681619288058,
                        0.5814591746714243,
                        0.5897147342739827,
                        0.5878134226154045,
                        0.5876144694767687,
                        0.5893579383517977,
                        0.5888812207775524,
                        0.5849063866455111,
                        0.5730816876504682,
                        0.5730304438805003,
                        0.596953902036653,
                        0.5957249934012898,
                        0.5642626739047394,
                        0.6464617471930786,
                        0.5947021478027795,
                        0.5790711403602324,
                        0.5808134352970901,
                        0.5802810579780736,
                        0.6969480646897743,
                        0.5601449317763075,
                        0.5797255777431898,
                        0.624194395776504,
                        0.5685887580762179,
                        0.5742165570760177,
                        0.5754686778298644,
                        0.6928315971764202,
                        0.6501722227007061,
                        0.6583553145972391,
                        0.5788012671443259,
                        0.6781959489539188,
                        0.5740390498206912,
                        0.5719095034869239,
                        0.5678420034703979,
                        0.5601691878348395,
                        0.5852738531623902,
                        0.5817044589838682,
                        0.5772471595548114,
                        0.5831804736558013,
                        0.645775893958049,
                        0.6852187720520513,
                        0.6624979651485375,
                        0.6805629255388127,
                        0.6745686893931483,
                        0.6384904578947609,
                        0.6437649248009999,
                        0.6408556566123983,
                        0.6492989552590801,
                        0.6547630114160921,
                        0.6435445966739616,
                        0.6362924881705352,
                        0.6491336038237804,
                        0.650861984143467,
                        0.6528032461920762,
                        0.6567540451377231,
                        0.571672019889763,
                        0.5709020199787067,
                        0.57978275558266,
                        0.561703180780653,
                        0.6245516160531565,
                        0.5847653106923911,
                        0.5837758223717225,
                        0.577903488858533,
                        0.5759592436119139,
                        0.578294917316242,
                        0.6710954919570145,
                        0.6751753048721436,
                        0.6773360026357816,
                        0.6037019592589323,
                        0.670003672704765,
                        0.5697059546093701,
                        0.6559954183303056,
                        0.5697397306813151,
                        0.5688922949788815,
                        0.5767522497923093,
                        0.6656743730480054,
                        0.6704519300340943,
                        0.6683226556956106,
                        0.6704658360587974,
                        0.674728798308787,
                        0.6527835807043656,
                        0.6484178596487263,
                        0.6531927006540472,
                        0.6543592215897469,
                        0.6546597334023951,
                        0.6537563652258032,
                        0.6519740178882587,
                        0.6598967928334412
                      ]
                    },
                    {
                      "label": "num_leaves",
                      "range": [
                        20,
                        120
                      ],
                      "values": [
                        116,
                        52,
                        62,
                        55,
                        79,
                        60,
                        89,
                        76,
                        51,
                        21,
                        24,
                        23,
                        28,
                        45,
                        40,
                        38,
                        94,
                        31,
                        31,
                        30,
                        32,
                        49,
                        51,
                        51,
                        61,
                        20,
                        20,
                        21,
                        54,
                        27,
                        43,
                        39,
                        23,
                        22,
                        23,
                        75,
                        50,
                        50,
                        120,
                        58,
                        46,
                        46,
                        46,
                        47,
                        37,
                        51,
                        89,
                        80,
                        48,
                        44,
                        28,
                        28,
                        49,
                        120,
                        66,
                        89,
                        81,
                        87,
                        87,
                        88,
                        82,
                        83,
                        71,
                        88,
                        67,
                        96,
                        88,
                        97,
                        88,
                        102,
                        97,
                        101,
                        95,
                        96,
                        102,
                        95,
                        70,
                        70,
                        100,
                        86,
                        106,
                        86,
                        91,
                        100,
                        91,
                        101,
                        62,
                        100,
                        68,
                        75,
                        73,
                        105,
                        105,
                        73,
                        76,
                        81,
                        111,
                        89,
                        76,
                        77,
                        90,
                        71,
                        102,
                        71,
                        70,
                        71,
                        75,
                        75,
                        76,
                        110,
                        104,
                        109,
                        103,
                        99,
                        104,
                        109,
                        40,
                        65,
                        114,
                        116,
                        68,
                        73,
                        72,
                        73,
                        83,
                        83,
                        104,
                        78,
                        80,
                        81,
                        80,
                        60,
                        77,
                        75,
                        76,
                        81,
                        85,
                        81,
                        80,
                        86,
                        86,
                        83,
                        85,
                        84,
                        84,
                        88,
                        112,
                        89,
                        112,
                        112,
                        56,
                        78,
                        78,
                        58,
                        56
                      ]
                    },
                    {
                      "label": "pos_bagging_fract...",
                      "range": [
                        0.8160837715464894,
                        0.9998896495435086
                      ],
                      "values": [
                        0.8177286760176368,
                        0.9998896495435086,
                        0.849493575323464,
                        0.922692650184147,
                        0.9477320172884489,
                        0.9163316851033451,
                        0.9514742046470188,
                        0.8160837715464894,
                        0.9778352917852264,
                        0.9681244480905621,
                        0.9346922449207113,
                        0.8687167713464565,
                        0.8718046093567172,
                        0.8915652961516405,
                        0.8508692213329014,
                        0.9139628488747517,
                        0.9488121698425803,
                        0.8997638329306848,
                        0.8953519996279169,
                        0.8917913880629829,
                        0.8985671406227188,
                        0.891455460532587,
                        0.8938715981820959,
                        0.895090350583964,
                        0.9103345935642214,
                        0.8853212425484009,
                        0.8834037185461106,
                        0.9222546574882287,
                        0.8867640407022651,
                        0.920347519786458,
                        0.8824814218521869,
                        0.8705099047212955,
                        0.9127334081376663,
                        0.8700620284875487,
                        0.9293534854867298,
                        0.9137761834503207,
                        0.9626071469686686,
                        0.9399068198704819,
                        0.8940298261912494,
                        0.8944038336305483,
                        0.9265435945527749,
                        0.9018135391679503,
                        0.8899785987706073,
                        0.9818446288732433,
                        0.9000517781046128,
                        0.9063987358137005,
                        0.9480132754388861,
                        0.9488190408704968,
                        0.9022260560782812,
                        0.8892456152163803,
                        0.896965363711158,
                        0.8946934700888568,
                        0.8971014723811787,
                        0.9626744932746568,
                        0.9453244739434866,
                        0.9432622670580062,
                        0.9484590705042224,
                        0.9435567560813118,
                        0.9542580766941746,
                        0.9431509962001191,
                        0.9364906316980468,
                        0.9507367010285491,
                        0.9337210224286088,
                        0.9357787548050895,
                        0.9302759396356447,
                        0.9311021023617045,
                        0.9310795011701207,
                        0.9306394828717998,
                        0.9655524911610331,
                        0.9309744866248278,
                        0.9650091275833435,
                        0.9325631737546806,
                        0.9313276581028765,
                        0.9289533127078033,
                        0.9663128258987486,
                        0.9233103075036676,
                        0.9238265043041819,
                        0.9239953769697352,
                        0.9718052912817915,
                        0.946763201907154,
                        0.9455911214313965,
                        0.945945340191786,
                        0.9459931685890571,
                        0.9275670170337365,
                        0.9313376356610353,
                        0.9755290898544802,
                        0.9371535096784116,
                        0.9361934215649778,
                        0.9290081906184271,
                        0.9366395534143076,
                        0.917295690716401,
                        0.9367174762559012,
                        0.9404317522340591,
                        0.9385249942985986,
                        0.9538580307883358,
                        0.9484283546019319,
                        0.9456420827122044,
                        0.9594037404582961,
                        0.9293524023826756,
                        0.9697113012290173,
                        0.9289989023422708,
                        0.9302743814053382,
                        0.9279859975222228,
                        0.9293843590597434,
                        0.9295202930546116,
                        0.9282332413311871,
                        0.9273049238060068,
                        0.9343867803781348,
                        0.9803141121337595,
                        0.9345722439026883,
                        0.9148499454749626,
                        0.9359168487425483,
                        0.9726600080033593,
                        0.9327687384885066,
                        0.9728005596589308,
                        0.9224015123615376,
                        0.9278534483823053,
                        0.9724971453201303,
                        0.9384163794929609,
                        0.9385790075941572,
                        0.957528660640414,
                        0.9527083571373134,
                        0.9645495072212337,
                        0.9659875743051038,
                        0.9328771274503361,
                        0.9333404387884761,
                        0.9827396636945938,
                        0.9275728154566582,
                        0.9283042538114735,
                        0.9355456530674557,
                        0.9361411770096316,
                        0.8868433948579548,
                        0.8860946350052776,
                        0.8771147579035432,
                        0.8792826647796707,
                        0.954900707687774,
                        0.8886130860595404,
                        0.9540307254440632,
                        0.887266170910256,
                        0.9617942950139188,
                        0.9429738542870347,
                        0.9627269389591948,
                        0.8925702676354175,
                        0.8901712919837588,
                        0.8990347764849103,
                        0.882317107778252,
                        0.8976459771423435,
                        0.892553648188568,
                        0.8815546840735441,
                        0.880156788940963,
                        0.9692653550608744,
                        0.9100029091135111,
                        0.9916266126430697,
                        0.9985336221579497,
                        0.9605978755937264
                      ]
                    }
                  ],
                  "labelangle": 30,
                  "labelside": "bottom",
                  "line": {
                    "color": [
                      0.19888805382418956,
                      0.20047569992077774,
                      0.20910185756296046,
                      0.22165194968520385,
                      0.20970582024004153,
                      0.20863535973025496,
                      0.205976042590228,
                      0.20072255938848146,
                      0.2103079845706956,
                      0.2082985236682758,
                      0.21432517239424106,
                      0.21878117433376693,
                      0.2171693482536861,
                      0.21744984150524466,
                      0.21223280984567508,
                      0.20701355958284187,
                      0.2124105635259939,
                      0.21972758597118455,
                      0.2115279512436663,
                      0.2206719340465987,
                      0.2136362753770463,
                      0.21504335218917753,
                      0.219367839636719,
                      0.21917870795179634,
                      0.2099963135598782,
                      0.21926905086157428,
                      0.21706161173331057,
                      0.22025535374120073,
                      0.22105592330869378,
                      0.2173713170067751,
                      0.21254599780388825,
                      0.21480241419196652,
                      0.21594933153827361,
                      0.21785422628097742,
                      0.21974227932369578,
                      0.21274360169405634,
                      0.23314606567455867,
                      0.2192691433693866,
                      0.21854547144728062,
                      0.21377048461040146,
                      0.21231545457583656,
                      0.21887410402252386,
                      0.21284436224085082,
                      0.21425871851356298,
                      0.21844640583975203,
                      0.21845549212461385,
                      0.22272155286404435,
                      0.2225100289438891,
                      0.2197372150192915,
                      0.2285882480344056,
                      0.2194083599945341,
                      0.22545448474364949,
                      0.2178789103116569,
                      0.22255595776964582,
                      0.21983167400169473,
                      0.2206255952537568,
                      0.2259114551939681,
                      0.22365116298472398,
                      0.2232476706747813,
                      0.22894540347169273,
                      0.21675187803904522,
                      0.21957476825069247,
                      0.2278646342582419,
                      0.21940233805299977,
                      0.22219866961511364,
                      0.22231879935074422,
                      0.22520719713550513,
                      0.22028065792862903,
                      0.22273779782394346,
                      0.2256436475251682,
                      0.21465205360605882,
                      0.2240640457565551,
                      0.21643501555704575,
                      0.22118252962649287,
                      0.21557410259449755,
                      0.2191717129962579,
                      0.2199342033441925,
                      0.22327581810790212,
                      0.22610994938283943,
                      0.2194953451323268,
                      0.22536110405144086,
                      0.2269258806198457,
                      0.2225469710499784,
                      0.22439513690754592,
                      0.2251968093636263,
                      0.21892491394620697,
                      0.21899534438087712,
                      0.2183193014291162,
                      0.22542895876437136,
                      0.23152049915846246,
                      0.2237970224051163,
                      0.2206845190111905,
                      0.21839216906937806,
                      0.22127277204793963,
                      0.23067532309960379,
                      0.2174017090545512,
                      0.23367174900617624,
                      0.22763072024138684,
                      0.22713827451790009,
                      0.22759824939539527,
                      0.22948493785167515,
                      0.2257929136719123,
                      0.2264516346460796,
                      0.21773180506881268,
                      0.22353217206589054,
                      0.22229253103025104,
                      0.22477455544499322,
                      0.22360552729287703,
                      0.22345027167342674,
                      0.22496800377207804,
                      0.21807878478825157,
                      0.22488788531533524,
                      0.2193430925950625,
                      0.2257406607535481,
                      0.22866092788175552,
                      0.22757211024013255,
                      0.2186433522154036,
                      0.22759589639051298,
                      0.23228023262772504,
                      0.22457417094223162,
                      0.22300294591381736,
                      0.22095556719543813,
                      0.21793276504562545,
                      0.22491583928229325,
                      0.2267351287658333,
                      0.22295099509959598,
                      0.218973927658516,
                      0.22261392364072,
                      0.23132508389565426,
                      0.21837467814044825,
                      0.22891527098872158,
                      0.23047209370615757,
                      0.22625374212884686,
                      0.22322070118176113,
                      0.2245906481976566,
                      0.2249146747264104,
                      0.22945358233210045,
                      0.22371852394603792,
                      0.22346884107091292,
                      0.223961262887281,
                      0.223734579459415,
                      0.22576745370130555,
                      0.22786977988957163,
                      0.22258749154909094,
                      0.2217642213271664,
                      0.22259346232066396,
                      0.22801331830049792,
                      0.22444358402071923,
                      0.22801604062148018,
                      0.2181848612078116,
                      0.22940172795364155,
                      0.22605456243319338,
                      0.2354243080384983,
                      0.2204803739656675,
                      0.22978889493403423
                    ],
                    "colorbar": {
                      "title": {
                        "text": "Objective Value"
                      }
                    },
                    "colorscale": [
                      [
                        0,
                        "rgb(247,251,255)"
                      ],
                      [
                        0.125,
                        "rgb(222,235,247)"
                      ],
                      [
                        0.25,
                        "rgb(198,219,239)"
                      ],
                      [
                        0.375,
                        "rgb(158,202,225)"
                      ],
                      [
                        0.5,
                        "rgb(107,174,214)"
                      ],
                      [
                        0.625,
                        "rgb(66,146,198)"
                      ],
                      [
                        0.75,
                        "rgb(33,113,181)"
                      ],
                      [
                        0.875,
                        "rgb(8,81,156)"
                      ],
                      [
                        1,
                        "rgb(8,48,107)"
                      ]
                    ],
                    "reversescale": false,
                    "showscale": true
                  },
                  "type": "parcoords"
                }
              ],
              "layout": {
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "heatmapgl": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmapgl"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                },
                "title": {
                  "text": "Parallel Coordinate Plot"
                }
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "opt.visualization.plot_parallel_coordinate(lgb_study.get(boosters[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "cliponaxis": false,
                  "hovertemplate": [
                    "booster (CategoricalDistribution): 0.0<extra></extra>",
                    "neg_bagging_fraction (UniformDistribution): 0.0036319353196422248<extra></extra>",
                    "max_bin (IntUniformDistribution): 0.008713095607648812<extra></extra>",
                    "min_split_gain (LogUniformDistribution): 0.009048116097537905<extra></extra>",
                    "rate_drop (LogUniformDistribution): 0.011276581763516029<extra></extra>",
                    "min_child_weight (IntUniformDistribution): 0.012863117451477295<extra></extra>",
                    "lambda_l1 (LogUniformDistribution): 0.01365419557697191<extra></extra>",
                    "cat_l2 (LogUniformDistribution): 0.015507595967379712<extra></extra>",
                    "cat_smooth (LogUniformDistribution): 0.01717119595059638<extra></extra>",
                    "skip_drop (LogUniformDistribution): 0.021590336930365994<extra></extra>",
                    "max_cat_threshold (IntUniformDistribution): 0.02367906403540362<extra></extra>",
                    "pos_bagging_fraction (UniformDistribution): 0.026357091415098604<extra></extra>",
                    "feature_fraction (UniformDistribution): 0.0355345685319286<extra></extra>",
                    "bagging_freq (IntUniformDistribution): 0.047475817297618274<extra></extra>",
                    "max_drop (IntUniformDistribution): 0.04913279189123012<extra></extra>",
                    "num_leaves (IntUniformDistribution): 0.0553079357246465<extra></extra>",
                    "max_depth (IntUniformDistribution): 0.05812025528694221<extra></extra>",
                    "lambda_l2 (LogUniformDistribution): 0.12646842111634748<extra></extra>",
                    "min_data_in_leaf (IntUniformDistribution): 0.1306879191669043<extra></extra>",
                    "eta (UniformDistribution): 0.16427377659597842<extra></extra>",
                    "min_data_per_group (IntUniformDistribution): 0.1695061882727657<extra></extra>"
                  ],
                  "marker": {
                    "color": "rgb(66,146,198)"
                  },
                  "orientation": "h",
                  "text": [
                    "0.0",
                    "0.0036319353196422248",
                    "0.008713095607648812",
                    "0.009048116097537905",
                    "0.011276581763516029",
                    "0.012863117451477295",
                    "0.01365419557697191",
                    "0.015507595967379712",
                    "0.01717119595059638",
                    "0.021590336930365994",
                    "0.02367906403540362",
                    "0.026357091415098604",
                    "0.0355345685319286",
                    "0.047475817297618274",
                    "0.04913279189123012",
                    "0.0553079357246465",
                    "0.05812025528694221",
                    "0.12646842111634748",
                    "0.1306879191669043",
                    "0.16427377659597842",
                    "0.1695061882727657"
                  ],
                  "textposition": "outside",
                  "texttemplate": "%{text:.2f}",
                  "type": "bar",
                  "x": [
                    0,
                    0.0036319353196422248,
                    0.008713095607648812,
                    0.009048116097537905,
                    0.011276581763516029,
                    0.012863117451477295,
                    0.01365419557697191,
                    0.015507595967379712,
                    0.01717119595059638,
                    0.021590336930365994,
                    0.02367906403540362,
                    0.026357091415098604,
                    0.0355345685319286,
                    0.047475817297618274,
                    0.04913279189123012,
                    0.0553079357246465,
                    0.05812025528694221,
                    0.12646842111634748,
                    0.1306879191669043,
                    0.16427377659597842,
                    0.1695061882727657
                  ],
                  "y": [
                    "booster",
                    "neg_bagging_fraction",
                    "max_bin",
                    "min_split_gain",
                    "rate_drop",
                    "min_child_weight",
                    "lambda_l1",
                    "cat_l2",
                    "cat_smooth",
                    "skip_drop",
                    "max_cat_threshold",
                    "pos_bagging_fraction",
                    "feature_fraction",
                    "bagging_freq",
                    "max_drop",
                    "num_leaves",
                    "max_depth",
                    "lambda_l2",
                    "min_data_in_leaf",
                    "eta",
                    "min_data_per_group"
                  ]
                }
              ],
              "layout": {
                "showlegend": false,
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "heatmapgl": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmapgl"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                },
                "title": {
                  "text": "Hyperparameter Importances"
                },
                "xaxis": {
                  "title": {
                    "text": "Importance for Objective Value"
                  }
                },
                "yaxis": {
                  "title": {
                    "text": "Hyperparameter"
                  }
                }
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "opt.visualization.plot_param_importances(lgb_study.get(boosters[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "dimensions": [
                    {
                      "label": "Objective Value",
                      "range": [
                        0.18432587042658996,
                        0.2362583793115674
                      ],
                      "values": [
                        0.20591527081035405,
                        0.18432587042658996,
                        0.2017252393053198,
                        0.20939215614545534,
                        0.21694154274891075,
                        0.19557172647430976,
                        0.2116721936623447,
                        0.2149995079140523,
                        0.20894907065431106,
                        0.21337754878330842,
                        0.21594430218886623,
                        0.21840865352960734,
                        0.21689928718955032,
                        0.21746519962969085,
                        0.2122374265445271,
                        0.2169676013553105,
                        0.21452649113020192,
                        0.21870195771956413,
                        0.21314188081079988,
                        0.21764853832165518,
                        0.21726310557200518,
                        0.21980785997997726,
                        0.22140519391633035,
                        0.21462998286352888,
                        0.21449502421005118,
                        0.21467491406188705,
                        0.21425455117894693,
                        0.2248688672832479,
                        0.21494055403752607,
                        0.21800213895852377,
                        0.21909853007341332,
                        0.2158862026443545,
                        0.21715161908149327,
                        0.22081973335343613,
                        0.2150227672618223,
                        0.21544606897483262,
                        0.22106983901493008,
                        0.21868104604231114,
                        0.2192334329588909,
                        0.22490738374629166,
                        0.21725828276911613,
                        0.21911846648449718,
                        0.21571172240563677,
                        0.21665742135339303,
                        0.21894495768116426,
                        0.21969059200649976,
                        0.2223686189111867,
                        0.21921927354660448,
                        0.21841621008605686,
                        0.22404359264219736,
                        0.21911923219265103,
                        0.2212116642940709,
                        0.22494328001929084,
                        0.21488941568886194,
                        0.22312924907539963,
                        0.22703726645103037,
                        0.22123755312941368,
                        0.22372304080730698,
                        0.23126543549399292,
                        0.22027256225917718,
                        0.2212358758585499,
                        0.22289962986256007,
                        0.22344486692942458,
                        0.22575718215845572,
                        0.22383118219194942,
                        0.22992294629873106,
                        0.2362583793115674,
                        0.21743805325159465,
                        0.22767538830095568,
                        0.2223132351050328,
                        0.22609548383311026,
                        0.22158229959010187,
                        0.2183778901913683,
                        0.22176188904631067,
                        0.21830470872637692,
                        0.23470978050260904,
                        0.21598005923684208,
                        0.2183558837829281,
                        0.22019589334248635,
                        0.22208276004455385,
                        0.21823563503743088,
                        0.22952632188775923,
                        0.22287904911870499,
                        0.2348520335042945,
                        0.22462584943743785,
                        0.22220540288974444,
                        0.21865773996161186,
                        0.22458201557010543,
                        0.22239888345350756,
                        0.22941944843340029,
                        0.23264150490512567,
                        0.22494867710293512,
                        0.22226162076624373,
                        0.2248486735125018,
                        0.227906055836346,
                        0.22660390977161432,
                        0.22720675728783557,
                        0.23484182324275996,
                        0.22138839872485355,
                        0.23055479564286346,
                        0.2225597034513424,
                        0.23275876025854453,
                        0.22192011654524454,
                        0.23417836453788574,
                        0.2249157660110681,
                        0.22287015275787342,
                        0.22292403497155405,
                        0.2284315716537463,
                        0.21933199819108856,
                        0.2216684894393941,
                        0.22546107347924665,
                        0.22136376208727646,
                        0.22799140416416278,
                        0.2180669676850985,
                        0.22792173354093537,
                        0.22775708502739572,
                        0.22888636954127434,
                        0.2232674718130064,
                        0.22209182693211754,
                        0.23394653485360636,
                        0.21850598962337933,
                        0.22555567138325316,
                        0.22652756528408619,
                        0.22511493581736083,
                        0.2242723851526985,
                        0.2342365849353873,
                        0.22466027321618562,
                        0.21881053314075719,
                        0.23429135104326804,
                        0.22312992866491013,
                        0.22180939292600477,
                        0.22839549327745798,
                        0.22280582339302885,
                        0.22050910442616392,
                        0.220809015514638,
                        0.23488249565892122,
                        0.22411570103774184,
                        0.23150655502464193,
                        0.22306165921549037,
                        0.2212484636732289,
                        0.22587109272234646,
                        0.2284811001831953,
                        0.2253525961171396,
                        0.22578632700713164,
                        0.236196652323164,
                        0.21873524053947455,
                        0.23290516968667677,
                        0.22888932295887834,
                        0.2319202787966522,
                        0.22279420940071612,
                        0.228603903947326,
                        0.22226054262587297,
                        0.22600459138048726,
                        0.2205446880923915,
                        0.23251361849488492,
                        0.22939387129624209,
                        0.21988516705592712,
                        0.22777300195320258,
                        0.22696650547783728
                      ]
                    },
                    {
                      "label": "bagging_freq",
                      "range": [
                        1,
                        16
                      ],
                      "values": [
                        15,
                        16,
                        1,
                        14,
                        2,
                        6,
                        6,
                        1,
                        6,
                        1,
                        1,
                        1,
                        1,
                        1,
                        3,
                        3,
                        4,
                        8,
                        9,
                        8,
                        8,
                        2,
                        11,
                        11,
                        8,
                        10,
                        7,
                        2,
                        2,
                        3,
                        3,
                        4,
                        7,
                        4,
                        4,
                        8,
                        5,
                        2,
                        2,
                        1,
                        1,
                        3,
                        3,
                        2,
                        2,
                        3,
                        4,
                        1,
                        3,
                        5,
                        5,
                        4,
                        3,
                        13,
                        1,
                        4,
                        4,
                        4,
                        4,
                        4,
                        4,
                        4,
                        4,
                        4,
                        4,
                        4,
                        4,
                        4,
                        4,
                        4,
                        4,
                        5,
                        5,
                        5,
                        5,
                        5,
                        4,
                        4,
                        5,
                        5,
                        6,
                        5,
                        4,
                        5,
                        5,
                        5,
                        4,
                        4,
                        4,
                        5,
                        4,
                        4,
                        4,
                        4,
                        3,
                        3,
                        3,
                        3,
                        3,
                        3,
                        3,
                        3,
                        3,
                        3,
                        3,
                        3,
                        3,
                        3,
                        3,
                        3,
                        2,
                        3,
                        3,
                        3,
                        3,
                        3,
                        2,
                        2,
                        3,
                        3,
                        3,
                        2,
                        2,
                        3,
                        3,
                        3,
                        3,
                        3,
                        4,
                        4,
                        4,
                        2,
                        3,
                        3,
                        5,
                        5,
                        5,
                        5,
                        7,
                        5,
                        5,
                        5,
                        5,
                        5,
                        5,
                        5,
                        6,
                        2,
                        5,
                        5,
                        5,
                        4,
                        4,
                        6,
                        6,
                        6,
                        5,
                        7,
                        5
                      ]
                    },
                    {
                      "label": "booster",
                      "range": [
                        0,
                        0
                      ],
                      "ticktext": [
                        "dart"
                      ],
                      "tickvals": [
                        0
                      ],
                      "values": [
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0
                      ]
                    },
                    {
                      "label": "cat_l2",
                      "range": [
                        -2.999003597286675,
                        -1.1537957638123821
                      ],
                      "ticktext": [
                        "0.001",
                        "0.01",
                        "0.0702"
                      ],
                      "tickvals": [
                        -2.999003597286675,
                        -2,
                        -1.1537957638123821
                      ],
                      "values": [
                        -2.296770903295234,
                        -1.9153812785797093,
                        -1.4842922439177597,
                        -2.2414384818510813,
                        -2.6044919566199543,
                        -2.9375705863033934,
                        -2.087723498446194,
                        -2.3095672594234844,
                        -2.8216404549238505,
                        -1.760655710185926,
                        -2.7337914595570676,
                        -2.7440305789785033,
                        -2.743975801075116,
                        -2.7846889988976504,
                        -2.5348060626934683,
                        -2.4593239821619024,
                        -2.4987366726673517,
                        -2.9982373659156916,
                        -2.9778297915363594,
                        -2.8549300235915895,
                        -2.9902750520764037,
                        -2.9829677578722826,
                        -2.833121367289149,
                        -2.880191860728232,
                        -2.8107920491109564,
                        -2.649862371627679,
                        -2.939822010443676,
                        -2.9802677768093853,
                        -2.9785351350659712,
                        -1.5011865052689786,
                        -1.5217371058974947,
                        -2.423962089967171,
                        -1.2812680891544035,
                        -1.6776132987267125,
                        -1.864818395125991,
                        -1.345712532593594,
                        -1.3658457490875284,
                        -2.821475715535166,
                        -1.519740572072276,
                        -1.192817961025769,
                        -1.3989160046270261,
                        -1.5132831533209805,
                        -1.5296842240469413,
                        -1.1862758363753507,
                        -1.174546399711323,
                        -2.0043168919226857,
                        -1.3467020898224265,
                        -2.8911899960749166,
                        -2.24713985579055,
                        -1.1537957638123821,
                        -1.9365756478879133,
                        -1.9973320777507586,
                        -2.999003597286675,
                        -1.990440330579736,
                        -2.805818084671848,
                        -2.089126301264844,
                        -1.731138463260941,
                        -2.0551415219237295,
                        -1.8771035970872416,
                        -1.223699688255214,
                        -2.0459974378166503,
                        -2.0311312167426823,
                        -1.8861312017703056,
                        -2.0371222869015395,
                        -1.800290948981084,
                        -1.7680911121591771,
                        -2.060996663997666,
                        -2.0393557627765952,
                        -2.0283010408403848,
                        -2.1104512434603944,
                        -1.7851868930350736,
                        -2.061827494021164,
                        -2.1515117839797107,
                        -2.0160150782812236,
                        -1.8940823379637544,
                        -2.0142482732441085,
                        -2.005156466635505,
                        -1.9658996823197699,
                        -2.0592648208161446,
                        -2.069498196472269,
                        -2.088566859493085,
                        -2.074924659310679,
                        -2.026022217604427,
                        -2.020936358548398,
                        -1.9122376072874567,
                        -2.1885726311901403,
                        -2.170744316344303,
                        -2.126924057914747,
                        -2.120784949084619,
                        -2.096485538304943,
                        -2.1247738382910955,
                        -2.13474502898512,
                        -2.133379818877861,
                        -2.1155209570902103,
                        -2.1241618872073715,
                        -2.5341069397096643,
                        -1.9822988129119126,
                        -1.9840218512288887,
                        -2.1041136569712977,
                        -1.9831200140031426,
                        -1.7574309763199274,
                        -1.852080023925999,
                        -1.909008248891132,
                        -2.0961281198334505,
                        -2.3623558083887,
                        -2.0903582469462285,
                        -2.22034657259781,
                        -1.9691658915475037,
                        -1.9887071953438482,
                        -2.348095479941635,
                        -2.3731917455469627,
                        -2.507311407370507,
                        -2.1888300501897,
                        -2.0842863681431574,
                        -1.9963151971310331,
                        -2.0047363363343953,
                        -2.4025266235795195,
                        -2.4273956221840023,
                        -2.414704023516533,
                        -2.303159637109681,
                        -2.2710250273261265,
                        -2.040548644562807,
                        -2.5673939751295753,
                        -1.845491719961182,
                        -2.0797418977615125,
                        -1.919309236517057,
                        -2.5927033047555565,
                        -1.9939468641342526,
                        -2.1583596153865803,
                        -2.5403334159179805,
                        -2.1034144416067435,
                        -1.9989706867258015,
                        -1.9224210821726433,
                        -2.0031087556102523,
                        -1.9053171519237233,
                        -1.9052041829394766,
                        -1.9068973839733665,
                        -1.9412582613806328,
                        -2.011328710369016,
                        -1.9500519652495427,
                        -2.204587730865136,
                        -1.9475437722704674,
                        -1.9607309576434893,
                        -1.9543183426130943,
                        -1.8889598033188897,
                        -1.8781474565622351,
                        -1.9257271785362915,
                        -1.9331143145951701,
                        -2.0029505654355626,
                        -1.9788967811260483,
                        -1.8614206677171732,
                        -1.9948741084192112,
                        -2.108904532410316,
                        -1.9055596302344728,
                        -1.888837450931023,
                        -1.9290815980301539,
                        -2.0321886227434978,
                        -1.9133578436704761,
                        -2.0902606740465743
                      ]
                    },
                    {
                      "label": "cat_smooth",
                      "range": [
                        -1.9777922418129128,
                        0.9984037748991688
                      ],
                      "ticktext": [
                        "0.0105",
                        "0.1",
                        "1",
                        "9.96"
                      ],
                      "tickvals": [
                        -1.9777922418129128,
                        -1,
                        0,
                        0.9984037748991688
                      ],
                      "values": [
                        0.8952156239186158,
                        -1.616383569075375,
                        0.229698316587587,
                        0.7076200178545617,
                        -1.050160914919684,
                        -1.4577963086283845,
                        -1.9777922418129128,
                        0.21266768628851157,
                        -0.826040613750266,
                        0.6578361882144868,
                        -1.9246458291164052,
                        -1.8697521878632788,
                        -1.8030024276294152,
                        -1.9289387540094247,
                        0.2533714820431288,
                        -1.2035867122000234,
                        -1.2256764073696784,
                        -1.6240876649753249,
                        -1.5578949770279649,
                        -1.6443639433991037,
                        -0.9306221852003113,
                        -1.6269700937093845,
                        -1.681555036889154,
                        -1.7218353412970608,
                        -1.4356226437888544,
                        -1.4985284575167477,
                        -1.3130027025791187,
                        -1.6020696099771197,
                        -1.606600268333702,
                        -1.6172056165732176,
                        -1.6205562724040217,
                        -1.788610072102738,
                        -1.672217507999951,
                        -1.6567105379301486,
                        -1.6688493359541943,
                        -1.4363657162174106,
                        -1.4126607848449244,
                        -1.4118734809029347,
                        -1.7682300798426511,
                        0.8155383033267789,
                        -1.783204600165816,
                        -1.7332606320318127,
                        -1.8257186759981285,
                        0.8916756626411463,
                        0.46741256917476814,
                        -1.7379227716187569,
                        -1.640970483268244,
                        -0.012751784681304102,
                        0.40284246109694577,
                        -1.8977436262794154,
                        -1.4762514843506969,
                        0.3455787747068636,
                        0.9392250711118568,
                        -1.3719314165409473,
                        0.7754896458384329,
                        0.7942212920585993,
                        -1.4716456166109666,
                        0.7686174568983589,
                        0.7675085363377674,
                        0.7317261656813571,
                        -1.7167515429297158,
                        0.7623929502339,
                        0.9426377899589554,
                        0.7609981954495827,
                        0.9291796114318238,
                        0.9346195750878078,
                        0.7559064080884264,
                        0.9196909653682355,
                        0.7463986956143032,
                        0.7861498305006048,
                        0.807126991425906,
                        0.9475445819538231,
                        0.9262183607759932,
                        0.9267082976195024,
                        0.9512613118327595,
                        0.9619753526693603,
                        0.7291369960315381,
                        0.962657464844983,
                        0.7656641402694268,
                        0.7456163206250506,
                        0.7620224731777648,
                        0.6504775953361531,
                        0.8799092906123245,
                        0.8564824999739623,
                        0.9408836154110849,
                        0.8472045214166377,
                        0.8500331011677985,
                        0.8601527878309851,
                        0.5667389584065583,
                        0.879849307456442,
                        0.8904083236715506,
                        0.6119081378133456,
                        0.5625019646266765,
                        0.896981064367725,
                        0.604260781154442,
                        0.6097579047935415,
                        0.6284948906888727,
                        0.5465705597671778,
                        0.5281292157352462,
                        0.6580274318285617,
                        0.6412840897675048,
                        0.6547318375631814,
                        0.6780288294676635,
                        0.9984037748991688,
                        -0.5410486604077844,
                        0.5239295950340911,
                        0.6417081536345938,
                        0.5977604299941346,
                        0.61943501506229,
                        -0.7906459947300433,
                        -0.41534810733056754,
                        -0.5643991395269469,
                        -0.22323529463161443,
                        0.49936339473579483,
                        0.5478343091542948,
                        0.5792519722801164,
                        0.46197646891126976,
                        -0.6129554082091672,
                        -0.3645103795860412,
                        -0.3928563763552846,
                        -0.47777958617715577,
                        0.5468245599843183,
                        0.3611792523870781,
                        0.7105826895585375,
                        0.7094627643738197,
                        0.6017882234569287,
                        0.21176997337744008,
                        -0.7033695525665533,
                        0.8289040882738924,
                        0.6300582556154934,
                        -0.8786789920558195,
                        0.552910190119517,
                        0.5386122402389296,
                        -0.12160917145259746,
                        0.8291548176990121,
                        0.8198355589952496,
                        0.555425381702824,
                        0.8173078453386917,
                        0.8242879187513564,
                        0.8447576561718834,
                        0.8220799591858027,
                        0.8817498347534141,
                        0.8308205392009307,
                        0.8729682049133476,
                        0.932676914270824,
                        0.7534026913012793,
                        0.9642592934901,
                        0.8749424956772109,
                        -0.043023965752365556,
                        0.8977914890853363,
                        0.9158429303083782,
                        0.67020692739556,
                        0.6726806031285045,
                        0.9153001026430849,
                        0.9509661161396535,
                        0.8782275813832385,
                        0.7914839559934507,
                        0.7417149567961933,
                        0.9407387667660041
                      ]
                    },
                    {
                      "label": "eta",
                      "range": [
                        0.006587155414942036,
                        0.19641853168836906
                      ],
                      "values": [
                        0.1576926736378219,
                        0.012270389586226466,
                        0.14808824133982973,
                        0.14330980878475127,
                        0.07453897066557327,
                        0.19641853168836906,
                        0.08246978091776806,
                        0.10283649247937258,
                        0.1345713543233579,
                        0.051730553439927655,
                        0.07483489285719352,
                        0.08088755610579089,
                        0.07835920150989531,
                        0.06446842079216451,
                        0.10977104872884502,
                        0.04576232603130918,
                        0.04739663801894681,
                        0.02893998540683053,
                        0.03169945627010571,
                        0.029297295757269894,
                        0.08777301107506276,
                        0.061738941208419086,
                        0.02430769865989825,
                        0.006587155414942036,
                        0.09306494056996711,
                        0.09819162537299284,
                        0.03812994753822937,
                        0.05952362706052472,
                        0.02530877249532064,
                        0.02463377091305637,
                        0.02511275223547012,
                        0.013459233550343487,
                        0.02411678700443233,
                        0.020705459623935663,
                        0.02012240782217745,
                        0.02302073518946344,
                        0.031582240942790635,
                        0.03411335266703418,
                        0.03486466768083488,
                        0.035519377633985286,
                        0.02252296735465058,
                        0.036535891585839184,
                        0.042106645575568924,
                        0.03449015813566955,
                        0.035407047102581975,
                        0.026681014733483558,
                        0.028433532706807957,
                        0.017927846056473292,
                        0.029505358747478335,
                        0.01270078313417979,
                        0.013221723131462498,
                        0.012630448456242978,
                        0.03868688721582432,
                        0.03839816542941284,
                        0.03284229056894536,
                        0.014065107682948963,
                        0.013706688368826499,
                        0.015977548758105576,
                        0.01337846656036684,
                        0.013143607901350286,
                        0.013508459243407572,
                        0.013829241994618222,
                        0.015855095189042094,
                        0.016304887087578986,
                        0.016773484056168114,
                        0.014270820158113252,
                        0.015483901019247749,
                        0.01495596071058206,
                        0.014508390293030703,
                        0.014175838858744079,
                        0.009517944801673409,
                        0.01860526712304202,
                        0.019499970357661375,
                        0.0191672054321759,
                        0.017803939974877902,
                        0.01628453930046231,
                        0.015269256621026203,
                        0.015674832483330115,
                        0.015368941428650716,
                        0.022080834415326038,
                        0.021093557302548825,
                        0.022008215670090033,
                        0.011545000961695018,
                        0.01754710515967719,
                        0.018162785449657437,
                        0.017549744549616234,
                        0.01841711521266919,
                        0.02874714086531199,
                        0.02168766661892901,
                        0.011481265916676581,
                        0.02439324738189498,
                        0.028442955657999733,
                        0.027728627314836843,
                        0.029645302364323646,
                        0.026939348771665997,
                        0.02379029825556323,
                        0.021874531825767665,
                        0.009361967662985431,
                        0.02143645386961493,
                        0.021605251876107706,
                        0.031568957863711285,
                        0.026181716031731337,
                        0.03160096432508625,
                        0.025055496504285624,
                        0.03110460421497299,
                        0.027019901368000976,
                        0.027736607182873615,
                        0.02574071798227431,
                        0.023321831089572875,
                        0.022630183518887046,
                        0.034215418271645585,
                        0.03592900068258811,
                        0.0204011306522291,
                        0.020947299985868098,
                        0.020150482884049328,
                        0.020698838516887225,
                        0.020000239935111706,
                        0.019545220128668852,
                        0.018603234444842794,
                        0.020558003631666318,
                        0.00867925287333242,
                        0.019873365664640666,
                        0.012397212048112895,
                        0.021411786785069872,
                        0.021145744985299537,
                        0.0221942594345121,
                        0.02592887212286956,
                        0.01847983079628558,
                        0.01348688984632548,
                        0.016396244695516024,
                        0.016983544154568514,
                        0.01812656660363271,
                        0.018698338921428616,
                        0.01972282794541159,
                        0.01987766435604479,
                        0.02774221187965855,
                        0.02808470964679463,
                        0.027111150768335906,
                        0.019918350693107382,
                        0.08444474467332325,
                        0.021140274601341207,
                        0.02805435497770948,
                        0.027442337618490794,
                        0.028493754077723296,
                        0.030681046997246598,
                        0.02324112490217066,
                        0.03194082557318674,
                        0.022186924741232624,
                        0.01584836044641124,
                        0.016055393236666642,
                        0.027012849021892143,
                        0.01621011080140547,
                        0.01572756803439733,
                        0.01573117489115416,
                        0.03504852577363895,
                        0.03169035752751469,
                        0.021657477210048934,
                        0.029456652717357375,
                        0.01811911983030383
                      ]
                    },
                    {
                      "label": "feature_fraction",
                      "range": [
                        0.9062861023482336,
                        0.9998487559256081
                      ],
                      "values": [
                        0.9083774254914848,
                        0.981386719113421,
                        0.9062861023482336,
                        0.9601480240012563,
                        0.9987413752422093,
                        0.9492620031161154,
                        0.988878482301316,
                        0.958233999789577,
                        0.9495245695704981,
                        0.9967939983238423,
                        0.9998487559256081,
                        0.9970034306527512,
                        0.9957642465041675,
                        0.9941836954091305,
                        0.9681899233033537,
                        0.9880869846743616,
                        0.9700393907729398,
                        0.9716056140731919,
                        0.9724953951067468,
                        0.978140652223127,
                        0.9754050862570516,
                        0.9740366386819942,
                        0.9839479743803621,
                        0.9830652175391777,
                        0.9577731167887065,
                        0.9630184222592626,
                        0.9883720193024578,
                        0.9740161063266572,
                        0.967669436806829,
                        0.9731236450916805,
                        0.972142728230344,
                        0.9738490464875991,
                        0.9746708946689693,
                        0.9732409958930429,
                        0.9746415203603109,
                        0.9662770014529561,
                        0.966063751081074,
                        0.9770578046187622,
                        0.981426741179843,
                        0.961112738912331,
                        0.9605900023919342,
                        0.9719776928196403,
                        0.9722437942162682,
                        0.9666005543558472,
                        0.9655943515165595,
                        0.9670954732360494,
                        0.9678743737710214,
                        0.9782622424048353,
                        0.976145839227249,
                        0.963713348117177,
                        0.9542218190654409,
                        0.9708088607594002,
                        0.9716199788662266,
                        0.9758830489836896,
                        0.9684352333088152,
                        0.9677899511704549,
                        0.9502498125777676,
                        0.9675368034056088,
                        0.966356971432694,
                        0.9489279641739518,
                        0.9673746900631062,
                        0.9492013845694021,
                        0.947176008194563,
                        0.9675820324533903,
                        0.9385394343905982,
                        0.9398667188425383,
                        0.9613249111700658,
                        0.9670427368120367,
                        0.9478594971061642,
                        0.9477247959544229,
                        0.9378778133658953,
                        0.9405186329515857,
                        0.9421343129091864,
                        0.9478162283979376,
                        0.9519454915640763,
                        0.9516360505274277,
                        0.9513730345782638,
                        0.9511011313721297,
                        0.9514057057317793,
                        0.9444332659328262,
                        0.9458542170118499,
                        0.9467451773533412,
                        0.9437177133277603,
                        0.941051188910816,
                        0.9402822501216501,
                        0.9434891100063133,
                        0.9427886758466512,
                        0.9411924493061592,
                        0.964732630522486,
                        0.9436934879493228,
                        0.9621267950406996,
                        0.9622862318196373,
                        0.9578925436402906,
                        0.9582130799189517,
                        0.968279618935662,
                        0.968358469807047,
                        0.9693420663434987,
                        0.9680563945266648,
                        0.9608363052070849,
                        0.9645549910010339,
                        0.9609376566100047,
                        0.969659606988512,
                        0.9695991033018732,
                        0.9639839785735254,
                        0.9638434798720837,
                        0.9656892633012826,
                        0.9687789938549318,
                        0.9697432229247188,
                        0.9660397390560723,
                        0.9645138019362288,
                        0.9676246558331033,
                        0.9638247951065413,
                        0.9677618938810325,
                        0.9583782719569891,
                        0.9710880930578059,
                        0.9718063405602868,
                        0.9679690245281782,
                        0.9683555303261131,
                        0.9686685139441855,
                        0.9703527531046797,
                        0.9702746946038651,
                        0.9731865604446763,
                        0.9711926727557546,
                        0.966416506341663,
                        0.9657596397991014,
                        0.9660725400862442,
                        0.9656151833608305,
                        0.9534468509293857,
                        0.965019329789948,
                        0.9716509463989846,
                        0.9718831007977196,
                        0.9717915866529557,
                        0.9638094180208268,
                        0.9625971859818437,
                        0.961641929726036,
                        0.9627186699709069,
                        0.962213487365075,
                        0.9637872621581958,
                        0.963361998428492,
                        0.9639438448388761,
                        0.9644265773745969,
                        0.9606588602268619,
                        0.9643201365595576,
                        0.9598730207219058,
                        0.959494840421603,
                        0.9648485284852184,
                        0.9618919462997292,
                        0.9608816525789892,
                        0.9673575981147557,
                        0.9550176961073471,
                        0.967719663281787,
                        0.9664483096588249,
                        0.9594441642488388,
                        0.9609327603234312,
                        0.958594923179672,
                        0.9572196694213174,
                        0.9646515315531314,
                        0.952539234901482,
                        0.940058473380886
                      ]
                    },
                    {
                      "label": "lambda_l1",
                      "range": [
                        -1.9990855206709803,
                        -0.06483761988021373
                      ],
                      "ticktext": [
                        "0.01",
                        "0.1",
                        "0.861"
                      ],
                      "tickvals": [
                        -1.9990855206709803,
                        -1,
                        -0.06483761988021373
                      ],
                      "values": [
                        -0.5212040179979647,
                        -0.6541054983232266,
                        -0.5382655667395833,
                        -1.3080745671111926,
                        -1.875893000269083,
                        -1.3311956490944483,
                        -1.2686383646981096,
                        -1.0913254882671763,
                        -1.3941675484681324,
                        -0.06483761988021373,
                        -1.9376251610304742,
                        -1.9877738903977629,
                        -1.9977028507780428,
                        -1.992438654356072,
                        -1.6641747498213577,
                        -1.613591456154037,
                        -1.6584270060599808,
                        -1.7689341054478593,
                        -1.5777183419890695,
                        -1.4998533858809164,
                        -1.5183866026597652,
                        -1.82723223014907,
                        -1.818911401922747,
                        -1.8201393210347712,
                        -1.1824661459183994,
                        -1.5003139213248995,
                        -1.599253382413016,
                        -1.9681573214618298,
                        -1.6403400548579479,
                        -1.9990855206709803,
                        -1.9824701263558364,
                        -1.4347286720395829,
                        -1.9318392641436746,
                        -1.9435275155393907,
                        -1.958383868727815,
                        -1.782902315393998,
                        -1.7976700661280551,
                        -1.6957962317106912,
                        -1.7000929519232482,
                        -0.64748022248243,
                        -1.910714116732985,
                        -1.8982115125631096,
                        -0.1882025058240105,
                        -1.9588982991530506,
                        -1.9651670170196993,
                        -1.9634415581456455,
                        -1.973177599776714,
                        -1.0732523838770907,
                        -1.8202684284754405,
                        -1.8243863068817903,
                        -1.7747924451485262,
                        -0.4679924939964203,
                        -1.7590914790597525,
                        -1.8776897827679937,
                        -1.917768677904703,
                        -1.9284861012253565,
                        -1.7503191707988093,
                        -0.2799999817938003,
                        -0.4028639943256641,
                        -0.26178915037165423,
                        -0.6843943475918787,
                        -1.9378990803220757,
                        -0.27648446488837325,
                        -0.4603346572521446,
                        -0.31668226873557437,
                        -0.18048340624056125,
                        -0.29769989180400136,
                        -0.2662753333483502,
                        -0.3064963782715966,
                        -0.30553202336750773,
                        -0.31049847650777745,
                        -0.18872034910807647,
                        -0.175638590141892,
                        -0.2544150804294486,
                        -0.4100437925722098,
                        -0.3655188520944777,
                        -0.15682019930541252,
                        -0.3898502110537129,
                        -0.25492675447670265,
                        -0.4243415059162333,
                        -0.25146789736628383,
                        -0.25849930783891,
                        -0.3590211113042106,
                        -0.34611621997516734,
                        -0.3577938074715685,
                        -0.3602823485200922,
                        -0.20654170940479946,
                        -0.5068517183962757,
                        -0.49892603441008,
                        -0.3877871444188565,
                        -0.3112232711030606,
                        -0.3032362372011097,
                        -0.2965281023597329,
                        -0.556713874895841,
                        -0.6075824804239779,
                        -0.5643582483156416,
                        -0.5677334435313105,
                        -0.557780748492371,
                        -0.5133531578538993,
                        -0.5452455929057289,
                        -0.5235917063052883,
                        -0.5460556751661257,
                        -0.5374650151437008,
                        -0.6285165075454217,
                        -0.5345162690106922,
                        -0.562898636723837,
                        -0.5661994344528446,
                        -0.5524175156946896,
                        -0.6723069607791906,
                        -0.6360075336154167,
                        -0.6285628336907377,
                        -0.7226157599277698,
                        -0.46426171344508615,
                        -0.474159241708509,
                        -0.46883221003433323,
                        -0.5165523937455195,
                        -0.7662932963058249,
                        -0.47181508738548256,
                        -0.46398684074110647,
                        -0.5227609256415571,
                        -0.4570975783165054,
                        -0.4171280285584533,
                        -0.5965253879374138,
                        -1.363592863710884,
                        -0.524566813741388,
                        -0.4173290280608368,
                        -0.5877979769748412,
                        -0.8493495077533418,
                        -0.6730233496542087,
                        -0.13503506751607416,
                        -0.7026504089235691,
                        -0.6950704733961618,
                        -0.5654830687303577,
                        -0.40182766389959085,
                        -0.6596736542707244,
                        -0.3785070062290074,
                        -0.39067425871741784,
                        -0.4358033025418072,
                        -0.687419135596297,
                        -0.6827040215674542,
                        -0.7480486607912614,
                        -0.36858364026496115,
                        -0.36098458965306685,
                        -0.3780056204829379,
                        -0.4273891184918306,
                        -0.4386473395552925,
                        -0.4686162040886494,
                        -0.3330683738461551,
                        -0.4027787065792328,
                        -0.3961573002988576,
                        -0.4739412131974514,
                        -0.6395561444649154,
                        -0.6434756603745158,
                        -0.3774157496379811,
                        -0.3430377933548646,
                        -0.2756655873942878,
                        -0.3628554893020866,
                        -0.24981403916413636,
                        -1.118883287507034
                      ]
                    },
                    {
                      "label": "lambda_l2",
                      "range": [
                        -2.9776990893597275,
                        0.6658324060005741
                      ],
                      "ticktext": [
                        "0.00105",
                        "0.01",
                        "0.1",
                        "1",
                        "4.63"
                      ],
                      "tickvals": [
                        -2.9776990893597275,
                        -2,
                        -1,
                        0,
                        0.6658324060005741
                      ],
                      "values": [
                        0.22889373830343426,
                        0.6658324060005741,
                        -0.520337343864357,
                        0.3724130431425304,
                        -1.0968829572517713,
                        -0.3144715931847693,
                        -0.45771637447617536,
                        -1.716423976174856,
                        -2.401614462000056,
                        -1.0274960562384179,
                        -2.849997317765869,
                        -1.4706107436588516,
                        -1.4146610853671397,
                        -1.1541744094128856,
                        -2.859623462157667,
                        -2.9776990893597275,
                        -0.7804503353101472,
                        -0.7813423524736409,
                        -0.8252419480750497,
                        -1.5864550175870393,
                        -1.5224843386989646,
                        -1.536735986760506,
                        -2.2451603279765413,
                        -2.1100535278726302,
                        -0.05805530192615869,
                        -0.6214274014082067,
                        -1.407263909015968,
                        -2.424365042569855,
                        -2.309011113271418,
                        -2.6604863796163682,
                        -2.6282038894063353,
                        -1.6186388769701516,
                        -2.5566279459577834,
                        -2.533828959763317,
                        -2.597847573985949,
                        -2.6008794466919767,
                        -2.0066353459659627,
                        -1.9894619701708816,
                        -2.2076385275243946,
                        -2.2101147256692273,
                        -2.034219794803824,
                        -2.20535145458841,
                        -2.073423548429378,
                        -2.041429334121704,
                        -1.9353178277200969,
                        -2.3620817694562435,
                        -2.2625101079875245,
                        -2.3511253554334863,
                        -2.145618743704074,
                        -2.4316982737948267,
                        -2.47348154981076,
                        -2.2228365821713676,
                        -2.4111616854202773,
                        -2.180858279510426,
                        -1.1036540674309174,
                        -2.401218291325643,
                        -2.3929025474570618,
                        -2.4829110762670403,
                        -2.5035241787501747,
                        -2.501221864922661,
                        -2.510461556563117,
                        -2.5248795701437903,
                        -2.3597860340244345,
                        -2.3763461109488753,
                        -2.3924954148133053,
                        -2.3953960588433065,
                        -2.391422262963601,
                        -2.705155403480566,
                        -2.405710590801037,
                        -2.727583172493498,
                        -2.4258260186724208,
                        -2.59932217643321,
                        -2.6058335387709417,
                        -2.2977738782095987,
                        -2.3116595141286114,
                        -2.303783995467967,
                        -2.3274311619489128,
                        -2.4923668752650205,
                        -2.9287303977581183,
                        -2.3180389765760565,
                        -2.5037902210121503,
                        -2.7739424505430685,
                        -2.5394317937695874,
                        -2.5283597421083757,
                        -2.643934509570875,
                        -2.6650276471503376,
                        -2.3709914845008973,
                        -2.3716667308883665,
                        -2.3696329390305917,
                        -2.730699595408538,
                        -2.4680856875030464,
                        -2.4519961761162463,
                        -2.421536803797365,
                        -2.453762476135945,
                        -2.420383682560824,
                        -2.405743539490268,
                        -2.3946383196676773,
                        -2.3925608454914524,
                        -2.413277434574058,
                        -2.585464731772331,
                        -2.424351929172905,
                        -2.4221189912737118,
                        -2.402776868978285,
                        -2.255332159091292,
                        -2.2502897760977136,
                        -2.259366820199502,
                        -2.2641370655957336,
                        -2.2624433843392193,
                        -2.6020309704810645,
                        -2.230737949001367,
                        -2.317608179668991,
                        -2.2329130940836173,
                        -2.3253906136621616,
                        -2.3377351876701664,
                        -2.104728628670344,
                        -2.244663482429688,
                        -2.132760172028527,
                        -2.3419107840642437,
                        -2.3576937114042495,
                        -2.3415370226579295,
                        -2.3511442963640925,
                        -2.300176045619328,
                        -2.2053702161366426,
                        -2.5330927172007196,
                        -2.254274653013849,
                        -2.280370678719288,
                        -2.3974883532605857,
                        -2.5738400211677486,
                        -2.3723422323934265,
                        -0.5226449724911945,
                        -2.3754254657288367,
                        -2.1851641516013314,
                        -2.1807913921237954,
                        -2.172243661054292,
                        -2.3510922916300525,
                        -2.3341912116710097,
                        -2.337193020873624,
                        -2.345585752209499,
                        -2.1160886485704853,
                        -2.135838274730091,
                        -2.263385491297826,
                        -2.2423220287225094,
                        -1.9823000792796568,
                        -2.260276494825539,
                        -2.2404169604052133,
                        -2.6902451779719025,
                        -2.1514116210589598,
                        -2.17178439948469,
                        -2.494743908607187,
                        -2.6038400237515393,
                        -2.485936449784427,
                        -2.4594436639822996,
                        -2.4972999884246843,
                        -2.1913070941570294,
                        -2.221032636881411,
                        -2.643652826857004,
                        -2.325586657401655,
                        -2.7273150385988707,
                        -2.444421417626011
                      ]
                    },
                    {
                      "label": "max_bin",
                      "range": [
                        20,
                        200
                      ],
                      "values": [
                        50,
                        88,
                        138,
                        22,
                        165,
                        131,
                        26,
                        146,
                        70,
                        193,
                        193,
                        197,
                        200,
                        197,
                        163,
                        173,
                        173,
                        178,
                        179,
                        178,
                        109,
                        176,
                        108,
                        107,
                        109,
                        122,
                        180,
                        185,
                        200,
                        198,
                        200,
                        188,
                        192,
                        168,
                        191,
                        195,
                        195,
                        195,
                        183,
                        182,
                        196,
                        182,
                        183,
                        182,
                        183,
                        190,
                        171,
                        171,
                        114,
                        166,
                        158,
                        161,
                        72,
                        105,
                        166,
                        177,
                        168,
                        41,
                        165,
                        166,
                        56,
                        164,
                        40,
                        42,
                        54,
                        34,
                        58,
                        50,
                        40,
                        40,
                        41,
                        52,
                        56,
                        62,
                        63,
                        25,
                        34,
                        75,
                        60,
                        32,
                        31,
                        28,
                        40,
                        24,
                        23,
                        25,
                        25,
                        42,
                        20,
                        23,
                        25,
                        25,
                        40,
                        43,
                        36,
                        43,
                        85,
                        44,
                        87,
                        25,
                        25,
                        24,
                        25,
                        25,
                        24,
                        48,
                        25,
                        25,
                        29,
                        29,
                        30,
                        30,
                        23,
                        133,
                        23,
                        23,
                        23,
                        23,
                        23,
                        24,
                        25,
                        20,
                        30,
                        37,
                        33,
                        24,
                        30,
                        26,
                        24,
                        24,
                        99,
                        143,
                        20,
                        20,
                        22,
                        142,
                        20,
                        23,
                        20,
                        20,
                        23,
                        140,
                        143,
                        125,
                        121,
                        26,
                        143,
                        24,
                        24,
                        115,
                        105,
                        131,
                        106,
                        139,
                        148,
                        150,
                        20,
                        158,
                        23
                      ]
                    },
                    {
                      "label": "max_cat_threshold",
                      "range": [
                        5,
                        50
                      ],
                      "values": [
                        27,
                        47,
                        44,
                        22,
                        24,
                        34,
                        20,
                        38,
                        39,
                        35,
                        15,
                        16,
                        15,
                        14,
                        15,
                        9,
                        7,
                        20,
                        20,
                        19,
                        27,
                        27,
                        25,
                        18,
                        19,
                        12,
                        16,
                        5,
                        50,
                        42,
                        50,
                        5,
                        37,
                        40,
                        38,
                        34,
                        47,
                        36,
                        42,
                        41,
                        45,
                        50,
                        49,
                        43,
                        43,
                        40,
                        43,
                        43,
                        46,
                        38,
                        44,
                        37,
                        44,
                        46,
                        46,
                        38,
                        40,
                        40,
                        40,
                        41,
                        41,
                        37,
                        39,
                        39,
                        39,
                        39,
                        39,
                        41,
                        41,
                        41,
                        36,
                        39,
                        39,
                        39,
                        41,
                        41,
                        41,
                        37,
                        42,
                        35,
                        35,
                        33,
                        39,
                        39,
                        33,
                        33,
                        33,
                        34,
                        36,
                        31,
                        41,
                        42,
                        37,
                        38,
                        38,
                        38,
                        40,
                        34,
                        34,
                        34,
                        38,
                        41,
                        41,
                        34,
                        35,
                        38,
                        38,
                        42,
                        42,
                        42,
                        42,
                        36,
                        35,
                        31,
                        43,
                        43,
                        41,
                        41,
                        35,
                        34,
                        34,
                        42,
                        39,
                        39,
                        39,
                        39,
                        36,
                        36,
                        31,
                        38,
                        35,
                        44,
                        41,
                        41,
                        28,
                        31,
                        30,
                        31,
                        31,
                        31,
                        43,
                        31,
                        31,
                        43,
                        31,
                        45,
                        32,
                        33,
                        30,
                        31,
                        31,
                        30,
                        30,
                        31,
                        31,
                        33,
                        31,
                        34,
                        32
                      ]
                    },
                    {
                      "label": "max_depth",
                      "range": [
                        4,
                        15
                      ],
                      "values": [
                        7,
                        7,
                        13,
                        9,
                        10,
                        7,
                        10,
                        15,
                        13,
                        4,
                        10,
                        10,
                        10,
                        11,
                        15,
                        11,
                        12,
                        8,
                        8,
                        8,
                        8,
                        8,
                        9,
                        9,
                        6,
                        10,
                        12,
                        11,
                        11,
                        11,
                        11,
                        11,
                        11,
                        11,
                        11,
                        13,
                        13,
                        13,
                        14,
                        14,
                        14,
                        14,
                        15,
                        15,
                        15,
                        14,
                        14,
                        14,
                        8,
                        14,
                        14,
                        14,
                        13,
                        15,
                        14,
                        14,
                        14,
                        14,
                        14,
                        14,
                        14,
                        14,
                        14,
                        14,
                        14,
                        14,
                        14,
                        14,
                        14,
                        14,
                        14,
                        14,
                        14,
                        14,
                        14,
                        14,
                        13,
                        14,
                        15,
                        15,
                        15,
                        14,
                        14,
                        13,
                        13,
                        13,
                        14,
                        14,
                        14,
                        13,
                        14,
                        14,
                        14,
                        14,
                        14,
                        14,
                        14,
                        14,
                        14,
                        14,
                        14,
                        14,
                        14,
                        14,
                        14,
                        14,
                        14,
                        15,
                        13,
                        14,
                        15,
                        15,
                        14,
                        14,
                        15,
                        15,
                        15,
                        15,
                        15,
                        15,
                        15,
                        15,
                        15,
                        14,
                        14,
                        14,
                        14,
                        14,
                        14,
                        15,
                        15,
                        15,
                        15,
                        15,
                        14,
                        14,
                        14,
                        14,
                        14,
                        14,
                        14,
                        14,
                        14,
                        14,
                        14,
                        13,
                        13,
                        15,
                        15,
                        14,
                        14,
                        14,
                        14,
                        13,
                        12,
                        12,
                        14,
                        11,
                        13
                      ]
                    },
                    {
                      "label": "max_drop",
                      "range": [
                        30,
                        58
                      ],
                      "values": [
                        38,
                        33,
                        32,
                        31,
                        42,
                        38,
                        50,
                        50,
                        48,
                        48,
                        48,
                        49,
                        49,
                        49,
                        44,
                        53,
                        58,
                        58,
                        42,
                        52,
                        42,
                        46,
                        51,
                        51,
                        35,
                        47,
                        53,
                        55,
                        55,
                        40,
                        42,
                        43,
                        43,
                        43,
                        43,
                        48,
                        48,
                        45,
                        48,
                        48,
                        48,
                        46,
                        45,
                        45,
                        45,
                        41,
                        41,
                        49,
                        54,
                        41,
                        41,
                        54,
                        54,
                        43,
                        48,
                        46,
                        40,
                        40,
                        42,
                        48,
                        40,
                        40,
                        39,
                        40,
                        40,
                        40,
                        40,
                        40,
                        40,
                        40,
                        40,
                        38,
                        40,
                        40,
                        40,
                        40,
                        40,
                        40,
                        41,
                        41,
                        42,
                        41,
                        41,
                        32,
                        41,
                        41,
                        41,
                        40,
                        39,
                        40,
                        39,
                        39,
                        39,
                        39,
                        40,
                        30,
                        40,
                        40,
                        55,
                        40,
                        32,
                        40,
                        30,
                        34,
                        38,
                        33,
                        38,
                        40,
                        38,
                        33,
                        33,
                        37,
                        34,
                        36,
                        40,
                        37,
                        40,
                        32,
                        34,
                        34,
                        35,
                        40,
                        31,
                        37,
                        39,
                        39,
                        37,
                        37,
                        41,
                        41,
                        41,
                        41,
                        41,
                        33,
                        34,
                        34,
                        34,
                        41,
                        42,
                        42,
                        42,
                        34,
                        34,
                        34,
                        35,
                        41,
                        40,
                        36,
                        39,
                        34,
                        43,
                        33,
                        33,
                        40,
                        33,
                        33,
                        42,
                        39,
                        41
                      ]
                    },
                    {
                      "label": "min_child_weight",
                      "range": [
                        1,
                        40
                      ],
                      "values": [
                        34,
                        19,
                        30,
                        22,
                        8,
                        25,
                        26,
                        11,
                        19,
                        3,
                        1,
                        4,
                        3,
                        1,
                        2,
                        8,
                        14,
                        14,
                        15,
                        13,
                        13,
                        14,
                        23,
                        18,
                        17,
                        11,
                        24,
                        16,
                        16,
                        20,
                        20,
                        18,
                        20,
                        20,
                        20,
                        19,
                        19,
                        22,
                        37,
                        23,
                        33,
                        23,
                        40,
                        37,
                        40,
                        18,
                        19,
                        19,
                        23,
                        18,
                        18,
                        16,
                        23,
                        16,
                        24,
                        17,
                        17,
                        19,
                        14,
                        14,
                        19,
                        19,
                        13,
                        14,
                        14,
                        14,
                        14,
                        16,
                        14,
                        14,
                        13,
                        11,
                        15,
                        15,
                        14,
                        15,
                        14,
                        15,
                        14,
                        13,
                        13,
                        13,
                        13,
                        13,
                        12,
                        12,
                        13,
                        15,
                        16,
                        13,
                        14,
                        16,
                        16,
                        15,
                        16,
                        15,
                        15,
                        15,
                        15,
                        17,
                        15,
                        15,
                        15,
                        15,
                        15,
                        16,
                        16,
                        16,
                        16,
                        14,
                        14,
                        16,
                        15,
                        15,
                        17,
                        17,
                        14,
                        17,
                        15,
                        15,
                        14,
                        14,
                        13,
                        16,
                        16,
                        14,
                        16,
                        16,
                        15,
                        12,
                        12,
                        17,
                        17,
                        14,
                        17,
                        17,
                        17,
                        15,
                        17,
                        17,
                        17,
                        17,
                        18,
                        18,
                        18,
                        14,
                        16,
                        15,
                        15,
                        13,
                        17,
                        15,
                        13,
                        13,
                        13,
                        14,
                        15,
                        16,
                        14
                      ]
                    },
                    {
                      "label": "min_data_in_leaf",
                      "range": [
                        3,
                        100
                      ],
                      "values": [
                        65,
                        76,
                        55,
                        9,
                        96,
                        29,
                        47,
                        93,
                        62,
                        43,
                        100,
                        35,
                        96,
                        39,
                        100,
                        36,
                        35,
                        36,
                        38,
                        36,
                        55,
                        24,
                        50,
                        45,
                        48,
                        51,
                        32,
                        38,
                        38,
                        36,
                        26,
                        21,
                        20,
                        30,
                        36,
                        29,
                        27,
                        27,
                        18,
                        18,
                        35,
                        34,
                        12,
                        13,
                        24,
                        19,
                        19,
                        32,
                        40,
                        26,
                        16,
                        26,
                        26,
                        26,
                        33,
                        33,
                        22,
                        23,
                        22,
                        22,
                        29,
                        29,
                        22,
                        22,
                        23,
                        23,
                        23,
                        22,
                        22,
                        24,
                        25,
                        20,
                        21,
                        20,
                        21,
                        28,
                        18,
                        27,
                        20,
                        19,
                        19,
                        17,
                        27,
                        17,
                        17,
                        17,
                        16,
                        14,
                        26,
                        15,
                        25,
                        25,
                        25,
                        11,
                        11,
                        23,
                        23,
                        12,
                        13,
                        13,
                        10,
                        22,
                        22,
                        8,
                        7,
                        7,
                        7,
                        7,
                        12,
                        5,
                        9,
                        5,
                        12,
                        4,
                        11,
                        9,
                        9,
                        3,
                        11,
                        11,
                        6,
                        10,
                        8,
                        11,
                        12,
                        8,
                        12,
                        13,
                        17,
                        18,
                        17,
                        6,
                        6,
                        5,
                        15,
                        17,
                        4,
                        18,
                        4,
                        5,
                        4,
                        16,
                        17,
                        18,
                        18,
                        11,
                        11,
                        8,
                        8,
                        16,
                        16,
                        13,
                        13,
                        16,
                        16,
                        18,
                        18,
                        10,
                        20
                      ]
                    },
                    {
                      "label": "min_data_per_group",
                      "range": [
                        5,
                        197
                      ],
                      "values": [
                        197,
                        36,
                        196,
                        132,
                        77,
                        44,
                        114,
                        197,
                        53,
                        53,
                        73,
                        73,
                        70,
                        72,
                        79,
                        97,
                        102,
                        126,
                        128,
                        124,
                        125,
                        130,
                        160,
                        169,
                        118,
                        105,
                        46,
                        67,
                        97,
                        83,
                        79,
                        76,
                        57,
                        73,
                        74,
                        75,
                        74,
                        65,
                        111,
                        51,
                        52,
                        51,
                        40,
                        114,
                        33,
                        32,
                        68,
                        95,
                        78,
                        31,
                        47,
                        30,
                        47,
                        65,
                        61,
                        41,
                        54,
                        47,
                        29,
                        28,
                        39,
                        40,
                        54,
                        20,
                        28,
                        27,
                        20,
                        28,
                        21,
                        30,
                        24,
                        12,
                        42,
                        12,
                        18,
                        36,
                        35,
                        20,
                        43,
                        32,
                        26,
                        5,
                        34,
                        33,
                        33,
                        8,
                        9,
                        8,
                        36,
                        32,
                        28,
                        28,
                        27,
                        27,
                        60,
                        51,
                        49,
                        51,
                        43,
                        52,
                        49,
                        52,
                        55,
                        18,
                        19,
                        23,
                        17,
                        51,
                        51,
                        23,
                        24,
                        19,
                        21,
                        51,
                        53,
                        49,
                        44,
                        47,
                        15,
                        25,
                        24,
                        29,
                        51,
                        53,
                        53,
                        20,
                        37,
                        47,
                        32,
                        31,
                        20,
                        15,
                        20,
                        20,
                        20,
                        15,
                        14,
                        20,
                        16,
                        14,
                        14,
                        15,
                        12,
                        14,
                        6,
                        26,
                        24,
                        19,
                        30,
                        5,
                        9,
                        17,
                        5,
                        23,
                        22,
                        19,
                        34,
                        23,
                        38
                      ]
                    },
                    {
                      "label": "min_split_gain",
                      "range": [
                        -2.78155931981785,
                        -0.0005203654161989648
                      ],
                      "ticktext": [
                        "0.00165",
                        "0.01",
                        "0.1",
                        "0.999"
                      ],
                      "tickvals": [
                        -2.78155931981785,
                        -2,
                        -1,
                        -0.0005203654161989648
                      ],
                      "values": [
                        -0.31680008520290687,
                        -0.5418521316936563,
                        -1.6474846582370444,
                        -1.0377553200017262,
                        -0.05993999070566618,
                        -2.1921703676566353,
                        -0.9756329879397141,
                        -1.4201583850984116,
                        -2.661136511833117,
                        -0.010040951267997375,
                        -1.0226026616803863,
                        -0.013558214547886742,
                        -1.0958068565882897,
                        -0.010762306158241907,
                        -1.8617155508819874,
                        -0.7023982751093697,
                        -0.2529934616945254,
                        -0.24503931231736745,
                        -0.32426117124837556,
                        -0.24407378120176118,
                        -0.2916836566769677,
                        -0.43121448027576226,
                        -0.549191346729139,
                        -0.5213458997244506,
                        -0.08703230297948046,
                        -0.3083582497289866,
                        -0.6599329025440233,
                        -0.42609812766053295,
                        -2.1138750280584047,
                        -0.34977089136428025,
                        -0.3750654156630749,
                        -0.37476105194638,
                        -0.2838341511414885,
                        -0.27974015456473567,
                        -0.27655213840871096,
                        -0.1795876815958542,
                        -0.18127300579270306,
                        -0.179883853074242,
                        -0.0005203654161989648,
                        -0.416868180028347,
                        -0.013568466003459975,
                        -0.05922025008844491,
                        -0.3305514076403624,
                        -0.34330047904321714,
                        -0.14441460395342218,
                        -0.1442264004042631,
                        -0.6221040535716148,
                        -0.4267316589221907,
                        -0.08520558776508615,
                        -0.5616722844859776,
                        -0.5995969569817567,
                        -0.6311240930143512,
                        -0.24899400283169715,
                        -0.37066788592628497,
                        -0.032548649205869126,
                        -0.48407159630240987,
                        -0.7197568727859663,
                        -0.774424846692489,
                        -0.7240826779373648,
                        -1.0495415544788407,
                        -0.7950114567617296,
                        -0.7256319201252116,
                        -1.021726734565556,
                        -0.8451039740123631,
                        -0.781416960902171,
                        -0.9436538632606986,
                        -1.0548001037154617,
                        -0.9919570176343667,
                        -0.9525890030049728,
                        -0.7112747675039035,
                        -0.9619601017563456,
                        -1.1327208555383714,
                        -1.101762092481653,
                        -0.7209817057238086,
                        -1.102425373888103,
                        -0.7350233483822379,
                        -0.7368672849771657,
                        -0.749764577079694,
                        -0.9173919436737689,
                        -1.2362721949368483,
                        -0.9066985398498703,
                        -1.2543142017880764,
                        -1.0497375072827804,
                        -1.0095223415557084,
                        -1.0225485840472193,
                        -1.174206702970358,
                        -0.9653928647592848,
                        -1.0211505509764782,
                        -1.0869725214041819,
                        -1.2314739783131121,
                        -0.8846866074646237,
                        -0.8910803739558394,
                        -0.8720121007855272,
                        -1.0132578112689974,
                        -1.0079434349751226,
                        -1.0252217591110986,
                        -1.0017197046012092,
                        -0.788623724658663,
                        -1.02441637283522,
                        -1.0268557722463898,
                        -0.928390675182945,
                        -0.9330342611716418,
                        -0.9342955814573658,
                        -0.9142467876559438,
                        -0.9416750482461548,
                        -1.0200764179768014,
                        -0.9110290065722356,
                        -1.0124355775248215,
                        -1.0122170920898508,
                        -0.9040969790482948,
                        -0.8516901746278204,
                        -0.8648978798906711,
                        -0.8270547640730181,
                        -0.9476707719897971,
                        -0.9234245053308964,
                        -0.9280888544639294,
                        -0.9207343758834327,
                        -0.8161173888220548,
                        -0.8182174543491983,
                        -0.8306579560123257,
                        -2.78155931981785,
                        -0.883728874423745,
                        -1.0692010429208068,
                        -0.9798465721346665,
                        -0.7593892973204895,
                        -0.9093807845752369,
                        -1.0336657629784627,
                        -1.3505072799560105,
                        -1.3492181148734246,
                        -0.9039746084310916,
                        -1.007089559135867,
                        -0.8944544331758726,
                        -0.8869139356784699,
                        -1.3357444697724805,
                        -1.2561360062160243,
                        -0.8412066783378501,
                        -1.4278160198737795,
                        -0.8069748897775698,
                        -0.7725102459457992,
                        -1.3232190617564956,
                        -1.4367742289199343,
                        -0.7902234228254087,
                        -1.4835394406823228,
                        -0.7730006301421908,
                        -0.6727756659342593,
                        -0.8268274322120618,
                        -0.7168471429352415,
                        -0.9007540599726542,
                        -0.8853073906499938,
                        -0.7089232868268137,
                        -0.7978305084827274,
                        -0.9247724448901259,
                        -0.6277176938161031,
                        -0.6282882387736394,
                        -0.6594189500472432,
                        -0.7227597444426987,
                        -0.9080972314114079,
                        -2.2803729169532363,
                        -1.200067844673721
                      ]
                    },
                    {
                      "label": "neg_bagging_fract...",
                      "range": [
                        0.5004927914123546,
                        0.699155399633693
                      ],
                      "values": [
                        0.5425161462008294,
                        0.6493995851792508,
                        0.5879755518330465,
                        0.6445170840927451,
                        0.5127342981764726,
                        0.6484764312892737,
                        0.6732041356206054,
                        0.6643103729368771,
                        0.6255377620067762,
                        0.5579857753394468,
                        0.6111703327047723,
                        0.5044444575586307,
                        0.5004927914123546,
                        0.6160058528318734,
                        0.5009449698903402,
                        0.5230306296224333,
                        0.5248232398214308,
                        0.5189614618294234,
                        0.5278896350646194,
                        0.5348450025406136,
                        0.5425686297292021,
                        0.5474553857832241,
                        0.633707943098105,
                        0.6318500562188791,
                        0.5142643950131246,
                        0.6180293399213934,
                        0.5064836726894739,
                        0.5939741649942012,
                        0.5911980660149373,
                        0.5068434991431173,
                        0.5076911994289304,
                        0.5634412779007971,
                        0.5164904911909285,
                        0.6249014980245868,
                        0.5640292125299637,
                        0.5825797667902779,
                        0.5787129746438152,
                        0.612180793791837,
                        0.5114110771720107,
                        0.6247209402754107,
                        0.5095316187446421,
                        0.6045036588990471,
                        0.5006195799523584,
                        0.6097538123988557,
                        0.6049225270474656,
                        0.604323962631651,
                        0.6162091078483642,
                        0.512464329148297,
                        0.5983162143175264,
                        0.6165594046788296,
                        0.6161350094185843,
                        0.6083774334355814,
                        0.6078736144006711,
                        0.699155399633693,
                        0.5901505509630429,
                        0.5902286669518512,
                        0.6224495830262982,
                        0.608842046887444,
                        0.6212627347489095,
                        0.5883376258677036,
                        0.5894423763074336,
                        0.6215378811621203,
                        0.6212095147568921,
                        0.6218852543097504,
                        0.6204211925892309,
                        0.6273513563793364,
                        0.6205433634105773,
                        0.6202872822458579,
                        0.6208554588579662,
                        0.6263280695394774,
                        0.62075989924529,
                        0.6403279416499565,
                        0.6210104774692439,
                        0.6202526088741392,
                        0.6224210566886315,
                        0.6205973616178766,
                        0.641269338086092,
                        0.6253576750952906,
                        0.6231811826607756,
                        0.6258666336140386,
                        0.6159811902276758,
                        0.6244152405898836,
                        0.6131809489108261,
                        0.613239117969444,
                        0.6121557515185628,
                        0.6113029078763909,
                        0.6194033937392992,
                        0.6443567909473793,
                        0.6196284303888207,
                        0.6096358595184951,
                        0.6589587152609147,
                        0.5928515348525951,
                        0.6000987071228719,
                        0.6232029580540299,
                        0.6768765630219168,
                        0.622067584895675,
                        0.6213728767660972,
                        0.6059962151632801,
                        0.594664724154829,
                        0.5947714799966144,
                        0.5937609397050608,
                        0.6531261075753263,
                        0.6493228634546689,
                        0.6679495159828513,
                        0.6842988160427044,
                        0.6298195490558045,
                        0.673532181245618,
                        0.6792229619746832,
                        0.6817879380373928,
                        0.6865592690760768,
                        0.6731508118126367,
                        0.6894321592511878,
                        0.5853731809117675,
                        0.6614421251503925,
                        0.6596264395854669,
                        0.675335986743619,
                        0.6585427906066642,
                        0.6738483670570184,
                        0.6795148110292919,
                        0.6719497563259097,
                        0.6725630699075218,
                        0.6578190030063655,
                        0.6551625585810272,
                        0.66484834434673,
                        0.6541880285981676,
                        0.6692951676662887,
                        0.64825536397923,
                        0.66944350427774,
                        0.6686653616338293,
                        0.6622993666511047,
                        0.6613981272565328,
                        0.6617100960964893,
                        0.6698115283466516,
                        0.6718373836472491,
                        0.6740623761565074,
                        0.6719318559787038,
                        0.6814145092428169,
                        0.666425652564378,
                        0.6638877890723961,
                        0.6712041672351077,
                        0.6716015611014263,
                        0.6675393685722725,
                        0.6650786878580504,
                        0.6666170168880212,
                        0.6672051215309787,
                        0.6808104247464728,
                        0.6606541729449319,
                        0.6608878549102563,
                        0.6715086015097853,
                        0.6621092852633136,
                        0.6624905172428854,
                        0.6622850481797747,
                        0.6589501753765639,
                        0.6581759679631117,
                        0.6627702944412638,
                        0.644554745842825,
                        0.6668889473375491,
                        0.6458050219738624,
                        0.6565764157063335
                      ]
                    },
                    {
                      "label": "num_leaves",
                      "range": [
                        20,
                        120
                      ],
                      "values": [
                        73,
                        48,
                        92,
                        48,
                        94,
                        53,
                        55,
                        77,
                        46,
                        57,
                        114,
                        119,
                        110,
                        118,
                        79,
                        106,
                        104,
                        101,
                        103,
                        101,
                        90,
                        84,
                        114,
                        115,
                        84,
                        84,
                        117,
                        107,
                        107,
                        101,
                        102,
                        101,
                        110,
                        110,
                        100,
                        91,
                        120,
                        91,
                        88,
                        120,
                        120,
                        96,
                        87,
                        105,
                        86,
                        92,
                        112,
                        93,
                        102,
                        91,
                        91,
                        90,
                        109,
                        99,
                        117,
                        94,
                        94,
                        89,
                        90,
                        94,
                        94,
                        114,
                        90,
                        89,
                        89,
                        118,
                        118,
                        118,
                        118,
                        119,
                        117,
                        115,
                        114,
                        89,
                        90,
                        51,
                        89,
                        116,
                        120,
                        111,
                        71,
                        43,
                        65,
                        116,
                        116,
                        34,
                        40,
                        32,
                        35,
                        26,
                        29,
                        117,
                        30,
                        116,
                        120,
                        115,
                        116,
                        44,
                        25,
                        27,
                        25,
                        24,
                        24,
                        24,
                        26,
                        120,
                        116,
                        27,
                        28,
                        26,
                        22,
                        22,
                        22,
                        20,
                        25,
                        26,
                        21,
                        24,
                        20,
                        20,
                        24,
                        28,
                        26,
                        43,
                        28,
                        28,
                        45,
                        30,
                        20,
                        21,
                        46,
                        24,
                        46,
                        25,
                        22,
                        53,
                        53,
                        23,
                        23,
                        23,
                        23,
                        54,
                        53,
                        51,
                        24,
                        37,
                        48,
                        37,
                        25,
                        36,
                        22,
                        25,
                        24,
                        54,
                        50,
                        55,
                        32,
                        22,
                        29
                      ]
                    },
                    {
                      "label": "pos_bagging_fract...",
                      "range": [
                        0.8168839857329464,
                        0.9999740329919601
                      ],
                      "values": [
                        0.8477767232840795,
                        0.9604470670515735,
                        0.8877193180364097,
                        0.896573338634613,
                        0.9905907766086356,
                        0.9753231306704755,
                        0.8271647837073594,
                        0.9069385628197258,
                        0.968560146671548,
                        0.9966427463113658,
                        0.997467019907177,
                        0.9942209793133492,
                        0.9999740329919601,
                        0.9326841796903316,
                        0.9197725631008394,
                        0.9435050082641603,
                        0.9770909087712063,
                        0.9787905571422253,
                        0.9794567278357679,
                        0.9404289512673845,
                        0.9369694886482369,
                        0.9375133343405919,
                        0.9628945047515443,
                        0.9637513361976282,
                        0.9628349779378956,
                        0.9383409519787168,
                        0.9446298151039483,
                        0.9917067559410851,
                        0.9135951727786137,
                        0.9898115473016064,
                        0.9897448558606708,
                        0.9797294481829203,
                        0.9911483686323419,
                        0.9765798005503552,
                        0.9945066367765827,
                        0.9518303753880778,
                        0.9612988039034362,
                        0.8872150002919821,
                        0.8650826622089187,
                        0.893563552962851,
                        0.8922997489896254,
                        0.9609507399456199,
                        0.8963557901410303,
                        0.8302506711724095,
                        0.8731702523770768,
                        0.8915729092725756,
                        0.8895518479893417,
                        0.9851138407601672,
                        0.9880232823326809,
                        0.9000275872336166,
                        0.8754600883264337,
                        0.8960611485934812,
                        0.896269794227694,
                        0.9038651433442523,
                        0.9968811865095261,
                        0.9836486584094563,
                        0.8600877424259443,
                        0.9100635423187424,
                        0.9002601211040885,
                        0.9093740209935619,
                        0.8961758385694251,
                        0.9960589041147714,
                        0.8985097247092602,
                        0.8985614216691856,
                        0.8984036441654274,
                        0.8959116414883189,
                        0.9003107421594994,
                        0.8995991390935426,
                        0.899297624339094,
                        0.8988418200538534,
                        0.8997356086259687,
                        0.9041075809435215,
                        0.9153615045871764,
                        0.9048841983649134,
                        0.8168839857329464,
                        0.90653340242293,
                        0.9148291307547148,
                        0.9975685725084411,
                        0.9082739152928915,
                        0.9081044918027904,
                        0.9082317490640361,
                        0.9007676706885782,
                        0.8929236363696412,
                        0.8932847978558033,
                        0.8916669814650652,
                        0.8909149370773211,
                        0.9020814900058137,
                        0.8996022581069357,
                        0.9053191640859201,
                        0.8963383672495433,
                        0.8954078134057779,
                        0.8973830263086928,
                        0.8967046462271806,
                        0.8999887007200165,
                        0.899601981632893,
                        0.9940435159717028,
                        0.9007735139758276,
                        0.9000501437986673,
                        0.9048302962367504,
                        0.9002722707498554,
                        0.9932549472575124,
                        0.90184454175136,
                        0.9040747057353414,
                        0.9018761109201683,
                        0.8999532218385147,
                        0.8982625737032551,
                        0.8987821750921693,
                        0.8987760561995788,
                        0.8986612395315282,
                        0.9018804688177543,
                        0.9062251110891157,
                        0.9113363590697886,
                        0.8964563469324841,
                        0.9039672597243248,
                        0.8946326024953599,
                        0.8966267584528782,
                        0.9027161418681076,
                        0.9032593608579247,
                        0.9038974066274884,
                        0.9019931961741091,
                        0.90884704815083,
                        0.8907503299180436,
                        0.9140038729009823,
                        0.8907544268315412,
                        0.8902606232286084,
                        0.8975595941547194,
                        0.8968423945654677,
                        0.8943483213552063,
                        0.9020518890152034,
                        0.9028683778037487,
                        0.8975613374215087,
                        0.8947473684191379,
                        0.8970148270339019,
                        0.8937187729490964,
                        0.8930979873368982,
                        0.8934617885435714,
                        0.8945070189750313,
                        0.8990306701992768,
                        0.888015484034003,
                        0.8885878748525191,
                        0.8931688548732664,
                        0.8857683872867163,
                        0.886530021418163,
                        0.8874358951938933,
                        0.9011735250852231,
                        0.9060278494587672,
                        0.8878735390484388,
                        0.8934697624852637,
                        0.9110113726880373,
                        0.9105789435121646,
                        0.9038591668102234,
                        0.9019901211943945,
                        0.8983321869000805,
                        0.8859968751786413,
                        0.8844414346583781,
                        0.882611203553053,
                        0.9011012940012744,
                        0.9258022790936201,
                        0.9045280492460498
                      ]
                    },
                    {
                      "label": "rate_drop",
                      "range": [
                        -1.9973293854457375,
                        -1.0158979225773275
                      ],
                      "ticktext": [
                        "0.0101",
                        "0.0964"
                      ],
                      "tickvals": [
                        -1.9973293854457375,
                        -1.0158979225773275
                      ],
                      "values": [
                        -1.4106130743838714,
                        -1.3176884263936144,
                        -1.471385805206421,
                        -1.7057606413370638,
                        -1.3242252083259742,
                        -1.9647783128278145,
                        -1.1357122141085438,
                        -1.310944343272683,
                        -1.6871320682357118,
                        -1.0158979225773275,
                        -1.0513748951542712,
                        -1.0444045283893795,
                        -1.0195457606461582,
                        -1.0443516475240557,
                        -1.5608694726243109,
                        -1.2285665353059403,
                        -1.2272835892322391,
                        -1.2391260452026795,
                        -1.2229067823844795,
                        -1.42894804356988,
                        -1.1018586757293536,
                        -1.4189931875780963,
                        -1.467362258245281,
                        -1.4830962193311295,
                        -1.1027114402471023,
                        -1.7965837295234364,
                        -1.1749345142055525,
                        -1.4382599056188137,
                        -1.4486729632560025,
                        -1.3100211064938936,
                        -1.302020145007505,
                        -1.478784928875243,
                        -1.473952350662807,
                        -1.4633997066929694,
                        -1.4693276975776977,
                        -1.1195581957575387,
                        -1.2967464638045063,
                        -1.424444005627534,
                        -1.4149249832492732,
                        -1.4219525924004008,
                        -1.4135181245864608,
                        -1.4493261540733617,
                        -1.4950442565648014,
                        -1.4517568248184143,
                        -1.49361636433102,
                        -1.548876813137755,
                        -1.5475521200672147,
                        -1.439250932474664,
                        -1.4584291302296613,
                        -1.5833034557888583,
                        -1.5621376620949003,
                        -1.4924215492827628,
                        -1.5104110002807902,
                        -1.493548413132623,
                        -1.4020502061921658,
                        -1.630440496399157,
                        -1.5168386611998983,
                        -1.5310695636755214,
                        -1.530280581287248,
                        -1.6060535668151807,
                        -1.5227782633574274,
                        -1.5218178919267682,
                        -1.5932578488421842,
                        -1.5889766183529939,
                        -1.5951258628727634,
                        -1.5523969259871218,
                        -1.5872646474414824,
                        -1.5809753625468639,
                        -1.5834995059842285,
                        -1.58436810227195,
                        -1.6515680012037757,
                        -1.607061198004007,
                        -1.599919651400603,
                        -1.5188547038204014,
                        -1.5235712791732698,
                        -1.5230673417763974,
                        -1.5190772783053923,
                        -1.5307706711367461,
                        -1.7519324064339565,
                        -1.5814318513021348,
                        -1.659029663625069,
                        -1.5822133850378797,
                        -1.6082266070591344,
                        -1.559887074545921,
                        -1.562072156584725,
                        -1.6178599183289981,
                        -1.5672459473017242,
                        -1.5967770936028687,
                        -1.5959893000732677,
                        -1.5701328674985322,
                        -1.5508666894348901,
                        -1.9889489936075544,
                        -1.5575202452078802,
                        -1.8762985807048347,
                        -1.5778861836278657,
                        -1.6391113974833538,
                        -1.6160074748536013,
                        -1.5692395944925104,
                        -1.8396764463291146,
                        -1.7767045889445312,
                        -1.572292954236054,
                        -1.674272756568951,
                        -1.859174094006359,
                        -1.8855653085256825,
                        -1.9600224764765108,
                        -1.9049683608471466,
                        -1.9548500538000155,
                        -1.9466494581324545,
                        -1.6795692321582867,
                        -1.9603041655214613,
                        -1.7807699575269398,
                        -1.975432463825738,
                        -1.9973293854457375,
                        -1.7523797813956037,
                        -1.9494783474455202,
                        -1.9752188455865647,
                        -1.7799873137310984,
                        -1.9970389284982593,
                        -1.9928218121086252,
                        -1.7612530090810632,
                        -1.9919222557404777,
                        -1.9871099149136882,
                        -1.7720434477101237,
                        -1.6502038316120449,
                        -1.647857749094985,
                        -1.6408664269532298,
                        -1.6913793140485545,
                        -1.9431176380133441,
                        -1.6965505116005026,
                        -1.6963986238936586,
                        -1.6849916223960246,
                        -1.6189024916930506,
                        -1.5676893233020555,
                        -1.5679859213937017,
                        -1.6752135641105563,
                        -1.6684753243986505,
                        -1.569916124785624,
                        -1.5796378669137854,
                        -1.6752890772727622,
                        -1.5562999039880834,
                        -1.669612251797479,
                        -1.5334548400320007,
                        -1.6668120156776187,
                        -1.5306134077229014,
                        -1.553330684516171,
                        -1.5790933285095894,
                        -1.51572309696214,
                        -1.9679776497230546,
                        -1.9317953725258628,
                        -1.5168274481892536,
                        -1.5780798363613497,
                        -1.7152896485098528,
                        -1.7158127893599737,
                        -1.4866665570501814,
                        -1.4895394712127188,
                        -1.7511927586399973,
                        -1.5561251924509771,
                        -1.7791723655352574,
                        -1.6328245159326586
                      ]
                    },
                    {
                      "label": "skip_drop",
                      "range": [
                        -0.9986549117335661,
                        -0.012678604524853934
                      ],
                      "ticktext": [
                        "0.1",
                        "0.971"
                      ],
                      "tickvals": [
                        -0.9986549117335661,
                        -0.012678604524853934
                      ],
                      "values": [
                        -0.15814979850025135,
                        -0.8154434249957188,
                        -0.4957517178805669,
                        -0.6415049369208771,
                        -0.4367344857206217,
                        -0.5122585679265913,
                        -0.7036950191130064,
                        -0.10733853286753652,
                        -0.13732795045808455,
                        -0.878872686307517,
                        -0.6740703810964873,
                        -0.9986549117335661,
                        -0.9126422297455173,
                        -0.670085103422849,
                        -0.2751529895843013,
                        -0.5706328155703939,
                        -0.6034657785809964,
                        -0.7821122415153753,
                        -0.5967624590513759,
                        -0.6008654469614103,
                        -0.8853085424209559,
                        -0.42643375768957953,
                        -0.7244535994975783,
                        -0.7253716606769932,
                        -0.9868499351466352,
                        -0.8431134871258438,
                        -0.5820495241428324,
                        -0.3329225832873164,
                        -0.6983170107212502,
                        -0.35134955989750866,
                        -0.4220480790447146,
                        -0.9007211474747384,
                        -0.41459162969843194,
                        -0.40269726556751656,
                        -0.8972687212302601,
                        -0.8150599554622421,
                        -0.4805207332272479,
                        -0.2898034256648286,
                        -0.2821427105334383,
                        -0.2733219087754676,
                        -0.43237476469456526,
                        -0.61917709988633,
                        -0.29631842013320286,
                        -0.29656500405500374,
                        -0.47736393324172866,
                        -0.37696362634454356,
                        -0.3766739001197991,
                        -0.382664767626912,
                        -0.45518725798459486,
                        -0.3743672729488798,
                        -0.447795269419459,
                        -0.4165715162866602,
                        -0.42518999953876274,
                        -0.012678604524853934,
                        -0.5013354261442753,
                        -0.4072867093763615,
                        -0.39330668862717444,
                        -0.39511704981671775,
                        -0.3926401705949032,
                        -0.3905697503099463,
                        -0.3891583273738656,
                        -0.3983048817686691,
                        -0.4086117587423391,
                        -0.40817470463527744,
                        -0.41028031871851656,
                        -0.4041986431778268,
                        -0.40453807517538815,
                        -0.4052379923899942,
                        -0.4032162099098359,
                        -0.40596039529112965,
                        -0.4062014227388026,
                        -0.37037610245152464,
                        -0.3794615196443363,
                        -0.42024705761542036,
                        -0.42768904973749167,
                        -0.4183444769474722,
                        -0.4170571509969442,
                        -0.43016243307967283,
                        -0.3908426179094432,
                        -0.436557290338486,
                        -0.46071010868412415,
                        -0.3931432589448433,
                        -0.39747106067392385,
                        -0.402816209082978,
                        -0.40775761799649457,
                        -0.40839054674619846,
                        -0.379177244943678,
                        -0.38163566118468867,
                        -0.36077665622900046,
                        -0.424314146413212,
                        -0.3871709318215061,
                        -0.38292311924809075,
                        -0.38041896512892825,
                        -0.321866579436633,
                        -0.30907531654563775,
                        -0.3454643653746092,
                        -0.3986067173130955,
                        -0.31074575632626966,
                        -0.3491395974245249,
                        -0.46781161140900884,
                        -0.31380400971364525,
                        -0.31870145749853385,
                        -0.3297603908259075,
                        -0.29700639672623064,
                        -0.273893674939488,
                        -0.2723996895171255,
                        -0.28021605838753244,
                        -0.29788025494850545,
                        -0.29699027235846537,
                        -0.23319668016272765,
                        -0.30166370005554133,
                        -0.3026176502921187,
                        -0.30476478846467603,
                        -0.31491106529792423,
                        -0.2987581185133478,
                        -0.25539466249615483,
                        -0.28789820411668926,
                        -0.26461798511443557,
                        -0.34325932485809646,
                        -0.3418136592826343,
                        -0.3402998309960822,
                        -0.34935740232555684,
                        -0.288572250629214,
                        -0.31654087063241715,
                        -0.3127796262826782,
                        -0.31361709600415355,
                        -0.4465596271594139,
                        -0.27673561399016516,
                        -0.4388406199797921,
                        -0.4484347223314768,
                        -0.33269748360179724,
                        -0.286208488171564,
                        -0.33176180608896855,
                        -0.28511635864871676,
                        -0.49305692994173517,
                        -0.49371619445016557,
                        -0.4702737410557487,
                        -0.49177349525794556,
                        -0.4224382320889688,
                        -0.22641493565570736,
                        -0.4275666927971602,
                        -0.5213643876973119,
                        -0.5131564772575783,
                        -0.5188451712760149,
                        -0.5235765847474875,
                        -0.5249397741528989,
                        -0.5689397792003883,
                        -0.3117233687180886,
                        -0.5824049948655019,
                        -0.5127227803842922,
                        -0.5424001366820612,
                        -0.5417937189181206,
                        -0.30910517286905287,
                        -0.5532065323941615,
                        -0.6572315406394851,
                        -0.6482692280863416,
                        -0.5331779340068525,
                        -0.66209719651903,
                        -0.37662367937574204
                      ]
                    }
                  ],
                  "labelangle": 30,
                  "labelside": "bottom",
                  "line": {
                    "color": [
                      0.20591527081035405,
                      0.18432587042658996,
                      0.2017252393053198,
                      0.20939215614545534,
                      0.21694154274891075,
                      0.19557172647430976,
                      0.2116721936623447,
                      0.2149995079140523,
                      0.20894907065431106,
                      0.21337754878330842,
                      0.21594430218886623,
                      0.21840865352960734,
                      0.21689928718955032,
                      0.21746519962969085,
                      0.2122374265445271,
                      0.2169676013553105,
                      0.21452649113020192,
                      0.21870195771956413,
                      0.21314188081079988,
                      0.21764853832165518,
                      0.21726310557200518,
                      0.21980785997997726,
                      0.22140519391633035,
                      0.21462998286352888,
                      0.21449502421005118,
                      0.21467491406188705,
                      0.21425455117894693,
                      0.2248688672832479,
                      0.21494055403752607,
                      0.21800213895852377,
                      0.21909853007341332,
                      0.2158862026443545,
                      0.21715161908149327,
                      0.22081973335343613,
                      0.2150227672618223,
                      0.21544606897483262,
                      0.22106983901493008,
                      0.21868104604231114,
                      0.2192334329588909,
                      0.22490738374629166,
                      0.21725828276911613,
                      0.21911846648449718,
                      0.21571172240563677,
                      0.21665742135339303,
                      0.21894495768116426,
                      0.21969059200649976,
                      0.2223686189111867,
                      0.21921927354660448,
                      0.21841621008605686,
                      0.22404359264219736,
                      0.21911923219265103,
                      0.2212116642940709,
                      0.22494328001929084,
                      0.21488941568886194,
                      0.22312924907539963,
                      0.22703726645103037,
                      0.22123755312941368,
                      0.22372304080730698,
                      0.23126543549399292,
                      0.22027256225917718,
                      0.2212358758585499,
                      0.22289962986256007,
                      0.22344486692942458,
                      0.22575718215845572,
                      0.22383118219194942,
                      0.22992294629873106,
                      0.2362583793115674,
                      0.21743805325159465,
                      0.22767538830095568,
                      0.2223132351050328,
                      0.22609548383311026,
                      0.22158229959010187,
                      0.2183778901913683,
                      0.22176188904631067,
                      0.21830470872637692,
                      0.23470978050260904,
                      0.21598005923684208,
                      0.2183558837829281,
                      0.22019589334248635,
                      0.22208276004455385,
                      0.21823563503743088,
                      0.22952632188775923,
                      0.22287904911870499,
                      0.2348520335042945,
                      0.22462584943743785,
                      0.22220540288974444,
                      0.21865773996161186,
                      0.22458201557010543,
                      0.22239888345350756,
                      0.22941944843340029,
                      0.23264150490512567,
                      0.22494867710293512,
                      0.22226162076624373,
                      0.2248486735125018,
                      0.227906055836346,
                      0.22660390977161432,
                      0.22720675728783557,
                      0.23484182324275996,
                      0.22138839872485355,
                      0.23055479564286346,
                      0.2225597034513424,
                      0.23275876025854453,
                      0.22192011654524454,
                      0.23417836453788574,
                      0.2249157660110681,
                      0.22287015275787342,
                      0.22292403497155405,
                      0.2284315716537463,
                      0.21933199819108856,
                      0.2216684894393941,
                      0.22546107347924665,
                      0.22136376208727646,
                      0.22799140416416278,
                      0.2180669676850985,
                      0.22792173354093537,
                      0.22775708502739572,
                      0.22888636954127434,
                      0.2232674718130064,
                      0.22209182693211754,
                      0.23394653485360636,
                      0.21850598962337933,
                      0.22555567138325316,
                      0.22652756528408619,
                      0.22511493581736083,
                      0.2242723851526985,
                      0.2342365849353873,
                      0.22466027321618562,
                      0.21881053314075719,
                      0.23429135104326804,
                      0.22312992866491013,
                      0.22180939292600477,
                      0.22839549327745798,
                      0.22280582339302885,
                      0.22050910442616392,
                      0.220809015514638,
                      0.23488249565892122,
                      0.22411570103774184,
                      0.23150655502464193,
                      0.22306165921549037,
                      0.2212484636732289,
                      0.22587109272234646,
                      0.2284811001831953,
                      0.2253525961171396,
                      0.22578632700713164,
                      0.236196652323164,
                      0.21873524053947455,
                      0.23290516968667677,
                      0.22888932295887834,
                      0.2319202787966522,
                      0.22279420940071612,
                      0.228603903947326,
                      0.22226054262587297,
                      0.22600459138048726,
                      0.2205446880923915,
                      0.23251361849488492,
                      0.22939387129624209,
                      0.21988516705592712,
                      0.22777300195320258,
                      0.22696650547783728
                    ],
                    "colorbar": {
                      "title": {
                        "text": "Objective Value"
                      }
                    },
                    "colorscale": [
                      [
                        0,
                        "rgb(247,251,255)"
                      ],
                      [
                        0.125,
                        "rgb(222,235,247)"
                      ],
                      [
                        0.25,
                        "rgb(198,219,239)"
                      ],
                      [
                        0.375,
                        "rgb(158,202,225)"
                      ],
                      [
                        0.5,
                        "rgb(107,174,214)"
                      ],
                      [
                        0.625,
                        "rgb(66,146,198)"
                      ],
                      [
                        0.75,
                        "rgb(33,113,181)"
                      ],
                      [
                        0.875,
                        "rgb(8,81,156)"
                      ],
                      [
                        1,
                        "rgb(8,48,107)"
                      ]
                    ],
                    "reversescale": false,
                    "showscale": true
                  },
                  "type": "parcoords"
                }
              ],
              "layout": {
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "heatmapgl": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmapgl"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                },
                "title": {
                  "text": "Parallel Coordinate Plot"
                }
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "opt.visualization.plot_parallel_coordinate(lgb_study.get(boosters[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "cliponaxis": false,
                  "hovertemplate": [
                    "booster (CategoricalDistribution): 0.0<extra></extra>",
                    "max_depth (IntUniformDistribution): 0.007647714564338191<extra></extra>",
                    "cat_l2 (UniformDistribution): 0.009298605674093864<extra></extra>",
                    "num_leaves (IntUniformDistribution): 0.012188117979548805<extra></extra>",
                    "max_cat_threshold (IntUniformDistribution): 0.014552890331456023<extra></extra>",
                    "min_data_in_leaf (IntUniformDistribution): 0.016453558754459145<extra></extra>",
                    "cat_smooth (UniformDistribution): 0.019780921546339255<extra></extra>",
                    "min_child_weight (IntUniformDistribution): 0.021057104784370225<extra></extra>",
                    "lambda_l2 (LogUniformDistribution): 0.04031988228858457<extra></extra>",
                    "eta (UniformDistribution): 0.0428260797597804<extra></extra>",
                    "min_data_per_group (IntUniformDistribution): 0.04492187924294728<extra></extra>",
                    "lambda_l1 (UniformDistribution): 0.060031252012006917<extra></extra>",
                    "feature_fraction (UniformDistribution): 0.06993043407833156<extra></extra>",
                    "top_rate (UniformDistribution): 0.172739485552273<extra></extra>",
                    "max_bin (IntUniformDistribution): 0.1889966532510302<extra></extra>",
                    "min_split_gain (UniformDistribution): 0.2792554201804404<extra></extra>"
                  ],
                  "marker": {
                    "color": "rgb(66,146,198)"
                  },
                  "orientation": "h",
                  "text": [
                    "0.0",
                    "0.007647714564338191",
                    "0.009298605674093864",
                    "0.012188117979548805",
                    "0.014552890331456023",
                    "0.016453558754459145",
                    "0.019780921546339255",
                    "0.021057104784370225",
                    "0.04031988228858457",
                    "0.0428260797597804",
                    "0.04492187924294728",
                    "0.060031252012006917",
                    "0.06993043407833156",
                    "0.172739485552273",
                    "0.1889966532510302",
                    "0.2792554201804404"
                  ],
                  "textposition": "outside",
                  "texttemplate": "%{text:.2f}",
                  "type": "bar",
                  "x": [
                    0,
                    0.007647714564338191,
                    0.009298605674093864,
                    0.012188117979548805,
                    0.014552890331456023,
                    0.016453558754459145,
                    0.019780921546339255,
                    0.021057104784370225,
                    0.04031988228858457,
                    0.0428260797597804,
                    0.04492187924294728,
                    0.060031252012006917,
                    0.06993043407833156,
                    0.172739485552273,
                    0.1889966532510302,
                    0.2792554201804404
                  ],
                  "y": [
                    "booster",
                    "max_depth",
                    "cat_l2",
                    "num_leaves",
                    "max_cat_threshold",
                    "min_data_in_leaf",
                    "cat_smooth",
                    "min_child_weight",
                    "lambda_l2",
                    "eta",
                    "min_data_per_group",
                    "lambda_l1",
                    "feature_fraction",
                    "top_rate",
                    "max_bin",
                    "min_split_gain"
                  ]
                }
              ],
              "layout": {
                "showlegend": false,
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "heatmapgl": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmapgl"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                },
                "title": {
                  "text": "Hyperparameter Importances"
                },
                "xaxis": {
                  "title": {
                    "text": "Importance for Objective Value"
                  }
                },
                "yaxis": {
                  "title": {
                    "text": "Hyperparameter"
                  }
                }
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "opt.visualization.plot_param_importances(lgb_study.get(boosters[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "dimensions": [
                    {
                      "label": "Objective Value",
                      "range": [
                        0.22118355006291165,
                        0.26532196167545063
                      ],
                      "values": [
                        0.23799384286273395,
                        0.25257026611385686,
                        0.23607234921980993,
                        0.23351004392260122,
                        0.22118355006291165,
                        0.2368054863573365,
                        0.23467817578951994,
                        0.2492183617272187,
                        0.2508034667728444,
                        0.24444355146697733,
                        0.24638441809695522,
                        0.24066073110273717,
                        0.2500992724128512,
                        0.2512497389906705,
                        0.24780014207800183,
                        0.24345589003523718,
                        0.24950559698288596,
                        0.2512468585781459,
                        0.24966547399488767,
                        0.2527316371024155,
                        0.2514909232994099,
                        0.2511396047960298,
                        0.2586352644702073,
                        0.2527264459805575,
                        0.25572363816910854,
                        0.25022635152072403,
                        0.24556031408083032,
                        0.24675938835375505,
                        0.2517645801757151,
                        0.2538164492920105,
                        0.2525943989047087,
                        0.24974231033993394,
                        0.2532202192933685,
                        0.25582444275876653,
                        0.2529551831471422,
                        0.24839273295219666,
                        0.2527985746283016,
                        0.25097194701688813,
                        0.2556160224341649,
                        0.2510635252106125,
                        0.2514807436210522,
                        0.24684229713746925,
                        0.2470559585496679,
                        0.2502647364386594,
                        0.25222208388466083,
                        0.25400125143797925,
                        0.2552580905005643,
                        0.2528342014614715,
                        0.2493985001778562,
                        0.2528384528802303,
                        0.2550233498938586,
                        0.2523083029470582,
                        0.25483072502545034,
                        0.24847497589226655,
                        0.2574753029167793,
                        0.25608749134198927,
                        0.2511703011467725,
                        0.2547536078051821,
                        0.2529914277269956,
                        0.25209671945226275,
                        0.2515369929044722,
                        0.2548329181498087,
                        0.25068697393310213,
                        0.2501431184287837,
                        0.2540030651641933,
                        0.2507047934728426,
                        0.25641341551762764,
                        0.25780701625469604,
                        0.25521824386459036,
                        0.2557960577331986,
                        0.2534074976345324,
                        0.2585956950317595,
                        0.25957896568406236,
                        0.252325709986834,
                        0.251712426654483,
                        0.25704328332362836,
                        0.2586001109656427,
                        0.253032392102843,
                        0.2582294697836728,
                        0.25615608164991127,
                        0.2597090938462958,
                        0.25817099974935753,
                        0.25732394817011095,
                        0.251840973701201,
                        0.25554155233484255,
                        0.2538934288059256,
                        0.2604836395582832,
                        0.25924654113987,
                        0.252060534249514,
                        0.25873673802174624,
                        0.2544991930599525,
                        0.2555580966475103,
                        0.25971665260699334,
                        0.26240806334113453,
                        0.25987806370287453,
                        0.2617452826463283,
                        0.2588429180727659,
                        0.26140396995493137,
                        0.25751223896826564,
                        0.2552430711790555,
                        0.25949895623877345,
                        0.26532196167545063,
                        0.2635506977103081,
                        0.258422205804421,
                        0.2607411123181213,
                        0.26077220028163106,
                        0.2564147969225439,
                        0.2618370498319524,
                        0.2574255385529174,
                        0.256073589906999,
                        0.26231410783114406,
                        0.25693832431455654,
                        0.26010458097199834,
                        0.25641098202249235,
                        0.26214657077906367,
                        0.25970132700171716,
                        0.2612381465463163,
                        0.25838319112920943,
                        0.26193894135573725,
                        0.2607055197450044,
                        0.2558238819843697,
                        0.26039411892238445,
                        0.2596285073734872,
                        0.25672325638029103,
                        0.25835134322104664,
                        0.25779739913631283,
                        0.2616895893152762,
                        0.25981441847356196,
                        0.2560462182784489,
                        0.25273645729321736,
                        0.2618738353401766,
                        0.2577028990584764,
                        0.25564175186673194,
                        0.25320855897174505,
                        0.2538377838640009,
                        0.2526526964817669,
                        0.2569033566900406,
                        0.25799946734201123,
                        0.2534882015509653,
                        0.25968570363497123,
                        0.256679453449559,
                        0.2592257173283327,
                        0.26163534353357887,
                        0.2599259310342126,
                        0.2548622979379641,
                        0.2613736175677654,
                        0.26220709023889477,
                        0.256967005043854,
                        0.25695966823922817,
                        0.2579806183913517,
                        0.26008790595455256,
                        0.2542587612681432,
                        0.25510121711750094,
                        0.2557056361980953,
                        0.2559235751087734,
                        0.2588756602797714,
                        0.26361563888417805,
                        0.2629685046632935,
                        0.26430512690245644,
                        0.25818162361334757,
                        0.25844180234975545,
                        0.2618657322486643,
                        0.258159260340855,
                        0.2560703510169188,
                        0.25513589733560715,
                        0.2603661126674567,
                        0.2609181723092779,
                        0.25602619550937156,
                        0.2583086996205922,
                        0.25882218456222217,
                        0.2602180736801283,
                        0.26155620250780726,
                        0.26080104715505814,
                        0.257790014753141,
                        0.25705983134166244,
                        0.25906326121060286
                      ]
                    },
                    {
                      "label": "booster",
                      "range": [
                        0,
                        0
                      ],
                      "ticktext": [
                        "goss"
                      ],
                      "tickvals": [
                        0
                      ],
                      "values": [
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0,
                        0
                      ]
                    },
                    {
                      "label": "cat_l2",
                      "range": [
                        0.002003953513231411,
                        0.003492744665085241
                      ],
                      "values": [
                        0.0023770012915399963,
                        0.0021101658783661873,
                        0.0028417675464967682,
                        0.0026838345277320017,
                        0.003078867371690268,
                        0.002289983971803947,
                        0.0024132102767287396,
                        0.0027841725706150653,
                        0.0030349370503348133,
                        0.003212274301469588,
                        0.0030896682216095496,
                        0.0026298611632777085,
                        0.0025623541992967954,
                        0.003338568514331944,
                        0.003344324549329337,
                        0.002983034241671877,
                        0.0034781507601363867,
                        0.0034552543744967136,
                        0.003492744665085241,
                        0.003476462365499494,
                        0.003329412172458045,
                        0.0033028337208436637,
                        0.0032772023694486565,
                        0.0033354851799437123,
                        0.0029309545449726,
                        0.0031884562876432574,
                        0.0032661167542221313,
                        0.0033328921732779923,
                        0.003360391952229691,
                        0.0021402991830204113,
                        0.0034524300466538347,
                        0.0032287757715720906,
                        0.0022947457545105993,
                        0.0022903591385164917,
                        0.0022927906399337096,
                        0.002132515532332704,
                        0.003230957908797958,
                        0.002003953513231411,
                        0.0024357020613995782,
                        0.002355522227842682,
                        0.0023397099447355673,
                        0.0024007292255140457,
                        0.002327901446649067,
                        0.002326397594840918,
                        0.0023657614024807333,
                        0.002371045508966523,
                        0.0022140594881332482,
                        0.002460605015055308,
                        0.0024675175494663936,
                        0.002452058825434117,
                        0.0022632086318053455,
                        0.0022821558718602994,
                        0.0024003964954334113,
                        0.0021586525896883234,
                        0.0023029267910544774,
                        0.0021453850250373985,
                        0.00238015344998232,
                        0.003223897555472623,
                        0.003311403477336039,
                        0.003175857717234037,
                        0.0032220737084165305,
                        0.0031811562702252754,
                        0.00321220133744472,
                        0.0032987906927439406,
                        0.0032617971489513685,
                        0.00331443522709238,
                        0.003255705324648504,
                        0.0032485821984712298,
                        0.003236452776233787,
                        0.003256288941373499,
                        0.003259828937530485,
                        0.003381911446605451,
                        0.0032652330108267065,
                        0.003257510026950122,
                        0.003230800965287415,
                        0.003232685135269417,
                        0.0032388336994090077,
                        0.002238224980914861,
                        0.0032126167643749693,
                        0.00319707542309611,
                        0.0028853336888426946,
                        0.0032037249189971317,
                        0.0032001733007180518,
                        0.003193411423903983,
                        0.0031945555342809645,
                        0.0022207990954472767,
                        0.002829026237298389,
                        0.003182373495486428,
                        0.0032062980771053328,
                        0.0032205388577900835,
                        0.0028823102475582837,
                        0.0030873755467589513,
                        0.0032000458917164232,
                        0.003165236552108504,
                        0.0031681411832879176,
                        0.002813816783319242,
                        0.0028865234725149766,
                        0.0028121700036749337,
                        0.003154403613692922,
                        0.0031019048268435124,
                        0.0028452933437894496,
                        0.002832945022550406,
                        0.0028281118573913913,
                        0.0028276997899626195,
                        0.002833654566070066,
                        0.002827241194271848,
                        0.002824352013629863,
                        0.0028250248437695245,
                        0.003140134506661768,
                        0.002818198072705453,
                        0.002822478906702202,
                        0.0028257769656412734,
                        0.0028347149885760243,
                        0.00283368043193138,
                        0.00284295733715014,
                        0.002854828630523567,
                        0.002848247384919744,
                        0.0028463478936136535,
                        0.0028641932563058157,
                        0.0027691319786029333,
                        0.002803076562919697,
                        0.002740287782138739,
                        0.002735770580978544,
                        0.0027425458687300856,
                        0.0027371720175186722,
                        0.0027311280366707482,
                        0.002731803102376289,
                        0.0028701950825657943,
                        0.002879959364226462,
                        0.0028828874055813183,
                        0.002699647054836767,
                        0.0028780642981563066,
                        0.0028075455313584415,
                        0.0029251883128576903,
                        0.0028475792849144243,
                        0.0028477525046346555,
                        0.0028495849622859294,
                        0.0027640883703447627,
                        0.0027642235350393593,
                        0.0027242627325861153,
                        0.002900748297866823,
                        0.0028265584852396135,
                        0.002788236962411542,
                        0.002724654556618487,
                        0.002870879281768578,
                        0.0027816684029561586,
                        0.0028683970662144423,
                        0.0028756617356547466,
                        0.0026708222848927403,
                        0.0028656244978029796,
                        0.002876983485159428,
                        0.00278895276534613,
                        0.002822254570311552,
                        0.002747387253511683,
                        0.0027433262678651206,
                        0.0028645353010103374,
                        0.00286247895908472,
                        0.002859503976637491,
                        0.002870937681183348,
                        0.003015538253026762,
                        0.0029167805895193312,
                        0.0028369848128228826,
                        0.002807430015290493,
                        0.002969665957676158,
                        0.0028064107411250967,
                        0.0028544171254900248,
                        0.0027126297438006823,
                        0.00265774074333722,
                        0.0027652600615917715,
                        0.002772142825801889,
                        0.0028324053852776163,
                        0.002913297573556813,
                        0.0029515723592510976,
                        0.002960832412384209,
                        0.0028745506667827952,
                        0.0028298976170453437
                      ]
                    },
                    {
                      "label": "cat_smooth",
                      "range": [
                        2.0071509287497813,
                        6.498855316542055
                      ],
                      "values": [
                        5.925189282006059,
                        5.875657935636863,
                        5.044862784912935,
                        2.8776718573188838,
                        2.944081300144676,
                        3.736469991415106,
                        2.2464577801344174,
                        5.187656278492092,
                        4.346751175619485,
                        4.440252864489608,
                        5.570368080724998,
                        2.878248625647796,
                        3.9121341538579193,
                        6.484259040403243,
                        6.407852102823963,
                        6.352798997057539,
                        6.176726233656675,
                        6.465247323023476,
                        6.4373170065380725,
                        5.780442094305964,
                        5.727930650844502,
                        5.792291372653756,
                        5.746801066352235,
                        5.986799330377028,
                        5.38516095101839,
                        5.344419589449092,
                        5.874726257609183,
                        6.498855316542055,
                        2.0108351504842106,
                        3.3366251614319733,
                        6.486189937213192,
                        5.951127791103988,
                        2.0071509287497813,
                        2.084180290308832,
                        6.061688130175775,
                        2.5032511955491348,
                        2.7074375998474802,
                        2.0967219751531543,
                        2.3664596307701418,
                        2.269132121020348,
                        2.3334991143519717,
                        2.3257581432369987,
                        2.354578328618746,
                        2.3201718256527557,
                        3.073903411643721,
                        2.252700344833433,
                        2.75227844430191,
                        2.748356341303558,
                        2.4189267032041584,
                        2.4392679703317945,
                        2.7651745843532742,
                        2.1781462240176546,
                        2.824035728097634,
                        2.592036006628838,
                        3.4366897115950374,
                        2.592999505162176,
                        2.780513474187998,
                        5.764556530767181,
                        5.932051508153088,
                        6.112676156722897,
                        5.895815260937384,
                        5.975673355833383,
                        6.148665982073387,
                        2.354242229107588,
                        2.3807229113311017,
                        2.384096893546697,
                        5.761459288062921,
                        5.6929916796024385,
                        3.4545776212869925,
                        3.4656599535017945,
                        2.2369692983644067,
                        2.5081754282891353,
                        3.3603845258493603,
                        3.4224007258358733,
                        3.2921980676458196,
                        3.1869296577229367,
                        3.179206125401603,
                        3.2760949079687536,
                        5.50642247112247,
                        5.53841349755831,
                        5.587581124171321,
                        6.01334603724808,
                        3.061779608159832,
                        3.3480846578895034,
                        3.0621086619876925,
                        5.524153377690688,
                        5.505662862511171,
                        5.504507108628863,
                        5.61810724519225,
                        5.489914924041577,
                        5.316410314391837,
                        5.595126887470398,
                        5.466511034519699,
                        5.342984404306893,
                        5.395604892313248,
                        5.332712093786356,
                        5.307161049706111,
                        5.308097139520911,
                        5.373980898003311,
                        5.4657238395228,
                        5.382734426908223,
                        5.4111463094755266,
                        5.2236758042633396,
                        5.214493603466551,
                        5.397757550224098,
                        5.231441645851645,
                        5.253318802571415,
                        5.229860169885731,
                        5.26330859663257,
                        5.244107349472462,
                        5.131454924407051,
                        5.397524896132993,
                        5.367053281606707,
                        5.131855015226831,
                        5.153043239908081,
                        5.3910995734233635,
                        5.103191441723849,
                        5.380566495108466,
                        5.0462916199176995,
                        5.075700300674777,
                        5.008612960084298,
                        5.025398868459798,
                        5.054132471345144,
                        5.073612978045959,
                        5.4383223736568915,
                        5.174309473874068,
                        4.777910079023194,
                        5.069770257184889,
                        5.07118906567914,
                        4.845472558300112,
                        5.426807477800371,
                        5.196840238844837,
                        5.0911277709613225,
                        5.434278320287494,
                        5.416886477568411,
                        5.419039233421348,
                        4.926958717377864,
                        4.926632607576773,
                        4.920750720367718,
                        5.163756804321824,
                        5.623731298258112,
                        5.04746517896592,
                        5.21251643699789,
                        5.234173687142705,
                        5.236460349426332,
                        5.241292994917008,
                        5.23174909140096,
                        5.261405265978644,
                        5.266715953497639,
                        5.335584246461105,
                        5.327396368870891,
                        5.188385220901673,
                        5.234022277602582,
                        5.26816568652192,
                        5.291452942692799,
                        5.2960435785097815,
                        5.110380873711029,
                        5.2711531642420155,
                        5.305339407042878,
                        5.476010753648876,
                        5.486593455370894,
                        5.192204019796349,
                        4.966713716577458,
                        4.97162682217146,
                        4.948523793546177,
                        5.097819845606036,
                        5.277706198344079,
                        5.168986226138609,
                        5.029251753970411,
                        5.052214346464238,
                        5.299663803574919,
                        5.320249339720423,
                        5.419594362075896,
                        5.162967968265273,
                        5.414109949046793,
                        5.141881886968699
                      ]
                    },
                    {
                      "label": "eta",
                      "range": [
                        0.07006072359699109,
                        0.07965514268941513
                      ],
                      "values": [
                        0.07395544662518917,
                        0.0720988004858504,
                        0.07058638823742382,
                        0.07110220635117667,
                        0.07730713237684239,
                        0.07771538203098736,
                        0.07276700259078742,
                        0.07373155565023351,
                        0.07956437764919257,
                        0.07691775286557866,
                        0.07483709578465891,
                        0.07768871648759197,
                        0.07006072359699109,
                        0.072507482537094,
                        0.07954016546939274,
                        0.0792773095833003,
                        0.07545285129999298,
                        0.07965514268941513,
                        0.07944034482025142,
                        0.07597134824437608,
                        0.07627348307845115,
                        0.07283711809575052,
                        0.07275648093566002,
                        0.07427751470155212,
                        0.0746189977207041,
                        0.07096403107920296,
                        0.07674499055078729,
                        0.07791136796938136,
                        0.07765377805294285,
                        0.07583453376853479,
                        0.0741476559122299,
                        0.07040917286130823,
                        0.07287362144407807,
                        0.07310487072999278,
                        0.07585476273654156,
                        0.0752856139887967,
                        0.07635194997003142,
                        0.07523739009197762,
                        0.07560345483194802,
                        0.07645134664701417,
                        0.07650920525383968,
                        0.07269922075803918,
                        0.0726786261297619,
                        0.07642267509973814,
                        0.07272250823600593,
                        0.07465147702274161,
                        0.07564186750772522,
                        0.0755981253058213,
                        0.07565545915906068,
                        0.07470288219886123,
                        0.07477121266394847,
                        0.07458197792417463,
                        0.07540096560735919,
                        0.07510106539875495,
                        0.0751545007551665,
                        0.07509887517509724,
                        0.07658927028424573,
                        0.07448115912820229,
                        0.0736243489207871,
                        0.07427786952775801,
                        0.0742704551770835,
                        0.07438570313020176,
                        0.07433878687563218,
                        0.0732658468242701,
                        0.07279633713880855,
                        0.07261235170467163,
                        0.07587436137069126,
                        0.07581739384727539,
                        0.07405005313559547,
                        0.07225380041380824,
                        0.07299207915092616,
                        0.07288717793715525,
                        0.0719376386742061,
                        0.07228816616685536,
                        0.07341357180948156,
                        0.07245454622809752,
                        0.07303657204066263,
                        0.07247627296548721,
                        0.07292852996000428,
                        0.07299451033183336,
                        0.0728941903009486,
                        0.07284108917968743,
                        0.07297917533529792,
                        0.07275687122237166,
                        0.07280551978419739,
                        0.07305691954046083,
                        0.07307773261425457,
                        0.07312489821356793,
                        0.07314116102631814,
                        0.07324432591163188,
                        0.07302692840013619,
                        0.0732018340208607,
                        0.07300307938121607,
                        0.07328084546594568,
                        0.07322955378015196,
                        0.07333008761519436,
                        0.07329217401706718,
                        0.07325397573736867,
                        0.07321032375626775,
                        0.07333643423121577,
                        0.07324238889395632,
                        0.07328979517371839,
                        0.07329544843846406,
                        0.07324435810516755,
                        0.07320728681697034,
                        0.07324433833379973,
                        0.07326978769902777,
                        0.07332544548522159,
                        0.0733372675748052,
                        0.07335106103682354,
                        0.07349747726013228,
                        0.07354483785704184,
                        0.07350965660905269,
                        0.0735265978534604,
                        0.07358936866785358,
                        0.07361294100125289,
                        0.07350987083434218,
                        0.07360378559790363,
                        0.07352590773132658,
                        0.07351647809772985,
                        0.07350067558718627,
                        0.07375889331673605,
                        0.07335665960935879,
                        0.07335234901431807,
                        0.07331023311261092,
                        0.07338612957009763,
                        0.07335294055086532,
                        0.07335822382872904,
                        0.07336185466253103,
                        0.07333046943170753,
                        0.07356907223792158,
                        0.0736110955239096,
                        0.07314661947028794,
                        0.07347170403948904,
                        0.0734291291972317,
                        0.0734576434845879,
                        0.07341829392199688,
                        0.07340047698673181,
                        0.0732108057719012,
                        0.07322305755843667,
                        0.0729750476408374,
                        0.0733486641272294,
                        0.07314453193211143,
                        0.07312101262808465,
                        0.07311117997343133,
                        0.07352836504600674,
                        0.07348833620074897,
                        0.07354864711191293,
                        0.07354367114324648,
                        0.07356033872853357,
                        0.07351755267398272,
                        0.0734913297534854,
                        0.07347222378957637,
                        0.07314558091238538,
                        0.07318360770883368,
                        0.0733121577090069,
                        0.07330632128467589,
                        0.07327678549360754,
                        0.07332079653241379,
                        0.07368233711506994,
                        0.07364219055550456,
                        0.07342374931424954,
                        0.07326522090157447,
                        0.07303719540079578,
                        0.07301314664937794,
                        0.07383656888839549,
                        0.07347530100979499,
                        0.07320190514684231,
                        0.07293760327809319,
                        0.07335124816329085,
                        0.0733511926737537,
                        0.07333240356714393,
                        0.07352752345563295,
                        0.07357462734208528,
                        0.073494836622022,
                        0.07341648891551313
                      ]
                    },
                    {
                      "label": "feature_fraction",
                      "range": [
                        0.9403474036258785,
                        0.9469900241270733
                      ],
                      "values": [
                        0.9415137111205462,
                        0.9439595924991366,
                        0.9420446763960327,
                        0.9452095639238848,
                        0.9407254059739092,
                        0.9417224142032081,
                        0.9423642843770372,
                        0.9403474036258785,
                        0.9403774989323315,
                        0.9459381269746069,
                        0.9405884074092368,
                        0.9454961473364355,
                        0.9450486219397145,
                        0.944203138749004,
                        0.9437776416778267,
                        0.9440786801509444,
                        0.9439958428631502,
                        0.9442502108322101,
                        0.9435502266573403,
                        0.9467647127684768,
                        0.9468083914769451,
                        0.9469335729454961,
                        0.9427388749973236,
                        0.9432727932497229,
                        0.9426037945222383,
                        0.9469448244284111,
                        0.9433788433579184,
                        0.9437040426784132,
                        0.9448913416234085,
                        0.9438029824579859,
                        0.9442379948601007,
                        0.9455413894783746,
                        0.9466029998266224,
                        0.9455945625932812,
                        0.9429447164928703,
                        0.946671999291752,
                        0.946590053985628,
                        0.9465632952057391,
                        0.9469900241270733,
                        0.9439324513516905,
                        0.9431566309481706,
                        0.9440226515012602,
                        0.9440105128441246,
                        0.9439263611952566,
                        0.9431360963193777,
                        0.9430256688982647,
                        0.946988945546699,
                        0.9468305217617686,
                        0.9463258495434955,
                        0.9422453945038776,
                        0.9463637955108499,
                        0.942953135176449,
                        0.9467072242204082,
                        0.94568533510909,
                        0.9464249991137471,
                        0.9464177033961425,
                        0.9452413033638486,
                        0.9429039132442488,
                        0.9435547684216399,
                        0.9436308173799173,
                        0.9468127140531714,
                        0.9435943608114685,
                        0.9427716489084906,
                        0.9433269793511179,
                        0.9425257731357702,
                        0.9435430517282245,
                        0.9438651009012007,
                        0.9423750484931597,
                        0.9426229025161872,
                        0.9422817471439568,
                        0.9423017667412207,
                        0.9421936154015322,
                        0.9423278975647763,
                        0.9421688302906167,
                        0.9429083760345671,
                        0.9429255347132741,
                        0.9430758445769324,
                        0.9428625158457977,
                        0.9424785472601767,
                        0.9436961151554689,
                        0.9443887826891451,
                        0.9437013823269941,
                        0.9446804749882249,
                        0.9444311231757513,
                        0.9430290966639876,
                        0.943715529944724,
                        0.9444067884789972,
                        0.9449932977037597,
                        0.9437407027699835,
                        0.9445301036129469,
                        0.9449776155615605,
                        0.9447789420628365,
                        0.9443434575774154,
                        0.944670904621495,
                        0.9447124690747711,
                        0.9446710309587995,
                        0.9447038243024037,
                        0.9445110668039536,
                        0.9447301136451495,
                        0.9448342784158865,
                        0.9445620652098417,
                        0.9446167822698687,
                        0.9446208609664822,
                        0.9445880826317901,
                        0.944636283549435,
                        0.9445891146696554,
                        0.9445237993699297,
                        0.9446475823881454,
                        0.9446211104903387,
                        0.944618087196114,
                        0.9443865509685772,
                        0.9444154469087261,
                        0.9446458859801974,
                        0.9446541049970814,
                        0.944318087164798,
                        0.9444749979260957,
                        0.9444059072450924,
                        0.9443864213664868,
                        0.9444236342738981,
                        0.9450500582384367,
                        0.9441825138837207,
                        0.9441234399811937,
                        0.9444970032749445,
                        0.9448743887191106,
                        0.9448514461484783,
                        0.9443231249498174,
                        0.9443387691785412,
                        0.944368403441815,
                        0.944306517223667,
                        0.9445118102719731,
                        0.9443198153142761,
                        0.9441565303999019,
                        0.9442204634372529,
                        0.9448146758212786,
                        0.9447705050760884,
                        0.9440055021772944,
                        0.9444059089635751,
                        0.9444046959143529,
                        0.9444049818554732,
                        0.9446259645660073,
                        0.9442515913988768,
                        0.9453611686302514,
                        0.9442953008093866,
                        0.9445181083211426,
                        0.9444590370464818,
                        0.9444874000843012,
                        0.9445140378269268,
                        0.9442863881902004,
                        0.9451086181420651,
                        0.944314356367432,
                        0.9440925216413896,
                        0.9441988278796859,
                        0.9445746835080756,
                        0.944338011145654,
                        0.9444122459282787,
                        0.9446556378098887,
                        0.9439842191399,
                        0.9440152780204027,
                        0.944038705901864,
                        0.9440762327666165,
                        0.9440954447476751,
                        0.9439165852825135,
                        0.9452555607477136,
                        0.9447668427897958,
                        0.9452491746050363,
                        0.9445829341758266,
                        0.9443654853952944,
                        0.9442989400398913,
                        0.944491204291397,
                        0.9444842614448419,
                        0.9450979575950853,
                        0.9442506751947493,
                        0.9442709763239417,
                        0.9442946655195432,
                        0.9443854266361361,
                        0.9448368575664324
                      ]
                    },
                    {
                      "label": "lambda_l1",
                      "range": [
                        0.020401664538530335,
                        0.1972885063536018
                      ],
                      "values": [
                        0.05287568167782561,
                        0.1069720298059572,
                        0.10411468439030888,
                        0.14811556142695492,
                        0.03688255695266242,
                        0.18461152490702432,
                        0.023969505546166652,
                        0.1299797492927787,
                        0.14415448139624953,
                        0.13067134538222594,
                        0.1972885063536018,
                        0.020401664538530335,
                        0.023281366526247706,
                        0.0792027200627457,
                        0.1283292050072638,
                        0.13076183763829186,
                        0.1016495872938764,
                        0.09374178916042976,
                        0.09621760814525737,
                        0.07417053931106543,
                        0.06527346797919638,
                        0.06775623436094128,
                        0.0657841003343484,
                        0.05834986526337527,
                        0.05089345156079397,
                        0.1117419902175392,
                        0.07813759133786363,
                        0.10632592569054983,
                        0.07162549757163639,
                        0.07215369321263775,
                        0.09545838190273329,
                        0.06069616052479685,
                        0.061745867553807156,
                        0.06247874231038167,
                        0.06158796538717164,
                        0.04867602334437442,
                        0.04839473636747205,
                        0.04981316103001927,
                        0.11962112779943551,
                        0.12509212281025933,
                        0.06023131332971873,
                        0.05922112942592192,
                        0.12428945059633975,
                        0.0665882521208902,
                        0.06705996863504711,
                        0.12157325013526774,
                        0.06703028383621616,
                        0.08965985201500819,
                        0.14235630751120074,
                        0.08961675730865543,
                        0.1438418828912233,
                        0.1330133263218537,
                        0.07573893873064633,
                        0.07103937398292075,
                        0.08952298793474704,
                        0.07405772818153951,
                        0.08623876425390076,
                        0.09970980961942705,
                        0.06676014502228944,
                        0.0693231301048876,
                        0.0661816348990478,
                        0.06708335557622647,
                        0.056463424028943734,
                        0.07851740360857554,
                        0.05984466652833857,
                        0.07874898121602565,
                        0.07272531878330082,
                        0.07764331463395906,
                        0.072635312722626,
                        0.07214820197028543,
                        0.06170030306472574,
                        0.061111906638863754,
                        0.06516654286207302,
                        0.0664075853323648,
                        0.0727363315109656,
                        0.07511412798691472,
                        0.05898390710481083,
                        0.07548880845765348,
                        0.06315698036036954,
                        0.07492878498129048,
                        0.07521506224941417,
                        0.0753928650169046,
                        0.07580856515460169,
                        0.054819694712300256,
                        0.07611119341784962,
                        0.07454301680132394,
                        0.08235895877458867,
                        0.07714434640944769,
                        0.07598581135973487,
                        0.08232768509833689,
                        0.0809313243710677,
                        0.0754435528243108,
                        0.07628273257619839,
                        0.08032966066100604,
                        0.07818179465283227,
                        0.08314777143892244,
                        0.08125352068449537,
                        0.08139045122638497,
                        0.0830740146567675,
                        0.08324825024097585,
                        0.08411798239941712,
                        0.08016922106726923,
                        0.08260152361109961,
                        0.08344921879692672,
                        0.08291530530127093,
                        0.08389389504050929,
                        0.08246078505471711,
                        0.0847381498214769,
                        0.08391848684726419,
                        0.0839596002468457,
                        0.08545857818227251,
                        0.08452301340562819,
                        0.08524870342050722,
                        0.0855286824761255,
                        0.08606011752180966,
                        0.0858118236522936,
                        0.08552298989798118,
                        0.08703282828244946,
                        0.08841507354897404,
                        0.087638790177697,
                        0.08026206228106918,
                        0.09119428855330125,
                        0.09146740980196899,
                        0.08713161996811185,
                        0.08748299711723087,
                        0.08811390205181989,
                        0.08667745087848891,
                        0.08678191379850285,
                        0.08603433342227758,
                        0.08515125948549422,
                        0.08043133221292467,
                        0.09432815127812526,
                        0.0800191692936784,
                        0.0891204429933413,
                        0.0883275832782111,
                        0.08890762599812811,
                        0.08867690755288125,
                        0.08875562538348551,
                        0.08567577359334447,
                        0.0844326012161547,
                        0.07935264920132136,
                        0.09151613418494578,
                        0.09098287382321481,
                        0.0918494833449019,
                        0.08674263232048687,
                        0.08563900589903273,
                        0.08560591726956487,
                        0.08699260689134207,
                        0.0860957258200076,
                        0.08249335249090478,
                        0.08209907522489737,
                        0.08155422333167053,
                        0.08825210955730642,
                        0.0935982335410157,
                        0.1044365608797947,
                        0.09280511356064611,
                        0.10339954332157973,
                        0.09295714370206046,
                        0.09167690382922887,
                        0.08588740935795848,
                        0.10321302184030491,
                        0.09038887519141166,
                        0.08209297431678908,
                        0.08171922530196737,
                        0.08270965702636188,
                        0.08721467660549209,
                        0.0921094236853509,
                        0.07639672238447236,
                        0.08880250315327551,
                        0.0803697441079558,
                        0.08910463760342356,
                        0.09461449867119316,
                        0.10529077216435216,
                        0.094900359842856,
                        0.0952246505665014,
                        0.09513804888393097
                      ]
                    },
                    {
                      "label": "lambda_l2",
                      "range": [
                        -0.39655144786671953,
                        -0.09695623168142824
                      ],
                      "ticktext": [
                        "0.401",
                        "0.8"
                      ],
                      "tickvals": [
                        -0.39655144786671953,
                        -0.09695623168142824
                      ],
                      "values": [
                        -0.2619895706377809,
                        -0.13072551201084084,
                        -0.34755476397546603,
                        -0.1954138612940038,
                        -0.16853577802233324,
                        -0.1699997281388943,
                        -0.31072848850915946,
                        -0.30231445237087823,
                        -0.11019550336930813,
                        -0.32763591988712953,
                        -0.23909939442108433,
                        -0.16505580658530786,
                        -0.39655144786671953,
                        -0.25365656654686924,
                        -0.09695623168142824,
                        -0.0999140805686664,
                        -0.09840371015367662,
                        -0.10994342883244058,
                        -0.11553409222019154,
                        -0.1358976609084966,
                        -0.22312000827035594,
                        -0.22989209043171685,
                        -0.22753893828318997,
                        -0.2705149480127033,
                        -0.2812046992879193,
                        -0.20310964509758364,
                        -0.24649409453127832,
                        -0.2129906421544732,
                        -0.2166127808503393,
                        -0.21157394543813288,
                        -0.11267345838493989,
                        -0.14138208812432662,
                        -0.1386270331733802,
                        -0.12296642107422925,
                        -0.12465195124602904,
                        -0.23516139165999655,
                        -0.16483240464240534,
                        -0.12548061668654023,
                        -0.104370225770451,
                        -0.1337659078122642,
                        -0.1196444123604732,
                        -0.10562147219355648,
                        -0.12102353588407788,
                        -0.14318043834501046,
                        -0.13450788064073194,
                        -0.13553865018216274,
                        -0.14377143658164787,
                        -0.15060651550033366,
                        -0.1445321133474272,
                        -0.2825854220171724,
                        -0.1535438049470058,
                        -0.1195274684824807,
                        -0.18040039034641867,
                        -0.1563717829334774,
                        -0.13708717806970944,
                        -0.3183943089763964,
                        -0.34611328185329177,
                        -0.1832077878546509,
                        -0.2798705916110321,
                        -0.2775506395533351,
                        -0.28665974654500004,
                        -0.2855844587868701,
                        -0.25336991387791685,
                        -0.29866423717709856,
                        -0.14465176454582002,
                        -0.10822697261804298,
                        -0.1364896910357639,
                        -0.16234848868716956,
                        -0.3066693315003207,
                        -0.16341296794157534,
                        -0.16323997324546233,
                        -0.13781813473517013,
                        -0.13587933818791587,
                        -0.13545887148945251,
                        -0.14512660908833355,
                        -0.14653758459559452,
                        -0.1550418680193901,
                        -0.1454540459417093,
                        -0.16122568033362134,
                        -0.16278160045094323,
                        -0.16677921285409997,
                        -0.16653700182032172,
                        -0.15995554323055927,
                        -0.16013113169403728,
                        -0.16284133771128786,
                        -0.16038545608969426,
                        -0.16075344599213243,
                        -0.16035676212853223,
                        -0.1703078045316837,
                        -0.16921942630364686,
                        -0.1701767209363651,
                        -0.1593480727666027,
                        -0.1659532997976914,
                        -0.15955717428547952,
                        -0.16422242859381664,
                        -0.16431490026229215,
                        -0.16465945448747998,
                        -0.16495146193878243,
                        -0.1639135205442337,
                        -0.16418072945750992,
                        -0.16216109696872266,
                        -0.16393419628326333,
                        -0.16485908859997822,
                        -0.16590015470772373,
                        -0.16561276676843498,
                        -0.16666364771327918,
                        -0.1659104734863712,
                        -0.17244337733724474,
                        -0.17533915499637626,
                        -0.17462608947274844,
                        -0.1708726161895849,
                        -0.17618439597000468,
                        -0.17473606321460858,
                        -0.17482996895332634,
                        -0.1734282702540723,
                        -0.17381548199548824,
                        -0.17639329312794108,
                        -0.17152422306890105,
                        -0.169780560810604,
                        -0.17102668568483986,
                        -0.16831342909817013,
                        -0.1811065977876446,
                        -0.17885691664404868,
                        -0.17784938012173843,
                        -0.181138255421385,
                        -0.18026101957969315,
                        -0.18031443600897137,
                        -0.173898279720575,
                        -0.17446604723426906,
                        -0.17346252676547835,
                        -0.1750016041576558,
                        -0.17413473726597908,
                        -0.1676968361108638,
                        -0.16659045487724344,
                        -0.16960171093174498,
                        -0.1677764112723644,
                        -0.15469759597913912,
                        -0.15777709861286895,
                        -0.1755375100321416,
                        -0.17885536660336623,
                        -0.16109697498138156,
                        -0.1624314312262107,
                        -0.17244956314462986,
                        -0.17203923038827276,
                        -0.1702888657129753,
                        -0.1712769336715398,
                        -0.1720762885071449,
                        -0.17231771591090947,
                        -0.1721576230983056,
                        -0.17366443373738125,
                        -0.17235226933748787,
                        -0.18231083885182597,
                        -0.18135792468754416,
                        -0.1657305119955388,
                        -0.16549535656559045,
                        -0.16597294719778788,
                        -0.16529535665431272,
                        -0.172293093560758,
                        -0.17503054399542475,
                        -0.17282514857023787,
                        -0.1723767963028714,
                        -0.1683893760230956,
                        -0.16807190198093644,
                        -0.16649689614050123,
                        -0.16712947233656597,
                        -0.16429466528316844,
                        -0.1776087090786068,
                        -0.1696803816286884,
                        -0.16897915200416533,
                        -0.177361118663225,
                        -0.17733090577905183,
                        -0.17720143418237855,
                        -0.16329138058941706,
                        -0.1627503227862806,
                        -0.16405424188573994,
                        -0.17221801683445154
                      ]
                    },
                    {
                      "label": "max_bin",
                      "range": [
                        55,
                        64
                      ],
                      "values": [
                        57,
                        58,
                        55,
                        55,
                        60,
                        64,
                        62,
                        58,
                        57,
                        60,
                        59,
                        55,
                        57,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        59,
                        59,
                        59,
                        59,
                        59,
                        59,
                        59,
                        59,
                        57,
                        57,
                        57,
                        58,
                        58,
                        58,
                        58,
                        59,
                        59,
                        59,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        59,
                        59,
                        59,
                        59,
                        59,
                        59,
                        59,
                        59,
                        58,
                        58,
                        58,
                        59,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        59,
                        59,
                        58,
                        58,
                        59,
                        59,
                        58,
                        58,
                        58,
                        58,
                        58,
                        59,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58,
                        58
                      ]
                    },
                    {
                      "label": "max_cat_threshold",
                      "range": [
                        12,
                        25
                      ],
                      "values": [
                        17,
                        25,
                        20,
                        25,
                        18,
                        15,
                        25,
                        20,
                        14,
                        18,
                        25,
                        15,
                        18,
                        12,
                        12,
                        12,
                        12,
                        12,
                        12,
                        22,
                        14,
                        14,
                        14,
                        16,
                        16,
                        20,
                        15,
                        16,
                        16,
                        16,
                        16,
                        23,
                        21,
                        23,
                        21,
                        16,
                        23,
                        23,
                        20,
                        20,
                        20,
                        20,
                        20,
                        20,
                        20,
                        25,
                        21,
                        21,
                        21,
                        21,
                        22,
                        22,
                        21,
                        22,
                        23,
                        23,
                        22,
                        20,
                        21,
                        21,
                        15,
                        15,
                        15,
                        14,
                        14,
                        21,
                        21,
                        21,
                        24,
                        24,
                        23,
                        21,
                        25,
                        25,
                        23,
                        23,
                        23,
                        21,
                        14,
                        14,
                        14,
                        14,
                        24,
                        24,
                        24,
                        23,
                        14,
                        14,
                        14,
                        14,
                        14,
                        14,
                        13,
                        13,
                        14,
                        14,
                        14,
                        14,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        12,
                        12,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        12,
                        13,
                        13,
                        13,
                        13,
                        13,
                        14,
                        14,
                        13,
                        14,
                        14,
                        12,
                        12,
                        15,
                        12,
                        12,
                        12,
                        13,
                        15,
                        12,
                        12,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        14,
                        14,
                        14,
                        13,
                        13,
                        12,
                        13,
                        13,
                        13,
                        13,
                        14,
                        14,
                        14,
                        13
                      ]
                    },
                    {
                      "label": "max_depth",
                      "range": [
                        5,
                        8
                      ],
                      "values": [
                        8,
                        7,
                        7,
                        8,
                        5,
                        7,
                        8,
                        7,
                        5,
                        7,
                        6,
                        8,
                        6,
                        8,
                        5,
                        5,
                        5,
                        5,
                        5,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        7,
                        7,
                        7,
                        8,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        8,
                        8,
                        7,
                        8,
                        7,
                        7,
                        7,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        7,
                        7,
                        7,
                        8,
                        8,
                        6,
                        7,
                        7,
                        7,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8,
                        8
                      ]
                    },
                    {
                      "label": "min_child_weight",
                      "range": [
                        15,
                        19
                      ],
                      "values": [
                        15,
                        19,
                        18,
                        17,
                        17,
                        19,
                        15,
                        16,
                        18,
                        16,
                        16,
                        15,
                        15,
                        19,
                        19,
                        19,
                        19,
                        19,
                        19,
                        19,
                        19,
                        19,
                        17,
                        17,
                        17,
                        17,
                        17,
                        18,
                        18,
                        18,
                        19,
                        19,
                        19,
                        19,
                        17,
                        18,
                        18,
                        17,
                        19,
                        19,
                        19,
                        19,
                        19,
                        19,
                        19,
                        19,
                        17,
                        17,
                        17,
                        17,
                        19,
                        19,
                        19,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        19,
                        19,
                        17,
                        17,
                        19,
                        19,
                        19,
                        19,
                        19,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17,
                        17
                      ]
                    },
                    {
                      "label": "min_data_in_leaf",
                      "range": [
                        1,
                        8
                      ],
                      "values": [
                        1,
                        1,
                        4,
                        8,
                        4,
                        8,
                        4,
                        8,
                        2,
                        6,
                        5,
                        3,
                        3,
                        1,
                        2,
                        1,
                        1,
                        1,
                        1,
                        2,
                        2,
                        2,
                        2,
                        1,
                        1,
                        2,
                        2,
                        3,
                        5,
                        3,
                        1,
                        6,
                        5,
                        6,
                        5,
                        2,
                        2,
                        6,
                        5,
                        5,
                        5,
                        5,
                        5,
                        5,
                        5,
                        5,
                        4,
                        4,
                        4,
                        4,
                        7,
                        7,
                        3,
                        5,
                        4,
                        4,
                        6,
                        7,
                        3,
                        3,
                        3,
                        3,
                        7,
                        3,
                        3,
                        3,
                        3,
                        3,
                        3,
                        3,
                        4,
                        3,
                        3,
                        3,
                        5,
                        5,
                        5,
                        5,
                        7,
                        3,
                        3,
                        3,
                        5,
                        5,
                        5,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        3,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        8,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        6,
                        7,
                        6,
                        6,
                        8,
                        8,
                        7,
                        8,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7,
                        7
                      ]
                    },
                    {
                      "label": "min_data_per_group",
                      "range": [
                        5,
                        15
                      ],
                      "values": [
                        11,
                        8,
                        13,
                        9,
                        15,
                        9,
                        11,
                        12,
                        13,
                        7,
                        12,
                        6,
                        12,
                        5,
                        5,
                        5,
                        5,
                        5,
                        5,
                        7,
                        6,
                        6,
                        6,
                        6,
                        6,
                        8,
                        7,
                        5,
                        5,
                        5,
                        5,
                        11,
                        11,
                        6,
                        6,
                        6,
                        6,
                        12,
                        7,
                        10,
                        7,
                        10,
                        10,
                        7,
                        10,
                        7,
                        7,
                        7,
                        7,
                        13,
                        7,
                        7,
                        8,
                        7,
                        6,
                        6,
                        5,
                        7,
                        6,
                        6,
                        6,
                        6,
                        6,
                        6,
                        6,
                        6,
                        12,
                        12,
                        6,
                        13,
                        6,
                        6,
                        12,
                        12,
                        12,
                        13,
                        13,
                        6,
                        6,
                        6,
                        6,
                        6,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        14,
                        14,
                        14,
                        14,
                        13,
                        14,
                        14,
                        13,
                        13,
                        13,
                        15,
                        15,
                        15,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        12,
                        12,
                        12,
                        12,
                        12,
                        12,
                        13,
                        12,
                        12,
                        14,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        13,
                        14,
                        13,
                        13,
                        13,
                        12,
                        12,
                        12,
                        12,
                        10,
                        12,
                        12
                      ]
                    },
                    {
                      "label": "min_split_gain",
                      "range": [
                        0.005017428330678744,
                        0.0139975122198246
                      ],
                      "values": [
                        0.00641548012914274,
                        0.013153959907061918,
                        0.011231968606259975,
                        0.009200792757828145,
                        0.007556660623378714,
                        0.005437373568205178,
                        0.005017428330678744,
                        0.011947820673926812,
                        0.009207032189715223,
                        0.00854933452182206,
                        0.006439380150239569,
                        0.00879679118385826,
                        0.009001306786304418,
                        0.013895874546504722,
                        0.013787997291057594,
                        0.00993641272752868,
                        0.009543492348254407,
                        0.01389329323175148,
                        0.01371434321711355,
                        0.013949180170676577,
                        0.01285334330005792,
                        0.013007414000697099,
                        0.012879216406469166,
                        0.012793019282888464,
                        0.01272033407831791,
                        0.011286745038995896,
                        0.007827609006557545,
                        0.0129558712732162,
                        0.012444090778562362,
                        0.013964996824074448,
                        0.012987849370552178,
                        0.005992990610973262,
                        0.0121196616534019,
                        0.012177546004933464,
                        0.00571984012338116,
                        0.012631572939938978,
                        0.012689647127594421,
                        0.01263801470465526,
                        0.00847872837383047,
                        0.013429609722606069,
                        0.011484648774699237,
                        0.011517583968658651,
                        0.013399757943412107,
                        0.011578488585837586,
                        0.009638151926423987,
                        0.011489133595383571,
                        0.005018994393670229,
                        0.005129850404020865,
                        0.005293451818450421,
                        0.01090536418344066,
                        0.009223099496876505,
                        0.008630103123288522,
                        0.010262252971048866,
                        0.009238524651839611,
                        0.010763857079891938,
                        0.01063522848408654,
                        0.011419613030875837,
                        0.013053342147685639,
                        0.013135808809398476,
                        0.013139327104276838,
                        0.01314796420145143,
                        0.012749675503750895,
                        0.009477913142157257,
                        0.006539412695721669,
                        0.012959090821499552,
                        0.010519422485754697,
                        0.012890968979222216,
                        0.012703050285329066,
                        0.012952781093621473,
                        0.012698298784466548,
                        0.013283065840577101,
                        0.013303218217163808,
                        0.012591668630521989,
                        0.012628495866995316,
                        0.013515203418320548,
                        0.013493820381814745,
                        0.012848352943166183,
                        0.013224132743120518,
                        0.01323316657269211,
                        0.0132438943705351,
                        0.012728028638364548,
                        0.013256571263110736,
                        0.013252141204969653,
                        0.013261476867534153,
                        0.013279971914321377,
                        0.012681807607281093,
                        0.012729968869620408,
                        0.01276115208502486,
                        0.012675797402176166,
                        0.012762733889391354,
                        0.012737949837538145,
                        0.013464426878152073,
                        0.012620888142595956,
                        0.013502757666193074,
                        0.013469905274900591,
                        0.01346889799265096,
                        0.013409121067190756,
                        0.01348799664109564,
                        0.013502277705870602,
                        0.013520191170338033,
                        0.013438404604176609,
                        0.013653991391068496,
                        0.013642387388530443,
                        0.013669802308194846,
                        0.013708210748220128,
                        0.013821147218071744,
                        0.013711177442144897,
                        0.013791988805598588,
                        0.013729161272244755,
                        0.013632981270840696,
                        0.013814507652801945,
                        0.013858962524821118,
                        0.013855382013551078,
                        0.013811393596584813,
                        0.01382180014091455,
                        0.013855647560776443,
                        0.013927583561370284,
                        0.013942901659409266,
                        0.01397998085221002,
                        0.0139874285126242,
                        0.013972453464831877,
                        0.013756396136881129,
                        0.013747804562813808,
                        0.013735333858937793,
                        0.01373545732038142,
                        0.013749889808845159,
                        0.013746505558692662,
                        0.013681199697081852,
                        0.013627347456373028,
                        0.013646035145009826,
                        0.013578292129222453,
                        0.013605891474682878,
                        0.013806201955243019,
                        0.013794896312334284,
                        0.013772375636530774,
                        0.01344816076206537,
                        0.013460637337932098,
                        0.013606971693259222,
                        0.013593236024522634,
                        0.013890740101335532,
                        0.013427918729668345,
                        0.013698495250402131,
                        0.013975287992919196,
                        0.013843405756735991,
                        0.0139975122198246,
                        0.01398901244252187,
                        0.01399217124463141,
                        0.013952395588371646,
                        0.013960077932840438,
                        0.01390296668518959,
                        0.013958856660323326,
                        0.013804940390042918,
                        0.013798033689184261,
                        0.01398818572450445,
                        0.013991861473696817,
                        0.013566759033653083,
                        0.013495081847623156,
                        0.013277410920610482,
                        0.013321257857702936,
                        0.013148751974216437,
                        0.013249549332150844,
                        0.013819169579363532,
                        0.013366872425254049,
                        0.01339677300859515,
                        0.013412134040729964,
                        0.013704310384522201,
                        0.013792302456214621,
                        0.013799986504482421,
                        0.013319102799183387,
                        0.013291228012198914,
                        0.013687181822923361,
                        0.013701241506673258,
                        0.013495109547555277,
                        0.01381521201234868,
                        0.013479184437265722,
                        0.013805570387664121
                      ]
                    },
                    {
                      "label": "num_leaves",
                      "range": [
                        38,
                        60
                      ],
                      "values": [
                        45,
                        44,
                        48,
                        42,
                        54,
                        60,
                        56,
                        50,
                        44,
                        41,
                        38,
                        44,
                        59,
                        38,
                        39,
                        38,
                        38,
                        38,
                        43,
                        40,
                        41,
                        40,
                        40,
                        41,
                        40,
                        41,
                        56,
                        40,
                        40,
                        40,
                        40,
                        45,
                        43,
                        43,
                        43,
                        42,
                        45,
                        45,
                        44,
                        44,
                        44,
                        44,
                        44,
                        44,
                        44,
                        44,
                        41,
                        41,
                        46,
                        47,
                        43,
                        45,
                        43,
                        39,
                        39,
                        60,
                        42,
                        43,
                        39,
                        39,
                        39,
                        55,
                        40,
                        43,
                        51,
                        58,
                        55,
                        43,
                        54,
                        60,
                        51,
                        44,
                        59,
                        60,
                        54,
                        44,
                        51,
                        56,
                        43,
                        43,
                        49,
                        43,
                        51,
                        55,
                        51,
                        50,
                        44,
                        50,
                        50,
                        51,
                        52,
                        52,
                        50,
                        52,
                        52,
                        52,
                        50,
                        52,
                        52,
                        50,
                        50,
                        50,
                        50,
                        50,
                        49,
                        52,
                        52,
                        49,
                        49,
                        49,
                        49,
                        49,
                        50,
                        49,
                        49,
                        50,
                        50,
                        50,
                        50,
                        50,
                        50,
                        49,
                        49,
                        49,
                        49,
                        49,
                        49,
                        49,
                        48,
                        48,
                        48,
                        48,
                        50,
                        51,
                        51,
                        51,
                        50,
                        50,
                        48,
                        48,
                        52,
                        49,
                        48,
                        48,
                        48,
                        48,
                        48,
                        50,
                        47,
                        47,
                        50,
                        48,
                        48,
                        51,
                        51,
                        50,
                        50,
                        50,
                        46,
                        50,
                        50,
                        49,
                        46,
                        46,
                        51,
                        49,
                        50,
                        45,
                        51,
                        51,
                        49,
                        48,
                        50,
                        47,
                        47,
                        50
                      ]
                    },
                    {
                      "label": "other_rate",
                      "range": [
                        0.00023986322449376374,
                        0.8885389061606181
                      ],
                      "values": [
                        0.12398565280403889,
                        0.3643323896398874,
                        0.48302049937801217,
                        0.08443558996829727,
                        0.5538729065194656,
                        0.06960619687330734,
                        0.5567467957001528,
                        0.26255617429836337,
                        0.24360607418992206,
                        0.2983178041810645,
                        0.11290622891653651,
                        0.2142501115960387,
                        0.1126966512145427,
                        0.03360417082866407,
                        0.0023419598052110864,
                        0.0645964141112893,
                        0.09237284066514034,
                        0.019871739949229084,
                        0.05637552482880098,
                        0.010113713176376058,
                        0.8885389061606181,
                        0.0012895929947922338,
                        0.003827578966132305,
                        0.0019280140023790332,
                        0.032400464639335,
                        0.6123562234012887,
                        0.17442824430615286,
                        0.00023986322449376374,
                        0.0023669952896334667,
                        0.11329532421385798,
                        0.0013294990630620832,
                        0.012615342963951346,
                        0.2165358247094431,
                        0.03920193631024744,
                        0.10860864090569675,
                        0.046971445207276794,
                        0.2231675953902646,
                        0.0629616002612598,
                        0.07508401222424338,
                        0.21643127265629855,
                        0.014854791157456877,
                        0.09696798383987176,
                        0.055686553116797634,
                        0.3356413663768198,
                        0.13840881131246724,
                        0.028428353127987766,
                        0.04806887804343462,
                        0.22586536861659362,
                        0.03656008757316667,
                        0.0762321595928299,
                        0.010607625879665794,
                        0.10357269985169873,
                        0.011637831144813465,
                        0.08798829480564659,
                        0.033924710594382415,
                        0.07134634003594836,
                        0.049050846030944326,
                        0.15054694794675216,
                        0.06798348848811595,
                        0.03146687427997609,
                        0.04342169930494307,
                        0.045546460590930093,
                        0.16619283200276658,
                        0.006356754561685013,
                        0.04882961313024878,
                        0.08000794780355087,
                        0.1363949150667549,
                        0.2040805184508382,
                        0.012774032162404404,
                        0.21657719345846974,
                        0.04373986383399029,
                        0.039703644428098706,
                        0.1761962482686374,
                        0.2003957140261911,
                        0.023218191390784758,
                        0.15435132459108197,
                        0.15992641856966955,
                        0.16020266961415391,
                        0.13709084998952661,
                        0.02514735214178801,
                        0.05009413999111768,
                        0.17747487596107012,
                        0.14703824373781996,
                        0.15574308137299056,
                        0.15502232511957798,
                        0.1813078860774223,
                        0.1513476045484385,
                        0.125747832140301,
                        0.15727604512738558,
                        0.1380319673382643,
                        0.1442196336585917,
                        0.14155240975358718,
                        0.1486457479401345,
                        0.14971776648390459,
                        0.12866777301501067,
                        0.12397379030982497,
                        0.14711759356546494,
                        0.13302312283258705,
                        0.12785054551314892,
                        0.12653259181517776,
                        0.13588167541308593,
                        0.12836337511071985,
                        0.12967088946961985,
                        0.13031831725655887,
                        0.12932994713976537,
                        0.1315899204068971,
                        0.13149402337218447,
                        0.12985101359892168,
                        0.13178778142118203,
                        0.1264021433298589,
                        0.11771315893061211,
                        0.12307931558849775,
                        0.1145459921222903,
                        0.1177455097484729,
                        0.11692561653575634,
                        0.12205914572039908,
                        0.11496304760097945,
                        0.11515120490976048,
                        0.11091609740560365,
                        0.10861552156980346,
                        0.11040142185982728,
                        0.10410494338635662,
                        0.09652647917344459,
                        0.14356862426087014,
                        0.14502271914393794,
                        0.1430621917240082,
                        0.11952583621074798,
                        0.1445739118500403,
                        0.11742180291023842,
                        0.11916553607065207,
                        0.11711050335740081,
                        0.09849203963844301,
                        0.13456606452575923,
                        0.1133413144722044,
                        0.11527501937099191,
                        0.1313207375032623,
                        0.10377567065124153,
                        0.14218931372984275,
                        0.14789978726995126,
                        0.12354163164946227,
                        0.10486807120280016,
                        0.1501229255631525,
                        0.1394255584505628,
                        0.11475575676120729,
                        0.1361846410751506,
                        0.11245785819914773,
                        0.1146153537802001,
                        0.08544035041271793,
                        0.4442160637092818,
                        0.09788747322897887,
                        0.13297355000293518,
                        0.11242984927940503,
                        0.08648004303980751,
                        0.11898508831388714,
                        0.12164005008597732,
                        0.11977375201515705,
                        0.13543174738758187,
                        0.13706397210049978,
                        0.13609778095611683,
                        0.1374817259340593,
                        0.13754038642788918,
                        0.1261343900888008,
                        0.11098931216437281,
                        0.10701215649782325,
                        0.10429427271170776,
                        0.12354626496322935,
                        0.09677067428730636,
                        0.16493085202900487,
                        0.08141318425112735,
                        0.13240569413491798,
                        0.10736223721125503,
                        0.11622892806150749,
                        0.14236632656727014,
                        0.11827740813020779,
                        0.4316509866942603,
                        0.1231426609891079
                      ]
                    },
                    {
                      "label": "top_rate",
                      "range": [
                        0.014054026518375673,
                        0.9997565521187126
                      ],
                      "values": [
                        0.662424956392463,
                        0.2417591915436597,
                        0.0823217077694812,
                        0.15626097164939207,
                        0.10794472036374592,
                        0.43394128708019863,
                        0.24529709898328295,
                        0.6675398982325833,
                        0.6386858211977333,
                        0.45822071686286814,
                        0.8693863661636576,
                        0.515005878090238,
                        0.3820644786484645,
                        0.9584775458436678,
                        0.9637993577494786,
                        0.9193807282583628,
                        0.8930484324524175,
                        0.97995354975591,
                        0.848970221709236,
                        0.9818498174623076,
                        0.014054026518375673,
                        0.9986952733465,
                        0.995561894590299,
                        0.9980628546273331,
                        0.7196459084687541,
                        0.19707392690877576,
                        0.0509444310236783,
                        0.9997565521187126,
                        0.9976232821210037,
                        0.7433851971657084,
                        0.9938955642798943,
                        0.9153707709235651,
                        0.6779723062516939,
                        0.8549913327794346,
                        0.40743237144604644,
                        0.6691727374491132,
                        0.670969582460196,
                        0.8013787681340113,
                        0.6573488358060962,
                        0.5772654611178946,
                        0.6355435321705301,
                        0.6469364510345094,
                        0.565248757966691,
                        0.35632862851397107,
                        0.5555901670637401,
                        0.5734176161869076,
                        0.6780822515347498,
                        0.713738356130781,
                        0.7278173465446084,
                        0.6808200201262729,
                        0.530475886296434,
                        0.5291310778058417,
                        0.6423100425039453,
                        0.6178256329371149,
                        0.6348429838829626,
                        0.63419408255435,
                        0.6776070106263251,
                        0.7075103754987575,
                        0.7165189501699015,
                        0.7079622421688677,
                        0.700817327229001,
                        0.7032989082819909,
                        0.6594072504651327,
                        0.8004410402415224,
                        0.7526226992545223,
                        0.7263536941218933,
                        0.6243938115465607,
                        0.6276684214571634,
                        0.6820740384610205,
                        0.6722019572406575,
                        0.669903906920604,
                        0.5869788172410708,
                        0.3626493084151933,
                        0.584773847390628,
                        0.6548916468346888,
                        0.33437217224658633,
                        0.35267664025399126,
                        0.32664682994382455,
                        0.5150167003432465,
                        0.6179085140724102,
                        0.6215381966348924,
                        0.38625958836448065,
                        0.37840826194401184,
                        0.34250168345475773,
                        0.2887239949105229,
                        0.37454742817711373,
                        0.3912008323952332,
                        0.3945423719545751,
                        0.5129899422349862,
                        0.3957993202814269,
                        0.5117402779080206,
                        0.27889167438685086,
                        0.38636864435628965,
                        0.38909502254412415,
                        0.37472835473954574,
                        0.39529018525404225,
                        0.43095319303772445,
                        0.38250173111618385,
                        0.38490746660570846,
                        0.38781340130033776,
                        0.39270973540098464,
                        0.38895880168990904,
                        0.4391186525758708,
                        0.44017952939239424,
                        0.3860124808101124,
                        0.38014775720082944,
                        0.44085361331486517,
                        0.38647426843926713,
                        0.4429177804914554,
                        0.38445771960266506,
                        0.3986618620209448,
                        0.3942530827065226,
                        0.42503333378826,
                        0.3963389214587115,
                        0.4040141233261718,
                        0.4008819152091167,
                        0.40165421616085134,
                        0.40307569919584174,
                        0.41427247262946015,
                        0.4575662083519294,
                        0.42056638230996424,
                        0.42299789190600673,
                        0.3728597590663147,
                        0.3648933550688487,
                        0.3666877982587064,
                        0.42817440570449944,
                        0.4278025634948973,
                        0.4288878868622799,
                        0.4260827603384368,
                        0.4253202501908303,
                        0.42390696687840645,
                        0.40837553370384644,
                        0.42715835295154125,
                        0.4346571540061495,
                        0.4381696454435389,
                        0.4308277544486695,
                        0.46054757604368557,
                        0.40754610609593955,
                        0.4046506382090514,
                        0.38984927592735746,
                        0.46062589597589937,
                        0.4091183631873835,
                        0.3678087146667334,
                        0.429491186447481,
                        0.43431037821301316,
                        0.4330685607956135,
                        0.4243499957421048,
                        0.3686737802375082,
                        0.36430820164015576,
                        0.3734925969784769,
                        0.49144346433295205,
                        0.42313645145146606,
                        0.32813180535820846,
                        0.39629297668262203,
                        0.3934088803368483,
                        0.3992901060368256,
                        0.3960589263451436,
                        0.3460628440632084,
                        0.41300543638626896,
                        0.36398096743665226,
                        0.37785046048661225,
                        0.4381708586529318,
                        0.4297515730363585,
                        0.41882723982127995,
                        0.42858978547250154,
                        0.3628525877493982,
                        0.37657526840412153,
                        0.4605949311160203,
                        0.35495725028828995,
                        0.4409529437037529,
                        0.41312164517007005,
                        0.40817126115175106,
                        0.33848243326108723,
                        0.4179776966794441,
                        0.45996849379000737,
                        0.43027072199230304
                      ]
                    }
                  ],
                  "labelangle": 30,
                  "labelside": "bottom",
                  "line": {
                    "color": [
                      0.23799384286273395,
                      0.25257026611385686,
                      0.23607234921980993,
                      0.23351004392260122,
                      0.22118355006291165,
                      0.2368054863573365,
                      0.23467817578951994,
                      0.2492183617272187,
                      0.2508034667728444,
                      0.24444355146697733,
                      0.24638441809695522,
                      0.24066073110273717,
                      0.2500992724128512,
                      0.2512497389906705,
                      0.24780014207800183,
                      0.24345589003523718,
                      0.24950559698288596,
                      0.2512468585781459,
                      0.24966547399488767,
                      0.2527316371024155,
                      0.2514909232994099,
                      0.2511396047960298,
                      0.2586352644702073,
                      0.2527264459805575,
                      0.25572363816910854,
                      0.25022635152072403,
                      0.24556031408083032,
                      0.24675938835375505,
                      0.2517645801757151,
                      0.2538164492920105,
                      0.2525943989047087,
                      0.24974231033993394,
                      0.2532202192933685,
                      0.25582444275876653,
                      0.2529551831471422,
                      0.24839273295219666,
                      0.2527985746283016,
                      0.25097194701688813,
                      0.2556160224341649,
                      0.2510635252106125,
                      0.2514807436210522,
                      0.24684229713746925,
                      0.2470559585496679,
                      0.2502647364386594,
                      0.25222208388466083,
                      0.25400125143797925,
                      0.2552580905005643,
                      0.2528342014614715,
                      0.2493985001778562,
                      0.2528384528802303,
                      0.2550233498938586,
                      0.2523083029470582,
                      0.25483072502545034,
                      0.24847497589226655,
                      0.2574753029167793,
                      0.25608749134198927,
                      0.2511703011467725,
                      0.2547536078051821,
                      0.2529914277269956,
                      0.25209671945226275,
                      0.2515369929044722,
                      0.2548329181498087,
                      0.25068697393310213,
                      0.2501431184287837,
                      0.2540030651641933,
                      0.2507047934728426,
                      0.25641341551762764,
                      0.25780701625469604,
                      0.25521824386459036,
                      0.2557960577331986,
                      0.2534074976345324,
                      0.2585956950317595,
                      0.25957896568406236,
                      0.252325709986834,
                      0.251712426654483,
                      0.25704328332362836,
                      0.2586001109656427,
                      0.253032392102843,
                      0.2582294697836728,
                      0.25615608164991127,
                      0.2597090938462958,
                      0.25817099974935753,
                      0.25732394817011095,
                      0.251840973701201,
                      0.25554155233484255,
                      0.2538934288059256,
                      0.2604836395582832,
                      0.25924654113987,
                      0.252060534249514,
                      0.25873673802174624,
                      0.2544991930599525,
                      0.2555580966475103,
                      0.25971665260699334,
                      0.26240806334113453,
                      0.25987806370287453,
                      0.2617452826463283,
                      0.2588429180727659,
                      0.26140396995493137,
                      0.25751223896826564,
                      0.2552430711790555,
                      0.25949895623877345,
                      0.26532196167545063,
                      0.2635506977103081,
                      0.258422205804421,
                      0.2607411123181213,
                      0.26077220028163106,
                      0.2564147969225439,
                      0.2618370498319524,
                      0.2574255385529174,
                      0.256073589906999,
                      0.26231410783114406,
                      0.25693832431455654,
                      0.26010458097199834,
                      0.25641098202249235,
                      0.26214657077906367,
                      0.25970132700171716,
                      0.2612381465463163,
                      0.25838319112920943,
                      0.26193894135573725,
                      0.2607055197450044,
                      0.2558238819843697,
                      0.26039411892238445,
                      0.2596285073734872,
                      0.25672325638029103,
                      0.25835134322104664,
                      0.25779739913631283,
                      0.2616895893152762,
                      0.25981441847356196,
                      0.2560462182784489,
                      0.25273645729321736,
                      0.2618738353401766,
                      0.2577028990584764,
                      0.25564175186673194,
                      0.25320855897174505,
                      0.2538377838640009,
                      0.2526526964817669,
                      0.2569033566900406,
                      0.25799946734201123,
                      0.2534882015509653,
                      0.25968570363497123,
                      0.256679453449559,
                      0.2592257173283327,
                      0.26163534353357887,
                      0.2599259310342126,
                      0.2548622979379641,
                      0.2613736175677654,
                      0.26220709023889477,
                      0.256967005043854,
                      0.25695966823922817,
                      0.2579806183913517,
                      0.26008790595455256,
                      0.2542587612681432,
                      0.25510121711750094,
                      0.2557056361980953,
                      0.2559235751087734,
                      0.2588756602797714,
                      0.26361563888417805,
                      0.2629685046632935,
                      0.26430512690245644,
                      0.25818162361334757,
                      0.25844180234975545,
                      0.2618657322486643,
                      0.258159260340855,
                      0.2560703510169188,
                      0.25513589733560715,
                      0.2603661126674567,
                      0.2609181723092779,
                      0.25602619550937156,
                      0.2583086996205922,
                      0.25882218456222217,
                      0.2602180736801283,
                      0.26155620250780726,
                      0.26080104715505814,
                      0.257790014753141,
                      0.25705983134166244,
                      0.25906326121060286
                    ],
                    "colorbar": {
                      "title": {
                        "text": "Objective Value"
                      }
                    },
                    "colorscale": [
                      [
                        0,
                        "rgb(247,251,255)"
                      ],
                      [
                        0.125,
                        "rgb(222,235,247)"
                      ],
                      [
                        0.25,
                        "rgb(198,219,239)"
                      ],
                      [
                        0.375,
                        "rgb(158,202,225)"
                      ],
                      [
                        0.5,
                        "rgb(107,174,214)"
                      ],
                      [
                        0.625,
                        "rgb(66,146,198)"
                      ],
                      [
                        0.75,
                        "rgb(33,113,181)"
                      ],
                      [
                        0.875,
                        "rgb(8,81,156)"
                      ],
                      [
                        1,
                        "rgb(8,48,107)"
                      ]
                    ],
                    "reversescale": false,
                    "showscale": true
                  },
                  "type": "parcoords"
                }
              ],
              "layout": {
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "heatmapgl": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmapgl"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                },
                "title": {
                  "text": "Parallel Coordinate Plot"
                }
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "opt.visualization.plot_parallel_coordinate(lgb_study.get(boosters[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "marker": {
                    "color": [
                      0,
                      1,
                      2,
                      3,
                      4,
                      6,
                      7,
                      9,
                      10,
                      11,
                      13,
                      15,
                      16,
                      17,
                      18,
                      19,
                      20,
                      21,
                      22,
                      29,
                      32,
                      33,
                      34,
                      35,
                      37,
                      41,
                      61,
                      72,
                      73,
                      76,
                      78,
                      84,
                      85,
                      86,
                      87,
                      93,
                      94,
                      99,
                      102,
                      103,
                      104,
                      105,
                      106,
                      107,
                      108,
                      109,
                      110,
                      113,
                      114,
                      115,
                      118,
                      119,
                      134,
                      143,
                      145,
                      146,
                      163,
                      177,
                      179,
                      181,
                      182,
                      183,
                      187,
                      194,
                      195,
                      196,
                      200,
                      201,
                      206,
                      207,
                      208,
                      210,
                      216,
                      217,
                      232,
                      233,
                      234,
                      236,
                      241,
                      242,
                      243,
                      244,
                      247,
                      248,
                      249,
                      250,
                      251,
                      252,
                      253,
                      254,
                      256,
                      257,
                      258,
                      259,
                      260,
                      261,
                      262,
                      263,
                      264,
                      265,
                      266,
                      267,
                      268,
                      269,
                      270,
                      271,
                      272,
                      273,
                      274,
                      275,
                      276,
                      277,
                      278,
                      279,
                      280,
                      281,
                      282,
                      283,
                      285,
                      286,
                      288,
                      292,
                      295,
                      296,
                      297,
                      298,
                      299,
                      300,
                      301,
                      302,
                      303,
                      304,
                      321,
                      323,
                      325,
                      327,
                      330,
                      331,
                      336,
                      337,
                      349,
                      353,
                      360,
                      361,
                      362,
                      364,
                      365,
                      366,
                      367,
                      368,
                      369,
                      377,
                      382,
                      390,
                      391,
                      393,
                      395,
                      396,
                      397,
                      403,
                      404,
                      421,
                      427,
                      428,
                      429,
                      436,
                      446,
                      459,
                      467,
                      474,
                      475,
                      478,
                      494,
                      495,
                      497,
                      499
                    ],
                    "colorbar": {
                      "title": {
                        "text": "#Trials"
                      },
                      "x": 1,
                      "xpad": 40
                    },
                    "colorscale": [
                      [
                        0,
                        "rgb(247,251,255)"
                      ],
                      [
                        0.125,
                        "rgb(222,235,247)"
                      ],
                      [
                        0.25,
                        "rgb(198,219,239)"
                      ],
                      [
                        0.375,
                        "rgb(158,202,225)"
                      ],
                      [
                        0.5,
                        "rgb(107,174,214)"
                      ],
                      [
                        0.625,
                        "rgb(66,146,198)"
                      ],
                      [
                        0.75,
                        "rgb(33,113,181)"
                      ],
                      [
                        0.875,
                        "rgb(8,81,156)"
                      ],
                      [
                        1,
                        "rgb(8,48,107)"
                      ]
                    ],
                    "line": {
                      "color": "Grey",
                      "width": 0.5
                    }
                  },
                  "mode": "markers",
                  "showlegend": false,
                  "type": "scatter",
                  "x": [
                    0.05287568167782561,
                    0.1069720298059572,
                    0.10411468439030888,
                    0.14811556142695492,
                    0.03688255695266242,
                    0.18461152490702432,
                    0.023969505546166652,
                    0.1299797492927787,
                    0.14415448139624953,
                    0.13067134538222594,
                    0.1972885063536018,
                    0.020401664538530335,
                    0.023281366526247706,
                    0.0792027200627457,
                    0.1283292050072638,
                    0.13076183763829186,
                    0.1016495872938764,
                    0.09374178916042976,
                    0.09621760814525737,
                    0.07417053931106543,
                    0.06527346797919638,
                    0.06775623436094128,
                    0.0657841003343484,
                    0.05834986526337527,
                    0.05089345156079397,
                    0.1117419902175392,
                    0.07813759133786363,
                    0.10632592569054983,
                    0.07162549757163639,
                    0.07215369321263775,
                    0.09545838190273329,
                    0.06069616052479685,
                    0.061745867553807156,
                    0.06247874231038167,
                    0.06158796538717164,
                    0.04867602334437442,
                    0.04839473636747205,
                    0.04981316103001927,
                    0.11962112779943551,
                    0.12509212281025933,
                    0.06023131332971873,
                    0.05922112942592192,
                    0.12428945059633975,
                    0.0665882521208902,
                    0.06705996863504711,
                    0.12157325013526774,
                    0.06703028383621616,
                    0.08965985201500819,
                    0.14235630751120074,
                    0.08961675730865543,
                    0.1438418828912233,
                    0.1330133263218537,
                    0.07573893873064633,
                    0.07103937398292075,
                    0.08952298793474704,
                    0.07405772818153951,
                    0.08623876425390076,
                    0.09970980961942705,
                    0.06676014502228944,
                    0.0693231301048876,
                    0.0661816348990478,
                    0.06708335557622647,
                    0.056463424028943734,
                    0.07851740360857554,
                    0.05984466652833857,
                    0.07874898121602565,
                    0.07272531878330082,
                    0.07764331463395906,
                    0.072635312722626,
                    0.07214820197028543,
                    0.06170030306472574,
                    0.061111906638863754,
                    0.06516654286207302,
                    0.0664075853323648,
                    0.0727363315109656,
                    0.07511412798691472,
                    0.05898390710481083,
                    0.07548880845765348,
                    0.06315698036036954,
                    0.07492878498129048,
                    0.07521506224941417,
                    0.0753928650169046,
                    0.07580856515460169,
                    0.054819694712300256,
                    0.07611119341784962,
                    0.07454301680132394,
                    0.08235895877458867,
                    0.07714434640944769,
                    0.07598581135973487,
                    0.08232768509833689,
                    0.0809313243710677,
                    0.0754435528243108,
                    0.07628273257619839,
                    0.08032966066100604,
                    0.07818179465283227,
                    0.08314777143892244,
                    0.08125352068449537,
                    0.08139045122638497,
                    0.0830740146567675,
                    0.08324825024097585,
                    0.08411798239941712,
                    0.08016922106726923,
                    0.08260152361109961,
                    0.08344921879692672,
                    0.08291530530127093,
                    0.08389389504050929,
                    0.08246078505471711,
                    0.0847381498214769,
                    0.08391848684726419,
                    0.0839596002468457,
                    0.08545857818227251,
                    0.08452301340562819,
                    0.08524870342050722,
                    0.0855286824761255,
                    0.08606011752180966,
                    0.0858118236522936,
                    0.08552298989798118,
                    0.08703282828244946,
                    0.08841507354897404,
                    0.087638790177697,
                    0.08026206228106918,
                    0.09119428855330125,
                    0.09146740980196899,
                    0.08713161996811185,
                    0.08748299711723087,
                    0.08811390205181989,
                    0.08667745087848891,
                    0.08678191379850285,
                    0.08603433342227758,
                    0.08515125948549422,
                    0.08043133221292467,
                    0.09432815127812526,
                    0.0800191692936784,
                    0.0891204429933413,
                    0.0883275832782111,
                    0.08890762599812811,
                    0.08867690755288125,
                    0.08875562538348551,
                    0.08567577359334447,
                    0.0844326012161547,
                    0.07935264920132136,
                    0.09151613418494578,
                    0.09098287382321481,
                    0.0918494833449019,
                    0.08674263232048687,
                    0.08563900589903273,
                    0.08560591726956487,
                    0.08699260689134207,
                    0.0860957258200076,
                    0.08249335249090478,
                    0.08209907522489737,
                    0.08155422333167053,
                    0.08825210955730642,
                    0.0935982335410157,
                    0.1044365608797947,
                    0.09280511356064611,
                    0.10339954332157973,
                    0.09295714370206046,
                    0.09167690382922887,
                    0.08588740935795848,
                    0.10321302184030491,
                    0.09038887519141166,
                    0.08209297431678908,
                    0.08171922530196737,
                    0.08270965702636188,
                    0.08721467660549209,
                    0.0921094236853509,
                    0.07639672238447236,
                    0.08880250315327551,
                    0.0803697441079558,
                    0.08910463760342356,
                    0.09461449867119316,
                    0.10529077216435216,
                    0.094900359842856,
                    0.0952246505665014,
                    0.09513804888393097
                  ],
                  "y": [
                    0.23799384286273395,
                    0.25257026611385686,
                    0.23607234921980993,
                    0.23351004392260122,
                    0.22118355006291165,
                    0.2368054863573365,
                    0.23467817578951994,
                    0.2492183617272187,
                    0.2508034667728444,
                    0.24444355146697733,
                    0.24638441809695522,
                    0.24066073110273717,
                    0.2500992724128512,
                    0.2512497389906705,
                    0.24780014207800183,
                    0.24345589003523718,
                    0.24950559698288596,
                    0.2512468585781459,
                    0.24966547399488767,
                    0.2527316371024155,
                    0.2514909232994099,
                    0.2511396047960298,
                    0.2586352644702073,
                    0.2527264459805575,
                    0.25572363816910854,
                    0.25022635152072403,
                    0.24556031408083032,
                    0.24675938835375505,
                    0.2517645801757151,
                    0.2538164492920105,
                    0.2525943989047087,
                    0.24974231033993394,
                    0.2532202192933685,
                    0.25582444275876653,
                    0.2529551831471422,
                    0.24839273295219666,
                    0.2527985746283016,
                    0.25097194701688813,
                    0.2556160224341649,
                    0.2510635252106125,
                    0.2514807436210522,
                    0.24684229713746925,
                    0.2470559585496679,
                    0.2502647364386594,
                    0.25222208388466083,
                    0.25400125143797925,
                    0.2552580905005643,
                    0.2528342014614715,
                    0.2493985001778562,
                    0.2528384528802303,
                    0.2550233498938586,
                    0.2523083029470582,
                    0.25483072502545034,
                    0.24847497589226655,
                    0.2574753029167793,
                    0.25608749134198927,
                    0.2511703011467725,
                    0.2547536078051821,
                    0.2529914277269956,
                    0.25209671945226275,
                    0.2515369929044722,
                    0.2548329181498087,
                    0.25068697393310213,
                    0.2501431184287837,
                    0.2540030651641933,
                    0.2507047934728426,
                    0.25641341551762764,
                    0.25780701625469604,
                    0.25521824386459036,
                    0.2557960577331986,
                    0.2534074976345324,
                    0.2585956950317595,
                    0.25957896568406236,
                    0.252325709986834,
                    0.251712426654483,
                    0.25704328332362836,
                    0.2586001109656427,
                    0.253032392102843,
                    0.2582294697836728,
                    0.25615608164991127,
                    0.2597090938462958,
                    0.25817099974935753,
                    0.25732394817011095,
                    0.251840973701201,
                    0.25554155233484255,
                    0.2538934288059256,
                    0.2604836395582832,
                    0.25924654113987,
                    0.252060534249514,
                    0.25873673802174624,
                    0.2544991930599525,
                    0.2555580966475103,
                    0.25971665260699334,
                    0.26240806334113453,
                    0.25987806370287453,
                    0.2617452826463283,
                    0.2588429180727659,
                    0.26140396995493137,
                    0.25751223896826564,
                    0.2552430711790555,
                    0.25949895623877345,
                    0.26532196167545063,
                    0.2635506977103081,
                    0.258422205804421,
                    0.2607411123181213,
                    0.26077220028163106,
                    0.2564147969225439,
                    0.2618370498319524,
                    0.2574255385529174,
                    0.256073589906999,
                    0.26231410783114406,
                    0.25693832431455654,
                    0.26010458097199834,
                    0.25641098202249235,
                    0.26214657077906367,
                    0.25970132700171716,
                    0.2612381465463163,
                    0.25838319112920943,
                    0.26193894135573725,
                    0.2607055197450044,
                    0.2558238819843697,
                    0.26039411892238445,
                    0.2596285073734872,
                    0.25672325638029103,
                    0.25835134322104664,
                    0.25779739913631283,
                    0.2616895893152762,
                    0.25981441847356196,
                    0.2560462182784489,
                    0.25273645729321736,
                    0.2618738353401766,
                    0.2577028990584764,
                    0.25564175186673194,
                    0.25320855897174505,
                    0.2538377838640009,
                    0.2526526964817669,
                    0.2569033566900406,
                    0.25799946734201123,
                    0.2534882015509653,
                    0.25968570363497123,
                    0.256679453449559,
                    0.2592257173283327,
                    0.26163534353357887,
                    0.2599259310342126,
                    0.2548622979379641,
                    0.2613736175677654,
                    0.26220709023889477,
                    0.256967005043854,
                    0.25695966823922817,
                    0.2579806183913517,
                    0.26008790595455256,
                    0.2542587612681432,
                    0.25510121711750094,
                    0.2557056361980953,
                    0.2559235751087734,
                    0.2588756602797714,
                    0.26361563888417805,
                    0.2629685046632935,
                    0.26430512690245644,
                    0.25818162361334757,
                    0.25844180234975545,
                    0.2618657322486643,
                    0.258159260340855,
                    0.2560703510169188,
                    0.25513589733560715,
                    0.2603661126674567,
                    0.2609181723092779,
                    0.25602619550937156,
                    0.2583086996205922,
                    0.25882218456222217,
                    0.2602180736801283,
                    0.26155620250780726,
                    0.26080104715505814,
                    0.257790014753141,
                    0.25705983134166244,
                    0.25906326121060286
                  ]
                }
              ],
              "layout": {
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "heatmapgl": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmapgl"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                },
                "title": {
                  "text": "Slice Plot"
                },
                "xaxis": {
                  "title": {
                    "text": "lambda_l1"
                  }
                },
                "yaxis": {
                  "title": {
                    "text": "Objective Value"
                  }
                }
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "opt.visualization.plot_slice(lgb_study.get(boosters[0]), params=['lambda_l1'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## FLAML experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_weight = np.ones(len(y))\n",
        "sample_weight[y == 1] *= counter[0]/counter[1]\n",
        "\n",
        "from flaml.model import XGBoostSklearnEstimator, LGBMEstimator\n",
        "\n",
        "class CostSensitiveXGB(XGBoostSklearnEstimator):\n",
        "    def __init__(self, **params):\n",
        "        super().__init__(booster='dart', scale_pos_weight=counter[0]/(counter[1]), **params)\n",
        "        \n",
        "class CostSensitiveLGBM(LGBMEstimator):\n",
        "    def __init__(self, **params):\n",
        "        super().__init__(boosting_type='dart', scale_pos_weight=counter[0]/(counter[1]), **params)\n",
        "\n",
        "from flaml import AutoML\n",
        "automl = AutoML()\n",
        "automl.add_learner(learner_name='CostXGB', learner_class=CostSensitiveXGB)\n",
        "automl.add_learner(learner_name='CostLGBM', learner_class=CostSensitiveLGBM)\n",
        "\n",
        "automl_params = {\n",
        "    \"time_budget\": 60*30,\n",
        "    \"metric\": 'ap',\n",
        "    \"eval_method\":'cv',\n",
        "    \"estimator_list\": ['xgboost'],\n",
        "    \"task\": 'classification',\n",
        "    \"log_file_name\": 'stroke_classification.log',\n",
        "    \"seed\": 7,\n",
        "    \"n_jobs\": 8,\n",
        "    \"split_ratio\": 0.3,\n",
        "    \"n_splits\": 10,\n",
        "    \"split_type\": 'stratified',\n",
        "    \"sample_weight\": sample_weight\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[flaml.automl: 10-20 17:47:03] {1459} INFO - Data split method: stratified\n",
            "[flaml.automl: 10-20 17:47:03] {1463} INFO - Evaluation method: cv\n",
            "[flaml.automl: 10-20 17:47:03] {1511} INFO - Minimizing error metric: 1-ap\n",
            "[flaml.automl: 10-20 17:47:03] {1548} INFO - List of ML learners in AutoML Run: ['xgboost']\n",
            "[flaml.automl: 10-20 17:47:03] {1778} INFO - iteration 0, current learner xgboost\n",
            "[flaml.automl: 10-20 17:47:04] {1895} INFO - Estimated sufficient time budget=3320s. Estimated necessary time budget=3s.\n",
            "[flaml.automl: 10-20 17:47:04] {1967} INFO -  at 0.4s,\testimator xgboost's best error=0.2208,\tbest estimator xgboost's best error=0.2208\n",
            "[flaml.automl: 10-20 17:47:04] {1778} INFO - iteration 1, current learner xgboost\n",
            "[flaml.automl: 10-20 17:47:04] {1967} INFO -  at 0.8s,\testimator xgboost's best error=0.1936,\tbest estimator xgboost's best error=0.1936\n",
            "[flaml.automl: 10-20 17:47:04] {1778} INFO - iteration 2, current learner xgboost\n",
            "[flaml.automl: 10-20 17:47:05] {1967} INFO -  at 1.2s,\testimator xgboost's best error=0.1936,\tbest estimator xgboost's best error=0.1936\n",
            "[flaml.automl: 10-20 17:47:05] {1778} INFO - iteration 3, current learner xgboost\n",
            "[flaml.automl: 10-20 17:47:05] {1967} INFO -  at 1.6s,\testimator xgboost's best error=0.1936,\tbest estimator xgboost's best error=0.1936\n",
            "[flaml.automl: 10-20 17:47:05] {1778} INFO - iteration 4, current learner xgboost\n",
            "[flaml.automl: 10-20 17:47:05] {1967} INFO -  at 2.1s,\testimator xgboost's best error=0.1866,\tbest estimator xgboost's best error=0.1866\n",
            "[flaml.automl: 10-20 17:47:05] {1778} INFO - iteration 5, current learner xgboost\n",
            "[flaml.automl: 10-20 17:47:06] {1967} INFO -  at 2.5s,\testimator xgboost's best error=0.1866,\tbest estimator xgboost's best error=0.1866\n",
            "[flaml.automl: 10-20 17:47:06] {1778} INFO - iteration 6, current learner xgboost\n",
            "[flaml.automl: 10-20 17:47:07] {1967} INFO -  at 3.3s,\testimator xgboost's best error=0.1866,\tbest estimator xgboost's best error=0.1866\n",
            "[flaml.automl: 10-20 17:47:07] {1778} INFO - iteration 7, current learner xgboost\n",
            "[flaml.automl: 10-20 17:47:07] {1967} INFO -  at 3.8s,\testimator xgboost's best error=0.1866,\tbest estimator xgboost's best error=0.1866\n",
            "[flaml.automl: 10-20 17:47:07] {1778} INFO - iteration 8, current learner xgboost\n",
            "[flaml.automl: 10-20 17:47:08] {1967} INFO -  at 5.1s,\testimator xgboost's best error=0.1770,\tbest estimator xgboost's best error=0.1770\n",
            "[flaml.automl: 10-20 17:47:08] {1778} INFO - iteration 9, current learner xgboost\n",
            "[flaml.automl: 10-20 17:47:09] {1967} INFO -  at 6.1s,\testimator xgboost's best error=0.1770,\tbest estimator xgboost's best error=0.1770\n",
            "[flaml.automl: 10-20 17:47:09] {1778} INFO - iteration 10, current learner xgboost\n",
            "[flaml.automl: 10-20 17:47:11] {1967} INFO -  at 8.0s,\testimator xgboost's best error=0.1770,\tbest estimator xgboost's best error=0.1770\n",
            "[flaml.automl: 10-20 17:47:11] {1778} INFO - iteration 11, current learner xgboost\n",
            "[flaml.automl: 10-20 17:47:13] {1967} INFO -  at 9.4s,\testimator xgboost's best error=0.1770,\tbest estimator xgboost's best error=0.1770\n",
            "[flaml.automl: 10-20 17:47:13] {1778} INFO - iteration 12, current learner xgboost\n",
            "[flaml.automl: 10-20 17:47:14] {1967} INFO -  at 10.6s,\testimator xgboost's best error=0.1770,\tbest estimator xgboost's best error=0.1770\n",
            "[flaml.automl: 10-20 17:47:14] {1778} INFO - iteration 13, current learner xgboost\n",
            "[flaml.automl: 10-20 17:47:15] {1967} INFO -  at 11.3s,\testimator xgboost's best error=0.1770,\tbest estimator xgboost's best error=0.1770\n",
            "[flaml.automl: 10-20 17:47:15] {1778} INFO - iteration 14, current learner xgboost\n",
            "[flaml.automl: 10-20 17:47:16] {1967} INFO -  at 12.7s,\testimator xgboost's best error=0.1731,\tbest estimator xgboost's best error=0.1731\n",
            "[flaml.automl: 10-20 17:47:16] {1778} INFO - iteration 15, current learner xgboost\n",
            "[flaml.automl: 10-20 17:47:17] {1967} INFO -  at 14.1s,\testimator xgboost's best error=0.1731,\tbest estimator xgboost's best error=0.1731\n",
            "[flaml.automl: 10-20 17:47:17] {1778} INFO - iteration 16, current learner xgboost\n",
            "[flaml.automl: 10-20 17:47:19] {1967} INFO -  at 15.7s,\testimator xgboost's best error=0.1731,\tbest estimator xgboost's best error=0.1731\n",
            "[flaml.automl: 10-20 17:47:19] {1778} INFO - iteration 17, current learner xgboost\n",
            "[flaml.automl: 10-20 17:47:20] {1967} INFO -  at 16.4s,\testimator xgboost's best error=0.1731,\tbest estimator xgboost's best error=0.1731\n",
            "[flaml.automl: 10-20 17:47:20] {1778} INFO - iteration 18, current learner xgboost\n",
            "[flaml.automl: 10-20 17:47:24] {1967} INFO -  at 20.4s,\testimator xgboost's best error=0.1731,\tbest estimator xgboost's best error=0.1731\n",
            "[flaml.automl: 10-20 17:47:24] {1778} INFO - iteration 19, current learner xgboost\n",
            "[flaml.automl: 10-20 17:47:25] {1967} INFO -  at 21.5s,\testimator xgboost's best error=0.1711,\tbest estimator xgboost's best error=0.1711\n",
            "[flaml.automl: 10-20 17:47:25] {1778} INFO - iteration 20, current learner xgboost\n",
            "[flaml.automl: 10-20 17:47:26] {1967} INFO -  at 23.1s,\testimator xgboost's best error=0.1711,\tbest estimator xgboost's best error=0.1711\n",
            "[flaml.automl: 10-20 17:47:26] {1778} INFO - iteration 21, current learner xgboost\n",
            "[flaml.automl: 10-20 17:47:27] {1967} INFO -  at 23.8s,\testimator xgboost's best error=0.1711,\tbest estimator xgboost's best error=0.1711\n",
            "[flaml.automl: 10-20 17:47:27] {1778} INFO - iteration 22, current learner xgboost\n",
            "[flaml.automl: 10-20 17:47:29] {1967} INFO -  at 25.8s,\testimator xgboost's best error=0.1711,\tbest estimator xgboost's best error=0.1711\n",
            "[flaml.automl: 10-20 17:47:29] {1778} INFO - iteration 23, current learner xgboost\n",
            "[flaml.automl: 10-20 17:47:30] {1967} INFO -  at 27.0s,\testimator xgboost's best error=0.1711,\tbest estimator xgboost's best error=0.1711\n",
            "[flaml.automl: 10-20 17:47:30] {1778} INFO - iteration 24, current learner xgboost\n",
            "[flaml.automl: 10-20 17:47:32] {1967} INFO -  at 29.2s,\testimator xgboost's best error=0.1711,\tbest estimator xgboost's best error=0.1711\n",
            "[flaml.automl: 10-20 17:47:32] {1778} INFO - iteration 25, current learner xgboost\n",
            "[flaml.automl: 10-20 17:47:34] {1967} INFO -  at 30.5s,\testimator xgboost's best error=0.1711,\tbest estimator xgboost's best error=0.1711\n",
            "[flaml.automl: 10-20 17:47:34] {1778} INFO - iteration 26, current learner xgboost\n",
            "[flaml.automl: 10-20 17:47:35] {1967} INFO -  at 31.4s,\testimator xgboost's best error=0.1711,\tbest estimator xgboost's best error=0.1711\n",
            "[flaml.automl: 10-20 17:47:35] {1778} INFO - iteration 27, current learner xgboost\n",
            "[flaml.automl: 10-20 17:47:36] {1967} INFO -  at 32.3s,\testimator xgboost's best error=0.1711,\tbest estimator xgboost's best error=0.1711\n",
            "[flaml.automl: 10-20 17:47:36] {1778} INFO - iteration 28, current learner xgboost\n",
            "[flaml.automl: 10-20 17:47:38] {1967} INFO -  at 34.3s,\testimator xgboost's best error=0.1711,\tbest estimator xgboost's best error=0.1711\n",
            "[flaml.automl: 10-20 17:47:38] {1778} INFO - iteration 29, current learner xgboost\n",
            "[flaml.automl: 10-20 17:47:38] {1967} INFO -  at 35.0s,\testimator xgboost's best error=0.1711,\tbest estimator xgboost's best error=0.1711\n",
            "[flaml.automl: 10-20 17:47:38] {1778} INFO - iteration 30, current learner xgboost\n",
            "[flaml.automl: 10-20 17:47:42] {1967} INFO -  at 38.3s,\testimator xgboost's best error=0.1711,\tbest estimator xgboost's best error=0.1711\n",
            "[flaml.automl: 10-20 17:47:42] {1778} INFO - iteration 31, current learner xgboost\n",
            "[flaml.automl: 10-20 17:47:42] {1967} INFO -  at 38.9s,\testimator xgboost's best error=0.1711,\tbest estimator xgboost's best error=0.1711\n",
            "[flaml.automl: 10-20 17:47:42] {1778} INFO - iteration 32, current learner xgboost\n",
            "[flaml.automl: 10-20 17:47:48] {1967} INFO -  at 44.4s,\testimator xgboost's best error=0.1711,\tbest estimator xgboost's best error=0.1711\n",
            "[flaml.automl: 10-20 17:47:48] {1778} INFO - iteration 33, current learner xgboost\n",
            "[flaml.automl: 10-20 17:47:49] {1967} INFO -  at 45.4s,\testimator xgboost's best error=0.1711,\tbest estimator xgboost's best error=0.1711\n",
            "[flaml.automl: 10-20 17:47:49] {1778} INFO - iteration 34, current learner xgboost\n",
            "[flaml.automl: 10-20 17:47:50] {1967} INFO -  at 46.7s,\testimator xgboost's best error=0.1711,\tbest estimator xgboost's best error=0.1711\n",
            "[flaml.automl: 10-20 17:47:50] {1778} INFO - iteration 35, current learner xgboost\n",
            "[flaml.automl: 10-20 17:47:52] {1967} INFO -  at 48.4s,\testimator xgboost's best error=0.1711,\tbest estimator xgboost's best error=0.1711\n",
            "[flaml.automl: 10-20 17:47:52] {1778} INFO - iteration 36, current learner xgboost\n",
            "[flaml.automl: 10-20 17:47:53] {1967} INFO -  at 49.4s,\testimator xgboost's best error=0.1711,\tbest estimator xgboost's best error=0.1711\n",
            "[flaml.automl: 10-20 17:47:53] {1778} INFO - iteration 37, current learner xgboost\n",
            "[flaml.automl: 10-20 17:47:55] {1967} INFO -  at 51.3s,\testimator xgboost's best error=0.1711,\tbest estimator xgboost's best error=0.1711\n",
            "[flaml.automl: 10-20 17:47:55] {1778} INFO - iteration 38, current learner xgboost\n",
            "[flaml.automl: 10-20 17:47:56] {1967} INFO -  at 52.4s,\testimator xgboost's best error=0.1711,\tbest estimator xgboost's best error=0.1711\n",
            "[flaml.automl: 10-20 17:47:56] {1778} INFO - iteration 39, current learner xgboost\n",
            "[flaml.automl: 10-20 17:47:57] {1967} INFO -  at 53.5s,\testimator xgboost's best error=0.1711,\tbest estimator xgboost's best error=0.1711\n",
            "[flaml.automl: 10-20 17:47:57] {1778} INFO - iteration 40, current learner xgboost\n",
            "[flaml.automl: 10-20 17:47:58] {1967} INFO -  at 54.9s,\testimator xgboost's best error=0.1711,\tbest estimator xgboost's best error=0.1711\n",
            "[flaml.automl: 10-20 17:47:58] {1778} INFO - iteration 41, current learner xgboost\n",
            "[flaml.automl: 10-20 17:48:00] {1967} INFO -  at 56.5s,\testimator xgboost's best error=0.1711,\tbest estimator xgboost's best error=0.1711\n",
            "[flaml.automl: 10-20 17:48:00] {1778} INFO - iteration 42, current learner xgboost\n",
            "[flaml.automl: 10-20 17:48:01] {1967} INFO -  at 57.5s,\testimator xgboost's best error=0.1711,\tbest estimator xgboost's best error=0.1711\n",
            "[flaml.automl: 10-20 17:48:01] {1778} INFO - iteration 43, current learner xgboost\n",
            "[flaml.automl: 10-20 17:48:04] {1967} INFO -  at 60.6s,\testimator xgboost's best error=0.1711,\tbest estimator xgboost's best error=0.1711\n",
            "[flaml.automl: 10-20 17:48:04] {1778} INFO - iteration 44, current learner xgboost\n",
            "[flaml.automl: 10-20 17:48:05] {1967} INFO -  at 61.4s,\testimator xgboost's best error=0.1711,\tbest estimator xgboost's best error=0.1711\n",
            "[flaml.automl: 10-20 17:48:05] {1778} INFO - iteration 45, current learner xgboost\n",
            "[flaml.automl: 10-20 17:48:06] {1967} INFO -  at 62.3s,\testimator xgboost's best error=0.1711,\tbest estimator xgboost's best error=0.1711\n",
            "[flaml.automl: 10-20 17:48:06] {1778} INFO - iteration 46, current learner xgboost\n",
            "[flaml.automl: 10-20 17:48:07] {1967} INFO -  at 64.1s,\testimator xgboost's best error=0.1711,\tbest estimator xgboost's best error=0.1711\n",
            "[flaml.automl: 10-20 17:48:07] {1778} INFO - iteration 47, current learner xgboost\n",
            "[flaml.automl: 10-20 17:48:09] {1967} INFO -  at 65.9s,\testimator xgboost's best error=0.1711,\tbest estimator xgboost's best error=0.1711\n",
            "[flaml.automl: 10-20 17:48:09] {1778} INFO - iteration 48, current learner xgboost\n",
            "[flaml.automl: 10-20 17:48:10] {1967} INFO -  at 66.8s,\testimator xgboost's best error=0.1711,\tbest estimator xgboost's best error=0.1711\n",
            "[flaml.automl: 10-20 17:48:10] {1778} INFO - iteration 49, current learner xgboost\n",
            "[flaml.automl: 10-20 17:48:12] {1967} INFO -  at 68.5s,\testimator xgboost's best error=0.1711,\tbest estimator xgboost's best error=0.1711\n",
            "[flaml.automl: 10-20 17:48:12] {1778} INFO - iteration 50, current learner xgboost\n",
            "[flaml.automl: 10-20 17:48:13] {1967} INFO -  at 69.5s,\testimator xgboost's best error=0.1711,\tbest estimator xgboost's best error=0.1711\n",
            "[flaml.automl: 10-20 17:48:13] {1778} INFO - iteration 51, current learner xgboost\n",
            "[flaml.automl: 10-20 17:48:14] {1967} INFO -  at 70.5s,\testimator xgboost's best error=0.1711,\tbest estimator xgboost's best error=0.1711\n",
            "[flaml.automl: 10-20 17:48:14] {1778} INFO - iteration 52, current learner xgboost\n",
            "[flaml.automl: 10-20 17:48:16] {1967} INFO -  at 72.2s,\testimator xgboost's best error=0.1711,\tbest estimator xgboost's best error=0.1711\n",
            "[flaml.automl: 10-20 17:48:16] {1778} INFO - iteration 53, current learner xgboost\n",
            "[flaml.automl: 10-20 17:48:17] {1967} INFO -  at 73.8s,\testimator xgboost's best error=0.1711,\tbest estimator xgboost's best error=0.1711\n",
            "[flaml.automl: 10-20 17:48:17] {1778} INFO - iteration 54, current learner xgboost\n",
            "[flaml.automl: 10-20 17:48:18] {1967} INFO -  at 75.1s,\testimator xgboost's best error=0.1711,\tbest estimator xgboost's best error=0.1711\n",
            "[flaml.automl: 10-20 17:48:18] {1778} INFO - iteration 55, current learner xgboost\n",
            "[flaml.automl: 10-20 17:48:19] {1967} INFO -  at 76.0s,\testimator xgboost's best error=0.1711,\tbest estimator xgboost's best error=0.1711\n",
            "[flaml.automl: 10-20 17:48:19] {1778} INFO - iteration 56, current learner xgboost\n",
            "[flaml.automl: 10-20 17:48:21] {1967} INFO -  at 78.1s,\testimator xgboost's best error=0.1699,\tbest estimator xgboost's best error=0.1699\n",
            "[flaml.automl: 10-20 17:48:21] {1778} INFO - iteration 57, current learner xgboost\n",
            "[flaml.automl: 10-20 17:48:23] {1967} INFO -  at 79.5s,\testimator xgboost's best error=0.1699,\tbest estimator xgboost's best error=0.1699\n",
            "[flaml.automl: 10-20 17:48:23] {1778} INFO - iteration 58, current learner xgboost\n",
            "[flaml.automl: 10-20 17:48:26] {1967} INFO -  at 82.2s,\testimator xgboost's best error=0.1699,\tbest estimator xgboost's best error=0.1699\n",
            "[flaml.automl: 10-20 17:48:26] {1778} INFO - iteration 59, current learner xgboost\n",
            "[flaml.automl: 10-20 17:48:28] {1967} INFO -  at 84.2s,\testimator xgboost's best error=0.1699,\tbest estimator xgboost's best error=0.1699\n",
            "[flaml.automl: 10-20 17:48:28] {1778} INFO - iteration 60, current learner xgboost\n",
            "[flaml.automl: 10-20 17:48:29] {1967} INFO -  at 85.4s,\testimator xgboost's best error=0.1684,\tbest estimator xgboost's best error=0.1684\n",
            "[flaml.automl: 10-20 17:48:29] {1778} INFO - iteration 61, current learner xgboost\n",
            "[flaml.automl: 10-20 17:48:30] {1967} INFO -  at 86.9s,\testimator xgboost's best error=0.1684,\tbest estimator xgboost's best error=0.1684\n",
            "[flaml.automl: 10-20 17:48:30] {1778} INFO - iteration 62, current learner xgboost\n",
            "[flaml.automl: 10-20 17:48:31] {1967} INFO -  at 88.0s,\testimator xgboost's best error=0.1684,\tbest estimator xgboost's best error=0.1684\n",
            "[flaml.automl: 10-20 17:48:31] {1778} INFO - iteration 63, current learner xgboost\n",
            "[flaml.automl: 10-20 17:48:33] {1967} INFO -  at 89.2s,\testimator xgboost's best error=0.1684,\tbest estimator xgboost's best error=0.1684\n",
            "[flaml.automl: 10-20 17:48:33] {1778} INFO - iteration 64, current learner xgboost\n",
            "[flaml.automl: 10-20 17:48:34] {1967} INFO -  at 90.6s,\testimator xgboost's best error=0.1684,\tbest estimator xgboost's best error=0.1684\n",
            "[flaml.automl: 10-20 17:48:34] {1778} INFO - iteration 65, current learner xgboost\n",
            "[flaml.automl: 10-20 17:48:35] {1967} INFO -  at 92.0s,\testimator xgboost's best error=0.1684,\tbest estimator xgboost's best error=0.1684\n",
            "[flaml.automl: 10-20 17:48:35] {1778} INFO - iteration 66, current learner xgboost\n",
            "[flaml.automl: 10-20 17:48:37] {1967} INFO -  at 93.3s,\testimator xgboost's best error=0.1684,\tbest estimator xgboost's best error=0.1684\n",
            "[flaml.automl: 10-20 17:48:37] {1778} INFO - iteration 67, current learner xgboost\n",
            "[flaml.automl: 10-20 17:48:38] {1967} INFO -  at 94.5s,\testimator xgboost's best error=0.1684,\tbest estimator xgboost's best error=0.1684\n",
            "[flaml.automl: 10-20 17:48:38] {1778} INFO - iteration 68, current learner xgboost\n",
            "[flaml.automl: 10-20 17:48:39] {1967} INFO -  at 95.9s,\testimator xgboost's best error=0.1684,\tbest estimator xgboost's best error=0.1684\n",
            "[flaml.automl: 10-20 17:48:39] {1778} INFO - iteration 69, current learner xgboost\n",
            "[flaml.automl: 10-20 17:48:44] {1967} INFO -  at 100.2s,\testimator xgboost's best error=0.1684,\tbest estimator xgboost's best error=0.1684\n",
            "[flaml.automl: 10-20 17:48:44] {1778} INFO - iteration 70, current learner xgboost\n",
            "[flaml.automl: 10-20 17:48:44] {1967} INFO -  at 100.7s,\testimator xgboost's best error=0.1684,\tbest estimator xgboost's best error=0.1684\n",
            "[flaml.automl: 10-20 17:48:44] {1778} INFO - iteration 71, current learner xgboost\n",
            "[flaml.automl: 10-20 17:48:45] {1967} INFO -  at 101.9s,\testimator xgboost's best error=0.1684,\tbest estimator xgboost's best error=0.1684\n",
            "[flaml.automl: 10-20 17:48:45] {1778} INFO - iteration 72, current learner xgboost\n",
            "[flaml.automl: 10-20 17:48:47] {1967} INFO -  at 103.3s,\testimator xgboost's best error=0.1684,\tbest estimator xgboost's best error=0.1684\n",
            "[flaml.automl: 10-20 17:48:47] {1778} INFO - iteration 73, current learner xgboost\n",
            "[flaml.automl: 10-20 17:48:48] {1967} INFO -  at 104.2s,\testimator xgboost's best error=0.1684,\tbest estimator xgboost's best error=0.1684\n",
            "[flaml.automl: 10-20 17:48:48] {1778} INFO - iteration 74, current learner xgboost\n",
            "[flaml.automl: 10-20 17:48:49] {1967} INFO -  at 106.0s,\testimator xgboost's best error=0.1684,\tbest estimator xgboost's best error=0.1684\n",
            "[flaml.automl: 10-20 17:48:49] {1778} INFO - iteration 75, current learner xgboost\n",
            "[flaml.automl: 10-20 17:48:50] {1967} INFO -  at 106.7s,\testimator xgboost's best error=0.1684,\tbest estimator xgboost's best error=0.1684\n",
            "[flaml.automl: 10-20 17:48:50] {1778} INFO - iteration 76, current learner xgboost\n",
            "[flaml.automl: 10-20 17:48:53] {1967} INFO -  at 109.9s,\testimator xgboost's best error=0.1684,\tbest estimator xgboost's best error=0.1684\n",
            "[flaml.automl: 10-20 17:48:53] {1778} INFO - iteration 77, current learner xgboost\n",
            "[flaml.automl: 10-20 17:48:55] {1967} INFO -  at 111.6s,\testimator xgboost's best error=0.1684,\tbest estimator xgboost's best error=0.1684\n",
            "[flaml.automl: 10-20 17:48:55] {1778} INFO - iteration 78, current learner xgboost\n",
            "[flaml.automl: 10-20 17:48:56] {1967} INFO -  at 112.6s,\testimator xgboost's best error=0.1684,\tbest estimator xgboost's best error=0.1684\n",
            "[flaml.automl: 10-20 17:48:56] {1778} INFO - iteration 79, current learner xgboost\n",
            "[flaml.automl: 10-20 17:48:57] {1967} INFO -  at 114.1s,\testimator xgboost's best error=0.1684,\tbest estimator xgboost's best error=0.1684\n",
            "[flaml.automl: 10-20 17:48:57] {1778} INFO - iteration 80, current learner xgboost\n",
            "[flaml.automl: 10-20 17:48:59] {1967} INFO -  at 115.2s,\testimator xgboost's best error=0.1684,\tbest estimator xgboost's best error=0.1684\n",
            "[flaml.automl: 10-20 17:48:59] {1778} INFO - iteration 81, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:01] {1967} INFO -  at 117.4s,\testimator xgboost's best error=0.1684,\tbest estimator xgboost's best error=0.1684\n",
            "[flaml.automl: 10-20 17:49:01] {1778} INFO - iteration 82, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:01] {1967} INFO -  at 118.2s,\testimator xgboost's best error=0.1684,\tbest estimator xgboost's best error=0.1684\n",
            "[flaml.automl: 10-20 17:49:01] {1778} INFO - iteration 83, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:03] {1967} INFO -  at 119.6s,\testimator xgboost's best error=0.1684,\tbest estimator xgboost's best error=0.1684\n",
            "[flaml.automl: 10-20 17:49:03] {1778} INFO - iteration 84, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:04] {1967} INFO -  at 120.7s,\testimator xgboost's best error=0.1684,\tbest estimator xgboost's best error=0.1684\n",
            "[flaml.automl: 10-20 17:49:04] {1778} INFO - iteration 85, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:06] {1967} INFO -  at 123.1s,\testimator xgboost's best error=0.1684,\tbest estimator xgboost's best error=0.1684\n",
            "[flaml.automl: 10-20 17:49:06] {1778} INFO - iteration 86, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:07] {1967} INFO -  at 123.9s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:07] {1778} INFO - iteration 87, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:08] {1967} INFO -  at 125.1s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:08] {1778} INFO - iteration 88, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:09] {1967} INFO -  at 125.7s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:09] {1778} INFO - iteration 89, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:10] {1967} INFO -  at 126.3s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:10] {1778} INFO - iteration 90, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:11] {1967} INFO -  at 127.2s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:11] {1778} INFO - iteration 91, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:11] {1967} INFO -  at 128.0s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:11] {1778} INFO - iteration 92, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:12] {1967} INFO -  at 128.9s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:12] {1778} INFO - iteration 93, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:13] {1967} INFO -  at 129.8s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:13] {1778} INFO - iteration 94, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:14] {1967} INFO -  at 130.7s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:14] {1778} INFO - iteration 95, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:14] {1967} INFO -  at 131.1s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:14] {1778} INFO - iteration 96, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:16] {1967} INFO -  at 132.9s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:16] {1778} INFO - iteration 97, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:17] {1967} INFO -  at 133.3s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:17] {1778} INFO - iteration 98, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:19] {1967} INFO -  at 135.5s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:19] {1778} INFO - iteration 99, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:19] {1967} INFO -  at 136.2s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:19] {1778} INFO - iteration 100, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:20] {1967} INFO -  at 137.1s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:20] {1778} INFO - iteration 101, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:21] {1967} INFO -  at 137.9s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:21] {1778} INFO - iteration 102, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:22] {1967} INFO -  at 138.7s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:22] {1778} INFO - iteration 103, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:24] {1967} INFO -  at 140.3s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:24] {1778} INFO - iteration 104, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:24] {1967} INFO -  at 140.9s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:24] {1778} INFO - iteration 105, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:25] {1967} INFO -  at 141.7s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:25] {1778} INFO - iteration 106, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:26] {1967} INFO -  at 142.4s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:26] {1778} INFO - iteration 107, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:26] {1967} INFO -  at 142.9s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:26] {1778} INFO - iteration 108, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:28] {1967} INFO -  at 145.0s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:28] {1778} INFO - iteration 109, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:29] {1967} INFO -  at 145.8s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:29] {1778} INFO - iteration 110, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:30] {1967} INFO -  at 146.6s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:30] {1778} INFO - iteration 111, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:31] {1967} INFO -  at 147.2s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:31] {1778} INFO - iteration 112, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:32] {1967} INFO -  at 148.4s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:32] {1778} INFO - iteration 113, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:34] {1967} INFO -  at 150.4s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:34] {1778} INFO - iteration 114, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:34] {1967} INFO -  at 150.8s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:34] {1778} INFO - iteration 115, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:35] {1967} INFO -  at 151.8s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:35] {1778} INFO - iteration 116, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:36] {1967} INFO -  at 152.6s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:36] {1778} INFO - iteration 117, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:36] {1967} INFO -  at 153.1s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:36] {1778} INFO - iteration 118, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:39] {1967} INFO -  at 155.2s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:39] {1778} INFO - iteration 119, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:39] {1967} INFO -  at 156.0s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:39] {1778} INFO - iteration 120, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:40] {1967} INFO -  at 156.8s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:40] {1778} INFO - iteration 121, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:41] {1967} INFO -  at 157.3s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:41] {1778} INFO - iteration 122, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:42] {1967} INFO -  at 158.3s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:42] {1778} INFO - iteration 123, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:42] {1967} INFO -  at 158.8s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:42] {1778} INFO - iteration 124, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:44] {1967} INFO -  at 160.2s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:44] {1778} INFO - iteration 125, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:45] {1967} INFO -  at 161.3s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:45] {1778} INFO - iteration 126, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:45] {1967} INFO -  at 161.9s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:45] {1778} INFO - iteration 127, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:46] {1967} INFO -  at 162.8s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:46] {1778} INFO - iteration 128, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:47] {1967} INFO -  at 163.5s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:47] {1778} INFO - iteration 129, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:49] {1967} INFO -  at 165.3s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:49] {1778} INFO - iteration 130, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:49] {1967} INFO -  at 165.7s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:49] {1778} INFO - iteration 131, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:50] {1967} INFO -  at 166.2s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:50] {1778} INFO - iteration 132, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:50] {1967} INFO -  at 167.1s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:50] {1778} INFO - iteration 133, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:51] {1967} INFO -  at 167.9s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:51] {1778} INFO - iteration 134, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:52] {1967} INFO -  at 168.5s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:52] {1778} INFO - iteration 135, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:52] {1967} INFO -  at 169.0s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:52] {1778} INFO - iteration 136, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:54] {1967} INFO -  at 170.2s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:54] {1778} INFO - iteration 137, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:54] {1967} INFO -  at 171.0s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:54] {1778} INFO - iteration 138, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:55] {1967} INFO -  at 171.5s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:55] {1778} INFO - iteration 139, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:55] {1967} INFO -  at 171.9s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:55] {1778} INFO - iteration 140, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:58] {1967} INFO -  at 174.8s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:58] {1778} INFO - iteration 141, current learner xgboost\n",
            "[flaml.automl: 10-20 17:49:59] {1967} INFO -  at 175.8s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:49:59] {1778} INFO - iteration 142, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:00] {1967} INFO -  at 176.3s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:00] {1778} INFO - iteration 143, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:01] {1967} INFO -  at 177.2s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:01] {1778} INFO - iteration 144, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:01] {1967} INFO -  at 177.9s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:01] {1778} INFO - iteration 145, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:02] {1967} INFO -  at 178.6s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:02] {1778} INFO - iteration 146, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:03] {1967} INFO -  at 179.5s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:03] {1778} INFO - iteration 147, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:03] {1967} INFO -  at 180.0s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:03] {1778} INFO - iteration 148, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:04] {1967} INFO -  at 181.0s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:04] {1778} INFO - iteration 149, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:05] {1967} INFO -  at 181.8s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:05] {1778} INFO - iteration 150, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:06] {1967} INFO -  at 182.5s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:06] {1778} INFO - iteration 151, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:07] {1967} INFO -  at 183.7s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:07] {1778} INFO - iteration 152, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:08] {1967} INFO -  at 184.3s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:08] {1778} INFO - iteration 153, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:08] {1967} INFO -  at 184.8s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:08] {1778} INFO - iteration 154, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:09] {1967} INFO -  at 186.1s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:09] {1778} INFO - iteration 155, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:10] {1967} INFO -  at 186.9s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:10] {1778} INFO - iteration 156, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:11] {1967} INFO -  at 187.8s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:11] {1778} INFO - iteration 157, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:12] {1967} INFO -  at 188.2s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:12] {1778} INFO - iteration 158, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:14] {1967} INFO -  at 190.7s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:14] {1778} INFO - iteration 159, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:15] {1967} INFO -  at 191.9s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:15] {1778} INFO - iteration 160, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:16] {1967} INFO -  at 192.4s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:16] {1778} INFO - iteration 161, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:17] {1967} INFO -  at 193.2s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:17] {1778} INFO - iteration 162, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:17] {1967} INFO -  at 194.0s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:17] {1778} INFO - iteration 163, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:18] {1967} INFO -  at 194.7s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:18] {1778} INFO - iteration 164, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:19] {1967} INFO -  at 195.6s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:19] {1778} INFO - iteration 165, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:20] {1967} INFO -  at 196.2s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:20] {1778} INFO - iteration 166, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:20] {1967} INFO -  at 197.1s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:20] {1778} INFO - iteration 167, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:21] {1967} INFO -  at 197.8s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:21] {1778} INFO - iteration 168, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:22] {1967} INFO -  at 198.6s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:22] {1778} INFO - iteration 169, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:24] {1967} INFO -  at 200.4s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:24] {1778} INFO - iteration 170, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:24] {1967} INFO -  at 200.8s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:24] {1778} INFO - iteration 171, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:25] {1967} INFO -  at 201.3s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:25] {1778} INFO - iteration 172, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:26] {1967} INFO -  at 202.2s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:26] {1778} INFO - iteration 173, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:27] {1967} INFO -  at 203.8s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:27] {1778} INFO - iteration 174, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:28] {1967} INFO -  at 204.3s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:28] {1778} INFO - iteration 175, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:29] {1967} INFO -  at 205.2s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:29] {1778} INFO - iteration 176, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:29] {1967} INFO -  at 205.8s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:29] {1778} INFO - iteration 177, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:30] {1967} INFO -  at 206.3s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:30] {1778} INFO - iteration 178, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:31] {1967} INFO -  at 207.6s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:31] {1778} INFO - iteration 179, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:31] {1967} INFO -  at 208.1s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:31] {1778} INFO - iteration 180, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:33] {1967} INFO -  at 210.0s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:33] {1778} INFO - iteration 181, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:34] {1967} INFO -  at 210.6s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:34] {1778} INFO - iteration 182, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:35] {1967} INFO -  at 211.3s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:35] {1778} INFO - iteration 183, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:36] {1967} INFO -  at 212.5s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:36] {1778} INFO - iteration 184, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:36] {1967} INFO -  at 213.0s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:36] {1778} INFO - iteration 185, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:37] {1967} INFO -  at 213.7s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:37] {1778} INFO - iteration 186, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:38] {1967} INFO -  at 214.4s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:38] {1778} INFO - iteration 187, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:38] {1967} INFO -  at 215.1s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:38] {1778} INFO - iteration 188, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:39] {1967} INFO -  at 215.9s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:39] {1778} INFO - iteration 189, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:41] {1967} INFO -  at 217.7s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:41] {1778} INFO - iteration 190, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:41] {1967} INFO -  at 218.1s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:41] {1778} INFO - iteration 191, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:42] {1967} INFO -  at 218.8s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:42] {1778} INFO - iteration 192, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:43] {1967} INFO -  at 219.7s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:43] {1778} INFO - iteration 193, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:44] {1967} INFO -  at 220.2s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:44] {1778} INFO - iteration 194, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:45] {1967} INFO -  at 221.6s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:45] {1778} INFO - iteration 195, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:46] {1967} INFO -  at 222.4s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:46] {1778} INFO - iteration 196, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:47] {1967} INFO -  at 223.3s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:47] {1778} INFO - iteration 197, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:47] {1967} INFO -  at 223.8s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:47] {1778} INFO - iteration 198, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:48] {1967} INFO -  at 225.0s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:48] {1778} INFO - iteration 199, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:49] {1967} INFO -  at 225.5s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:49] {1778} INFO - iteration 200, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:50] {1967} INFO -  at 227.1s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:50] {1778} INFO - iteration 201, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:51] {1967} INFO -  at 227.7s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:51] {1778} INFO - iteration 202, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:52] {1967} INFO -  at 228.7s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:52] {1778} INFO - iteration 203, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:54] {1967} INFO -  at 230.6s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:54] {1778} INFO - iteration 204, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:54] {1967} INFO -  at 231.0s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:54] {1778} INFO - iteration 205, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:55] {1967} INFO -  at 231.6s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:55] {1778} INFO - iteration 206, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:56] {1967} INFO -  at 232.6s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:56] {1778} INFO - iteration 207, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:57] {1967} INFO -  at 233.3s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:57] {1778} INFO - iteration 208, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:57] {1967} INFO -  at 234.0s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:57] {1778} INFO - iteration 209, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:58] {1967} INFO -  at 234.5s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:58] {1778} INFO - iteration 210, current learner xgboost\n",
            "[flaml.automl: 10-20 17:50:59] {1967} INFO -  at 235.6s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:50:59] {1778} INFO - iteration 211, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:00] {1967} INFO -  at 236.4s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:51:00] {1778} INFO - iteration 212, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:00] {1967} INFO -  at 237.0s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:51:00] {1778} INFO - iteration 213, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:01] {1967} INFO -  at 238.0s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:51:01] {1778} INFO - iteration 214, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:02] {1967} INFO -  at 238.7s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:51:02] {1778} INFO - iteration 215, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:03] {1967} INFO -  at 239.5s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:51:03] {1778} INFO - iteration 216, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:03] {1967} INFO -  at 240.1s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:51:03] {1778} INFO - iteration 217, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:04] {1967} INFO -  at 240.8s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:51:04] {1778} INFO - iteration 218, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:05] {1967} INFO -  at 241.6s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:51:05] {1778} INFO - iteration 219, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:05] {1967} INFO -  at 242.1s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:51:05] {1778} INFO - iteration 220, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:07] {1967} INFO -  at 243.8s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:51:07] {1778} INFO - iteration 221, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:08] {1967} INFO -  at 244.8s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:51:08] {1778} INFO - iteration 222, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:09] {1967} INFO -  at 245.4s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:51:09] {1778} INFO - iteration 223, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:09] {1967} INFO -  at 245.9s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:51:09] {1778} INFO - iteration 224, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:11] {1967} INFO -  at 247.5s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:51:11] {1778} INFO - iteration 225, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:12] {1967} INFO -  at 248.9s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:51:12] {1778} INFO - iteration 226, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:13] {1967} INFO -  at 249.4s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:51:13] {1778} INFO - iteration 227, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:13] {1967} INFO -  at 249.9s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:51:13] {1778} INFO - iteration 228, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:14] {1967} INFO -  at 250.9s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:51:14] {1778} INFO - iteration 229, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:15] {1967} INFO -  at 251.5s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:51:15] {1778} INFO - iteration 230, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:16] {1967} INFO -  at 252.6s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:51:16] {1778} INFO - iteration 231, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:17] {1967} INFO -  at 253.4s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:51:17] {1778} INFO - iteration 232, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:17] {1967} INFO -  at 254.0s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:51:17] {1778} INFO - iteration 233, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:19] {1967} INFO -  at 255.8s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:51:19] {1778} INFO - iteration 234, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:20] {1967} INFO -  at 256.3s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:51:20] {1778} INFO - iteration 235, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:21] {1967} INFO -  at 258.1s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:51:21] {1778} INFO - iteration 236, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:22] {1967} INFO -  at 258.6s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:51:22] {1778} INFO - iteration 237, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:22] {1967} INFO -  at 259.1s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:51:22] {1778} INFO - iteration 238, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:24] {1967} INFO -  at 260.3s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:51:24] {1778} INFO - iteration 239, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:25] {1967} INFO -  at 261.2s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:51:25] {1778} INFO - iteration 240, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:25] {1967} INFO -  at 261.8s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:51:25] {1778} INFO - iteration 241, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:26] {1967} INFO -  at 262.7s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:51:26] {1778} INFO - iteration 242, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:27] {1967} INFO -  at 263.3s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:51:27] {1778} INFO - iteration 243, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:27] {1967} INFO -  at 264.1s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:51:27] {1778} INFO - iteration 244, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:28] {1967} INFO -  at 264.8s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:51:28] {1778} INFO - iteration 245, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:29] {1967} INFO -  at 265.6s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:51:29] {1778} INFO - iteration 246, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:30] {1967} INFO -  at 266.2s,\testimator xgboost's best error=0.1644,\tbest estimator xgboost's best error=0.1644\n",
            "[flaml.automl: 10-20 17:51:30] {1778} INFO - iteration 247, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:31] {1967} INFO -  at 267.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:51:31] {1778} INFO - iteration 248, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:32] {1967} INFO -  at 268.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:51:32] {1778} INFO - iteration 249, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:33] {1967} INFO -  at 269.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:51:33] {1778} INFO - iteration 250, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:34] {1967} INFO -  at 271.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:51:34] {1778} INFO - iteration 251, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:35] {1967} INFO -  at 272.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:51:35] {1778} INFO - iteration 252, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:36] {1967} INFO -  at 272.6s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:51:36] {1778} INFO - iteration 253, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:38] {1967} INFO -  at 275.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:51:38] {1778} INFO - iteration 254, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:39] {1967} INFO -  at 275.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:51:39] {1778} INFO - iteration 255, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:41] {1967} INFO -  at 277.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:51:41] {1778} INFO - iteration 256, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:42] {1967} INFO -  at 278.6s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:51:42] {1778} INFO - iteration 257, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:43] {1967} INFO -  at 279.4s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:51:43] {1778} INFO - iteration 258, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:44] {1967} INFO -  at 281.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:51:44] {1778} INFO - iteration 259, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:45] {1967} INFO -  at 281.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:51:45] {1778} INFO - iteration 260, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:46] {1967} INFO -  at 282.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:51:46] {1778} INFO - iteration 261, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:48] {1967} INFO -  at 284.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:51:48] {1778} INFO - iteration 262, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:49] {1967} INFO -  at 285.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:51:49] {1778} INFO - iteration 263, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:50] {1967} INFO -  at 286.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:51:50] {1778} INFO - iteration 264, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:50] {1967} INFO -  at 286.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:51:50] {1778} INFO - iteration 265, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:54] {1967} INFO -  at 290.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:51:54] {1778} INFO - iteration 266, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:56] {1967} INFO -  at 292.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:51:56] {1778} INFO - iteration 267, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:57] {1967} INFO -  at 293.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:51:57] {1778} INFO - iteration 268, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:57] {1967} INFO -  at 293.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:51:57] {1778} INFO - iteration 269, current learner xgboost\n",
            "[flaml.automl: 10-20 17:51:59] {1967} INFO -  at 295.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:51:59] {1778} INFO - iteration 270, current learner xgboost\n",
            "[flaml.automl: 10-20 17:52:00] {1967} INFO -  at 296.4s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:52:00] {1778} INFO - iteration 271, current learner xgboost\n",
            "[flaml.automl: 10-20 17:52:02] {1967} INFO -  at 298.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:52:02] {1778} INFO - iteration 272, current learner xgboost\n",
            "[flaml.automl: 10-20 17:52:03] {1967} INFO -  at 299.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:52:03] {1778} INFO - iteration 273, current learner xgboost\n",
            "[flaml.automl: 10-20 17:52:04] {1967} INFO -  at 300.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:52:04] {1778} INFO - iteration 274, current learner xgboost\n",
            "[flaml.automl: 10-20 17:52:07] {1967} INFO -  at 304.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:52:07] {1778} INFO - iteration 275, current learner xgboost\n",
            "[flaml.automl: 10-20 17:52:08] {1967} INFO -  at 304.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:52:08] {1778} INFO - iteration 276, current learner xgboost\n",
            "[flaml.automl: 10-20 17:52:10] {1967} INFO -  at 306.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:52:10] {1778} INFO - iteration 277, current learner xgboost\n",
            "[flaml.automl: 10-20 17:52:11] {1967} INFO -  at 307.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:52:11] {1778} INFO - iteration 278, current learner xgboost\n",
            "[flaml.automl: 10-20 17:52:13] {1967} INFO -  at 309.6s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:52:13] {1778} INFO - iteration 279, current learner xgboost\n",
            "[flaml.automl: 10-20 17:52:14] {1967} INFO -  at 310.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:52:14] {1778} INFO - iteration 280, current learner xgboost\n",
            "[flaml.automl: 10-20 17:52:14] {1967} INFO -  at 311.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:52:14] {1778} INFO - iteration 281, current learner xgboost\n",
            "[flaml.automl: 10-20 17:52:16] {1967} INFO -  at 313.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:52:16] {1778} INFO - iteration 282, current learner xgboost\n",
            "[flaml.automl: 10-20 17:52:19] {1967} INFO -  at 315.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:52:19] {1778} INFO - iteration 283, current learner xgboost\n",
            "[flaml.automl: 10-20 17:52:20] {1967} INFO -  at 316.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:52:20] {1778} INFO - iteration 284, current learner xgboost\n",
            "[flaml.automl: 10-20 17:52:21] {1967} INFO -  at 317.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:52:21] {1778} INFO - iteration 285, current learner xgboost\n",
            "[flaml.automl: 10-20 17:52:22] {1967} INFO -  at 318.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:52:22] {1778} INFO - iteration 286, current learner xgboost\n",
            "[flaml.automl: 10-20 17:52:22] {1967} INFO -  at 319.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:52:22] {1778} INFO - iteration 287, current learner xgboost\n",
            "[flaml.automl: 10-20 17:52:25] {1967} INFO -  at 321.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:52:25] {1778} INFO - iteration 288, current learner xgboost\n",
            "[flaml.automl: 10-20 17:52:30] {1967} INFO -  at 327.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:52:30] {1778} INFO - iteration 289, current learner xgboost\n",
            "[flaml.automl: 10-20 17:52:31] {1967} INFO -  at 327.6s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:52:31] {1778} INFO - iteration 290, current learner xgboost\n",
            "[flaml.automl: 10-20 17:52:32] {1967} INFO -  at 328.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:52:32] {1778} INFO - iteration 291, current learner xgboost\n",
            "[flaml.automl: 10-20 17:52:33] {1967} INFO -  at 330.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:52:33] {1778} INFO - iteration 292, current learner xgboost\n",
            "[flaml.automl: 10-20 17:52:34] {1967} INFO -  at 330.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:52:34] {1778} INFO - iteration 293, current learner xgboost\n",
            "[flaml.automl: 10-20 17:52:35] {1967} INFO -  at 331.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:52:35] {1778} INFO - iteration 294, current learner xgboost\n",
            "[flaml.automl: 10-20 17:52:36] {1967} INFO -  at 333.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:52:36] {1778} INFO - iteration 295, current learner xgboost\n",
            "[flaml.automl: 10-20 17:52:37] {1967} INFO -  at 333.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:52:37] {1778} INFO - iteration 296, current learner xgboost\n",
            "[flaml.automl: 10-20 17:52:40] {1967} INFO -  at 336.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:52:40] {1778} INFO - iteration 297, current learner xgboost\n",
            "[flaml.automl: 10-20 17:52:40] {1967} INFO -  at 336.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:52:40] {1778} INFO - iteration 298, current learner xgboost\n",
            "[flaml.automl: 10-20 17:52:42] {1967} INFO -  at 338.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:52:42] {1778} INFO - iteration 299, current learner xgboost\n",
            "[flaml.automl: 10-20 17:52:43] {1967} INFO -  at 339.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:52:43] {1778} INFO - iteration 300, current learner xgboost\n",
            "[flaml.automl: 10-20 17:52:44] {1967} INFO -  at 340.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:52:44] {1778} INFO - iteration 301, current learner xgboost\n",
            "[flaml.automl: 10-20 17:52:45] {1967} INFO -  at 341.4s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:52:45] {1778} INFO - iteration 302, current learner xgboost\n",
            "[flaml.automl: 10-20 17:52:45] {1967} INFO -  at 341.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:52:45] {1778} INFO - iteration 303, current learner xgboost\n",
            "[flaml.automl: 10-20 17:52:48] {1967} INFO -  at 344.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:52:48] {1778} INFO - iteration 304, current learner xgboost\n",
            "[flaml.automl: 10-20 17:52:48] {1967} INFO -  at 344.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:52:48] {1778} INFO - iteration 305, current learner xgboost\n",
            "[flaml.automl: 10-20 17:52:50] {1967} INFO -  at 347.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:52:50] {1778} INFO - iteration 306, current learner xgboost\n",
            "[flaml.automl: 10-20 17:52:51] {1967} INFO -  at 348.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:52:51] {1778} INFO - iteration 307, current learner xgboost\n",
            "[flaml.automl: 10-20 17:52:52] {1967} INFO -  at 348.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:52:52] {1778} INFO - iteration 308, current learner xgboost\n",
            "[flaml.automl: 10-20 17:52:53] {1967} INFO -  at 350.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:52:53] {1778} INFO - iteration 309, current learner xgboost\n",
            "[flaml.automl: 10-20 17:52:55] {1967} INFO -  at 351.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:52:55] {1778} INFO - iteration 310, current learner xgboost\n",
            "[flaml.automl: 10-20 17:52:55] {1967} INFO -  at 351.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:52:55] {1778} INFO - iteration 311, current learner xgboost\n",
            "[flaml.automl: 10-20 17:52:57] {1967} INFO -  at 353.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:52:57] {1778} INFO - iteration 312, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:00] {1967} INFO -  at 357.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:00] {1778} INFO - iteration 313, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:01] {1967} INFO -  at 357.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:01] {1778} INFO - iteration 314, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:02] {1967} INFO -  at 358.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:02] {1778} INFO - iteration 315, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:03] {1967} INFO -  at 359.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:03] {1778} INFO - iteration 316, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:04] {1967} INFO -  at 360.6s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:04] {1778} INFO - iteration 317, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:06] {1967} INFO -  at 362.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:06] {1778} INFO - iteration 318, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:07] {1967} INFO -  at 363.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:07] {1778} INFO - iteration 319, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:08] {1967} INFO -  at 365.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:08] {1778} INFO - iteration 320, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:09] {1967} INFO -  at 365.6s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:09] {1778} INFO - iteration 321, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:11] {1967} INFO -  at 367.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:11] {1778} INFO - iteration 322, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:12] {1967} INFO -  at 368.6s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:12] {1778} INFO - iteration 323, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:14] {1967} INFO -  at 370.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:14] {1778} INFO - iteration 324, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:15] {1967} INFO -  at 371.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:15] {1778} INFO - iteration 325, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:16] {1967} INFO -  at 372.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:16] {1778} INFO - iteration 326, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:17] {1967} INFO -  at 373.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:17] {1778} INFO - iteration 327, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:18] {1967} INFO -  at 374.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:18] {1778} INFO - iteration 328, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:19] {1967} INFO -  at 375.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:19] {1778} INFO - iteration 329, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:20] {1967} INFO -  at 377.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:20] {1778} INFO - iteration 330, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:21] {1967} INFO -  at 377.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:21] {1778} INFO - iteration 331, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:23] {1967} INFO -  at 380.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:23] {1778} INFO - iteration 332, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:24] {1967} INFO -  at 381.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:24] {1778} INFO - iteration 333, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:26] {1967} INFO -  at 382.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:26] {1778} INFO - iteration 334, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:27] {1967} INFO -  at 383.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:27] {1778} INFO - iteration 335, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:29] {1967} INFO -  at 385.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:29] {1778} INFO - iteration 336, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:29] {1967} INFO -  at 386.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:29] {1778} INFO - iteration 337, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:31] {1967} INFO -  at 388.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:31] {1778} INFO - iteration 338, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:32] {1967} INFO -  at 388.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:32] {1778} INFO - iteration 339, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:33] {1967} INFO -  at 389.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:33] {1778} INFO - iteration 340, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:34] {1967} INFO -  at 391.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:34] {1778} INFO - iteration 341, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:35] {1967} INFO -  at 391.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:35] {1778} INFO - iteration 342, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:36] {1967} INFO -  at 392.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:36] {1778} INFO - iteration 343, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:38] {1967} INFO -  at 394.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:38] {1778} INFO - iteration 344, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:38] {1967} INFO -  at 394.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:38] {1778} INFO - iteration 345, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:40] {1967} INFO -  at 396.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:40] {1778} INFO - iteration 346, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:40] {1967} INFO -  at 397.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:40] {1778} INFO - iteration 347, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:42] {1967} INFO -  at 398.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:42] {1778} INFO - iteration 348, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:42] {1967} INFO -  at 399.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:42] {1778} INFO - iteration 349, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:45] {1967} INFO -  at 401.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:45] {1778} INFO - iteration 350, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:46] {1967} INFO -  at 402.4s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:46] {1778} INFO - iteration 351, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:47] {1967} INFO -  at 404.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:47] {1778} INFO - iteration 352, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:48] {1967} INFO -  at 405.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:48] {1778} INFO - iteration 353, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:50] {1967} INFO -  at 407.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:50] {1778} INFO - iteration 354, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:52] {1967} INFO -  at 408.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:52] {1778} INFO - iteration 355, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:53] {1967} INFO -  at 409.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:53] {1778} INFO - iteration 356, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:55] {1967} INFO -  at 411.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:55] {1778} INFO - iteration 357, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:55] {1967} INFO -  at 412.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:55] {1778} INFO - iteration 358, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:58] {1967} INFO -  at 414.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:58] {1778} INFO - iteration 359, current learner xgboost\n",
            "[flaml.automl: 10-20 17:53:58] {1967} INFO -  at 415.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:53:58] {1778} INFO - iteration 360, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:00] {1967} INFO -  at 416.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:00] {1778} INFO - iteration 361, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:01] {1967} INFO -  at 417.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:01] {1778} INFO - iteration 362, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:02] {1967} INFO -  at 418.6s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:02] {1778} INFO - iteration 363, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:03] {1967} INFO -  at 419.4s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:03] {1778} INFO - iteration 364, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:04] {1967} INFO -  at 420.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:04] {1778} INFO - iteration 365, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:05] {1967} INFO -  at 421.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:05] {1778} INFO - iteration 366, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:06] {1967} INFO -  at 422.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:06] {1778} INFO - iteration 367, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:07] {1967} INFO -  at 423.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:07] {1778} INFO - iteration 368, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:07] {1967} INFO -  at 424.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:07] {1778} INFO - iteration 369, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:12] {1967} INFO -  at 428.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:12] {1778} INFO - iteration 370, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:13] {1967} INFO -  at 430.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:13] {1778} INFO - iteration 371, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:14] {1967} INFO -  at 431.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:14] {1778} INFO - iteration 372, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:15] {1967} INFO -  at 431.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:15] {1778} INFO - iteration 373, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:16] {1967} INFO -  at 433.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:16] {1778} INFO - iteration 374, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:18] {1967} INFO -  at 434.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:18] {1778} INFO - iteration 375, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:18] {1967} INFO -  at 434.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:18] {1778} INFO - iteration 376, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:19] {1967} INFO -  at 435.6s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:19] {1778} INFO - iteration 377, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:21] {1967} INFO -  at 437.6s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:21] {1778} INFO - iteration 378, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:22] {1967} INFO -  at 438.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:22] {1778} INFO - iteration 379, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:23] {1967} INFO -  at 440.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:23] {1778} INFO - iteration 380, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:27] {1967} INFO -  at 443.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:27] {1778} INFO - iteration 381, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:27] {1967} INFO -  at 443.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:27] {1778} INFO - iteration 382, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:30] {1967} INFO -  at 446.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:30] {1778} INFO - iteration 383, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:31] {1967} INFO -  at 447.4s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:31] {1778} INFO - iteration 384, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:32] {1967} INFO -  at 448.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:32] {1778} INFO - iteration 385, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:33] {1967} INFO -  at 450.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:33] {1778} INFO - iteration 386, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:35] {1967} INFO -  at 451.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:35] {1778} INFO - iteration 387, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:36] {1967} INFO -  at 452.6s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:36] {1778} INFO - iteration 388, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:38] {1967} INFO -  at 454.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:38] {1778} INFO - iteration 389, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:39] {1967} INFO -  at 455.4s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:39] {1778} INFO - iteration 390, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:40] {1967} INFO -  at 456.4s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:40] {1778} INFO - iteration 391, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:41] {1967} INFO -  at 457.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:41] {1778} INFO - iteration 392, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:42] {1967} INFO -  at 458.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:42] {1778} INFO - iteration 393, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:43] {1967} INFO -  at 459.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:43] {1778} INFO - iteration 394, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:44] {1967} INFO -  at 460.6s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:44] {1778} INFO - iteration 395, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:45] {1967} INFO -  at 461.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:45] {1778} INFO - iteration 396, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:46] {1967} INFO -  at 462.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:46] {1778} INFO - iteration 397, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:48] {1967} INFO -  at 464.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:48] {1778} INFO - iteration 398, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:49] {1967} INFO -  at 465.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:49] {1778} INFO - iteration 399, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:49] {1967} INFO -  at 465.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:49] {1778} INFO - iteration 400, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:50] {1967} INFO -  at 466.6s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:50] {1778} INFO - iteration 401, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:52] {1967} INFO -  at 468.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:52] {1778} INFO - iteration 402, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:53] {1967} INFO -  at 469.4s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:53] {1778} INFO - iteration 403, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:57] {1967} INFO -  at 473.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:57] {1778} INFO - iteration 404, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:58] {1967} INFO -  at 474.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:58] {1778} INFO - iteration 405, current learner xgboost\n",
            "[flaml.automl: 10-20 17:54:59] {1967} INFO -  at 475.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:54:59] {1778} INFO - iteration 406, current learner xgboost\n",
            "[flaml.automl: 10-20 17:55:00] {1967} INFO -  at 476.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:55:00] {1778} INFO - iteration 407, current learner xgboost\n",
            "[flaml.automl: 10-20 17:55:01] {1967} INFO -  at 477.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:55:01] {1778} INFO - iteration 408, current learner xgboost\n",
            "[flaml.automl: 10-20 17:55:03] {1967} INFO -  at 480.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:55:03] {1778} INFO - iteration 409, current learner xgboost\n",
            "[flaml.automl: 10-20 17:55:04] {1967} INFO -  at 480.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:55:04] {1778} INFO - iteration 410, current learner xgboost\n",
            "[flaml.automl: 10-20 17:55:05] {1967} INFO -  at 481.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:55:05] {1778} INFO - iteration 411, current learner xgboost\n",
            "[flaml.automl: 10-20 17:55:06] {1967} INFO -  at 482.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:55:06] {1778} INFO - iteration 412, current learner xgboost\n",
            "[flaml.automl: 10-20 17:55:07] {1967} INFO -  at 483.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:55:07] {1778} INFO - iteration 413, current learner xgboost\n",
            "[flaml.automl: 10-20 17:55:08] {1967} INFO -  at 484.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:55:08] {1778} INFO - iteration 414, current learner xgboost\n",
            "[flaml.automl: 10-20 17:55:09] {1967} INFO -  at 485.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:55:09] {1778} INFO - iteration 415, current learner xgboost\n",
            "[flaml.automl: 10-20 17:55:10] {1967} INFO -  at 486.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:55:10] {1778} INFO - iteration 416, current learner xgboost\n",
            "[flaml.automl: 10-20 17:55:11] {1967} INFO -  at 487.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:55:11] {1778} INFO - iteration 417, current learner xgboost\n",
            "[flaml.automl: 10-20 17:55:13] {1967} INFO -  at 489.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:55:13] {1778} INFO - iteration 418, current learner xgboost\n",
            "[flaml.automl: 10-20 17:55:13] {1967} INFO -  at 489.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:55:13] {1778} INFO - iteration 419, current learner xgboost\n",
            "[flaml.automl: 10-20 17:55:16] {1967} INFO -  at 493.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:55:16] {1778} INFO - iteration 420, current learner xgboost\n",
            "[flaml.automl: 10-20 17:55:17] {1967} INFO -  at 493.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:55:17] {1778} INFO - iteration 421, current learner xgboost\n",
            "[flaml.automl: 10-20 17:55:19] {1967} INFO -  at 495.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:55:19] {1778} INFO - iteration 422, current learner xgboost\n",
            "[flaml.automl: 10-20 17:55:20] {1967} INFO -  at 496.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:55:20] {1778} INFO - iteration 423, current learner xgboost\n",
            "[flaml.automl: 10-20 17:55:21] {1967} INFO -  at 497.6s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:55:21] {1778} INFO - iteration 424, current learner xgboost\n",
            "[flaml.automl: 10-20 17:55:23] {1967} INFO -  at 500.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:55:23] {1778} INFO - iteration 425, current learner xgboost\n",
            "[flaml.automl: 10-20 17:55:24] {1967} INFO -  at 500.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:55:24] {1778} INFO - iteration 426, current learner xgboost\n",
            "[flaml.automl: 10-20 17:55:25] {1967} INFO -  at 501.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:55:25] {1778} INFO - iteration 427, current learner xgboost\n",
            "[flaml.automl: 10-20 17:55:27] {1967} INFO -  at 503.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:55:27] {1778} INFO - iteration 428, current learner xgboost\n",
            "[flaml.automl: 10-20 17:55:28] {1967} INFO -  at 504.4s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:55:28] {1778} INFO - iteration 429, current learner xgboost\n",
            "[flaml.automl: 10-20 17:55:30] {1967} INFO -  at 506.4s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:55:30] {1778} INFO - iteration 430, current learner xgboost\n",
            "[flaml.automl: 10-20 17:55:30] {1967} INFO -  at 507.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:55:30] {1778} INFO - iteration 431, current learner xgboost\n",
            "[flaml.automl: 10-20 17:55:35] {1967} INFO -  at 511.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:55:35] {1778} INFO - iteration 432, current learner xgboost\n",
            "[flaml.automl: 10-20 17:55:37] {1967} INFO -  at 513.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:55:37] {1778} INFO - iteration 433, current learner xgboost\n",
            "[flaml.automl: 10-20 17:55:38] {1967} INFO -  at 514.6s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:55:38] {1778} INFO - iteration 434, current learner xgboost\n",
            "[flaml.automl: 10-20 17:55:41] {1967} INFO -  at 517.4s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:55:41] {1778} INFO - iteration 435, current learner xgboost\n",
            "[flaml.automl: 10-20 17:55:42] {1967} INFO -  at 518.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:55:42] {1778} INFO - iteration 436, current learner xgboost\n",
            "[flaml.automl: 10-20 17:55:43] {1967} INFO -  at 519.4s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:55:43] {1778} INFO - iteration 437, current learner xgboost\n",
            "[flaml.automl: 10-20 17:55:44] {1967} INFO -  at 520.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:55:44] {1778} INFO - iteration 438, current learner xgboost\n",
            "[flaml.automl: 10-20 17:55:45] {1967} INFO -  at 521.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:55:45] {1778} INFO - iteration 439, current learner xgboost\n",
            "[flaml.automl: 10-20 17:55:47] {1967} INFO -  at 523.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:55:47] {1778} INFO - iteration 440, current learner xgboost\n",
            "[flaml.automl: 10-20 17:55:49] {1967} INFO -  at 525.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:55:49] {1778} INFO - iteration 441, current learner xgboost\n",
            "[flaml.automl: 10-20 17:55:50] {1967} INFO -  at 526.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:55:50] {1778} INFO - iteration 442, current learner xgboost\n",
            "[flaml.automl: 10-20 17:55:50] {1967} INFO -  at 527.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:55:50] {1778} INFO - iteration 443, current learner xgboost\n",
            "[flaml.automl: 10-20 17:55:52] {1967} INFO -  at 528.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:55:52] {1778} INFO - iteration 444, current learner xgboost\n",
            "[flaml.automl: 10-20 17:55:54] {1967} INFO -  at 530.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:55:54] {1778} INFO - iteration 445, current learner xgboost\n",
            "[flaml.automl: 10-20 17:55:55] {1967} INFO -  at 531.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:55:55] {1778} INFO - iteration 446, current learner xgboost\n",
            "[flaml.automl: 10-20 17:55:56] {1967} INFO -  at 532.4s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:55:56] {1778} INFO - iteration 447, current learner xgboost\n",
            "[flaml.automl: 10-20 17:55:57] {1967} INFO -  at 533.4s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:55:57] {1778} INFO - iteration 448, current learner xgboost\n",
            "[flaml.automl: 10-20 17:55:57] {1967} INFO -  at 534.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:55:57] {1778} INFO - iteration 449, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:00] {1967} INFO -  at 536.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:00] {1778} INFO - iteration 450, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:01] {1967} INFO -  at 538.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:01] {1778} INFO - iteration 451, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:02] {1967} INFO -  at 539.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:02] {1778} INFO - iteration 452, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:03] {1967} INFO -  at 540.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:03] {1778} INFO - iteration 453, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:05] {1967} INFO -  at 541.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:05] {1778} INFO - iteration 454, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:06] {1967} INFO -  at 542.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:06] {1778} INFO - iteration 455, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:07] {1967} INFO -  at 543.6s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:07] {1778} INFO - iteration 456, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:08] {1967} INFO -  at 544.6s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:08] {1778} INFO - iteration 457, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:10] {1967} INFO -  at 546.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:10] {1778} INFO - iteration 458, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:10] {1967} INFO -  at 546.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:10] {1778} INFO - iteration 459, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:13] {1967} INFO -  at 549.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:13] {1778} INFO - iteration 460, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:14] {1967} INFO -  at 550.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:14] {1778} INFO - iteration 461, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:15] {1967} INFO -  at 551.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:15] {1778} INFO - iteration 462, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:16] {1967} INFO -  at 552.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:16] {1778} INFO - iteration 463, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:18] {1967} INFO -  at 554.4s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:18] {1778} INFO - iteration 464, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:18] {1967} INFO -  at 555.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:18] {1778} INFO - iteration 465, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:20] {1967} INFO -  at 556.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:20] {1778} INFO - iteration 466, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:20] {1967} INFO -  at 557.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:20] {1778} INFO - iteration 467, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:21] {1967} INFO -  at 558.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:21] {1778} INFO - iteration 468, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:24] {1967} INFO -  at 560.4s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:24] {1778} INFO - iteration 469, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:24] {1967} INFO -  at 561.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:24] {1778} INFO - iteration 470, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:25] {1967} INFO -  at 561.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:25] {1778} INFO - iteration 471, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:27] {1967} INFO -  at 563.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:27] {1778} INFO - iteration 472, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:29] {1967} INFO -  at 565.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:29] {1778} INFO - iteration 473, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:29] {1967} INFO -  at 566.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:29] {1778} INFO - iteration 474, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:30] {1967} INFO -  at 566.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:30] {1778} INFO - iteration 475, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:32] {1967} INFO -  at 568.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:32] {1778} INFO - iteration 476, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:33] {1967} INFO -  at 569.4s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:33] {1778} INFO - iteration 477, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:34] {1967} INFO -  at 570.6s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:34] {1778} INFO - iteration 478, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:35] {1967} INFO -  at 571.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:35] {1778} INFO - iteration 479, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:36] {1967} INFO -  at 573.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:36] {1778} INFO - iteration 480, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:37] {1967} INFO -  at 573.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:37] {1778} INFO - iteration 481, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:38] {1967} INFO -  at 575.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:38] {1778} INFO - iteration 482, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:39] {1967} INFO -  at 575.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:39] {1778} INFO - iteration 483, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:41] {1967} INFO -  at 578.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:41] {1778} INFO - iteration 484, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:42] {1967} INFO -  at 579.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:42] {1778} INFO - iteration 485, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:43] {1967} INFO -  at 580.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:43] {1778} INFO - iteration 486, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:44] {1967} INFO -  at 581.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:44] {1778} INFO - iteration 487, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:46] {1967} INFO -  at 582.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:46] {1778} INFO - iteration 488, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:47] {1967} INFO -  at 583.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:47] {1778} INFO - iteration 489, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:49] {1967} INFO -  at 585.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:49] {1778} INFO - iteration 490, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:50] {1967} INFO -  at 586.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:50] {1778} INFO - iteration 491, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:51] {1967} INFO -  at 587.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:51] {1778} INFO - iteration 492, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:52] {1967} INFO -  at 588.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:52] {1778} INFO - iteration 493, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:55] {1967} INFO -  at 591.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:55] {1778} INFO - iteration 494, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:56] {1967} INFO -  at 592.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:56] {1778} INFO - iteration 495, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:58] {1967} INFO -  at 594.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:58] {1778} INFO - iteration 496, current learner xgboost\n",
            "[flaml.automl: 10-20 17:56:59] {1967} INFO -  at 596.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:56:59] {1778} INFO - iteration 497, current learner xgboost\n",
            "[flaml.automl: 10-20 17:57:00] {1967} INFO -  at 596.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:57:00] {1778} INFO - iteration 498, current learner xgboost\n",
            "[flaml.automl: 10-20 17:57:02] {1967} INFO -  at 598.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:57:02] {1778} INFO - iteration 499, current learner xgboost\n",
            "[flaml.automl: 10-20 17:57:03] {1967} INFO -  at 600.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:57:03] {1778} INFO - iteration 500, current learner xgboost\n",
            "[flaml.automl: 10-20 17:57:04] {1967} INFO -  at 600.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:57:04] {1778} INFO - iteration 501, current learner xgboost\n",
            "[flaml.automl: 10-20 17:57:05] {1967} INFO -  at 601.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:57:05] {1778} INFO - iteration 502, current learner xgboost\n",
            "[flaml.automl: 10-20 17:57:06] {1967} INFO -  at 602.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:57:06] {1778} INFO - iteration 503, current learner xgboost\n",
            "[flaml.automl: 10-20 17:57:15] {1967} INFO -  at 611.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:57:15] {1778} INFO - iteration 504, current learner xgboost\n",
            "[flaml.automl: 10-20 17:57:20] {1967} INFO -  at 616.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:57:20] {1778} INFO - iteration 505, current learner xgboost\n",
            "[flaml.automl: 10-20 17:57:20] {1967} INFO -  at 616.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:57:20] {1778} INFO - iteration 506, current learner xgboost\n",
            "[flaml.automl: 10-20 17:57:21] {1967} INFO -  at 617.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:57:21] {1778} INFO - iteration 507, current learner xgboost\n",
            "[flaml.automl: 10-20 17:57:23] {1967} INFO -  at 619.6s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:57:23] {1778} INFO - iteration 508, current learner xgboost\n",
            "[flaml.automl: 10-20 17:57:24] {1967} INFO -  at 620.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:57:24] {1778} INFO - iteration 509, current learner xgboost\n",
            "[flaml.automl: 10-20 17:57:25] {1967} INFO -  at 622.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:57:25] {1778} INFO - iteration 510, current learner xgboost\n",
            "[flaml.automl: 10-20 17:57:30] {1967} INFO -  at 626.4s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:57:30] {1778} INFO - iteration 511, current learner xgboost\n",
            "[flaml.automl: 10-20 17:57:30] {1967} INFO -  at 627.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:57:30] {1778} INFO - iteration 512, current learner xgboost\n",
            "[flaml.automl: 10-20 17:57:32] {1967} INFO -  at 628.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:57:32] {1778} INFO - iteration 513, current learner xgboost\n",
            "[flaml.automl: 10-20 17:57:33] {1967} INFO -  at 629.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:57:33] {1778} INFO - iteration 514, current learner xgboost\n",
            "[flaml.automl: 10-20 17:57:34] {1967} INFO -  at 631.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:57:34] {1778} INFO - iteration 515, current learner xgboost\n",
            "[flaml.automl: 10-20 17:57:35] {1967} INFO -  at 631.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:57:35] {1778} INFO - iteration 516, current learner xgboost\n",
            "[flaml.automl: 10-20 17:57:36] {1967} INFO -  at 632.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:57:36] {1778} INFO - iteration 517, current learner xgboost\n",
            "[flaml.automl: 10-20 17:57:38] {1967} INFO -  at 634.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:57:38] {1778} INFO - iteration 518, current learner xgboost\n",
            "[flaml.automl: 10-20 17:57:38] {1967} INFO -  at 635.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:57:38] {1778} INFO - iteration 519, current learner xgboost\n",
            "[flaml.automl: 10-20 17:57:40] {1967} INFO -  at 636.4s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:57:40] {1778} INFO - iteration 520, current learner xgboost\n",
            "[flaml.automl: 10-20 17:57:41] {1967} INFO -  at 637.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:57:41] {1778} INFO - iteration 521, current learner xgboost\n",
            "[flaml.automl: 10-20 17:57:43] {1967} INFO -  at 639.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:57:43] {1778} INFO - iteration 522, current learner xgboost\n",
            "[flaml.automl: 10-20 17:57:44] {1967} INFO -  at 640.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:57:44] {1778} INFO - iteration 523, current learner xgboost\n",
            "[flaml.automl: 10-20 17:57:45] {1967} INFO -  at 641.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:57:45] {1778} INFO - iteration 524, current learner xgboost\n",
            "[flaml.automl: 10-20 17:57:49] {1967} INFO -  at 645.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:57:49] {1778} INFO - iteration 525, current learner xgboost\n",
            "[flaml.automl: 10-20 17:57:49] {1967} INFO -  at 645.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:57:49] {1778} INFO - iteration 526, current learner xgboost\n",
            "[flaml.automl: 10-20 17:57:50] {1967} INFO -  at 646.4s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:57:50] {1778} INFO - iteration 527, current learner xgboost\n",
            "[flaml.automl: 10-20 17:57:55] {1967} INFO -  at 651.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:57:55] {1778} INFO - iteration 528, current learner xgboost\n",
            "[flaml.automl: 10-20 17:57:56] {1967} INFO -  at 652.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:57:56] {1778} INFO - iteration 529, current learner xgboost\n",
            "[flaml.automl: 10-20 17:57:57] {1967} INFO -  at 653.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:57:57] {1778} INFO - iteration 530, current learner xgboost\n",
            "[flaml.automl: 10-20 17:57:58] {1967} INFO -  at 654.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:57:58] {1778} INFO - iteration 531, current learner xgboost\n",
            "[flaml.automl: 10-20 17:58:00] {1967} INFO -  at 657.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:58:00] {1778} INFO - iteration 532, current learner xgboost\n",
            "[flaml.automl: 10-20 17:58:03] {1967} INFO -  at 660.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:58:03] {1778} INFO - iteration 533, current learner xgboost\n",
            "[flaml.automl: 10-20 17:58:04] {1967} INFO -  at 660.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:58:04] {1778} INFO - iteration 534, current learner xgboost\n",
            "[flaml.automl: 10-20 17:58:05] {1967} INFO -  at 661.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:58:05] {1778} INFO - iteration 535, current learner xgboost\n",
            "[flaml.automl: 10-20 17:58:07] {1967} INFO -  at 663.6s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:58:07] {1778} INFO - iteration 536, current learner xgboost\n",
            "[flaml.automl: 10-20 17:58:08] {1967} INFO -  at 664.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:58:08] {1778} INFO - iteration 537, current learner xgboost\n",
            "[flaml.automl: 10-20 17:58:10] {1967} INFO -  at 667.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:58:10] {1778} INFO - iteration 538, current learner xgboost\n",
            "[flaml.automl: 10-20 17:58:11] {1967} INFO -  at 667.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:58:11] {1778} INFO - iteration 539, current learner xgboost\n",
            "[flaml.automl: 10-20 17:58:13] {1967} INFO -  at 669.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:58:13] {1778} INFO - iteration 540, current learner xgboost\n",
            "[flaml.automl: 10-20 17:58:14] {1967} INFO -  at 670.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:58:14] {1778} INFO - iteration 541, current learner xgboost\n",
            "[flaml.automl: 10-20 17:58:15] {1967} INFO -  at 671.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:58:15] {1778} INFO - iteration 542, current learner xgboost\n",
            "[flaml.automl: 10-20 17:58:16] {1967} INFO -  at 672.4s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:58:16] {1778} INFO - iteration 543, current learner xgboost\n",
            "[flaml.automl: 10-20 17:58:18] {1967} INFO -  at 674.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:58:18] {1778} INFO - iteration 544, current learner xgboost\n",
            "[flaml.automl: 10-20 17:58:19] {1967} INFO -  at 675.6s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:58:19] {1778} INFO - iteration 545, current learner xgboost\n",
            "[flaml.automl: 10-20 17:58:20] {1967} INFO -  at 677.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:58:20] {1778} INFO - iteration 546, current learner xgboost\n",
            "[flaml.automl: 10-20 17:58:21] {1967} INFO -  at 678.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:58:21] {1778} INFO - iteration 547, current learner xgboost\n",
            "[flaml.automl: 10-20 17:58:23] {1967} INFO -  at 679.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:58:23] {1778} INFO - iteration 548, current learner xgboost\n",
            "[flaml.automl: 10-20 17:58:24] {1967} INFO -  at 680.4s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:58:24] {1778} INFO - iteration 549, current learner xgboost\n",
            "[flaml.automl: 10-20 17:58:25] {1967} INFO -  at 682.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:58:25] {1778} INFO - iteration 550, current learner xgboost\n",
            "[flaml.automl: 10-20 17:58:27] {1967} INFO -  at 683.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:58:27] {1778} INFO - iteration 551, current learner xgboost\n",
            "[flaml.automl: 10-20 17:58:28] {1967} INFO -  at 684.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:58:28] {1778} INFO - iteration 552, current learner xgboost\n",
            "[flaml.automl: 10-20 17:58:29] {1967} INFO -  at 685.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:58:29] {1778} INFO - iteration 553, current learner xgboost\n",
            "[flaml.automl: 10-20 17:58:32] {1967} INFO -  at 689.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:58:32] {1778} INFO - iteration 554, current learner xgboost\n",
            "[flaml.automl: 10-20 17:58:43] {1967} INFO -  at 699.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:58:43] {1778} INFO - iteration 555, current learner xgboost\n",
            "[flaml.automl: 10-20 17:58:44] {1967} INFO -  at 700.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:58:44] {1778} INFO - iteration 556, current learner xgboost\n",
            "[flaml.automl: 10-20 17:58:51] {1967} INFO -  at 707.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:58:51] {1778} INFO - iteration 557, current learner xgboost\n",
            "[flaml.automl: 10-20 17:58:53] {1967} INFO -  at 709.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:58:53] {1778} INFO - iteration 558, current learner xgboost\n",
            "[flaml.automl: 10-20 17:58:54] {1967} INFO -  at 710.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:58:54] {1778} INFO - iteration 559, current learner xgboost\n",
            "[flaml.automl: 10-20 17:58:55] {1967} INFO -  at 711.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:58:55] {1778} INFO - iteration 560, current learner xgboost\n",
            "[flaml.automl: 10-20 17:58:56] {1967} INFO -  at 713.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:58:56] {1778} INFO - iteration 561, current learner xgboost\n",
            "[flaml.automl: 10-20 17:58:58] {1967} INFO -  at 714.4s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:58:58] {1778} INFO - iteration 562, current learner xgboost\n",
            "[flaml.automl: 10-20 17:59:04] {1967} INFO -  at 720.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:59:04] {1778} INFO - iteration 563, current learner xgboost\n",
            "[flaml.automl: 10-20 17:59:04] {1967} INFO -  at 721.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:59:04] {1778} INFO - iteration 564, current learner xgboost\n",
            "[flaml.automl: 10-20 17:59:06] {1967} INFO -  at 722.6s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:59:06] {1778} INFO - iteration 565, current learner xgboost\n",
            "[flaml.automl: 10-20 17:59:07] {1967} INFO -  at 723.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:59:07] {1778} INFO - iteration 566, current learner xgboost\n",
            "[flaml.automl: 10-20 17:59:07] {1967} INFO -  at 724.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:59:07] {1778} INFO - iteration 567, current learner xgboost\n",
            "[flaml.automl: 10-20 17:59:09] {1967} INFO -  at 725.6s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:59:09] {1778} INFO - iteration 568, current learner xgboost\n",
            "[flaml.automl: 10-20 17:59:11] {1967} INFO -  at 727.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:59:11] {1778} INFO - iteration 569, current learner xgboost\n",
            "[flaml.automl: 10-20 17:59:13] {1967} INFO -  at 729.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:59:13] {1778} INFO - iteration 570, current learner xgboost\n",
            "[flaml.automl: 10-20 17:59:13] {1967} INFO -  at 730.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:59:13] {1778} INFO - iteration 571, current learner xgboost\n",
            "[flaml.automl: 10-20 17:59:16] {1967} INFO -  at 732.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:59:16] {1778} INFO - iteration 572, current learner xgboost\n",
            "[flaml.automl: 10-20 17:59:19] {1967} INFO -  at 735.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:59:19] {1778} INFO - iteration 573, current learner xgboost\n",
            "[flaml.automl: 10-20 17:59:20] {1967} INFO -  at 736.6s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:59:20] {1778} INFO - iteration 574, current learner xgboost\n",
            "[flaml.automl: 10-20 17:59:21] {1967} INFO -  at 737.4s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:59:21] {1778} INFO - iteration 575, current learner xgboost\n",
            "[flaml.automl: 10-20 17:59:23] {1967} INFO -  at 739.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:59:23] {1778} INFO - iteration 576, current learner xgboost\n",
            "[flaml.automl: 10-20 17:59:25] {1967} INFO -  at 742.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:59:25] {1778} INFO - iteration 577, current learner xgboost\n",
            "[flaml.automl: 10-20 17:59:27] {1967} INFO -  at 743.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:59:27] {1778} INFO - iteration 578, current learner xgboost\n",
            "[flaml.automl: 10-20 17:59:29] {1967} INFO -  at 745.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:59:29] {1778} INFO - iteration 579, current learner xgboost\n",
            "[flaml.automl: 10-20 17:59:30] {1967} INFO -  at 746.4s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:59:30] {1778} INFO - iteration 580, current learner xgboost\n",
            "[flaml.automl: 10-20 17:59:36] {1967} INFO -  at 752.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:59:36] {1778} INFO - iteration 581, current learner xgboost\n",
            "[flaml.automl: 10-20 17:59:37] {1967} INFO -  at 753.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:59:37] {1778} INFO - iteration 582, current learner xgboost\n",
            "[flaml.automl: 10-20 17:59:39] {1967} INFO -  at 755.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:59:39] {1778} INFO - iteration 583, current learner xgboost\n",
            "[flaml.automl: 10-20 17:59:40] {1967} INFO -  at 757.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:59:40] {1778} INFO - iteration 584, current learner xgboost\n",
            "[flaml.automl: 10-20 17:59:41] {1967} INFO -  at 758.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:59:41] {1778} INFO - iteration 585, current learner xgboost\n",
            "[flaml.automl: 10-20 17:59:47] {1967} INFO -  at 763.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:59:47] {1778} INFO - iteration 586, current learner xgboost\n",
            "[flaml.automl: 10-20 17:59:48] {1967} INFO -  at 764.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:59:48] {1778} INFO - iteration 587, current learner xgboost\n",
            "[flaml.automl: 10-20 17:59:51] {1967} INFO -  at 767.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:59:51] {1778} INFO - iteration 588, current learner xgboost\n",
            "[flaml.automl: 10-20 17:59:52] {1967} INFO -  at 768.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:59:52] {1778} INFO - iteration 589, current learner xgboost\n",
            "[flaml.automl: 10-20 17:59:55] {1967} INFO -  at 771.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:59:55] {1778} INFO - iteration 590, current learner xgboost\n",
            "[flaml.automl: 10-20 17:59:57] {1967} INFO -  at 773.4s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:59:57] {1778} INFO - iteration 591, current learner xgboost\n",
            "[flaml.automl: 10-20 17:59:58] {1967} INFO -  at 774.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 17:59:58] {1778} INFO - iteration 592, current learner xgboost\n",
            "[flaml.automl: 10-20 18:00:01] {1967} INFO -  at 778.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:00:01] {1778} INFO - iteration 593, current learner xgboost\n",
            "[flaml.automl: 10-20 18:00:02] {1967} INFO -  at 778.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:00:02] {1778} INFO - iteration 594, current learner xgboost\n",
            "[flaml.automl: 10-20 18:00:04] {1967} INFO -  at 781.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:00:04] {1778} INFO - iteration 595, current learner xgboost\n",
            "[flaml.automl: 10-20 18:00:05] {1967} INFO -  at 782.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:00:05] {1778} INFO - iteration 596, current learner xgboost\n",
            "[flaml.automl: 10-20 18:00:06] {1967} INFO -  at 782.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:00:06] {1778} INFO - iteration 597, current learner xgboost\n",
            "[flaml.automl: 10-20 18:00:10] {1967} INFO -  at 786.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:00:10] {1778} INFO - iteration 598, current learner xgboost\n",
            "[flaml.automl: 10-20 18:00:11] {1967} INFO -  at 787.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:00:11] {1778} INFO - iteration 599, current learner xgboost\n",
            "[flaml.automl: 10-20 18:00:15] {1967} INFO -  at 791.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:00:15] {1778} INFO - iteration 600, current learner xgboost\n",
            "[flaml.automl: 10-20 18:00:17] {1967} INFO -  at 793.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:00:17] {1778} INFO - iteration 601, current learner xgboost\n",
            "[flaml.automl: 10-20 18:00:18] {1967} INFO -  at 794.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:00:18] {1778} INFO - iteration 602, current learner xgboost\n",
            "[flaml.automl: 10-20 18:00:20] {1967} INFO -  at 797.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:00:20] {1778} INFO - iteration 603, current learner xgboost\n",
            "[flaml.automl: 10-20 18:00:22] {1967} INFO -  at 798.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:00:22] {1778} INFO - iteration 604, current learner xgboost\n",
            "[flaml.automl: 10-20 18:00:23] {1967} INFO -  at 799.6s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:00:23] {1778} INFO - iteration 605, current learner xgboost\n",
            "[flaml.automl: 10-20 18:00:28] {1967} INFO -  at 804.4s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:00:28] {1778} INFO - iteration 606, current learner xgboost\n",
            "[flaml.automl: 10-20 18:00:29] {1967} INFO -  at 805.6s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:00:29] {1778} INFO - iteration 607, current learner xgboost\n",
            "[flaml.automl: 10-20 18:00:31] {1967} INFO -  at 807.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:00:31] {1778} INFO - iteration 608, current learner xgboost\n",
            "[flaml.automl: 10-20 18:00:33] {1967} INFO -  at 809.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:00:33] {1778} INFO - iteration 609, current learner xgboost\n",
            "[flaml.automl: 10-20 18:00:34] {1967} INFO -  at 810.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:00:34] {1778} INFO - iteration 610, current learner xgboost\n",
            "[flaml.automl: 10-20 18:00:36] {1967} INFO -  at 812.4s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:00:36] {1778} INFO - iteration 611, current learner xgboost\n",
            "[flaml.automl: 10-20 18:00:37] {1967} INFO -  at 813.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:00:37] {1778} INFO - iteration 612, current learner xgboost\n",
            "[flaml.automl: 10-20 18:00:37] {1967} INFO -  at 813.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:00:37] {1778} INFO - iteration 613, current learner xgboost\n",
            "[flaml.automl: 10-20 18:00:42] {1967} INFO -  at 819.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:00:42] {1778} INFO - iteration 614, current learner xgboost\n",
            "[flaml.automl: 10-20 18:00:44] {1967} INFO -  at 820.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:00:44] {1778} INFO - iteration 615, current learner xgboost\n",
            "[flaml.automl: 10-20 18:00:46] {1967} INFO -  at 822.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:00:46] {1778} INFO - iteration 616, current learner xgboost\n",
            "[flaml.automl: 10-20 18:00:47] {1967} INFO -  at 823.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:00:47] {1778} INFO - iteration 617, current learner xgboost\n",
            "[flaml.automl: 10-20 18:00:48] {1967} INFO -  at 825.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:00:48] {1778} INFO - iteration 618, current learner xgboost\n",
            "[flaml.automl: 10-20 18:00:51] {1967} INFO -  at 828.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:00:51] {1778} INFO - iteration 619, current learner xgboost\n",
            "[flaml.automl: 10-20 18:00:52] {1967} INFO -  at 828.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:00:52] {1778} INFO - iteration 620, current learner xgboost\n",
            "[flaml.automl: 10-20 18:00:54] {1967} INFO -  at 830.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:00:54] {1778} INFO - iteration 621, current learner xgboost\n",
            "[flaml.automl: 10-20 18:00:55] {1967} INFO -  at 832.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:00:55] {1778} INFO - iteration 622, current learner xgboost\n",
            "[flaml.automl: 10-20 18:00:57] {1967} INFO -  at 833.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:00:57] {1778} INFO - iteration 623, current learner xgboost\n",
            "[flaml.automl: 10-20 18:00:59] {1967} INFO -  at 835.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:00:59] {1778} INFO - iteration 624, current learner xgboost\n",
            "[flaml.automl: 10-20 18:01:01] {1967} INFO -  at 837.4s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:01:01] {1778} INFO - iteration 625, current learner xgboost\n",
            "[flaml.automl: 10-20 18:01:02] {1967} INFO -  at 838.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:01:02] {1778} INFO - iteration 626, current learner xgboost\n",
            "[flaml.automl: 10-20 18:01:03] {1967} INFO -  at 839.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:01:03] {1778} INFO - iteration 627, current learner xgboost\n",
            "[flaml.automl: 10-20 18:01:04] {1967} INFO -  at 841.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:01:04] {1778} INFO - iteration 628, current learner xgboost\n",
            "[flaml.automl: 10-20 18:01:08] {1967} INFO -  at 844.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:01:08] {1778} INFO - iteration 629, current learner xgboost\n",
            "[flaml.automl: 10-20 18:01:09] {1967} INFO -  at 845.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:01:09] {1778} INFO - iteration 630, current learner xgboost\n",
            "[flaml.automl: 10-20 18:01:09] {1967} INFO -  at 846.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:01:09] {1778} INFO - iteration 631, current learner xgboost\n",
            "[flaml.automl: 10-20 18:01:12] {1967} INFO -  at 848.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:01:12] {1778} INFO - iteration 632, current learner xgboost\n",
            "[flaml.automl: 10-20 18:01:13] {1967} INFO -  at 849.6s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:01:13] {1778} INFO - iteration 633, current learner xgboost\n",
            "[flaml.automl: 10-20 18:01:14] {1967} INFO -  at 851.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:01:14] {1778} INFO - iteration 634, current learner xgboost\n",
            "[flaml.automl: 10-20 18:01:15] {1967} INFO -  at 851.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:01:15] {1778} INFO - iteration 635, current learner xgboost\n",
            "[flaml.automl: 10-20 18:01:17] {1967} INFO -  at 853.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:01:17] {1778} INFO - iteration 636, current learner xgboost\n",
            "[flaml.automl: 10-20 18:01:18] {1967} INFO -  at 854.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:01:18] {1778} INFO - iteration 637, current learner xgboost\n",
            "[flaml.automl: 10-20 18:01:20] {1967} INFO -  at 856.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:01:20] {1778} INFO - iteration 638, current learner xgboost\n",
            "[flaml.automl: 10-20 18:01:23] {1967} INFO -  at 859.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:01:23] {1778} INFO - iteration 639, current learner xgboost\n",
            "[flaml.automl: 10-20 18:01:23] {1967} INFO -  at 860.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:01:23] {1778} INFO - iteration 640, current learner xgboost\n",
            "[flaml.automl: 10-20 18:01:24] {1967} INFO -  at 861.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:01:24] {1778} INFO - iteration 641, current learner xgboost\n",
            "[flaml.automl: 10-20 18:01:25] {1967} INFO -  at 861.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:01:25] {1778} INFO - iteration 642, current learner xgboost\n",
            "[flaml.automl: 10-20 18:01:26] {1967} INFO -  at 862.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:01:26] {1778} INFO - iteration 643, current learner xgboost\n",
            "[flaml.automl: 10-20 18:01:28] {1967} INFO -  at 864.4s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:01:28] {1778} INFO - iteration 644, current learner xgboost\n",
            "[flaml.automl: 10-20 18:01:28] {1967} INFO -  at 865.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:01:28] {1778} INFO - iteration 645, current learner xgboost\n",
            "[flaml.automl: 10-20 18:01:32] {1967} INFO -  at 869.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:01:32] {1778} INFO - iteration 646, current learner xgboost\n",
            "[flaml.automl: 10-20 18:01:34] {1967} INFO -  at 871.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:01:34] {1778} INFO - iteration 647, current learner xgboost\n",
            "[flaml.automl: 10-20 18:01:35] {1967} INFO -  at 871.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:01:35] {1778} INFO - iteration 648, current learner xgboost\n",
            "[flaml.automl: 10-20 18:01:37] {1967} INFO -  at 874.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:01:37] {1778} INFO - iteration 649, current learner xgboost\n",
            "[flaml.automl: 10-20 18:01:38] {1967} INFO -  at 875.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:01:38] {1778} INFO - iteration 650, current learner xgboost\n",
            "[flaml.automl: 10-20 18:01:44] {1967} INFO -  at 880.6s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:01:44] {1778} INFO - iteration 651, current learner xgboost\n",
            "[flaml.automl: 10-20 18:01:44] {1967} INFO -  at 881.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:01:44] {1778} INFO - iteration 652, current learner xgboost\n",
            "[flaml.automl: 10-20 18:01:45] {1967} INFO -  at 881.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:01:45] {1778} INFO - iteration 653, current learner xgboost\n",
            "[flaml.automl: 10-20 18:01:47] {1967} INFO -  at 883.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:01:47] {1778} INFO - iteration 654, current learner xgboost\n",
            "[flaml.automl: 10-20 18:01:50] {1967} INFO -  at 886.4s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:01:50] {1778} INFO - iteration 655, current learner xgboost\n",
            "[flaml.automl: 10-20 18:01:50] {1967} INFO -  at 886.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:01:50] {1778} INFO - iteration 656, current learner xgboost\n",
            "[flaml.automl: 10-20 18:01:52] {1967} INFO -  at 888.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:01:52] {1778} INFO - iteration 657, current learner xgboost\n",
            "[flaml.automl: 10-20 18:01:53] {1967} INFO -  at 889.6s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:01:53] {1778} INFO - iteration 658, current learner xgboost\n",
            "[flaml.automl: 10-20 18:01:54] {1967} INFO -  at 890.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:01:54] {1778} INFO - iteration 659, current learner xgboost\n",
            "[flaml.automl: 10-20 18:01:55] {1967} INFO -  at 891.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:01:55] {1778} INFO - iteration 660, current learner xgboost\n",
            "[flaml.automl: 10-20 18:01:56] {1967} INFO -  at 892.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:01:56] {1778} INFO - iteration 661, current learner xgboost\n",
            "[flaml.automl: 10-20 18:02:00] {1967} INFO -  at 896.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:02:00] {1778} INFO - iteration 662, current learner xgboost\n",
            "[flaml.automl: 10-20 18:02:01] {1967} INFO -  at 897.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:02:01] {1778} INFO - iteration 663, current learner xgboost\n",
            "[flaml.automl: 10-20 18:02:02] {1967} INFO -  at 898.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:02:02] {1778} INFO - iteration 664, current learner xgboost\n",
            "[flaml.automl: 10-20 18:02:03] {1967} INFO -  at 899.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:02:03] {1778} INFO - iteration 665, current learner xgboost\n",
            "[flaml.automl: 10-20 18:02:04] {1967} INFO -  at 901.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:02:04] {1778} INFO - iteration 666, current learner xgboost\n",
            "[flaml.automl: 10-20 18:02:05] {1967} INFO -  at 901.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:02:05] {1778} INFO - iteration 667, current learner xgboost\n",
            "[flaml.automl: 10-20 18:02:08] {1967} INFO -  at 904.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:02:08] {1778} INFO - iteration 668, current learner xgboost\n",
            "[flaml.automl: 10-20 18:02:08] {1967} INFO -  at 904.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:02:08] {1778} INFO - iteration 669, current learner xgboost\n",
            "[flaml.automl: 10-20 18:02:11] {1967} INFO -  at 907.6s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:02:11] {1778} INFO - iteration 670, current learner xgboost\n",
            "[flaml.automl: 10-20 18:02:12] {1967} INFO -  at 908.4s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:02:12] {1778} INFO - iteration 671, current learner xgboost\n",
            "[flaml.automl: 10-20 18:02:14] {1967} INFO -  at 910.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:02:14] {1778} INFO - iteration 672, current learner xgboost\n",
            "[flaml.automl: 10-20 18:02:14] {1967} INFO -  at 911.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:02:14] {1778} INFO - iteration 673, current learner xgboost\n",
            "[flaml.automl: 10-20 18:02:19] {1967} INFO -  at 915.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:02:19] {1778} INFO - iteration 674, current learner xgboost\n",
            "[flaml.automl: 10-20 18:02:19] {1967} INFO -  at 915.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:02:19] {1778} INFO - iteration 675, current learner xgboost\n",
            "[flaml.automl: 10-20 18:02:25] {1967} INFO -  at 921.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:02:25] {1778} INFO - iteration 676, current learner xgboost\n",
            "[flaml.automl: 10-20 18:02:26] {1967} INFO -  at 922.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:02:26] {1778} INFO - iteration 677, current learner xgboost\n",
            "[flaml.automl: 10-20 18:02:27] {1967} INFO -  at 923.4s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:02:27] {1778} INFO - iteration 678, current learner xgboost\n",
            "[flaml.automl: 10-20 18:02:30] {1967} INFO -  at 926.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:02:30] {1778} INFO - iteration 679, current learner xgboost\n",
            "[flaml.automl: 10-20 18:02:30] {1967} INFO -  at 927.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:02:30] {1778} INFO - iteration 680, current learner xgboost\n",
            "[flaml.automl: 10-20 18:02:31] {1967} INFO -  at 927.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:02:31] {1778} INFO - iteration 681, current learner xgboost\n",
            "[flaml.automl: 10-20 18:02:37] {1967} INFO -  at 933.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:02:37] {1778} INFO - iteration 682, current learner xgboost\n",
            "[flaml.automl: 10-20 18:02:38] {1967} INFO -  at 934.4s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:02:38] {1778} INFO - iteration 683, current learner xgboost\n",
            "[flaml.automl: 10-20 18:02:40] {1967} INFO -  at 936.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:02:40] {1778} INFO - iteration 684, current learner xgboost\n",
            "[flaml.automl: 10-20 18:02:41] {1967} INFO -  at 937.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:02:41] {1778} INFO - iteration 685, current learner xgboost\n",
            "[flaml.automl: 10-20 18:02:42] {1967} INFO -  at 939.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:02:42] {1778} INFO - iteration 686, current learner xgboost\n",
            "[flaml.automl: 10-20 18:02:43] {1967} INFO -  at 940.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:02:43] {1778} INFO - iteration 687, current learner xgboost\n",
            "[flaml.automl: 10-20 18:02:44] {1967} INFO -  at 941.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:02:44] {1778} INFO - iteration 688, current learner xgboost\n",
            "[flaml.automl: 10-20 18:02:46] {1967} INFO -  at 942.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:02:46] {1778} INFO - iteration 689, current learner xgboost\n",
            "[flaml.automl: 10-20 18:02:48] {1967} INFO -  at 944.4s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:02:48] {1778} INFO - iteration 690, current learner xgboost\n",
            "[flaml.automl: 10-20 18:02:49] {1967} INFO -  at 945.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:02:49] {1778} INFO - iteration 691, current learner xgboost\n",
            "[flaml.automl: 10-20 18:02:50] {1967} INFO -  at 946.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:02:50] {1778} INFO - iteration 692, current learner xgboost\n",
            "[flaml.automl: 10-20 18:02:51] {1967} INFO -  at 947.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:02:51] {1778} INFO - iteration 693, current learner xgboost\n",
            "[flaml.automl: 10-20 18:02:53] {1967} INFO -  at 949.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:02:53] {1778} INFO - iteration 694, current learner xgboost\n",
            "[flaml.automl: 10-20 18:02:54] {1967} INFO -  at 950.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:02:54] {1778} INFO - iteration 695, current learner xgboost\n",
            "[flaml.automl: 10-20 18:02:56] {1967} INFO -  at 952.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:02:56] {1778} INFO - iteration 696, current learner xgboost\n",
            "[flaml.automl: 10-20 18:02:57] {1967} INFO -  at 953.6s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:02:57] {1778} INFO - iteration 697, current learner xgboost\n",
            "[flaml.automl: 10-20 18:02:58] {1967} INFO -  at 954.3s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:02:58] {1778} INFO - iteration 698, current learner xgboost\n",
            "[flaml.automl: 10-20 18:02:58] {1967} INFO -  at 955.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:02:58] {1778} INFO - iteration 699, current learner xgboost\n",
            "[flaml.automl: 10-20 18:03:01] {1967} INFO -  at 958.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:03:01] {1778} INFO - iteration 700, current learner xgboost\n",
            "[flaml.automl: 10-20 18:03:02] {1967} INFO -  at 958.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:03:02] {1778} INFO - iteration 701, current learner xgboost\n",
            "[flaml.automl: 10-20 18:03:05] {1967} INFO -  at 961.4s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:03:05] {1778} INFO - iteration 702, current learner xgboost\n",
            "[flaml.automl: 10-20 18:03:07] {1967} INFO -  at 964.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:03:07] {1778} INFO - iteration 703, current learner xgboost\n",
            "[flaml.automl: 10-20 18:03:08] {1967} INFO -  at 965.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:03:08] {1778} INFO - iteration 704, current learner xgboost\n",
            "[flaml.automl: 10-20 18:03:10] {1967} INFO -  at 966.2s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:03:10] {1778} INFO - iteration 705, current learner xgboost\n",
            "[flaml.automl: 10-20 18:03:10] {1967} INFO -  at 967.1s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:03:10] {1778} INFO - iteration 706, current learner xgboost\n",
            "[flaml.automl: 10-20 18:03:13] {1967} INFO -  at 969.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:03:13] {1778} INFO - iteration 707, current learner xgboost\n",
            "[flaml.automl: 10-20 18:03:14] {1967} INFO -  at 970.6s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:03:14] {1778} INFO - iteration 708, current learner xgboost\n",
            "[flaml.automl: 10-20 18:03:15] {1967} INFO -  at 971.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:03:15] {1778} INFO - iteration 709, current learner xgboost\n",
            "[flaml.automl: 10-20 18:03:16] {1967} INFO -  at 972.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:03:16] {1778} INFO - iteration 710, current learner xgboost\n",
            "[flaml.automl: 10-20 18:03:17] {1967} INFO -  at 973.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:03:17] {1778} INFO - iteration 711, current learner xgboost\n",
            "[flaml.automl: 10-20 18:03:18] {1967} INFO -  at 974.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:03:18] {1778} INFO - iteration 712, current learner xgboost\n",
            "[flaml.automl: 10-20 18:03:19] {1967} INFO -  at 975.4s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:03:19] {1778} INFO - iteration 713, current learner xgboost\n",
            "[flaml.automl: 10-20 18:03:23] {1967} INFO -  at 979.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:03:23] {1778} INFO - iteration 714, current learner xgboost\n",
            "[flaml.automl: 10-20 18:03:24] {1967} INFO -  at 980.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:03:24] {1778} INFO - iteration 715, current learner xgboost\n",
            "[flaml.automl: 10-20 18:03:26] {1967} INFO -  at 982.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:03:26] {1778} INFO - iteration 716, current learner xgboost\n",
            "[flaml.automl: 10-20 18:03:28] {1967} INFO -  at 984.8s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:03:28] {1778} INFO - iteration 717, current learner xgboost\n",
            "[flaml.automl: 10-20 18:03:29] {1967} INFO -  at 985.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:03:29] {1778} INFO - iteration 718, current learner xgboost\n",
            "[flaml.automl: 10-20 18:03:31] {1967} INFO -  at 988.0s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:03:31] {1778} INFO - iteration 719, current learner xgboost\n",
            "[flaml.automl: 10-20 18:03:32] {1967} INFO -  at 988.9s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:03:32] {1778} INFO - iteration 720, current learner xgboost\n",
            "[flaml.automl: 10-20 18:03:34] {1967} INFO -  at 990.4s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:03:34] {1778} INFO - iteration 721, current learner xgboost\n",
            "[flaml.automl: 10-20 18:03:35] {1967} INFO -  at 991.6s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:03:35] {1778} INFO - iteration 722, current learner xgboost\n",
            "[flaml.automl: 10-20 18:03:37] {1967} INFO -  at 993.6s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:03:37] {1778} INFO - iteration 723, current learner xgboost\n",
            "[flaml.automl: 10-20 18:03:38] {1967} INFO -  at 994.5s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:03:38] {1778} INFO - iteration 724, current learner xgboost\n",
            "[flaml.automl: 10-20 18:03:39] {1967} INFO -  at 995.6s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:03:39] {1778} INFO - iteration 725, current learner xgboost\n",
            "[flaml.automl: 10-20 18:03:42] {1967} INFO -  at 998.7s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:03:42] {1778} INFO - iteration 726, current learner xgboost\n",
            "[flaml.automl: 10-20 18:03:44] {1967} INFO -  at 1000.6s,\testimator xgboost's best error=0.1631,\tbest estimator xgboost's best error=0.1631\n",
            "[flaml.automl: 10-20 18:03:44] {1778} INFO - iteration 727, current learner xgboost\n",
            "[flaml.automl: 10-20 18:03:45] {1967} INFO -  at 1001.7s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:03:45] {1778} INFO - iteration 728, current learner xgboost\n",
            "[flaml.automl: 10-20 18:03:46] {1967} INFO -  at 1002.5s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:03:46] {1778} INFO - iteration 729, current learner xgboost\n",
            "[flaml.automl: 10-20 18:03:47] {1967} INFO -  at 1003.6s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:03:47] {1778} INFO - iteration 730, current learner xgboost\n",
            "[flaml.automl: 10-20 18:03:48] {1967} INFO -  at 1004.7s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:03:48] {1778} INFO - iteration 731, current learner xgboost\n",
            "[flaml.automl: 10-20 18:03:49] {1967} INFO -  at 1005.8s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:03:49] {1778} INFO - iteration 732, current learner xgboost\n",
            "[flaml.automl: 10-20 18:03:50] {1967} INFO -  at 1006.7s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:03:50] {1778} INFO - iteration 733, current learner xgboost\n",
            "[flaml.automl: 10-20 18:03:51] {1967} INFO -  at 1007.5s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:03:51] {1778} INFO - iteration 734, current learner xgboost\n",
            "[flaml.automl: 10-20 18:03:52] {1967} INFO -  at 1008.5s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:03:52] {1778} INFO - iteration 735, current learner xgboost\n",
            "[flaml.automl: 10-20 18:03:53] {1967} INFO -  at 1009.7s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:03:53] {1778} INFO - iteration 736, current learner xgboost\n",
            "[flaml.automl: 10-20 18:03:54] {1967} INFO -  at 1010.6s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:03:54] {1778} INFO - iteration 737, current learner xgboost\n",
            "[flaml.automl: 10-20 18:03:55] {1967} INFO -  at 1011.6s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:03:55] {1778} INFO - iteration 738, current learner xgboost\n",
            "[flaml.automl: 10-20 18:03:56] {1967} INFO -  at 1012.3s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:03:56] {1778} INFO - iteration 739, current learner xgboost\n",
            "[flaml.automl: 10-20 18:03:57] {1967} INFO -  at 1014.0s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:03:57] {1778} INFO - iteration 740, current learner xgboost\n",
            "[flaml.automl: 10-20 18:03:58] {1967} INFO -  at 1015.1s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:03:58] {1778} INFO - iteration 741, current learner xgboost\n",
            "[flaml.automl: 10-20 18:03:59] {1967} INFO -  at 1016.2s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:03:59] {1778} INFO - iteration 742, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:00] {1967} INFO -  at 1017.1s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:00] {1778} INFO - iteration 743, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:01] {1967} INFO -  at 1018.0s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:01] {1778} INFO - iteration 744, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:03] {1967} INFO -  at 1019.9s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:03] {1778} INFO - iteration 745, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:04] {1967} INFO -  at 1020.5s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:04] {1778} INFO - iteration 746, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:05] {1967} INFO -  at 1021.6s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:05] {1778} INFO - iteration 747, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:06] {1967} INFO -  at 1022.6s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:06] {1778} INFO - iteration 748, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:09] {1967} INFO -  at 1025.7s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:09] {1778} INFO - iteration 749, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:10] {1967} INFO -  at 1026.3s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:10] {1778} INFO - iteration 750, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:10] {1967} INFO -  at 1027.1s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:10] {1778} INFO - iteration 751, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:12] {1967} INFO -  at 1029.1s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:12] {1778} INFO - iteration 752, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:14] {1967} INFO -  at 1030.6s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:14] {1778} INFO - iteration 753, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:14] {1967} INFO -  at 1031.2s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:14] {1778} INFO - iteration 754, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:15] {1967} INFO -  at 1031.9s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:15] {1778} INFO - iteration 755, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:16] {1967} INFO -  at 1033.0s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:16] {1778} INFO - iteration 756, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:18] {1967} INFO -  at 1034.4s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:18] {1778} INFO - iteration 757, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:18] {1967} INFO -  at 1035.0s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:18] {1778} INFO - iteration 758, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:20] {1967} INFO -  at 1036.2s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:20] {1778} INFO - iteration 759, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:21] {1967} INFO -  at 1037.4s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:21] {1778} INFO - iteration 760, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:21] {1967} INFO -  at 1038.1s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:21] {1778} INFO - iteration 761, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:23] {1967} INFO -  at 1039.2s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:23] {1778} INFO - iteration 762, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:24] {1967} INFO -  at 1040.7s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:24] {1778} INFO - iteration 763, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:25] {1967} INFO -  at 1041.3s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:25] {1778} INFO - iteration 764, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:28] {1967} INFO -  at 1044.7s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:28] {1778} INFO - iteration 765, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:29] {1967} INFO -  at 1045.2s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:29] {1778} INFO - iteration 766, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:30] {1967} INFO -  at 1046.2s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:30] {1778} INFO - iteration 767, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:31] {1967} INFO -  at 1047.2s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:31] {1778} INFO - iteration 768, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:32] {1967} INFO -  at 1048.3s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:32] {1778} INFO - iteration 769, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:32] {1967} INFO -  at 1049.1s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:32] {1778} INFO - iteration 770, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:34] {1967} INFO -  at 1050.4s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:34] {1778} INFO - iteration 771, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:34] {1967} INFO -  at 1051.1s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:34] {1778} INFO - iteration 772, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:36] {1967} INFO -  at 1052.2s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:36] {1778} INFO - iteration 773, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:36] {1967} INFO -  at 1053.2s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:37] {1778} INFO - iteration 774, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:38] {1967} INFO -  at 1054.6s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:38] {1778} INFO - iteration 775, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:39] {1967} INFO -  at 1055.3s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:39] {1778} INFO - iteration 776, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:39] {1967} INFO -  at 1055.8s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:39] {1778} INFO - iteration 777, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:42] {1967} INFO -  at 1058.5s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:42] {1778} INFO - iteration 778, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:43] {1967} INFO -  at 1059.9s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:43] {1778} INFO - iteration 779, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:44] {1967} INFO -  at 1060.7s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:44] {1778} INFO - iteration 780, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:45] {1967} INFO -  at 1062.0s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:45] {1778} INFO - iteration 781, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:48] {1967} INFO -  at 1064.2s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:48] {1778} INFO - iteration 782, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:50] {1967} INFO -  at 1066.3s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:50] {1778} INFO - iteration 783, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:51] {1967} INFO -  at 1067.7s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:51] {1778} INFO - iteration 784, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:52] {1967} INFO -  at 1068.9s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:52] {1778} INFO - iteration 785, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:53] {1967} INFO -  at 1070.1s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:53] {1778} INFO - iteration 786, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:54] {1967} INFO -  at 1070.7s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:54] {1778} INFO - iteration 787, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:57] {1967} INFO -  at 1073.9s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:57] {1778} INFO - iteration 788, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:58] {1967} INFO -  at 1074.9s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:58] {1778} INFO - iteration 789, current learner xgboost\n",
            "[flaml.automl: 10-20 18:04:59] {1967} INFO -  at 1075.9s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:04:59] {1778} INFO - iteration 790, current learner xgboost\n",
            "[flaml.automl: 10-20 18:05:01] {1967} INFO -  at 1077.8s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:05:01] {1778} INFO - iteration 791, current learner xgboost\n",
            "[flaml.automl: 10-20 18:05:02] {1967} INFO -  at 1078.5s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:05:02] {1778} INFO - iteration 792, current learner xgboost\n",
            "[flaml.automl: 10-20 18:05:03] {1967} INFO -  at 1080.0s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:05:03] {1778} INFO - iteration 793, current learner xgboost\n",
            "[flaml.automl: 10-20 18:05:05] {1967} INFO -  at 1081.2s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:05:05] {1778} INFO - iteration 794, current learner xgboost\n",
            "[flaml.automl: 10-20 18:05:05] {1967} INFO -  at 1082.1s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:05:05] {1778} INFO - iteration 795, current learner xgboost\n",
            "[flaml.automl: 10-20 18:05:07] {1967} INFO -  at 1083.5s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:05:07] {1778} INFO - iteration 796, current learner xgboost\n",
            "[flaml.automl: 10-20 18:05:08] {1967} INFO -  at 1084.2s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:05:08] {1778} INFO - iteration 797, current learner xgboost\n",
            "[flaml.automl: 10-20 18:05:09] {1967} INFO -  at 1085.7s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:05:09] {1778} INFO - iteration 798, current learner xgboost\n",
            "[flaml.automl: 10-20 18:05:10] {1967} INFO -  at 1086.5s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:05:10] {1778} INFO - iteration 799, current learner xgboost\n",
            "[flaml.automl: 10-20 18:05:12] {1967} INFO -  at 1088.4s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:05:12] {1778} INFO - iteration 800, current learner xgboost\n",
            "[flaml.automl: 10-20 18:05:14] {1967} INFO -  at 1090.2s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:05:14] {1778} INFO - iteration 801, current learner xgboost\n",
            "[flaml.automl: 10-20 18:05:15] {1967} INFO -  at 1091.2s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:05:15] {1778} INFO - iteration 802, current learner xgboost\n",
            "[flaml.automl: 10-20 18:05:16] {1967} INFO -  at 1092.4s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:05:16] {1778} INFO - iteration 803, current learner xgboost\n",
            "[flaml.automl: 10-20 18:05:17] {1967} INFO -  at 1093.9s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:05:17] {1778} INFO - iteration 804, current learner xgboost\n",
            "[flaml.automl: 10-20 18:05:19] {1967} INFO -  at 1096.0s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:05:19] {1778} INFO - iteration 805, current learner xgboost\n",
            "[flaml.automl: 10-20 18:05:21] {1967} INFO -  at 1097.6s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:05:21] {1778} INFO - iteration 806, current learner xgboost\n",
            "[flaml.automl: 10-20 18:05:22] {1967} INFO -  at 1098.5s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:05:22] {1778} INFO - iteration 807, current learner xgboost\n",
            "[flaml.automl: 10-20 18:05:24] {1967} INFO -  at 1100.3s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:05:24] {1778} INFO - iteration 808, current learner xgboost\n",
            "[flaml.automl: 10-20 18:05:24] {1967} INFO -  at 1101.0s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:05:24] {1778} INFO - iteration 809, current learner xgboost\n",
            "[flaml.automl: 10-20 18:05:26] {1967} INFO -  at 1102.8s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:05:26] {1778} INFO - iteration 810, current learner xgboost\n",
            "[flaml.automl: 10-20 18:05:27] {1967} INFO -  at 1103.4s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:05:27] {1778} INFO - iteration 811, current learner xgboost\n",
            "[flaml.automl: 10-20 18:05:30] {1967} INFO -  at 1106.2s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:05:30] {1778} INFO - iteration 812, current learner xgboost\n",
            "[flaml.automl: 10-20 18:05:30] {1967} INFO -  at 1107.0s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:05:30] {1778} INFO - iteration 813, current learner xgboost\n",
            "[flaml.automl: 10-20 18:05:33] {1967} INFO -  at 1109.7s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:05:33] {1778} INFO - iteration 814, current learner xgboost\n",
            "[flaml.automl: 10-20 18:05:34] {1967} INFO -  at 1110.6s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:05:34] {1778} INFO - iteration 815, current learner xgboost\n",
            "[flaml.automl: 10-20 18:05:36] {1967} INFO -  at 1112.4s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:05:36] {1778} INFO - iteration 816, current learner xgboost\n",
            "[flaml.automl: 10-20 18:05:38] {1967} INFO -  at 1114.4s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:05:38] {1778} INFO - iteration 817, current learner xgboost\n",
            "[flaml.automl: 10-20 18:05:40] {1967} INFO -  at 1116.2s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:05:40] {1778} INFO - iteration 818, current learner xgboost\n",
            "[flaml.automl: 10-20 18:05:41] {1967} INFO -  at 1117.5s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:05:41] {1778} INFO - iteration 819, current learner xgboost\n",
            "[flaml.automl: 10-20 18:05:42] {1967} INFO -  at 1118.5s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:05:42] {1778} INFO - iteration 820, current learner xgboost\n",
            "[flaml.automl: 10-20 18:05:43] {1967} INFO -  at 1119.5s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:05:43] {1778} INFO - iteration 821, current learner xgboost\n",
            "[flaml.automl: 10-20 18:05:44] {1967} INFO -  at 1120.6s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:05:44] {1778} INFO - iteration 822, current learner xgboost\n",
            "[flaml.automl: 10-20 18:05:46] {1967} INFO -  at 1122.6s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:05:46] {1778} INFO - iteration 823, current learner xgboost\n",
            "[flaml.automl: 10-20 18:05:47] {1967} INFO -  at 1123.7s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:05:47] {1778} INFO - iteration 824, current learner xgboost\n",
            "[flaml.automl: 10-20 18:05:49] {1967} INFO -  at 1125.3s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:05:49] {1778} INFO - iteration 825, current learner xgboost\n",
            "[flaml.automl: 10-20 18:05:50] {1967} INFO -  at 1126.2s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:05:50] {1778} INFO - iteration 826, current learner xgboost\n",
            "[flaml.automl: 10-20 18:05:50] {1967} INFO -  at 1126.8s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:05:50] {1778} INFO - iteration 827, current learner xgboost\n",
            "[flaml.automl: 10-20 18:05:53] {1967} INFO -  at 1129.4s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:05:53] {1778} INFO - iteration 828, current learner xgboost\n",
            "[flaml.automl: 10-20 18:05:54] {1967} INFO -  at 1131.0s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:05:54] {1778} INFO - iteration 829, current learner xgboost\n",
            "[flaml.automl: 10-20 18:05:55] {1967} INFO -  at 1131.8s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:05:55] {1778} INFO - iteration 830, current learner xgboost\n",
            "[flaml.automl: 10-20 18:05:57] {1967} INFO -  at 1133.8s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:05:57] {1778} INFO - iteration 831, current learner xgboost\n",
            "[flaml.automl: 10-20 18:05:58] {1967} INFO -  at 1134.5s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:05:58] {1778} INFO - iteration 832, current learner xgboost\n",
            "[flaml.automl: 10-20 18:05:58] {1967} INFO -  at 1135.1s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:05:58] {1778} INFO - iteration 833, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:02] {1967} INFO -  at 1138.5s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:02] {1778} INFO - iteration 834, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:03] {1967} INFO -  at 1139.2s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:03] {1778} INFO - iteration 835, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:04] {1967} INFO -  at 1140.2s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:04] {1778} INFO - iteration 836, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:05] {1967} INFO -  at 1141.2s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:05] {1778} INFO - iteration 837, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:05] {1967} INFO -  at 1142.0s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:05] {1778} INFO - iteration 838, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:07] {1967} INFO -  at 1143.2s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:07] {1778} INFO - iteration 839, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:08] {1967} INFO -  at 1144.3s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:08] {1778} INFO - iteration 840, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:09] {1967} INFO -  at 1145.7s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:09] {1778} INFO - iteration 841, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:10] {1967} INFO -  at 1146.6s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:10] {1778} INFO - iteration 842, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:11] {1967} INFO -  at 1147.3s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:11] {1778} INFO - iteration 843, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:13] {1967} INFO -  at 1149.7s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:13] {1778} INFO - iteration 844, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:14] {1967} INFO -  at 1150.8s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:14] {1778} INFO - iteration 845, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:15] {1967} INFO -  at 1151.7s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:15] {1778} INFO - iteration 846, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:16] {1967} INFO -  at 1152.4s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:16] {1778} INFO - iteration 847, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:18] {1967} INFO -  at 1154.4s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:18] {1778} INFO - iteration 848, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:18] {1967} INFO -  at 1155.1s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:18] {1778} INFO - iteration 849, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:20] {1967} INFO -  at 1156.3s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:20] {1778} INFO - iteration 850, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:21] {1967} INFO -  at 1157.9s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:21] {1778} INFO - iteration 851, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:22] {1967} INFO -  at 1158.6s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:22] {1778} INFO - iteration 852, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:24] {1967} INFO -  at 1160.6s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:24] {1778} INFO - iteration 853, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:25] {1967} INFO -  at 1161.2s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:25] {1778} INFO - iteration 854, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:25] {1967} INFO -  at 1161.9s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:25] {1778} INFO - iteration 855, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:27] {1967} INFO -  at 1163.6s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:27] {1778} INFO - iteration 856, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:29] {1967} INFO -  at 1165.2s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:29] {1778} INFO - iteration 857, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:29] {1967} INFO -  at 1165.8s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:29] {1778} INFO - iteration 858, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:30] {1967} INFO -  at 1166.9s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:30] {1778} INFO - iteration 859, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:31] {1967} INFO -  at 1167.9s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:31] {1778} INFO - iteration 860, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:32] {1967} INFO -  at 1168.5s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:32] {1778} INFO - iteration 861, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:34] {1967} INFO -  at 1170.4s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:34] {1778} INFO - iteration 862, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:35] {1967} INFO -  at 1171.8s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:35] {1778} INFO - iteration 863, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:36] {1967} INFO -  at 1172.5s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:36] {1778} INFO - iteration 864, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:37] {1967} INFO -  at 1173.4s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:37] {1778} INFO - iteration 865, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:38] {1967} INFO -  at 1174.6s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:38] {1778} INFO - iteration 866, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:39] {1967} INFO -  at 1176.0s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:39] {1778} INFO - iteration 867, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:40] {1967} INFO -  at 1176.8s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:40] {1778} INFO - iteration 868, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:41] {1967} INFO -  at 1177.7s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:41] {1778} INFO - iteration 869, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:42] {1967} INFO -  at 1178.4s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:42] {1778} INFO - iteration 870, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:42] {1967} INFO -  at 1179.1s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:42] {1778} INFO - iteration 871, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:44] {1967} INFO -  at 1180.6s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:44] {1778} INFO - iteration 872, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:46] {1967} INFO -  at 1182.3s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:46] {1778} INFO - iteration 873, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:46] {1967} INFO -  at 1183.1s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:46] {1778} INFO - iteration 874, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:48] {1967} INFO -  at 1184.9s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:48] {1778} INFO - iteration 875, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:49] {1967} INFO -  at 1185.4s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:49] {1778} INFO - iteration 876, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:50] {1967} INFO -  at 1186.7s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:50] {1778} INFO - iteration 877, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:51] {1967} INFO -  at 1187.3s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:51] {1778} INFO - iteration 878, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:52] {1967} INFO -  at 1188.3s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:52] {1778} INFO - iteration 879, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:52] {1967} INFO -  at 1189.2s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:53] {1778} INFO - iteration 880, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:53] {1967} INFO -  at 1190.0s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:53] {1778} INFO - iteration 881, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:54] {1967} INFO -  at 1191.2s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:54] {1778} INFO - iteration 882, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:57] {1967} INFO -  at 1193.2s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:57] {1778} INFO - iteration 883, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:57] {1967} INFO -  at 1193.7s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:57] {1778} INFO - iteration 884, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:58] {1967} INFO -  at 1194.6s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:58] {1778} INFO - iteration 885, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:59] {1967} INFO -  at 1195.6s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:59] {1778} INFO - iteration 886, current learner xgboost\n",
            "[flaml.automl: 10-20 18:06:59] {1967} INFO -  at 1196.1s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:06:59] {1778} INFO - iteration 887, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:01] {1967} INFO -  at 1197.3s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:01] {1778} INFO - iteration 888, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:01] {1967} INFO -  at 1198.0s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:01] {1778} INFO - iteration 889, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:03] {1967} INFO -  at 1199.8s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:03] {1778} INFO - iteration 890, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:04] {1967} INFO -  at 1200.8s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:04] {1778} INFO - iteration 891, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:05] {1967} INFO -  at 1201.5s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:05] {1778} INFO - iteration 892, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:06] {1967} INFO -  at 1202.9s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:06] {1778} INFO - iteration 893, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:07] {1967} INFO -  at 1203.7s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:07] {1778} INFO - iteration 894, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:09] {1967} INFO -  at 1205.8s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:09] {1778} INFO - iteration 895, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:10] {1967} INFO -  at 1206.4s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:10] {1778} INFO - iteration 896, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:11] {1967} INFO -  at 1207.3s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:11] {1778} INFO - iteration 897, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:12] {1967} INFO -  at 1208.5s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:12] {1778} INFO - iteration 898, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:13] {1967} INFO -  at 1209.9s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:13] {1778} INFO - iteration 899, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:14] {1967} INFO -  at 1210.4s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:14] {1778} INFO - iteration 900, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:15] {1967} INFO -  at 1212.0s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:15] {1778} INFO - iteration 901, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:16] {1967} INFO -  at 1212.5s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:16] {1778} INFO - iteration 902, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:16] {1967} INFO -  at 1213.0s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:16] {1778} INFO - iteration 903, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:18] {1967} INFO -  at 1214.9s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:18] {1778} INFO - iteration 904, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:19] {1967} INFO -  at 1215.8s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:19] {1778} INFO - iteration 905, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:20] {1967} INFO -  at 1216.4s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:20] {1778} INFO - iteration 906, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:21] {1967} INFO -  at 1217.4s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:21] {1778} INFO - iteration 907, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:21] {1967} INFO -  at 1218.0s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:21] {1778} INFO - iteration 908, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:22] {1967} INFO -  at 1218.6s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:22] {1778} INFO - iteration 909, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:23] {1967} INFO -  at 1220.0s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:23] {1778} INFO - iteration 910, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:24] {1967} INFO -  at 1220.4s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:24] {1778} INFO - iteration 911, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:26] {1967} INFO -  at 1222.3s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:26] {1778} INFO - iteration 912, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:27] {1967} INFO -  at 1223.9s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:27] {1778} INFO - iteration 913, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:28] {1967} INFO -  at 1224.4s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:28] {1778} INFO - iteration 914, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:30] {1967} INFO -  at 1226.3s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:30] {1778} INFO - iteration 915, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:30] {1967} INFO -  at 1227.0s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:30] {1778} INFO - iteration 916, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:31] {1967} INFO -  at 1228.0s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:31] {1778} INFO - iteration 917, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:32] {1967} INFO -  at 1229.1s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:32] {1778} INFO - iteration 918, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:33] {1967} INFO -  at 1229.8s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:33] {1778} INFO - iteration 919, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:34] {1967} INFO -  at 1230.8s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:34] {1778} INFO - iteration 920, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:36] {1967} INFO -  at 1232.7s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:36] {1778} INFO - iteration 921, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:37] {1967} INFO -  at 1233.3s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:37] {1778} INFO - iteration 922, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:38] {1967} INFO -  at 1234.9s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:38] {1778} INFO - iteration 923, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:39] {1967} INFO -  at 1235.5s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:39] {1778} INFO - iteration 924, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:39] {1967} INFO -  at 1236.0s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:39] {1778} INFO - iteration 925, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:42] {1967} INFO -  at 1238.3s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:42] {1778} INFO - iteration 926, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:42] {1967} INFO -  at 1239.0s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:42] {1778} INFO - iteration 927, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:44] {1967} INFO -  at 1240.2s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:44] {1778} INFO - iteration 928, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:45] {1967} INFO -  at 1241.5s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:45] {1778} INFO - iteration 929, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:45] {1967} INFO -  at 1242.1s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:45] {1778} INFO - iteration 930, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:46] {1967} INFO -  at 1242.7s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:46] {1778} INFO - iteration 931, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:49] {1967} INFO -  at 1245.3s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:49] {1778} INFO - iteration 932, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:50] {1967} INFO -  at 1246.5s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:50] {1778} INFO - iteration 933, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:51] {1967} INFO -  at 1247.2s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:51] {1778} INFO - iteration 934, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:51] {1967} INFO -  at 1247.8s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:51] {1778} INFO - iteration 935, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:53] {1967} INFO -  at 1249.4s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:53] {1778} INFO - iteration 936, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:53] {1967} INFO -  at 1250.1s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:53] {1778} INFO - iteration 937, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:54] {1967} INFO -  at 1250.9s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:54] {1778} INFO - iteration 938, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:55] {1967} INFO -  at 1251.8s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:55] {1778} INFO - iteration 939, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:56] {1967} INFO -  at 1252.6s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:56] {1778} INFO - iteration 940, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:57] {1967} INFO -  at 1253.2s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:57] {1778} INFO - iteration 941, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:58] {1967} INFO -  at 1254.8s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:58] {1778} INFO - iteration 942, current learner xgboost\n",
            "[flaml.automl: 10-20 18:07:59] {1967} INFO -  at 1255.6s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:07:59] {1778} INFO - iteration 943, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:00] {1967} INFO -  at 1256.3s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:00] {1778} INFO - iteration 944, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:00] {1967} INFO -  at 1257.0s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:00] {1778} INFO - iteration 945, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:02] {1967} INFO -  at 1258.7s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:02] {1778} INFO - iteration 946, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:03] {1967} INFO -  at 1259.3s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:03] {1778} INFO - iteration 947, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:03] {1967} INFO -  at 1260.1s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:03] {1778} INFO - iteration 948, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:04] {1967} INFO -  at 1260.9s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:04] {1778} INFO - iteration 949, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:05] {1967} INFO -  at 1261.8s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:05] {1778} INFO - iteration 950, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:07] {1967} INFO -  at 1263.5s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:07] {1778} INFO - iteration 951, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:08] {1967} INFO -  at 1264.2s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:08] {1778} INFO - iteration 952, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:08] {1967} INFO -  at 1264.8s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:08] {1778} INFO - iteration 953, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:10] {1967} INFO -  at 1266.2s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:10] {1778} INFO - iteration 954, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:10] {1967} INFO -  at 1266.9s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:10] {1778} INFO - iteration 955, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:11] {1967} INFO -  at 1267.9s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:11] {1778} INFO - iteration 956, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:13] {1967} INFO -  at 1269.3s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:13] {1778} INFO - iteration 957, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:13] {1967} INFO -  at 1270.1s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:13] {1778} INFO - iteration 958, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:14] {1967} INFO -  at 1270.7s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:14] {1778} INFO - iteration 959, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:15] {1967} INFO -  at 1271.8s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:15] {1778} INFO - iteration 960, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:16] {1967} INFO -  at 1272.4s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:16] {1778} INFO - iteration 961, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:17] {1967} INFO -  at 1273.5s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:17] {1778} INFO - iteration 962, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:17] {1967} INFO -  at 1274.1s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:17] {1778} INFO - iteration 963, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:19] {1967} INFO -  at 1275.3s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:19] {1778} INFO - iteration 964, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:19] {1967} INFO -  at 1275.8s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:19] {1778} INFO - iteration 965, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:20] {1967} INFO -  at 1276.9s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:20] {1778} INFO - iteration 966, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:21] {1967} INFO -  at 1277.5s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:21] {1778} INFO - iteration 967, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:22] {1967} INFO -  at 1278.9s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:22] {1778} INFO - iteration 968, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:24] {1967} INFO -  at 1281.1s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:24] {1778} INFO - iteration 969, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:25] {1967} INFO -  at 1281.6s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:25] {1778} INFO - iteration 970, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:26] {1967} INFO -  at 1282.3s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:26] {1778} INFO - iteration 971, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:27] {1967} INFO -  at 1283.4s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:27] {1778} INFO - iteration 972, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:27] {1967} INFO -  at 1283.9s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:27] {1778} INFO - iteration 973, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:29] {1967} INFO -  at 1285.6s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:29] {1778} INFO - iteration 974, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:30] {1967} INFO -  at 1286.5s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:30] {1778} INFO - iteration 975, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:31] {1967} INFO -  at 1287.3s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:31] {1778} INFO - iteration 976, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:31] {1967} INFO -  at 1287.8s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:31] {1778} INFO - iteration 977, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:33] {1967} INFO -  at 1289.9s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:33] {1778} INFO - iteration 978, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:34] {1967} INFO -  at 1290.4s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:34] {1778} INFO - iteration 979, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:35] {1967} INFO -  at 1291.9s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:35] {1778} INFO - iteration 980, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:36] {1967} INFO -  at 1292.8s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:36] {1778} INFO - iteration 981, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:37] {1967} INFO -  at 1293.5s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:37] {1778} INFO - iteration 982, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:38] {1967} INFO -  at 1294.7s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:38] {1778} INFO - iteration 983, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:39] {1967} INFO -  at 1295.7s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:39] {1778} INFO - iteration 984, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:40] {1967} INFO -  at 1296.2s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:40] {1778} INFO - iteration 985, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:43] {1967} INFO -  at 1299.4s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:43] {1778} INFO - iteration 986, current learner xgboost\n",
            "[flaml.automl: 10-20 18:08:43] {1967} INFO -  at 1299.9s,\testimator xgboost's best error=0.1629,\tbest estimator xgboost's best error=0.1629\n",
            "[flaml.automl: 10-20 18:08:43] {1778} INFO - iteration 987, current learner xgboost\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16124/38488929.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mautoml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mautoml_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32mc:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\flaml\\automl.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X_train, y_train, dataframe, label, metric, task, n_jobs, log_file_name, estimator_list, time_budget, max_iter, sample, ensemble, eval_method, log_type, model_history, split_ratio, n_splits, log_training_metric, mem_thres, pred_time_limit, train_time_limit, X_val, y_val, sample_weight_val, groups_val, groups, verbose, retrain_full, split_type, learner_selector, hpo_method, starting_points, seed, n_concurrent_trials, keep_search_state, early_stop, append_log, auto_augment, min_sample_size, **fit_kwargs)\u001b[0m\n\u001b[0;32m   1565\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtraining_log_writer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_file_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappend_log\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msave_helper\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1566\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_training_log\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msave_helper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1567\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1568\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1569\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_training_log\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\flaml\\automl.py\u001b[0m in \u001b[0;36m_search\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2060\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2061\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_concurrent_trials\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2062\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_search_sequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2063\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2064\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_search_parallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\flaml\\automl.py\u001b[0m in \u001b[0;36m_search_sequential\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1862\u001b[0m                     )\n\u001b[0;32m   1863\u001b[0m             \u001b[0mstart_run_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1864\u001b[1;33m             analysis = tune.run(\n\u001b[0m\u001b[0;32m   1865\u001b[0m                 \u001b[0msearch_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m                 \u001b[0msearch_alg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msearch_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch_alg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\flaml\\tune\\tune.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(training_function, config, low_cost_partial_config, cat_hp_cost, metric, mode, time_budget_s, points_to_evaluate, evaluated_rewards, prune_attr, min_resource, max_resource, reduction_factor, report_intermediate_result, search_alg, verbose, local_dir, num_samples, resources_per_trial, config_constraints, metric_constraints, max_failure, use_ray)\u001b[0m\n\u001b[0;32m    391\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"trial {num_trials} config: {trial_to_run.config}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 393\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial_to_run\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    394\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\flaml\\automl.py\u001b[0m in \u001b[0;36m_compute_with_config_base\u001b[1;34m(self, estimator, config_w_resource)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[0mpred_time\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m         \u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m             \u001b[0msampled_X_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[0msampled_y_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\flaml\\ml.py\u001b[0m in \u001b[0;36mcompute_estimator\u001b[1;34m(X_train, y_train, X_val, y_val, weight_val, groups_val, budget, kf, config_dic, task, estimator_name, eval_method, eval_metric, best_val_loss, n_jobs, estimator_class, log_training_metric, fit_kwargs)\u001b[0m\n\u001b[0;32m    441\u001b[0m         )\n\u001b[0;32m    442\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m         val_loss, metric_for_logging, train_time, pred_time = evaluate_model_CV(\n\u001b[0m\u001b[0;32m    444\u001b[0m             \u001b[0mconfig_dic\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\flaml\\ml.py\u001b[0m in \u001b[0;36mevaluate_model_CV\u001b[1;34m(config, estimator, X_train_all, y_train_all, budget, kf, task, eval_metric, best_val_loss, log_training_metric, fit_kwargs)\u001b[0m\n\u001b[0;32m    351\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m             \u001b[0mgroups_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m         val_loss_i, metric_i, train_time_i, pred_time_i = get_test_loss(\n\u001b[0m\u001b[0;32m    354\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\flaml\\ml.py\u001b[0m in \u001b[0;36mget_test_loss\u001b[1;34m(config, estimator, X_train, y_train, X_test, y_test, weight_test, groups_test, eval_metric, obj, labels, budget, log_training_metric, fit_kwargs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;31m#     fit_kwargs['X_val'] = X_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[1;31m#     fit_kwargs['y_val'] = y_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m     \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbudget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    264\u001b[0m     test_loss, metric_for_logging, pred_time, _ = _eval_estimator(\n\u001b[0;32m    265\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\flaml\\model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X_train, y_train, budget, **kwargs)\u001b[0m\n\u001b[0;32m    512\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tree_method\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"auto\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 514\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbudget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\flaml\\model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X_train, y_train, budget, **kwargs)\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"n_estimators\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"n_estimators\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"n_estimators\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\flaml\\model.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X_train, y_train, **kwargs)\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlevel\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDEBUG\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"flaml.model - {model} fit started\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlevel\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDEBUG\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"flaml.model - {model} fit finished\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 422\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m    907\u001b[0m             eval_group=None, label_transform=label_transform)\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 909\u001b[1;33m         self._Booster = train(xgb_options, train_dmatrix,\n\u001b[0m\u001b[0;32m    910\u001b[0m                               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_num_boosting_rounds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m                               \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    225\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m     \"\"\"\n\u001b[1;32m--> 227\u001b[1;33m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[0;32m    228\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1279\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1280\u001b[1;33m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[0;32m   1281\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1282\u001b[0m                                                     dtrain.handle))\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "automl.fit(X_train=X, y_train=y, **automl_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best hyperparmeter config: {'n_estimators': 144, 'max_leaves': 24, 'min_child_weight': 0.09194426120273991, 'learning_rate': 0.07146410645081408, 'subsample': 0.9692308733367908, 'colsample_bylevel': 0.9305472752621012, 'colsample_bytree': 0.8849860673444865, 'reg_alpha': 0.003396501679614063, 'reg_lambda': 82.49928920076438}\n",
            "Best ROC_PR on validation data: 0.8212\n",
            "Training duration of best run: 12.33 s\n"
          ]
        }
      ],
      "source": [
        "print('Best hyperparmeter config:', automl.best_config)\n",
        "print('Best ROC_PR on validation data: {0:.4g}'.format(1-automl.best_loss))\n",
        "print('Training duration of best run: {0:.4g} s'.format(automl.best_config_train_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='dart',\n",
              "              colsample_bylevel=0.9305472752621012, colsample_bynode=1,\n",
              "              colsample_bytree=0.8849860673444865, gamma=0, gpu_id=-1,\n",
              "              grow_policy='lossguide', importance_type='gain',\n",
              "              interaction_constraints='', learning_rate=0.07146410645081408,\n",
              "              max_delta_step=0, max_depth=0, max_leaves=24,\n",
              "              min_child_weight=0.09194426120273991, missing=nan,\n",
              "              monotone_constraints='()', n_estimators=144, n_jobs=8,\n",
              "              num_parallel_tree=1, random_state=0,\n",
              "              reg_alpha=0.003396501679614063, reg_lambda=82.49928920076438,\n",
              "              scale_pos_weight=19.542713567839197, subsample=0.9692308733367908,\n",
              "              tree_method='hist', use_label_encoder=False,\n",
              "              validate_parameters=1, verbosity=0)"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "automl.model.estimator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "xgb_params = dict(\n",
        "    bbase_score=0.5, booster='gbtree',\n",
        "              colsample_bylevel=0.7821065428999804, colsample_bynode=1,\n",
        "              colsample_bytree=0.86585064209194, gamma=0, gpu_id=-1,\n",
        "              grow_policy='lossguide', importance_type='gain',\n",
        "              interaction_constraints='', learning_rate=0.05676981288924362,\n",
        "              max_delta_step=0, max_depth=0, max_leaves=78,\n",
        "              min_child_weight=35.020683109493056,\n",
        "              monotone_constraints='()', n_estimators=12, n_jobs=8,\n",
        "              num_parallel_tree=1, random_state=0,\n",
        "              reg_alpha=0.0011944454888602083, reg_lambda=0.480781096367355,\n",
        "              scale_pos_weight=counter[0]/counter[1], subsample=0.971784995750149,\n",
        "              tree_method='hist', use_label_encoder=False,\n",
        "              validate_parameters=1, verbosity=0\n",
        ")\n",
        "\n",
        "lgbm_params = dict(\n",
        "    objective='binary',\n",
        "    boosting_type='dart',\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=3,\n",
        "    min_data_in_leaf=23,\n",
        "    max_delta_step =23,\n",
        "    min_gain_to_split=2,\n",
        "    min_child_weight=0.5,\n",
        "    scale_pos_weight=counter[0]/(counter[1]),\n",
        "    metric='average_precision'\n",
        ")\n",
        "\n",
        "trad_classifiers = [\n",
        "    SVC(class_weight='balanced', C=.005),\n",
        "    RandomForestClassifier(class_weight='balanced', criterion='gini', max_depth=5, min_samples_split=4, min_samples_leaf=6, max_features='sqrt', n_estimators=50, n_jobs=-1),\n",
        "    GradientBoostingClassifier(n_estimators=50, learning_rate=0.001, max_depth=5, min_samples_split=4, min_samples_leaf=6, loss='exponential', max_features='log2'),\n",
        "    LogisticRegression(class_weight='balanced', solver='liblinear', C=.1, n_jobs=-1),\n",
        "    #XGBClassifier(**xgb_params),\n",
        "    LGBMClassifier(**lgbm_params, n_jobs=-1)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 15 is smaller than n_iter=150. Running 15 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 15 candidates, totalling 150 fits\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16124/796374038.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m                                  verbose=1)\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0msearch_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrand_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Best model {search_result.best_params_} with PR_AUC of {search_result.best_score_}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mmeans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msearch_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean_test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1765\u001b[0m         \u001b[1;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1766\u001b[1;33m         evaluate_candidates(\n\u001b[0m\u001b[0;32m   1767\u001b[0m             ParameterSampler(\n\u001b[0;32m   1768\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    836\u001b[0m                     )\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 838\u001b[1;33m                 out = parallel(\n\u001b[0m\u001b[0;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[0;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1056\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1057\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 935\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    936\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Michel\\Documents\\NURE\\Python\\DS Fundamentals\\Final Project\\app\\env\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\Program Files\\Python38\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    437\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\Program Files\\Python38\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "param_grid = dict(\n",
        "    C=[0.0001, 0.001, 0.01, 0.1, 1],\n",
        "    solver=['liblinear','lbfgs','newton-cg']\n",
        ")\n",
        "rand_search = RandomizedSearchCV(estimator=trad_classifiers[-3], \n",
        "                                 param_distributions=param_grid, \n",
        "                                 scoring='average_precision', \n",
        "                                 n_iter=150, \n",
        "                                 n_jobs=-1, \n",
        "                                 cv=StratifiedShuffleSplit(n_splits=10, test_size=0.3, random_state=0), \n",
        "                                 verbose=1)\n",
        "\n",
        "search_result = rand_search.fit(X,y)\n",
        "print(f'Best model {search_result.best_params_} with PR_AUC of {search_result.best_score_}')\n",
        "means = search_result.cv_results_['mean_test_score']\n",
        "stds = search_result.cv_results_['std_test_score']\n",
        "params = search_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"{mean} ({stdev}) with: {param}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:    6.1s remaining:    4.0s\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    7.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:    0.4s remaining:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.6s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:    0.3s remaining:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.5s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:    0.5s remaining:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.6s finished\n"
          ]
        }
      ],
      "source": [
        "log_cols = [\"Classifier\", \"PR_AUC\", \"Recall (TPR)\", \"Fbeta\"]\n",
        "log = pd.DataFrame(columns=log_cols)\n",
        "\n",
        "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.3, random_state=0)\n",
        "scoring = {\n",
        "    'PR_AUC': 'average_precision',\n",
        "    'recall': 'recall',\n",
        "    'Fbeta': make_scorer(fbeta_score, beta=2)\n",
        "}\n",
        "acc_dict = {}\n",
        "\n",
        "for clf in trad_classifiers:\n",
        "    name = clf.__class__.__name__\n",
        "    scores = cross_validate(clf, X, y, scoring=scoring, cv=sss, verbose=1, n_jobs=-1)\n",
        "    roc_auc = scores['test_PR_AUC'].mean()\n",
        "    recall = scores['test_recall'].mean()\n",
        "    fbeta = scores['test_Fbeta'].mean()\n",
        "    \n",
        "    acc_dict[name] = np.array([roc_auc, recall, fbeta])\n",
        "\n",
        "for clf in acc_dict:\n",
        "    log_entry = pd.DataFrame([[clf, acc_dict[clf][0], acc_dict[clf][1], acc_dict[clf][2]]], columns = log_cols)\n",
        "    log = log.append(log_entry)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Classifier</th>\n",
              "      <th>PR_AUC</th>\n",
              "      <th>Recall (TPR)</th>\n",
              "      <th>Fbeta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SVC</td>\n",
              "      <td>0.189784</td>\n",
              "      <td>0.878333</td>\n",
              "      <td>0.366297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.212700</td>\n",
              "      <td>0.755000</td>\n",
              "      <td>0.385929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>0.235451</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.189418</td>\n",
              "      <td>0.828333</td>\n",
              "      <td>0.387422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LGBMClassifier</td>\n",
              "      <td>0.235003</td>\n",
              "      <td>0.753333</td>\n",
              "      <td>0.395536</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Classifier    PR_AUC  Recall (TPR)     Fbeta\n",
              "0                         SVC  0.189784      0.878333  0.366297\n",
              "0      RandomForestClassifier  0.212700      0.755000  0.385929\n",
              "0  GradientBoostingClassifier  0.235451      0.000000  0.000000\n",
              "0          LogisticRegression  0.189418      0.828333  0.387422\n",
              "0              LGBMClassifier  0.235003      0.753333  0.395536"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:title={'center':'Classifier Accuracy'}, xlabel='model performance', ylabel='Classifier'>"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(log)\n",
        "\n",
        "plt.title('Classifier Accuracy')\n",
        "log = pd.melt(log, id_vars='Classifier', var_name='metrics', value_name='model performance')\n",
        "sns.set_color_codes(\"muted\")\n",
        "sns.barplot(x = 'model performance', y = 'Classifier', data = log, hue='metrics')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Deep learning model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import AUC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.constraints import maxnorm\n",
        "\n",
        "class_weights = {0: X.shape[0]/(counter[0]), 1: X.shape[0]/counter[1]}\n",
        "\n",
        "def create_model(learn_rate=0.0001, epsilon=1e-7, drop_rate=0.3, weight_constraint=2, nodes=140, init_mode='lecun_uniform', act_func='sigmoid'):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units=nodes, input_dim=X.shape[1], activation=act_func, kernel_initializer=init_mode, kernel_constraint=maxnorm(weight_constraint))),\n",
        "    model.add(Dropout(drop_rate))\n",
        "    model.add(Dense(units=1, activation='sigmoid'))\n",
        "    model._name = '60-1'\n",
        "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=learn_rate, epsilon=epsilon), metrics=[AUC(curve='PR')], weighted_metrics=[AUC(curve='PR')])\n",
        "    return model\n",
        "\n",
        "dl_clf = KerasClassifier(build_fn=create_model, verbose=0, batch_size=10, class_weight=class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 1000 candidates, totalling 10000 fits\n",
            "Best model {'weight_constraint': 1, 'nodes': 80, 'learn_rate': 0.0001, 'init_mode': 'glorot_uniform', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.4, 'batch_size': 20, 'act_func': 'relu'} with PR_AUC of 0.19970912317141393\n",
            "0.1905770265717395 (0.028339059560505562) with: {'weight_constraint': 4, 'nodes': 80, 'learn_rate': 0.01, 'init_mode': 'he_normal', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.16090430078568255 (0.028203087753878874) with: {'weight_constraint': 3, 'nodes': 160, 'learn_rate': 0.1, 'init_mode': 'lecun_uniform', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.0, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.14007978270357058 (0.010898622419491773) with: {'weight_constraint': 1, 'nodes': 240, 'learn_rate': 0.0001, 'init_mode': 'he_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.4, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.07840377953325674 (0.006666703563114997) with: {'weight_constraint': 5, 'nodes': 180, 'learn_rate': 0.1, 'init_mode': 'he_uniform', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.6000000000000001, 'batch_size': 80, 'act_func': 'relu'}\n",
            "0.13295236859047438 (0.033284624481427036) with: {'weight_constraint': 2, 'nodes': 200, 'learn_rate': 0.1, 'init_mode': 'uniform', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.2, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.17647888457631794 (0.017541679970667707) with: {'weight_constraint': 4, 'nodes': 160, 'learn_rate': 0.0001, 'init_mode': 'normal', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.4, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.1494321034443818 (0.017317212188489094) with: {'weight_constraint': 3, 'nodes': 60, 'learn_rate': 0.0001, 'init_mode': 'glorot_uniform', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.4, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.19038802485046324 (0.027883786789434657) with: {'weight_constraint': 1, 'nodes': 100, 'learn_rate': 0.01, 'init_mode': 'lecun_uniform', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.1, 'batch_size': 40, 'act_func': 'linear'}\n",
            "0.19128436305028793 (0.03298880633819719) with: {'weight_constraint': 3, 'nodes': 140, 'learn_rate': 0.0001, 'init_mode': 'uniform', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.0, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.1793663244687445 (0.016410693997224075) with: {'weight_constraint': 2, 'nodes': 120, 'learn_rate': 0.0001, 'init_mode': 'glorot_uniform', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.2, 'batch_size': 80, 'act_func': 'relu'}\n",
            "0.1505949046234508 (0.013910915774197886) with: {'weight_constraint': 1, 'nodes': 120, 'learn_rate': 0.001, 'init_mode': 'he_normal', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.8, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.18542300572477124 (0.030497064203451732) with: {'weight_constraint': 1, 'nodes': 100, 'learn_rate': 0.01, 'init_mode': 'uniform', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.2, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.15596328182562078 (0.022720420977709342) with: {'weight_constraint': 5, 'nodes': 180, 'learn_rate': 0.0001, 'init_mode': 'lecun_uniform', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.5, 'batch_size': 80, 'act_func': 'relu'}\n",
            "0.17441584853874526 (0.027330295964127973) with: {'weight_constraint': 5, 'nodes': 200, 'learn_rate': 0.1, 'init_mode': 'glorot_uniform', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.0, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.19194127383635215 (0.03818921182552397) with: {'weight_constraint': 5, 'nodes': 120, 'learn_rate': 0.0001, 'init_mode': 'he_uniform', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.1, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.18868084082482223 (0.02612118766883034) with: {'weight_constraint': 1, 'nodes': 200, 'learn_rate': 0.01, 'init_mode': 'lecun_uniform', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.30000000000000004, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.12043300227091469 (0.029874453960071143) with: {'weight_constraint': 3, 'nodes': 160, 'learn_rate': 0.1, 'init_mode': 'he_uniform', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.9, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.13604973831601733 (0.011521024918562385) with: {'weight_constraint': 3, 'nodes': 200, 'learn_rate': 0.001, 'init_mode': 'uniform', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.0, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.1882591303694197 (0.033461234766932066) with: {'weight_constraint': 2, 'nodes': 240, 'learn_rate': 0.1, 'init_mode': 'lecun_uniform', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.1, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.18178809876000684 (0.017345666457603607) with: {'weight_constraint': 5, 'nodes': 240, 'learn_rate': 0.01, 'init_mode': 'uniform', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.7000000000000001, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.1790728992536439 (0.023831645293771683) with: {'weight_constraint': 2, 'nodes': 240, 'learn_rate': 0.001, 'init_mode': 'he_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.7000000000000001, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.11942174696235386 (0.020912206902173717) with: {'weight_constraint': 3, 'nodes': 160, 'learn_rate': 0.01, 'init_mode': 'he_normal', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.9, 'batch_size': 10, 'act_func': 'relu'}\n",
            "0.1779010337657017 (0.01879599548192465) with: {'weight_constraint': 3, 'nodes': 100, 'learn_rate': 0.01, 'init_mode': 'he_uniform', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.6000000000000001, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.10912280206459705 (0.016036166305153345) with: {'weight_constraint': 3, 'nodes': 220, 'learn_rate': 0.1, 'init_mode': 'he_normal', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.16720047998567258 (0.0168527955179595) with: {'weight_constraint': 2, 'nodes': 200, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.7000000000000001, 'batch_size': 40, 'act_func': 'linear'}\n",
            "0.19081183914312566 (0.028115084036521975) with: {'weight_constraint': 5, 'nodes': 180, 'learn_rate': 0.0001, 'init_mode': 'he_normal', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.1, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.1536022506921393 (0.010291216381151233) with: {'weight_constraint': 1, 'nodes': 120, 'learn_rate': 0.0001, 'init_mode': 'he_normal', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.16992691517141306 (0.015617527553829093) with: {'weight_constraint': 1, 'nodes': 100, 'learn_rate': 0.0001, 'init_mode': 'he_uniform', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.8, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.16142989807612934 (0.013413655175254717) with: {'weight_constraint': 1, 'nodes': 200, 'learn_rate': 0.001, 'init_mode': 'normal', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.8, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.18110211895803105 (0.029708590014466133) with: {'weight_constraint': 4, 'nodes': 60, 'learn_rate': 0.1, 'init_mode': 'lecun_uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.30000000000000004, 'batch_size': 40, 'act_func': 'linear'}\n",
            "0.17198471403638077 (0.013499109280892154) with: {'weight_constraint': 2, 'nodes': 240, 'learn_rate': 0.001, 'init_mode': 'he_normal', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.18939737099215184 (0.03116896664621638) with: {'weight_constraint': 4, 'nodes': 140, 'learn_rate': 0.001, 'init_mode': 'normal', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.0, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.14240428189019796 (0.024526095061900188) with: {'weight_constraint': 5, 'nodes': 220, 'learn_rate': 0.1, 'init_mode': 'uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.7000000000000001, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.12885667910555745 (0.021070314988989796) with: {'weight_constraint': 3, 'nodes': 100, 'learn_rate': 0.1, 'init_mode': 'normal', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.9, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.1569267288982653 (0.01374382889962789) with: {'weight_constraint': 4, 'nodes': 100, 'learn_rate': 0.0001, 'init_mode': 'uniform', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.1, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.18109343211968032 (0.02864026775095853) with: {'weight_constraint': 1, 'nodes': 80, 'learn_rate': 0.01, 'init_mode': 'lecun_uniform', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.6000000000000001, 'batch_size': 10, 'act_func': 'sigmoid'}\n",
            "0.18816411277127246 (0.032268213830169167) with: {'weight_constraint': 1, 'nodes': 60, 'learn_rate': 0.001, 'init_mode': 'he_uniform', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.2, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.1855192810824455 (0.02793700273771209) with: {'weight_constraint': 2, 'nodes': 80, 'learn_rate': 0.0001, 'init_mode': 'lecun_uniform', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.2, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.18546740643115023 (0.02751660711140205) with: {'weight_constraint': 2, 'nodes': 140, 'learn_rate': 0.01, 'init_mode': 'glorot_normal', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.2, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.1873963115571813 (0.028050529368925707) with: {'weight_constraint': 3, 'nodes': 220, 'learn_rate': 0.01, 'init_mode': 'glorot_normal', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.1, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.1916209104100846 (0.034947497445015144) with: {'weight_constraint': 3, 'nodes': 240, 'learn_rate': 0.01, 'init_mode': 'uniform', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.4, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.17375844719907124 (0.0251782739292317) with: {'weight_constraint': 5, 'nodes': 200, 'learn_rate': 0.01, 'init_mode': 'he_normal', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.5, 'batch_size': 80, 'act_func': 'relu'}\n",
            "0.12899169814933314 (0.03040888147826789) with: {'weight_constraint': 2, 'nodes': 200, 'learn_rate': 0.1, 'init_mode': 'uniform', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.9, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.18368784846388747 (0.029611252648606225) with: {'weight_constraint': 1, 'nodes': 160, 'learn_rate': 0.001, 'init_mode': 'normal', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.2, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.18147501221745066 (0.020436906894699212) with: {'weight_constraint': 5, 'nodes': 220, 'learn_rate': 0.0001, 'init_mode': 'lecun_uniform', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.7000000000000001, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.19377796609756712 (0.029473202058765743) with: {'weight_constraint': 2, 'nodes': 180, 'learn_rate': 0.01, 'init_mode': 'lecun_uniform', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.6000000000000001, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.15930437989462382 (0.01978564633233764) with: {'weight_constraint': 1, 'nodes': 140, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.8, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.16211438877882528 (0.021210169315852317) with: {'weight_constraint': 4, 'nodes': 200, 'learn_rate': 0.0001, 'init_mode': 'he_normal', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.6000000000000001, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.18637873875961133 (0.021495733479163174) with: {'weight_constraint': 1, 'nodes': 60, 'learn_rate': 0.001, 'init_mode': 'he_uniform', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.7000000000000001, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.1652281983990864 (0.01799940668723198) with: {'weight_constraint': 3, 'nodes': 120, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.2, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.18393024237316274 (0.025181904845385784) with: {'weight_constraint': 4, 'nodes': 100, 'learn_rate': 0.01, 'init_mode': 'normal', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.30000000000000004, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.18600872373656055 (0.026588699965607806) with: {'weight_constraint': 1, 'nodes': 240, 'learn_rate': 0.01, 'init_mode': 'glorot_normal', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.7000000000000001, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.17757586622115923 (0.020767374659566268) with: {'weight_constraint': 4, 'nodes': 120, 'learn_rate': 0.01, 'init_mode': 'normal', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.0, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.18789518064569022 (0.029908643172333615) with: {'weight_constraint': 3, 'nodes': 120, 'learn_rate': 0.001, 'init_mode': 'uniform', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.1, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.1710062006947225 (0.01574518686522821) with: {'weight_constraint': 5, 'nodes': 120, 'learn_rate': 0.1, 'init_mode': 'he_uniform', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.0, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.09648834677883582 (0.009857767070768209) with: {'weight_constraint': 4, 'nodes': 240, 'learn_rate': 0.1, 'init_mode': 'he_uniform', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.30000000000000004, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.18752591659286197 (0.02664280264212671) with: {'weight_constraint': 4, 'nodes': 120, 'learn_rate': 0.01, 'init_mode': 'uniform', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.30000000000000004, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.17070938287236917 (0.022648527636428984) with: {'weight_constraint': 3, 'nodes': 220, 'learn_rate': 0.1, 'init_mode': 'lecun_uniform', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.5, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.1739165047436481 (0.020367734710794592) with: {'weight_constraint': 4, 'nodes': 240, 'learn_rate': 0.01, 'init_mode': 'he_normal', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.2, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.18797581368033425 (0.031195092130767675) with: {'weight_constraint': 5, 'nodes': 140, 'learn_rate': 0.01, 'init_mode': 'glorot_normal', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.4, 'batch_size': 10, 'act_func': 'relu'}\n",
            "0.15522306522926957 (0.015592210839613395) with: {'weight_constraint': 4, 'nodes': 200, 'learn_rate': 0.0001, 'init_mode': 'he_normal', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.9, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.18782836896294375 (0.03123975263941365) with: {'weight_constraint': 3, 'nodes': 100, 'learn_rate': 0.01, 'init_mode': 'lecun_uniform', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.1, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.16856175015249308 (0.024494999647835913) with: {'weight_constraint': 1, 'nodes': 80, 'learn_rate': 0.01, 'init_mode': 'glorot_normal', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.9, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.0808164539859007 (0.01015086878488889) with: {'weight_constraint': 3, 'nodes': 120, 'learn_rate': 0.1, 'init_mode': 'glorot_normal', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.6000000000000001, 'batch_size': 80, 'act_func': 'relu'}\n",
            "0.15899133552583478 (0.02963015385603174) with: {'weight_constraint': 4, 'nodes': 160, 'learn_rate': 0.1, 'init_mode': 'lecun_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.4, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.1694079765623397 (0.02597088883525339) with: {'weight_constraint': 3, 'nodes': 60, 'learn_rate': 0.01, 'init_mode': 'normal', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.9, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.16401649402643198 (0.03415786742258396) with: {'weight_constraint': 5, 'nodes': 120, 'learn_rate': 0.1, 'init_mode': 'glorot_uniform', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.30000000000000004, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.13729910146724947 (0.03616654354703347) with: {'weight_constraint': 3, 'nodes': 160, 'learn_rate': 0.1, 'init_mode': 'lecun_uniform', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.5, 'batch_size': 10, 'act_func': 'sigmoid'}\n",
            "0.182394810139603 (0.023441471703038935) with: {'weight_constraint': 2, 'nodes': 60, 'learn_rate': 0.0001, 'init_mode': 'he_normal', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.4, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.18621064473761184 (0.031010414364794528) with: {'weight_constraint': 1, 'nodes': 120, 'learn_rate': 0.01, 'init_mode': 'glorot_uniform', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.9, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.15444129226741737 (0.018738292909408465) with: {'weight_constraint': 3, 'nodes': 160, 'learn_rate': 0.1, 'init_mode': 'he_uniform', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.8, 'batch_size': 10, 'act_func': 'sigmoid'}\n",
            "0.16726300806347255 (0.02887503595545689) with: {'weight_constraint': 1, 'nodes': 60, 'learn_rate': 0.1, 'init_mode': 'normal', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.9, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.1880917414107756 (0.030110186032584564) with: {'weight_constraint': 3, 'nodes': 80, 'learn_rate': 0.0001, 'init_mode': 'lecun_uniform', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.6000000000000001, 'batch_size': 10, 'act_func': 'relu'}\n",
            "0.16194217342696474 (0.04381633301152723) with: {'weight_constraint': 1, 'nodes': 160, 'learn_rate': 0.01, 'init_mode': 'he_normal', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.4, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.18882701969442717 (0.030753871244595065) with: {'weight_constraint': 5, 'nodes': 160, 'learn_rate': 0.0001, 'init_mode': 'glorot_uniform', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.1, 'batch_size': 10, 'act_func': 'sigmoid'}\n",
            "0.13330595519988614 (0.017734258573459286) with: {'weight_constraint': 1, 'nodes': 160, 'learn_rate': 0.0001, 'init_mode': 'he_uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.0, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.16943334677951247 (0.010612501626820457) with: {'weight_constraint': 4, 'nodes': 180, 'learn_rate': 0.0001, 'init_mode': 'lecun_uniform', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.4, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.18948256791392062 (0.027974942369424778) with: {'weight_constraint': 4, 'nodes': 160, 'learn_rate': 0.01, 'init_mode': 'glorot_uniform', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.13685870859662091 (0.009617851649919068) with: {'weight_constraint': 5, 'nodes': 60, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.8, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.1109556456328658 (0.05256909007413437) with: {'weight_constraint': 2, 'nodes': 80, 'learn_rate': 0.1, 'init_mode': 'lecun_uniform', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.7000000000000001, 'batch_size': 10, 'act_func': 'sigmoid'}\n",
            "0.1940843465980055 (0.03126741847381052) with: {'weight_constraint': 4, 'nodes': 60, 'learn_rate': 0.01, 'init_mode': 'he_uniform', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.7000000000000001, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.187437675840809 (0.024344121157337053) with: {'weight_constraint': 1, 'nodes': 160, 'learn_rate': 0.01, 'init_mode': 'normal', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.5, 'batch_size': 80, 'act_func': 'relu'}\n",
            "0.18215631254827586 (0.032641780707095135) with: {'weight_constraint': 1, 'nodes': 160, 'learn_rate': 0.01, 'init_mode': 'lecun_uniform', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.30000000000000004, 'batch_size': 40, 'act_func': 'linear'}\n",
            "0.18626366889300405 (0.024640745342941337) with: {'weight_constraint': 5, 'nodes': 160, 'learn_rate': 0.0001, 'init_mode': 'glorot_uniform', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.4, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.18684297539931904 (0.024763584065620466) with: {'weight_constraint': 3, 'nodes': 240, 'learn_rate': 0.001, 'init_mode': 'he_normal', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.0, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.16749146106541654 (0.020324156663390505) with: {'weight_constraint': 2, 'nodes': 80, 'learn_rate': 0.0001, 'init_mode': 'glorot_uniform', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.30000000000000004, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.1920774255213275 (0.027823830158274044) with: {'weight_constraint': 1, 'nodes': 140, 'learn_rate': 0.0001, 'init_mode': 'lecun_uniform', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.7000000000000001, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.1916742625566231 (0.03428483045529385) with: {'weight_constraint': 5, 'nodes': 80, 'learn_rate': 0.01, 'init_mode': 'normal', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.5, 'batch_size': 40, 'act_func': 'linear'}\n",
            "0.18888199951833234 (0.030055066978775323) with: {'weight_constraint': 1, 'nodes': 200, 'learn_rate': 0.001, 'init_mode': 'uniform', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.9, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.18108609164643236 (0.02073069929102549) with: {'weight_constraint': 5, 'nodes': 120, 'learn_rate': 0.0001, 'init_mode': 'he_normal', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.0, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.17450315509320657 (0.02428269073629037) with: {'weight_constraint': 1, 'nodes': 240, 'learn_rate': 0.001, 'init_mode': 'normal', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.1, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.13307159856529932 (0.026343188713910275) with: {'weight_constraint': 1, 'nodes': 100, 'learn_rate': 0.0001, 'init_mode': 'lecun_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.2, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.1729875311460472 (0.03598364396745364) with: {'weight_constraint': 5, 'nodes': 240, 'learn_rate': 0.1, 'init_mode': 'normal', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.1, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.1508368842099785 (0.012633828928511611) with: {'weight_constraint': 5, 'nodes': 140, 'learn_rate': 0.0001, 'init_mode': 'glorot_uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.2, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.18969595047083646 (0.02918195890128353) with: {'weight_constraint': 2, 'nodes': 180, 'learn_rate': 0.001, 'init_mode': 'glorot_normal', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.6000000000000001, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.18496706011768507 (0.0258204679052022) with: {'weight_constraint': 2, 'nodes': 100, 'learn_rate': 0.001, 'init_mode': 'glorot_uniform', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.4, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.1821346943235544 (0.02306126474546044) with: {'weight_constraint': 1, 'nodes': 140, 'learn_rate': 0.001, 'init_mode': 'normal', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.13900665687196043 (0.04103108602041703) with: {'weight_constraint': 3, 'nodes': 220, 'learn_rate': 0.1, 'init_mode': 'glorot_uniform', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.7000000000000001, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.19450772054760881 (0.028608971177504074) with: {'weight_constraint': 1, 'nodes': 80, 'learn_rate': 0.001, 'init_mode': 'normal', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.5, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.1856872054479059 (0.019906568249184506) with: {'weight_constraint': 2, 'nodes': 200, 'learn_rate': 0.01, 'init_mode': 'he_normal', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.4, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.188240887128618 (0.03207335315257608) with: {'weight_constraint': 4, 'nodes': 160, 'learn_rate': 0.001, 'init_mode': 'glorot_uniform', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.6000000000000001, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.170381916594744 (0.02018815186401043) with: {'weight_constraint': 5, 'nodes': 120, 'learn_rate': 0.0001, 'init_mode': 'he_uniform', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.7000000000000001, 'batch_size': 10, 'act_func': 'relu'}\n",
            "0.17380585177432653 (0.027552706522698103) with: {'weight_constraint': 1, 'nodes': 60, 'learn_rate': 0.01, 'init_mode': 'he_uniform', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.9, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.15532690781402173 (0.03832805056547888) with: {'weight_constraint': 4, 'nodes': 220, 'learn_rate': 0.1, 'init_mode': 'he_normal', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.0, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.18735936122309865 (0.02695118964765342) with: {'weight_constraint': 5, 'nodes': 80, 'learn_rate': 0.001, 'init_mode': 'glorot_uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.4, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.11559058336696237 (0.03921001499886148) with: {'weight_constraint': 2, 'nodes': 160, 'learn_rate': 0.1, 'init_mode': 'glorot_uniform', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.5, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.19013548777888906 (0.024505472025195665) with: {'weight_constraint': 4, 'nodes': 160, 'learn_rate': 0.01, 'init_mode': 'normal', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.0, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.19185558360350846 (0.029729614919739734) with: {'weight_constraint': 1, 'nodes': 200, 'learn_rate': 0.001, 'init_mode': 'glorot_uniform', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.1, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.13168941280845356 (0.03622163509251583) with: {'weight_constraint': 4, 'nodes': 180, 'learn_rate': 0.1, 'init_mode': 'glorot_uniform', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.8, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.17046061932126505 (0.019438780450945152) with: {'weight_constraint': 4, 'nodes': 200, 'learn_rate': 0.0001, 'init_mode': 'normal', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.6000000000000001, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.17779017629577096 (0.017750509450799406) with: {'weight_constraint': 4, 'nodes': 160, 'learn_rate': 0.01, 'init_mode': 'lecun_uniform', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.6000000000000001, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.17955649138775023 (0.02287413512177649) with: {'weight_constraint': 4, 'nodes': 120, 'learn_rate': 0.1, 'init_mode': 'glorot_uniform', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.1, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.17180036545657315 (0.020947820451930197) with: {'weight_constraint': 5, 'nodes': 100, 'learn_rate': 0.01, 'init_mode': 'he_normal', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.30000000000000004, 'batch_size': 80, 'act_func': 'relu'}\n",
            "0.14786911507414038 (0.011601221290937155) with: {'weight_constraint': 3, 'nodes': 180, 'learn_rate': 0.0001, 'init_mode': 'normal', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.4, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.1773287026448939 (0.02261096841855875) with: {'weight_constraint': 2, 'nodes': 180, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.8, 'batch_size': 10, 'act_func': 'relu'}\n",
            "0.18779227337401236 (0.026317771991949058) with: {'weight_constraint': 5, 'nodes': 80, 'learn_rate': 0.1, 'init_mode': 'he_normal', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.2, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.175122335577892 (0.016544027841832648) with: {'weight_constraint': 4, 'nodes': 100, 'learn_rate': 0.0001, 'init_mode': 'he_uniform', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.17748445896981802 (0.02216012210139758) with: {'weight_constraint': 5, 'nodes': 140, 'learn_rate': 0.01, 'init_mode': 'he_uniform', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.1, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.1886003686107522 (0.025727962032982256) with: {'weight_constraint': 3, 'nodes': 240, 'learn_rate': 0.001, 'init_mode': 'he_normal', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.6000000000000001, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.1863764631810752 (0.02680404617331167) with: {'weight_constraint': 4, 'nodes': 180, 'learn_rate': 0.01, 'init_mode': 'he_uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.8, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.18132877361015745 (0.017417113658826536) with: {'weight_constraint': 3, 'nodes': 60, 'learn_rate': 0.01, 'init_mode': 'he_normal', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.2, 'batch_size': 10, 'act_func': 'sigmoid'}\n",
            "0.09788944435688815 (0.018049879570729288) with: {'weight_constraint': 4, 'nodes': 240, 'learn_rate': 0.1, 'init_mode': 'glorot_normal', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.6000000000000001, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.15040283322261427 (0.010031699862367353) with: {'weight_constraint': 4, 'nodes': 220, 'learn_rate': 0.001, 'init_mode': 'glorot_normal', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.8, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.18902619006997315 (0.019698674559882123) with: {'weight_constraint': 1, 'nodes': 200, 'learn_rate': 0.001, 'init_mode': 'he_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.4, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.18538677160640366 (0.020303182283311183) with: {'weight_constraint': 4, 'nodes': 200, 'learn_rate': 0.001, 'init_mode': 'he_uniform', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.1, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.1255724031363092 (0.021670699775187808) with: {'weight_constraint': 4, 'nodes': 160, 'learn_rate': 0.1, 'init_mode': 'he_uniform', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.4, 'batch_size': 40, 'act_func': 'linear'}\n",
            "0.18800657393529915 (0.03166021166999123) with: {'weight_constraint': 2, 'nodes': 60, 'learn_rate': 0.01, 'init_mode': 'he_normal', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.9, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.12756137201718307 (0.016739730956179207) with: {'weight_constraint': 4, 'nodes': 80, 'learn_rate': 0.1, 'init_mode': 'normal', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.19070701082345878 (0.028245006749838052) with: {'weight_constraint': 3, 'nodes': 240, 'learn_rate': 0.001, 'init_mode': 'lecun_uniform', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.4, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.1897715573755744 (0.02892463828306043) with: {'weight_constraint': 5, 'nodes': 80, 'learn_rate': 0.01, 'init_mode': 'he_uniform', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.1, 'batch_size': 40, 'act_func': 'linear'}\n",
            "0.1767638036614249 (0.0175737985133426) with: {'weight_constraint': 3, 'nodes': 220, 'learn_rate': 0.01, 'init_mode': 'he_normal', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.30000000000000004, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.1901738833282937 (0.02714551475944436) with: {'weight_constraint': 4, 'nodes': 120, 'learn_rate': 0.01, 'init_mode': 'he_normal', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.30000000000000004, 'batch_size': 80, 'act_func': 'relu'}\n",
            "0.17777546571203443 (0.03104685554284423) with: {'weight_constraint': 4, 'nodes': 140, 'learn_rate': 0.01, 'init_mode': 'uniform', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.1, 'batch_size': 10, 'act_func': 'sigmoid'}\n",
            "0.19132292310421703 (0.030427400442911208) with: {'weight_constraint': 3, 'nodes': 160, 'learn_rate': 0.001, 'init_mode': 'uniform', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.8, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.1808136296071847 (0.0280585246393613) with: {'weight_constraint': 1, 'nodes': 140, 'learn_rate': 0.01, 'init_mode': 'he_uniform', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.1, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.18716108561859915 (0.025388345751459897) with: {'weight_constraint': 2, 'nodes': 100, 'learn_rate': 0.01, 'init_mode': 'he_uniform', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.4, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.19201483541028064 (0.02713497868875932) with: {'weight_constraint': 4, 'nodes': 160, 'learn_rate': 0.0001, 'init_mode': 'he_uniform', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.1, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.1735244523769508 (0.023233273079272518) with: {'weight_constraint': 5, 'nodes': 140, 'learn_rate': 0.1, 'init_mode': 'normal', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.7000000000000001, 'batch_size': 40, 'act_func': 'linear'}\n",
            "0.18416999678217474 (0.028874972694992222) with: {'weight_constraint': 5, 'nodes': 220, 'learn_rate': 0.001, 'init_mode': 'he_uniform', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.6000000000000001, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.17341433199436868 (0.029942955762679288) with: {'weight_constraint': 3, 'nodes': 160, 'learn_rate': 0.01, 'init_mode': 'lecun_uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.4, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.1763517341446364 (0.018128007309889494) with: {'weight_constraint': 4, 'nodes': 120, 'learn_rate': 0.1, 'init_mode': 'he_uniform', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.7000000000000001, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.19304087752961327 (0.027759899052908665) with: {'weight_constraint': 2, 'nodes': 240, 'learn_rate': 0.01, 'init_mode': 'lecun_uniform', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.30000000000000004, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.19062052821900105 (0.020905043202778747) with: {'weight_constraint': 3, 'nodes': 200, 'learn_rate': 0.01, 'init_mode': 'lecun_uniform', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.2, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.18263069187741665 (0.026881420035157005) with: {'weight_constraint': 5, 'nodes': 180, 'learn_rate': 0.01, 'init_mode': 'uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.7000000000000001, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.16542835099868358 (0.014563758938653236) with: {'weight_constraint': 1, 'nodes': 100, 'learn_rate': 0.001, 'init_mode': 'glorot_normal', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.7000000000000001, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.1727500734897977 (0.019248190977914845) with: {'weight_constraint': 3, 'nodes': 120, 'learn_rate': 0.1, 'init_mode': 'he_normal', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.0, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.14758241981231943 (0.034690521862052376) with: {'weight_constraint': 4, 'nodes': 140, 'learn_rate': 0.1, 'init_mode': 'glorot_normal', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.0, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.190823907670533 (0.03366001749095938) with: {'weight_constraint': 2, 'nodes': 80, 'learn_rate': 0.0001, 'init_mode': 'he_normal', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.0, 'batch_size': 10, 'act_func': 'relu'}\n",
            "0.1347594065675185 (0.04073051235373245) with: {'weight_constraint': 2, 'nodes': 180, 'learn_rate': 0.1, 'init_mode': 'uniform', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.4, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.1822354418916902 (0.020239737932067597) with: {'weight_constraint': 1, 'nodes': 120, 'learn_rate': 0.001, 'init_mode': 'glorot_uniform', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.6000000000000001, 'batch_size': 10, 'act_func': 'relu'}\n",
            "0.18416740906226234 (0.03290251855224973) with: {'weight_constraint': 3, 'nodes': 200, 'learn_rate': 0.01, 'init_mode': 'he_uniform', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.1, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.15787791638452087 (0.019690911070060442) with: {'weight_constraint': 3, 'nodes': 80, 'learn_rate': 0.1, 'init_mode': 'he_uniform', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.8, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.1736749748532852 (0.022869065289948354) with: {'weight_constraint': 5, 'nodes': 120, 'learn_rate': 0.001, 'init_mode': 'he_uniform', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.9, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.19016776562814885 (0.03133479160491362) with: {'weight_constraint': 3, 'nodes': 200, 'learn_rate': 0.0001, 'init_mode': 'uniform', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.30000000000000004, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.18493523784150234 (0.02681702131440879) with: {'weight_constraint': 4, 'nodes': 100, 'learn_rate': 0.001, 'init_mode': 'he_uniform', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.9, 'batch_size': 10, 'act_func': 'relu'}\n",
            "0.16924291419856458 (0.02544714528414826) with: {'weight_constraint': 2, 'nodes': 200, 'learn_rate': 0.01, 'init_mode': 'uniform', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.6000000000000001, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.17569346202428388 (0.02202224709516916) with: {'weight_constraint': 1, 'nodes': 220, 'learn_rate': 0.01, 'init_mode': 'lecun_uniform', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.6000000000000001, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.14825154031824445 (0.036968105254068295) with: {'weight_constraint': 2, 'nodes': 120, 'learn_rate': 0.1, 'init_mode': 'glorot_uniform', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.0, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.19275453234841428 (0.0314764247530028) with: {'weight_constraint': 1, 'nodes': 140, 'learn_rate': 0.0001, 'init_mode': 'normal', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.6000000000000001, 'batch_size': 80, 'act_func': 'relu'}\n",
            "0.12744305065480704 (0.016880532572424473) with: {'weight_constraint': 5, 'nodes': 80, 'learn_rate': 0.0001, 'init_mode': 'he_normal', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.0, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.19227745922532508 (0.03161983213117699) with: {'weight_constraint': 3, 'nodes': 120, 'learn_rate': 0.01, 'init_mode': 'uniform', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.6000000000000001, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.1177135767350942 (0.027022416794122418) with: {'weight_constraint': 1, 'nodes': 240, 'learn_rate': 0.1, 'init_mode': 'uniform', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.6000000000000001, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.06502634793772488 (0.028516659350744735) with: {'weight_constraint': 1, 'nodes': 140, 'learn_rate': 0.1, 'init_mode': 'he_normal', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.18619873417261035 (0.03384769386029652) with: {'weight_constraint': 2, 'nodes': 180, 'learn_rate': 0.01, 'init_mode': 'uniform', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.2, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.18122958949029594 (0.026400639211771933) with: {'weight_constraint': 3, 'nodes': 60, 'learn_rate': 0.0001, 'init_mode': 'normal', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.7000000000000001, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.17699156304698443 (0.020181920766989794) with: {'weight_constraint': 5, 'nodes': 220, 'learn_rate': 0.0001, 'init_mode': 'he_normal', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.6000000000000001, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.18963523434419252 (0.02487266617191617) with: {'weight_constraint': 3, 'nodes': 100, 'learn_rate': 0.1, 'init_mode': 'lecun_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.30000000000000004, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.17106789646990975 (0.021824496259866634) with: {'weight_constraint': 2, 'nodes': 160, 'learn_rate': 0.1, 'init_mode': 'he_uniform', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.30000000000000004, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.1393941478256901 (0.014064761707154363) with: {'weight_constraint': 4, 'nodes': 140, 'learn_rate': 0.0001, 'init_mode': 'he_uniform', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.4, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.18720188777815136 (0.0324141421520734) with: {'weight_constraint': 5, 'nodes': 200, 'learn_rate': 0.001, 'init_mode': 'uniform', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.6000000000000001, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.18360495478598132 (0.027102809740424068) with: {'weight_constraint': 5, 'nodes': 60, 'learn_rate': 0.0001, 'init_mode': 'glorot_uniform', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.2, 'batch_size': 10, 'act_func': 'sigmoid'}\n",
            "0.18704542885008651 (0.021937756977503) with: {'weight_constraint': 3, 'nodes': 180, 'learn_rate': 0.01, 'init_mode': 'he_normal', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.1, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.18077567260486227 (0.022009695644279913) with: {'weight_constraint': 5, 'nodes': 100, 'learn_rate': 0.001, 'init_mode': 'uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.9, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.14618354974509104 (0.037625066176651074) with: {'weight_constraint': 5, 'nodes': 120, 'learn_rate': 0.1, 'init_mode': 'he_normal', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.7000000000000001, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.1844147057850361 (0.026329133460950695) with: {'weight_constraint': 1, 'nodes': 160, 'learn_rate': 0.01, 'init_mode': 'normal', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.8, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.19156394055460718 (0.033607670229145625) with: {'weight_constraint': 1, 'nodes': 100, 'learn_rate': 0.01, 'init_mode': 'glorot_uniform', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.4, 'batch_size': 40, 'act_func': 'linear'}\n",
            "0.1855957915417224 (0.027064299700102254) with: {'weight_constraint': 1, 'nodes': 60, 'learn_rate': 0.01, 'init_mode': 'lecun_uniform', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.9, 'batch_size': 80, 'act_func': 'relu'}\n",
            "0.1877766546668342 (0.031062224088194923) with: {'weight_constraint': 2, 'nodes': 80, 'learn_rate': 0.001, 'init_mode': 'glorot_normal', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.5, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.18878827606107854 (0.02453227528032787) with: {'weight_constraint': 5, 'nodes': 200, 'learn_rate': 0.001, 'init_mode': 'glorot_uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.7000000000000001, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.1788702546694516 (0.019598492260240925) with: {'weight_constraint': 4, 'nodes': 160, 'learn_rate': 0.01, 'init_mode': 'he_normal', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.15699798221073155 (0.014266200117135594) with: {'weight_constraint': 5, 'nodes': 80, 'learn_rate': 0.0001, 'init_mode': 'normal', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.7000000000000001, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.13921870937228545 (0.009813886251441365) with: {'weight_constraint': 5, 'nodes': 80, 'learn_rate': 0.0001, 'init_mode': 'normal', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.1, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.13657220296714637 (0.011027891978965096) with: {'weight_constraint': 2, 'nodes': 120, 'learn_rate': 0.0001, 'init_mode': 'uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.1855272705787427 (0.025406958025830335) with: {'weight_constraint': 4, 'nodes': 160, 'learn_rate': 0.01, 'init_mode': 'glorot_normal', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.4, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.1935749176481023 (0.025885682841515798) with: {'weight_constraint': 1, 'nodes': 220, 'learn_rate': 0.001, 'init_mode': 'lecun_uniform', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.4, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.17595378828299219 (0.019882537107709892) with: {'weight_constraint': 3, 'nodes': 180, 'learn_rate': 0.0001, 'init_mode': 'glorot_uniform', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.1902477764512563 (0.03264625535936777) with: {'weight_constraint': 1, 'nodes': 60, 'learn_rate': 0.0001, 'init_mode': 'he_uniform', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.1, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.17512386013885553 (0.026863258462087453) with: {'weight_constraint': 2, 'nodes': 160, 'learn_rate': 0.1, 'init_mode': 'normal', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.1886219702487814 (0.025845768373278424) with: {'weight_constraint': 1, 'nodes': 120, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.5, 'batch_size': 80, 'act_func': 'relu'}\n",
            "0.1717371822599206 (0.01863611815693149) with: {'weight_constraint': 4, 'nodes': 100, 'learn_rate': 0.01, 'init_mode': 'he_uniform', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.0, 'batch_size': 10, 'act_func': 'sigmoid'}\n",
            "0.1880488704350282 (0.03031369468214732) with: {'weight_constraint': 5, 'nodes': 80, 'learn_rate': 0.01, 'init_mode': 'glorot_uniform', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.6000000000000001, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.07254735154808607 (0.01827025492711018) with: {'weight_constraint': 5, 'nodes': 160, 'learn_rate': 0.1, 'init_mode': 'he_uniform', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.9, 'batch_size': 80, 'act_func': 'relu'}\n",
            "0.17963794250920667 (0.01965824646658642) with: {'weight_constraint': 3, 'nodes': 80, 'learn_rate': 0.001, 'init_mode': 'he_normal', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.1, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.17111314979379014 (0.01770852736435597) with: {'weight_constraint': 1, 'nodes': 160, 'learn_rate': 0.001, 'init_mode': 'glorot_normal', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.0, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.1904695730873312 (0.02848472405411599) with: {'weight_constraint': 2, 'nodes': 60, 'learn_rate': 0.0001, 'init_mode': 'he_normal', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.2, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.15810099242602701 (0.026473333592017003) with: {'weight_constraint': 4, 'nodes': 140, 'learn_rate': 0.1, 'init_mode': 'glorot_normal', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.4, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.19200062879315166 (0.033695524802304144) with: {'weight_constraint': 3, 'nodes': 180, 'learn_rate': 0.0001, 'init_mode': 'uniform', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.18176982560624064 (0.029805270909117138) with: {'weight_constraint': 5, 'nodes': 60, 'learn_rate': 0.1, 'init_mode': 'normal', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.30000000000000004, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.18657068295215495 (0.03260228892648028) with: {'weight_constraint': 2, 'nodes': 200, 'learn_rate': 0.0001, 'init_mode': 'he_uniform', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.1, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.18929781651674288 (0.028949441446023245) with: {'weight_constraint': 1, 'nodes': 200, 'learn_rate': 0.001, 'init_mode': 'he_normal', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.7000000000000001, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.19267454115752658 (0.02766339075321519) with: {'weight_constraint': 1, 'nodes': 60, 'learn_rate': 0.01, 'init_mode': 'normal', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.30000000000000004, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.18261114872335954 (0.03350475622021731) with: {'weight_constraint': 5, 'nodes': 160, 'learn_rate': 0.001, 'init_mode': 'normal', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.6000000000000001, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.19378978936574193 (0.030035851442319284) with: {'weight_constraint': 3, 'nodes': 80, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.2, 'batch_size': 10, 'act_func': 'relu'}\n",
            "0.18745093746225033 (0.03627840450569088) with: {'weight_constraint': 4, 'nodes': 100, 'learn_rate': 0.001, 'init_mode': 'glorot_uniform', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.2, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.19380199504838858 (0.0337424604186373) with: {'weight_constraint': 3, 'nodes': 180, 'learn_rate': 0.001, 'init_mode': 'glorot_uniform', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.4, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.1924288150134041 (0.03376620876762124) with: {'weight_constraint': 2, 'nodes': 60, 'learn_rate': 0.01, 'init_mode': 'glorot_normal', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.4, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.18302473760456062 (0.02800300912297314) with: {'weight_constraint': 1, 'nodes': 200, 'learn_rate': 0.01, 'init_mode': 'lecun_uniform', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.7000000000000001, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.13694772659044196 (0.012376446989510166) with: {'weight_constraint': 4, 'nodes': 80, 'learn_rate': 0.0001, 'init_mode': 'lecun_uniform', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.5, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.18796262011119325 (0.025161544178450422) with: {'weight_constraint': 3, 'nodes': 140, 'learn_rate': 0.001, 'init_mode': 'he_normal', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.1, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.18153096648206843 (0.031596059772207356) with: {'weight_constraint': 1, 'nodes': 200, 'learn_rate': 0.01, 'init_mode': 'normal', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.15710493667951964 (0.016343999089241047) with: {'weight_constraint': 2, 'nodes': 240, 'learn_rate': 0.001, 'init_mode': 'he_uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.8, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.1480914066053359 (0.06650483100790024) with: {'weight_constraint': 2, 'nodes': 80, 'learn_rate': 0.1, 'init_mode': 'lecun_uniform', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.0, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.18206671502237853 (0.028794997691937586) with: {'weight_constraint': 3, 'nodes': 80, 'learn_rate': 0.001, 'init_mode': 'he_uniform', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.9, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.17794738735169374 (0.019905608476681762) with: {'weight_constraint': 3, 'nodes': 180, 'learn_rate': 0.01, 'init_mode': 'he_uniform', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.7000000000000001, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.16837343789775866 (0.016032093426811743) with: {'weight_constraint': 1, 'nodes': 200, 'learn_rate': 0.01, 'init_mode': 'he_normal', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.4, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.17932088449261854 (0.02401565018883208) with: {'weight_constraint': 4, 'nodes': 140, 'learn_rate': 0.01, 'init_mode': 'he_normal', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 10, 'act_func': 'sigmoid'}\n",
            "0.18525011964574603 (0.02403288807187739) with: {'weight_constraint': 5, 'nodes': 100, 'learn_rate': 0.001, 'init_mode': 'glorot_normal', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.9, 'batch_size': 40, 'act_func': 'linear'}\n",
            "0.16752237868927936 (0.017269976625083415) with: {'weight_constraint': 4, 'nodes': 100, 'learn_rate': 0.0001, 'init_mode': 'uniform', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.5, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.1813941202246796 (0.03170082612069637) with: {'weight_constraint': 3, 'nodes': 180, 'learn_rate': 0.01, 'init_mode': 'glorot_uniform', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.04890773262283771 (1.5954243230414945e-05) with: {'weight_constraint': 1, 'nodes': 140, 'learn_rate': 0.1, 'init_mode': 'uniform', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 10, 'act_func': 'relu'}\n",
            "0.15747249033318997 (0.021135855520745577) with: {'weight_constraint': 5, 'nodes': 60, 'learn_rate': 0.1, 'init_mode': 'glorot_uniform', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.6000000000000001, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.1911822710602312 (0.03165250547117452) with: {'weight_constraint': 5, 'nodes': 140, 'learn_rate': 0.001, 'init_mode': 'normal', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.2, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.191008756039945 (0.02708012582848802) with: {'weight_constraint': 3, 'nodes': 160, 'learn_rate': 0.01, 'init_mode': 'normal', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.30000000000000004, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.1778320831164277 (0.018394007144628122) with: {'weight_constraint': 4, 'nodes': 80, 'learn_rate': 0.01, 'init_mode': 'uniform', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.4, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.18594618476639718 (0.03188811738130136) with: {'weight_constraint': 5, 'nodes': 140, 'learn_rate': 0.01, 'init_mode': 'glorot_normal', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.5, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.17855755598330406 (0.027710037439704262) with: {'weight_constraint': 2, 'nodes': 180, 'learn_rate': 0.01, 'init_mode': 'he_normal', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.2, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.1911831525510821 (0.03370633154023738) with: {'weight_constraint': 5, 'nodes': 100, 'learn_rate': 0.01, 'init_mode': 'normal', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.5, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.17074616202138035 (0.027311228536175833) with: {'weight_constraint': 1, 'nodes': 160, 'learn_rate': 0.1, 'init_mode': 'glorot_uniform', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.5, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.18422538602875288 (0.021411334189463574) with: {'weight_constraint': 4, 'nodes': 200, 'learn_rate': 0.01, 'init_mode': 'he_uniform', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.17544622906561677 (0.03168023788226123) with: {'weight_constraint': 2, 'nodes': 60, 'learn_rate': 0.0001, 'init_mode': 'he_uniform', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.30000000000000004, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.1939353878070371 (0.03318510847951783) with: {'weight_constraint': 2, 'nodes': 120, 'learn_rate': 0.01, 'init_mode': 'normal', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.4, 'batch_size': 10, 'act_func': 'relu'}\n",
            "0.17947250943219598 (0.025133580663824474) with: {'weight_constraint': 2, 'nodes': 200, 'learn_rate': 0.1, 'init_mode': 'he_normal', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.2, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.1684619507591112 (0.03532297829064076) with: {'weight_constraint': 2, 'nodes': 240, 'learn_rate': 0.1, 'init_mode': 'he_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.0, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.16916186361483362 (0.020720175975577508) with: {'weight_constraint': 2, 'nodes': 220, 'learn_rate': 0.001, 'init_mode': 'glorot_uniform', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.2, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.16965288346958118 (0.016278258762360037) with: {'weight_constraint': 4, 'nodes': 240, 'learn_rate': 0.0001, 'init_mode': 'he_uniform', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.0, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.1839426678626636 (0.028586108717682992) with: {'weight_constraint': 2, 'nodes': 200, 'learn_rate': 0.001, 'init_mode': 'he_uniform', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.1, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.16858859808766657 (0.020827931308165678) with: {'weight_constraint': 2, 'nodes': 80, 'learn_rate': 0.0001, 'init_mode': 'he_uniform', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.7000000000000001, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.11956946161120245 (0.029054276841023966) with: {'weight_constraint': 5, 'nodes': 200, 'learn_rate': 0.1, 'init_mode': 'glorot_normal', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.7000000000000001, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.16969563215521796 (0.031129489264395876) with: {'weight_constraint': 5, 'nodes': 60, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.9, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.16884481839628823 (0.018802247944112675) with: {'weight_constraint': 4, 'nodes': 160, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.1, 'batch_size': 80, 'act_func': 'relu'}\n",
            "0.1814111955309953 (0.022223348278982126) with: {'weight_constraint': 3, 'nodes': 220, 'learn_rate': 0.01, 'init_mode': 'glorot_uniform', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.0, 'batch_size': 80, 'act_func': 'relu'}\n",
            "0.19189680733741593 (0.02561201984582252) with: {'weight_constraint': 2, 'nodes': 240, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.7000000000000001, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.12738169549817557 (0.017840359456189288) with: {'weight_constraint': 2, 'nodes': 160, 'learn_rate': 0.0001, 'init_mode': 'lecun_uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.1, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.18572450997718967 (0.02105096455424412) with: {'weight_constraint': 4, 'nodes': 160, 'learn_rate': 0.001, 'init_mode': 'lecun_uniform', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.1700200954112006 (0.017601168131161152) with: {'weight_constraint': 3, 'nodes': 160, 'learn_rate': 0.001, 'init_mode': 'glorot_uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.9, 'batch_size': 80, 'act_func': 'relu'}\n",
            "0.050959640945565654 (0.00613980091053589) with: {'weight_constraint': 1, 'nodes': 200, 'learn_rate': 0.1, 'init_mode': 'uniform', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.1739714480524785 (0.028500845565405816) with: {'weight_constraint': 1, 'nodes': 220, 'learn_rate': 0.1, 'init_mode': 'he_uniform', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.4, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.17110110587218222 (0.017600952168467757) with: {'weight_constraint': 3, 'nodes': 60, 'learn_rate': 0.0001, 'init_mode': 'lecun_uniform', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.0, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.18087900773171417 (0.023467673365410117) with: {'weight_constraint': 1, 'nodes': 220, 'learn_rate': 0.1, 'init_mode': 'glorot_normal', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.0, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.18780309847710897 (0.033826563362160875) with: {'weight_constraint': 4, 'nodes': 220, 'learn_rate': 0.0001, 'init_mode': 'glorot_uniform', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.0, 'batch_size': 10, 'act_func': 'sigmoid'}\n",
            "0.18036213453306785 (0.023336308872423835) with: {'weight_constraint': 1, 'nodes': 120, 'learn_rate': 0.001, 'init_mode': 'he_normal', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.30000000000000004, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.18637090644126894 (0.03612805025168417) with: {'weight_constraint': 5, 'nodes': 160, 'learn_rate': 0.001, 'init_mode': 'glorot_uniform', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.2, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.18091674003114733 (0.03334343317210013) with: {'weight_constraint': 5, 'nodes': 120, 'learn_rate': 0.01, 'init_mode': 'he_uniform', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.9, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.17575213759038089 (0.020974665854774623) with: {'weight_constraint': 5, 'nodes': 140, 'learn_rate': 0.001, 'init_mode': 'he_uniform', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.5, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.16250293991215764 (0.02468131402604698) with: {'weight_constraint': 5, 'nodes': 60, 'learn_rate': 0.1, 'init_mode': 'uniform', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.2, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.14762947512778618 (0.014503351651825366) with: {'weight_constraint': 5, 'nodes': 240, 'learn_rate': 0.1, 'init_mode': 'he_uniform', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.6000000000000001, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.1746781774143695 (0.022492898266532904) with: {'weight_constraint': 2, 'nodes': 80, 'learn_rate': 0.1, 'init_mode': 'lecun_uniform', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.18793205278178157 (0.026480836411566566) with: {'weight_constraint': 1, 'nodes': 140, 'learn_rate': 0.01, 'init_mode': 'he_uniform', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.0, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.15618119734863362 (0.019086039134364553) with: {'weight_constraint': 3, 'nodes': 180, 'learn_rate': 0.0001, 'init_mode': 'he_normal', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.9, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.15289365619129153 (0.02761678611525067) with: {'weight_constraint': 4, 'nodes': 140, 'learn_rate': 0.0001, 'init_mode': 'glorot_uniform', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.2, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.19146614693191247 (0.03331191717914881) with: {'weight_constraint': 3, 'nodes': 180, 'learn_rate': 0.01, 'init_mode': 'glorot_uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.1, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.1685134947807264 (0.016817369491211098) with: {'weight_constraint': 5, 'nodes': 200, 'learn_rate': 0.1, 'init_mode': 'he_uniform', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.2, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.17603669816294606 (0.02125433833296594) with: {'weight_constraint': 2, 'nodes': 120, 'learn_rate': 0.1, 'init_mode': 'uniform', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.2, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.18886494841143708 (0.02444785378212739) with: {'weight_constraint': 5, 'nodes': 180, 'learn_rate': 0.001, 'init_mode': 'he_normal', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.7000000000000001, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.17366348809971982 (0.044210342553463566) with: {'weight_constraint': 1, 'nodes': 120, 'learn_rate': 0.1, 'init_mode': 'uniform', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.4, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.1746617352393342 (0.020662402003189473) with: {'weight_constraint': 2, 'nodes': 120, 'learn_rate': 0.0001, 'init_mode': 'uniform', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.0, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.18177777636073006 (0.02377074250936675) with: {'weight_constraint': 2, 'nodes': 200, 'learn_rate': 0.01, 'init_mode': 'uniform', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.6000000000000001, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.18837382166098168 (0.029134443580723556) with: {'weight_constraint': 1, 'nodes': 180, 'learn_rate': 0.001, 'init_mode': 'lecun_uniform', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.30000000000000004, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.11452896237264772 (0.02797038751961342) with: {'weight_constraint': 3, 'nodes': 200, 'learn_rate': 0.1, 'init_mode': 'glorot_normal', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.16698953706946024 (0.02283449335875752) with: {'weight_constraint': 4, 'nodes': 60, 'learn_rate': 0.1, 'init_mode': 'lecun_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.190939696306117 (0.026590737533116082) with: {'weight_constraint': 3, 'nodes': 60, 'learn_rate': 0.01, 'init_mode': 'lecun_uniform', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.17429253014342738 (0.02912247190993253) with: {'weight_constraint': 5, 'nodes': 220, 'learn_rate': 0.001, 'init_mode': 'normal', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.30000000000000004, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.18234424032184343 (0.024834017019625097) with: {'weight_constraint': 5, 'nodes': 200, 'learn_rate': 0.001, 'init_mode': 'he_normal', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.4, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.08169838108453893 (0.019699686632091915) with: {'weight_constraint': 3, 'nodes': 120, 'learn_rate': 0.1, 'init_mode': 'he_uniform', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.6000000000000001, 'batch_size': 80, 'act_func': 'relu'}\n",
            "0.18012409683396763 (0.023032624293883162) with: {'weight_constraint': 1, 'nodes': 80, 'learn_rate': 0.0001, 'init_mode': 'normal', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.14516251854419562 (0.013111350584915348) with: {'weight_constraint': 2, 'nodes': 180, 'learn_rate': 0.0001, 'init_mode': 'lecun_uniform', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.7000000000000001, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.1474100042275406 (0.03165544190182151) with: {'weight_constraint': 3, 'nodes': 120, 'learn_rate': 0.1, 'init_mode': 'lecun_uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.9, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.1883714182467941 (0.030022005831479997) with: {'weight_constraint': 1, 'nodes': 140, 'learn_rate': 0.01, 'init_mode': 'normal', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.1, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.18279550552494536 (0.02487985241664481) with: {'weight_constraint': 3, 'nodes': 220, 'learn_rate': 0.01, 'init_mode': 'normal', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.2, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.1904256449868821 (0.030975749288982557) with: {'weight_constraint': 2, 'nodes': 220, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.1, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.18159016334173902 (0.03977747517631725) with: {'weight_constraint': 1, 'nodes': 120, 'learn_rate': 0.01, 'init_mode': 'he_normal', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.7000000000000001, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.18689550908197844 (0.030841747912884923) with: {'weight_constraint': 1, 'nodes': 180, 'learn_rate': 0.001, 'init_mode': 'he_normal', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.2, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.16935987643382125 (0.01864819499809914) with: {'weight_constraint': 2, 'nodes': 60, 'learn_rate': 0.1, 'init_mode': 'uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.1, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.13854038906351646 (0.01426414328193777) with: {'weight_constraint': 2, 'nodes': 80, 'learn_rate': 0.0001, 'init_mode': 'lecun_uniform', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.8, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.17310378079215347 (0.024315494080436043) with: {'weight_constraint': 1, 'nodes': 120, 'learn_rate': 0.0001, 'init_mode': 'lecun_uniform', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.9, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.13074817939597677 (0.02118641047076664) with: {'weight_constraint': 3, 'nodes': 60, 'learn_rate': 0.0001, 'init_mode': 'he_normal', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.5, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.18680893195951928 (0.029770123796479503) with: {'weight_constraint': 5, 'nodes': 200, 'learn_rate': 0.001, 'init_mode': 'glorot_uniform', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.0, 'batch_size': 40, 'act_func': 'linear'}\n",
            "0.16196812165281593 (0.017728001219284698) with: {'weight_constraint': 4, 'nodes': 100, 'learn_rate': 0.0001, 'init_mode': 'he_normal', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.18919731984429508 (0.03426296837564871) with: {'weight_constraint': 4, 'nodes': 240, 'learn_rate': 0.01, 'init_mode': 'uniform', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.2, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.16762959331602642 (0.01514195143837667) with: {'weight_constraint': 2, 'nodes': 140, 'learn_rate': 0.0001, 'init_mode': 'uniform', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.8, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.14501340705925478 (0.022995007190603822) with: {'weight_constraint': 3, 'nodes': 120, 'learn_rate': 0.1, 'init_mode': 'normal', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 40, 'act_func': 'linear'}\n",
            "0.19059979782098466 (0.03185436962772798) with: {'weight_constraint': 1, 'nodes': 80, 'learn_rate': 0.001, 'init_mode': 'glorot_uniform', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.17692854987016093 (0.031248951191221706) with: {'weight_constraint': 5, 'nodes': 140, 'learn_rate': 0.0001, 'init_mode': 'lecun_uniform', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.2, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.18710992352507427 (0.027974788004866465) with: {'weight_constraint': 1, 'nodes': 80, 'learn_rate': 0.01, 'init_mode': 'he_uniform', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.5, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.18757873741513148 (0.032791591509044815) with: {'weight_constraint': 4, 'nodes': 220, 'learn_rate': 0.001, 'init_mode': 'uniform', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.7000000000000001, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.14203163782035425 (0.02120304985883636) with: {'weight_constraint': 3, 'nodes': 80, 'learn_rate': 0.0001, 'init_mode': 'he_uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.9, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.18681454674583892 (0.025991256908625065) with: {'weight_constraint': 4, 'nodes': 200, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.5, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.1507474230076396 (0.04831498849403258) with: {'weight_constraint': 4, 'nodes': 200, 'learn_rate': 0.1, 'init_mode': 'lecun_uniform', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.5, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.17725461847206975 (0.023437960048803122) with: {'weight_constraint': 5, 'nodes': 60, 'learn_rate': 0.0001, 'init_mode': 'normal', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.7000000000000001, 'batch_size': 10, 'act_func': 'sigmoid'}\n",
            "0.1515195389370367 (0.033341802525657875) with: {'weight_constraint': 4, 'nodes': 220, 'learn_rate': 0.1, 'init_mode': 'normal', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.5, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.19008408329078677 (0.025912505742621862) with: {'weight_constraint': 1, 'nodes': 80, 'learn_rate': 0.001, 'init_mode': 'glorot_normal', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.0, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.18803642772181428 (0.029722260831893534) with: {'weight_constraint': 2, 'nodes': 180, 'learn_rate': 0.001, 'init_mode': 'glorot_uniform', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.6000000000000001, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.1928484106672129 (0.02323782725381048) with: {'weight_constraint': 1, 'nodes': 120, 'learn_rate': 0.01, 'init_mode': 'he_normal', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.0, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.1937642521556498 (0.02920775543457218) with: {'weight_constraint': 3, 'nodes': 80, 'learn_rate': 0.0001, 'init_mode': 'uniform', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.5, 'batch_size': 10, 'act_func': 'relu'}\n",
            "0.17849299719719797 (0.022871098549652098) with: {'weight_constraint': 4, 'nodes': 200, 'learn_rate': 0.001, 'init_mode': 'he_uniform', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.5, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.18856818483349855 (0.029099917602996447) with: {'weight_constraint': 5, 'nodes': 60, 'learn_rate': 0.001, 'init_mode': 'normal', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.8, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.1629726471950655 (0.014081010199158623) with: {'weight_constraint': 2, 'nodes': 180, 'learn_rate': 0.001, 'init_mode': 'uniform', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.9, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.13773065141121618 (0.02793149655575356) with: {'weight_constraint': 5, 'nodes': 100, 'learn_rate': 0.1, 'init_mode': 'glorot_normal', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.7000000000000001, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.16231763297108212 (0.026504971674707663) with: {'weight_constraint': 3, 'nodes': 220, 'learn_rate': 0.0001, 'init_mode': 'he_uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.0, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.16544485887272944 (0.031176898339386323) with: {'weight_constraint': 2, 'nodes': 200, 'learn_rate': 0.1, 'init_mode': 'lecun_uniform', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.6000000000000001, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.15731705687444203 (0.015756656719618692) with: {'weight_constraint': 4, 'nodes': 60, 'learn_rate': 0.001, 'init_mode': 'he_normal', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.9, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.18613080879310123 (0.026404257585040957) with: {'weight_constraint': 5, 'nodes': 80, 'learn_rate': 0.001, 'init_mode': 'normal', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.6000000000000001, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.1813697878870962 (0.029735237423270944) with: {'weight_constraint': 1, 'nodes': 180, 'learn_rate': 0.0001, 'init_mode': 'glorot_uniform', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.2, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.1372297732169623 (0.03534296714326241) with: {'weight_constraint': 5, 'nodes': 160, 'learn_rate': 0.1, 'init_mode': 'uniform', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.7000000000000001, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.0921017425235007 (0.025735244867636765) with: {'weight_constraint': 4, 'nodes': 200, 'learn_rate': 0.1, 'init_mode': 'lecun_uniform', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.4, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.18443515325642795 (0.023543539387338202) with: {'weight_constraint': 4, 'nodes': 100, 'learn_rate': 0.01, 'init_mode': 'he_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.13857536063874745 (0.02567011413495938) with: {'weight_constraint': 3, 'nodes': 200, 'learn_rate': 0.1, 'init_mode': 'he_normal', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 10, 'act_func': 'sigmoid'}\n",
            "0.16216736544000424 (0.015722142870312764) with: {'weight_constraint': 4, 'nodes': 220, 'learn_rate': 0.0001, 'init_mode': 'glorot_uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.7000000000000001, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.18152139829277575 (0.031037764761300043) with: {'weight_constraint': 1, 'nodes': 120, 'learn_rate': 0.01, 'init_mode': 'glorot_uniform', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.7000000000000001, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.1327988976849047 (0.013751446162528826) with: {'weight_constraint': 1, 'nodes': 240, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.1841558638776174 (0.026792126582089987) with: {'weight_constraint': 1, 'nodes': 180, 'learn_rate': 0.1, 'init_mode': 'lecun_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.6000000000000001, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.1876954582060069 (0.03148467935574739) with: {'weight_constraint': 4, 'nodes': 60, 'learn_rate': 0.1, 'init_mode': 'glorot_uniform', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.2, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.18242204949352622 (0.02346705478493061) with: {'weight_constraint': 4, 'nodes': 100, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.2, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.17295137599861332 (0.01898665493478685) with: {'weight_constraint': 3, 'nodes': 200, 'learn_rate': 0.0001, 'init_mode': 'uniform', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.18363480604582932 (0.028227911153642787) with: {'weight_constraint': 4, 'nodes': 80, 'learn_rate': 0.01, 'init_mode': 'he_normal', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.6000000000000001, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.16195202060546282 (0.01762594567634376) with: {'weight_constraint': 1, 'nodes': 160, 'learn_rate': 0.01, 'init_mode': 'lecun_uniform', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 10, 'act_func': 'relu'}\n",
            "0.1766356689820897 (0.018065242860004015) with: {'weight_constraint': 2, 'nodes': 100, 'learn_rate': 0.0001, 'init_mode': 'he_uniform', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.10352625048187321 (0.036094680208593244) with: {'weight_constraint': 4, 'nodes': 240, 'learn_rate': 0.1, 'init_mode': 'uniform', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.1, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.17322656089960248 (0.02330369611012585) with: {'weight_constraint': 4, 'nodes': 240, 'learn_rate': 0.001, 'init_mode': 'glorot_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.2, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.14497054168375884 (0.01561495611483523) with: {'weight_constraint': 5, 'nodes': 80, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.18915923861110026 (0.036932628490365035) with: {'weight_constraint': 5, 'nodes': 80, 'learn_rate': 0.001, 'init_mode': 'uniform', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.0, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.17505628000120646 (0.035618950272332126) with: {'weight_constraint': 5, 'nodes': 180, 'learn_rate': 0.1, 'init_mode': 'he_normal', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.6000000000000001, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.06929772471957465 (0.018120218465183732) with: {'weight_constraint': 4, 'nodes': 160, 'learn_rate': 0.1, 'init_mode': 'lecun_uniform', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.2, 'batch_size': 10, 'act_func': 'relu'}\n",
            "0.10198125030152345 (0.021172149924048356) with: {'weight_constraint': 1, 'nodes': 120, 'learn_rate': 0.1, 'init_mode': 'he_normal', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.6000000000000001, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.16782161017141367 (0.020244890725218255) with: {'weight_constraint': 2, 'nodes': 180, 'learn_rate': 0.001, 'init_mode': 'lecun_uniform', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.30000000000000004, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.12863708937838664 (0.03225407007635252) with: {'weight_constraint': 5, 'nodes': 60, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.9, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.17635337043647997 (0.028202467295588746) with: {'weight_constraint': 5, 'nodes': 160, 'learn_rate': 0.001, 'init_mode': 'he_normal', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.4, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.06460670876948568 (0.015938597411099955) with: {'weight_constraint': 5, 'nodes': 60, 'learn_rate': 0.1, 'init_mode': 'he_normal', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.30000000000000004, 'batch_size': 10, 'act_func': 'relu'}\n",
            "0.17777281152506236 (0.02053342088038101) with: {'weight_constraint': 1, 'nodes': 240, 'learn_rate': 0.1, 'init_mode': 'he_normal', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.4, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.12151353672849578 (0.0255376579410975) with: {'weight_constraint': 5, 'nodes': 160, 'learn_rate': 0.1, 'init_mode': 'lecun_uniform', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.8, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.18985540821845293 (0.022649373238126092) with: {'weight_constraint': 5, 'nodes': 180, 'learn_rate': 0.001, 'init_mode': 'lecun_uniform', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.30000000000000004, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.18632668301929337 (0.03411005654003087) with: {'weight_constraint': 1, 'nodes': 100, 'learn_rate': 0.01, 'init_mode': 'lecun_uniform', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.1, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.19096901886973913 (0.031168090665759714) with: {'weight_constraint': 1, 'nodes': 240, 'learn_rate': 0.1, 'init_mode': 'glorot_normal', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.18695394783086217 (0.030549476214860677) with: {'weight_constraint': 5, 'nodes': 140, 'learn_rate': 0.001, 'init_mode': 'uniform', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.6000000000000001, 'batch_size': 80, 'act_func': 'relu'}\n",
            "0.16767278083113407 (0.017055744603673206) with: {'weight_constraint': 5, 'nodes': 200, 'learn_rate': 0.0001, 'init_mode': 'he_uniform', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.7000000000000001, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.19267624540258158 (0.030553218567644806) with: {'weight_constraint': 5, 'nodes': 240, 'learn_rate': 0.01, 'init_mode': 'glorot_normal', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.6000000000000001, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.1884185877396109 (0.030871713908737865) with: {'weight_constraint': 4, 'nodes': 160, 'learn_rate': 0.001, 'init_mode': 'uniform', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.30000000000000004, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.17148171727564948 (0.04032468665942287) with: {'weight_constraint': 5, 'nodes': 100, 'learn_rate': 0.1, 'init_mode': 'lecun_uniform', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.1, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.18884230135740562 (0.026451265895590166) with: {'weight_constraint': 5, 'nodes': 200, 'learn_rate': 0.1, 'init_mode': 'glorot_normal', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.1, 'batch_size': 80, 'act_func': 'relu'}\n",
            "0.14765301954247093 (0.010968863915358543) with: {'weight_constraint': 3, 'nodes': 140, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.4, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.1861195209193371 (0.028577706527704274) with: {'weight_constraint': 4, 'nodes': 80, 'learn_rate': 0.01, 'init_mode': 'uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.7000000000000001, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.16184052544657748 (0.014212385157322482) with: {'weight_constraint': 2, 'nodes': 180, 'learn_rate': 0.001, 'init_mode': 'uniform', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.9, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.19161755806945266 (0.030577844077872125) with: {'weight_constraint': 4, 'nodes': 140, 'learn_rate': 0.0001, 'init_mode': 'lecun_uniform', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.1, 'batch_size': 10, 'act_func': 'sigmoid'}\n",
            "0.18957085663080603 (0.026657252810446452) with: {'weight_constraint': 1, 'nodes': 180, 'learn_rate': 0.01, 'init_mode': 'he_normal', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.30000000000000004, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.16733865332322043 (0.024394505659405454) with: {'weight_constraint': 4, 'nodes': 100, 'learn_rate': 0.1, 'init_mode': 'glorot_uniform', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.6000000000000001, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.19375748490841013 (0.03184289158992639) with: {'weight_constraint': 2, 'nodes': 160, 'learn_rate': 0.001, 'init_mode': 'glorot_uniform', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.30000000000000004, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.18663072354185867 (0.034838172448579785) with: {'weight_constraint': 5, 'nodes': 80, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.30000000000000004, 'batch_size': 10, 'act_func': 'sigmoid'}\n",
            "0.18710551688096366 (0.025351840213475047) with: {'weight_constraint': 5, 'nodes': 240, 'learn_rate': 0.001, 'init_mode': 'normal', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.9, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.1893288003304711 (0.03264996489154638) with: {'weight_constraint': 5, 'nodes': 80, 'learn_rate': 0.001, 'init_mode': 'glorot_uniform', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.183007224022322 (0.017377104454743445) with: {'weight_constraint': 5, 'nodes': 240, 'learn_rate': 0.001, 'init_mode': 'lecun_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.7000000000000001, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.09244607357323341 (0.012304431108017395) with: {'weight_constraint': 5, 'nodes': 60, 'learn_rate': 0.1, 'init_mode': 'he_uniform', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.1, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.09139367856693287 (0.01912861627273634) with: {'weight_constraint': 2, 'nodes': 240, 'learn_rate': 0.1, 'init_mode': 'glorot_uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.5, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.18079438866791991 (0.02183240719866292) with: {'weight_constraint': 2, 'nodes': 60, 'learn_rate': 0.01, 'init_mode': 'uniform', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.4, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.18591082389899677 (0.024800306432261745) with: {'weight_constraint': 2, 'nodes': 240, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.0, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.18451461012673984 (0.019423404092126482) with: {'weight_constraint': 5, 'nodes': 240, 'learn_rate': 0.001, 'init_mode': 'lecun_uniform', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.1, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.14967836510510663 (0.03354482460425856) with: {'weight_constraint': 3, 'nodes': 60, 'learn_rate': 0.1, 'init_mode': 'he_uniform', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.30000000000000004, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.18579401876495721 (0.022675972894910842) with: {'weight_constraint': 2, 'nodes': 120, 'learn_rate': 0.0001, 'init_mode': 'lecun_uniform', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 10, 'act_func': 'relu'}\n",
            "0.1446125263572345 (0.012831334008158368) with: {'weight_constraint': 2, 'nodes': 240, 'learn_rate': 0.0001, 'init_mode': 'normal', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.30000000000000004, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.17774299656234394 (0.020781966039529726) with: {'weight_constraint': 5, 'nodes': 200, 'learn_rate': 0.01, 'init_mode': 'he_uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.2, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.1804799180602869 (0.02008571579089275) with: {'weight_constraint': 4, 'nodes': 180, 'learn_rate': 0.0001, 'init_mode': 'lecun_uniform', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.2, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.17529611940607012 (0.04611792888759156) with: {'weight_constraint': 4, 'nodes': 180, 'learn_rate': 0.1, 'init_mode': 'uniform', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.2, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.1884020813844047 (0.02544992222328978) with: {'weight_constraint': 3, 'nodes': 100, 'learn_rate': 0.01, 'init_mode': 'he_uniform', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.4, 'batch_size': 80, 'act_func': 'relu'}\n",
            "0.17142269939471927 (0.01999351396432041) with: {'weight_constraint': 1, 'nodes': 60, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.17294923670090095 (0.02730215670503798) with: {'weight_constraint': 5, 'nodes': 100, 'learn_rate': 0.001, 'init_mode': 'glorot_normal', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.191162279555038 (0.03023989241750945) with: {'weight_constraint': 5, 'nodes': 240, 'learn_rate': 0.001, 'init_mode': 'glorot_normal', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.7000000000000001, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.1892948459711782 (0.026430487167891367) with: {'weight_constraint': 4, 'nodes': 240, 'learn_rate': 0.001, 'init_mode': 'uniform', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.0, 'batch_size': 10, 'act_func': 'relu'}\n",
            "0.1674307802617106 (0.022884364887900258) with: {'weight_constraint': 4, 'nodes': 180, 'learn_rate': 0.01, 'init_mode': 'lecun_uniform', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.9, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.18755158553305257 (0.03003095211266793) with: {'weight_constraint': 1, 'nodes': 80, 'learn_rate': 0.001, 'init_mode': 'glorot_normal', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.6000000000000001, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.14423174656784976 (0.03895603753532875) with: {'weight_constraint': 4, 'nodes': 100, 'learn_rate': 0.1, 'init_mode': 'glorot_normal', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.1, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.19061187571478716 (0.03188633385840274) with: {'weight_constraint': 1, 'nodes': 180, 'learn_rate': 0.01, 'init_mode': 'normal', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.4, 'batch_size': 40, 'act_func': 'linear'}\n",
            "0.18886356955782954 (0.024687974745352427) with: {'weight_constraint': 1, 'nodes': 60, 'learn_rate': 0.0001, 'init_mode': 'he_uniform', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.30000000000000004, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.16647740059131477 (0.034951344996209506) with: {'weight_constraint': 2, 'nodes': 100, 'learn_rate': 0.1, 'init_mode': 'normal', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.4, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.17220770845511263 (0.035227932043340536) with: {'weight_constraint': 5, 'nodes': 240, 'learn_rate': 0.01, 'init_mode': 'normal', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.2, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.1886798903563851 (0.023713127916844712) with: {'weight_constraint': 3, 'nodes': 80, 'learn_rate': 0.01, 'init_mode': 'he_uniform', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.6000000000000001, 'batch_size': 80, 'act_func': 'relu'}\n",
            "0.19192752815465294 (0.0278696019669093) with: {'weight_constraint': 2, 'nodes': 100, 'learn_rate': 0.01, 'init_mode': 'glorot_uniform', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.4, 'batch_size': 80, 'act_func': 'relu'}\n",
            "0.15062861702002941 (0.022324189895498215) with: {'weight_constraint': 5, 'nodes': 200, 'learn_rate': 0.1, 'init_mode': 'he_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 10, 'act_func': 'sigmoid'}\n",
            "0.1880222312134241 (0.028795107404909506) with: {'weight_constraint': 2, 'nodes': 100, 'learn_rate': 0.0001, 'init_mode': 'normal', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.5, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.17989365175826233 (0.027038723375372425) with: {'weight_constraint': 2, 'nodes': 180, 'learn_rate': 0.1, 'init_mode': 'glorot_uniform', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.0, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.172412850286369 (0.023182211769180425) with: {'weight_constraint': 5, 'nodes': 80, 'learn_rate': 0.1, 'init_mode': 'glorot_normal', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.2, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.19056513657048127 (0.026383335204836746) with: {'weight_constraint': 1, 'nodes': 80, 'learn_rate': 0.0001, 'init_mode': 'glorot_uniform', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.4, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.1572131360023512 (0.013297034220744875) with: {'weight_constraint': 3, 'nodes': 60, 'learn_rate': 0.001, 'init_mode': 'uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.9, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.12379839788629529 (0.044967967580485844) with: {'weight_constraint': 4, 'nodes': 140, 'learn_rate': 0.1, 'init_mode': 'lecun_uniform', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.8, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.19510685294555863 (0.0292988754112154) with: {'weight_constraint': 5, 'nodes': 60, 'learn_rate': 0.01, 'init_mode': 'he_normal', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.4, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.16017080381094556 (0.012961893966069756) with: {'weight_constraint': 2, 'nodes': 60, 'learn_rate': 0.001, 'init_mode': 'lecun_uniform', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.7000000000000001, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.1887371012828239 (0.032012400108837116) with: {'weight_constraint': 3, 'nodes': 140, 'learn_rate': 0.001, 'init_mode': 'uniform', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.0, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.17448058743751105 (0.018876990939928444) with: {'weight_constraint': 2, 'nodes': 200, 'learn_rate': 0.0001, 'init_mode': 'normal', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.0, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.1943627710106014 (0.02784511475107947) with: {'weight_constraint': 5, 'nodes': 180, 'learn_rate': 0.0001, 'init_mode': 'normal', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.7000000000000001, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.15391372521467828 (0.012908831389115479) with: {'weight_constraint': 1, 'nodes': 220, 'learn_rate': 0.0001, 'init_mode': 'he_normal', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.1, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.17913197321870647 (0.02610582638326942) with: {'weight_constraint': 5, 'nodes': 100, 'learn_rate': 0.001, 'init_mode': 'lecun_uniform', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.0, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.1900512376735925 (0.03183753804962033) with: {'weight_constraint': 5, 'nodes': 200, 'learn_rate': 0.01, 'init_mode': 'normal', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.1, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.1366511643042507 (0.027425775912190996) with: {'weight_constraint': 4, 'nodes': 160, 'learn_rate': 0.1, 'init_mode': 'he_uniform', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.2, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.17391189363950868 (0.022873858616746658) with: {'weight_constraint': 5, 'nodes': 220, 'learn_rate': 0.1, 'init_mode': 'lecun_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.7000000000000001, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.15652393677038526 (0.036425527230068366) with: {'weight_constraint': 2, 'nodes': 120, 'learn_rate': 0.1, 'init_mode': 'glorot_uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.5, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.19347689091822534 (0.028716294398927096) with: {'weight_constraint': 4, 'nodes': 180, 'learn_rate': 0.001, 'init_mode': 'he_normal', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.13324171890698294 (0.022177625616257288) with: {'weight_constraint': 2, 'nodes': 220, 'learn_rate': 0.1, 'init_mode': 'he_uniform', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.9, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.15921395428589805 (0.012175340893056361) with: {'weight_constraint': 1, 'nodes': 100, 'learn_rate': 0.001, 'init_mode': 'normal', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.30000000000000004, 'batch_size': 40, 'act_func': 'linear'}\n",
            "0.17547069189715456 (0.017127073789075287) with: {'weight_constraint': 5, 'nodes': 120, 'learn_rate': 0.01, 'init_mode': 'glorot_uniform', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.6000000000000001, 'batch_size': 10, 'act_func': 'relu'}\n",
            "0.1926907764811179 (0.025795209444063372) with: {'weight_constraint': 5, 'nodes': 220, 'learn_rate': 0.01, 'init_mode': 'glorot_normal', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.7000000000000001, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.1904040971581667 (0.029317031403878143) with: {'weight_constraint': 3, 'nodes': 100, 'learn_rate': 0.01, 'init_mode': 'uniform', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.5, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.1888381218112792 (0.02262538426524054) with: {'weight_constraint': 1, 'nodes': 120, 'learn_rate': 0.001, 'init_mode': 'glorot_normal', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.1, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.19042258953164543 (0.021868619136606048) with: {'weight_constraint': 3, 'nodes': 140, 'learn_rate': 0.001, 'init_mode': 'glorot_normal', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.6000000000000001, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.18631065150730863 (0.024083123098839948) with: {'weight_constraint': 1, 'nodes': 220, 'learn_rate': 0.0001, 'init_mode': 'he_uniform', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.2, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.10247654405114723 (0.037777250611158955) with: {'weight_constraint': 1, 'nodes': 240, 'learn_rate': 0.1, 'init_mode': 'he_uniform', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.1, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.1760776949319824 (0.023600529495019677) with: {'weight_constraint': 1, 'nodes': 120, 'learn_rate': 0.0001, 'init_mode': 'uniform', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.8, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.18739528537870398 (0.03186120332169595) with: {'weight_constraint': 5, 'nodes': 60, 'learn_rate': 0.01, 'init_mode': 'glorot_uniform', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.1904451222416051 (0.02929406202432389) with: {'weight_constraint': 5, 'nodes': 160, 'learn_rate': 0.001, 'init_mode': 'he_normal', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.5, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.0503311269944466 (0.0030519841965749037) with: {'weight_constraint': 4, 'nodes': 140, 'learn_rate': 0.1, 'init_mode': 'lecun_uniform', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.9, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.16779455952849437 (0.02046197149372748) with: {'weight_constraint': 3, 'nodes': 80, 'learn_rate': 0.001, 'init_mode': 'glorot_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.0, 'batch_size': 40, 'act_func': 'linear'}\n",
            "0.16038618695940082 (0.032167494647016286) with: {'weight_constraint': 1, 'nodes': 240, 'learn_rate': 0.1, 'init_mode': 'glorot_normal', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.7000000000000001, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.18952886310256395 (0.022304486965350544) with: {'weight_constraint': 5, 'nodes': 120, 'learn_rate': 0.001, 'init_mode': 'he_normal', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.2, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.1921067184156438 (0.03244520434553897) with: {'weight_constraint': 2, 'nodes': 80, 'learn_rate': 0.001, 'init_mode': 'glorot_normal', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.30000000000000004, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.1705291744616521 (0.022286801796207137) with: {'weight_constraint': 4, 'nodes': 60, 'learn_rate': 0.1, 'init_mode': 'glorot_normal', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.2, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.1029637612727953 (0.04331895825118167) with: {'weight_constraint': 5, 'nodes': 200, 'learn_rate': 0.1, 'init_mode': 'he_uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.30000000000000004, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.1808199367062449 (0.022352655304858107) with: {'weight_constraint': 5, 'nodes': 160, 'learn_rate': 0.1, 'init_mode': 'he_normal', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.4, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.13393562270756376 (0.009939195768276515) with: {'weight_constraint': 3, 'nodes': 60, 'learn_rate': 0.0001, 'init_mode': 'uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.0, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.18978681427138339 (0.03127947903845507) with: {'weight_constraint': 4, 'nodes': 180, 'learn_rate': 0.01, 'init_mode': 'glorot_normal', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.2, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.14525174298843024 (0.02029989555347976) with: {'weight_constraint': 2, 'nodes': 200, 'learn_rate': 0.1, 'init_mode': 'lecun_uniform', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.9, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.18638749677553218 (0.025786421799823257) with: {'weight_constraint': 5, 'nodes': 180, 'learn_rate': 0.0001, 'init_mode': 'normal', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.18392923577750953 (0.031849059239972485) with: {'weight_constraint': 4, 'nodes': 80, 'learn_rate': 0.01, 'init_mode': 'glorot_normal', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.8, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.09545172738139196 (0.010187902133651951) with: {'weight_constraint': 5, 'nodes': 240, 'learn_rate': 0.1, 'init_mode': 'lecun_uniform', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.30000000000000004, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.19222246946953372 (0.023913125069118243) with: {'weight_constraint': 3, 'nodes': 100, 'learn_rate': 0.001, 'init_mode': 'lecun_uniform', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.6000000000000001, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.1629210406763651 (0.03031660709129642) with: {'weight_constraint': 1, 'nodes': 200, 'learn_rate': 0.1, 'init_mode': 'lecun_uniform', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.4, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.15102673587723 (0.015714384571185458) with: {'weight_constraint': 2, 'nodes': 180, 'learn_rate': 0.0001, 'init_mode': 'uniform', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.8, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.16856433540453813 (0.0270333827758687) with: {'weight_constraint': 3, 'nodes': 200, 'learn_rate': 0.01, 'init_mode': 'glorot_uniform', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.1887538555511544 (0.02578359346585191) with: {'weight_constraint': 2, 'nodes': 140, 'learn_rate': 0.01, 'init_mode': 'uniform', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.0, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.1875681108307228 (0.03132915491744428) with: {'weight_constraint': 4, 'nodes': 80, 'learn_rate': 0.001, 'init_mode': 'glorot_uniform', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.1, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.18548828366679307 (0.03187813314271447) with: {'weight_constraint': 2, 'nodes': 100, 'learn_rate': 0.001, 'init_mode': 'glorot_normal', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.1901759557721679 (0.019428189571323733) with: {'weight_constraint': 4, 'nodes': 160, 'learn_rate': 0.01, 'init_mode': 'he_normal', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.18929308839194592 (0.03207846490212928) with: {'weight_constraint': 5, 'nodes': 120, 'learn_rate': 0.01, 'init_mode': 'glorot_uniform', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.0, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.18633580868641741 (0.030222955854844816) with: {'weight_constraint': 1, 'nodes': 240, 'learn_rate': 0.01, 'init_mode': 'glorot_uniform', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.9, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.14141856383287207 (0.020040676195002882) with: {'weight_constraint': 2, 'nodes': 180, 'learn_rate': 0.0001, 'init_mode': 'glorot_uniform', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.30000000000000004, 'batch_size': 40, 'act_func': 'linear'}\n",
            "0.17215417753109444 (0.028520582416578233) with: {'weight_constraint': 2, 'nodes': 120, 'learn_rate': 0.1, 'init_mode': 'normal', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.5, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.15486240783607014 (0.018287361008780607) with: {'weight_constraint': 3, 'nodes': 220, 'learn_rate': 0.1, 'init_mode': 'normal', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.1879079594121288 (0.022591615477120925) with: {'weight_constraint': 4, 'nodes': 180, 'learn_rate': 0.001, 'init_mode': 'he_uniform', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.4, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.1317167598755372 (0.00970243500659714) with: {'weight_constraint': 5, 'nodes': 140, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.5, 'batch_size': 40, 'act_func': 'linear'}\n",
            "0.18706930683340214 (0.030780117012781074) with: {'weight_constraint': 4, 'nodes': 160, 'learn_rate': 0.01, 'init_mode': 'glorot_normal', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.6000000000000001, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.1914826868793373 (0.03151024495477853) with: {'weight_constraint': 2, 'nodes': 160, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.2, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.1654696715393107 (0.017718007962747025) with: {'weight_constraint': 1, 'nodes': 200, 'learn_rate': 0.0001, 'init_mode': 'uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.6000000000000001, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.1784216467568271 (0.022434109458124393) with: {'weight_constraint': 1, 'nodes': 240, 'learn_rate': 0.1, 'init_mode': 'lecun_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.0, 'batch_size': 80, 'act_func': 'relu'}\n",
            "0.11361472414026268 (0.023758483876871968) with: {'weight_constraint': 1, 'nodes': 60, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.0, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.13303485397371256 (0.015419698113071062) with: {'weight_constraint': 5, 'nodes': 220, 'learn_rate': 0.0001, 'init_mode': 'he_uniform', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.5, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.183166181270008 (0.031357933087098895) with: {'weight_constraint': 3, 'nodes': 100, 'learn_rate': 0.01, 'init_mode': 'glorot_uniform', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.2, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.1798523080746685 (0.02444545669960553) with: {'weight_constraint': 1, 'nodes': 220, 'learn_rate': 0.01, 'init_mode': 'glorot_uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.8, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.16479232109125236 (0.027868367941914524) with: {'weight_constraint': 4, 'nodes': 60, 'learn_rate': 0.0001, 'init_mode': 'lecun_uniform', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 10, 'act_func': 'relu'}\n",
            "0.18264240837186468 (0.02420419682772571) with: {'weight_constraint': 4, 'nodes': 160, 'learn_rate': 0.01, 'init_mode': 'he_normal', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.6000000000000001, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.1911675044144095 (0.029161361637497066) with: {'weight_constraint': 5, 'nodes': 120, 'learn_rate': 0.001, 'init_mode': 'glorot_normal', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.8, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.15718848557006204 (0.022014799378846397) with: {'weight_constraint': 4, 'nodes': 60, 'learn_rate': 0.0001, 'init_mode': 'he_normal', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.6000000000000001, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.17560518083966548 (0.02539404282077602) with: {'weight_constraint': 3, 'nodes': 180, 'learn_rate': 0.0001, 'init_mode': 'he_normal', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.1, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.15661256772556073 (0.03184042475682301) with: {'weight_constraint': 2, 'nodes': 200, 'learn_rate': 0.1, 'init_mode': 'glorot_normal', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.5, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.11295260342943533 (0.02131432799262175) with: {'weight_constraint': 1, 'nodes': 180, 'learn_rate': 0.1, 'init_mode': 'uniform', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.30000000000000004, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.1771753706587224 (0.017686416134785263) with: {'weight_constraint': 1, 'nodes': 140, 'learn_rate': 0.001, 'init_mode': 'he_uniform', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.05909217783458602 (0.0111335132906061) with: {'weight_constraint': 5, 'nodes': 200, 'learn_rate': 0.1, 'init_mode': 'uniform', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.8, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.18861110621605612 (0.03047751595295323) with: {'weight_constraint': 4, 'nodes': 140, 'learn_rate': 0.01, 'init_mode': 'normal', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.4, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.18665878000044742 (0.03132412975377969) with: {'weight_constraint': 3, 'nodes': 200, 'learn_rate': 0.001, 'init_mode': 'uniform', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.2, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.19970912317141393 (0.029443547765152723) with: {'weight_constraint': 1, 'nodes': 80, 'learn_rate': 0.0001, 'init_mode': 'glorot_uniform', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.4, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.1846617220029368 (0.024379278473735146) with: {'weight_constraint': 4, 'nodes': 80, 'learn_rate': 0.0001, 'init_mode': 'he_uniform', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.30000000000000004, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.18739465754858414 (0.027093444059926523) with: {'weight_constraint': 5, 'nodes': 60, 'learn_rate': 0.001, 'init_mode': 'glorot_normal', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.0, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.1881237272957679 (0.031878613801647214) with: {'weight_constraint': 1, 'nodes': 240, 'learn_rate': 0.001, 'init_mode': 'lecun_uniform', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.9, 'batch_size': 10, 'act_func': 'sigmoid'}\n",
            "0.17958255889706248 (0.025352111722615596) with: {'weight_constraint': 2, 'nodes': 100, 'learn_rate': 0.0001, 'init_mode': 'uniform', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.9, 'batch_size': 10, 'act_func': 'relu'}\n",
            "0.08484770277978101 (0.016351625674331977) with: {'weight_constraint': 4, 'nodes': 100, 'learn_rate': 0.1, 'init_mode': 'glorot_normal', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.2, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.1749114519112591 (0.023323670775631588) with: {'weight_constraint': 3, 'nodes': 180, 'learn_rate': 0.1, 'init_mode': 'lecun_uniform', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.7000000000000001, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.180274927997604 (0.027887088732368857) with: {'weight_constraint': 3, 'nodes': 140, 'learn_rate': 0.01, 'init_mode': 'normal', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.7000000000000001, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.16985169247353343 (0.010280754037242294) with: {'weight_constraint': 2, 'nodes': 160, 'learn_rate': 0.1, 'init_mode': 'he_uniform', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.6000000000000001, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.16459100296839685 (0.014380558448093035) with: {'weight_constraint': 3, 'nodes': 100, 'learn_rate': 0.01, 'init_mode': 'normal', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.9, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.1900641115174047 (0.027658463491585607) with: {'weight_constraint': 2, 'nodes': 180, 'learn_rate': 0.0001, 'init_mode': 'he_normal', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.30000000000000004, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.1875994511133196 (0.024855498271472737) with: {'weight_constraint': 5, 'nodes': 240, 'learn_rate': 0.001, 'init_mode': 'glorot_normal', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.7000000000000001, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.049174598781307456 (0.0010521310414405797) with: {'weight_constraint': 3, 'nodes': 180, 'learn_rate': 0.1, 'init_mode': 'lecun_uniform', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.8, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.15890961295158282 (0.011588193169772961) with: {'weight_constraint': 1, 'nodes': 180, 'learn_rate': 0.001, 'init_mode': 'he_uniform', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.9, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.1643144875561649 (0.022473261709035065) with: {'weight_constraint': 4, 'nodes': 120, 'learn_rate': 0.0001, 'init_mode': 'lecun_uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.8, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.18637534827827945 (0.02906952891070362) with: {'weight_constraint': 1, 'nodes': 220, 'learn_rate': 0.0001, 'init_mode': 'uniform', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.2, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.18979017320231045 (0.033577870070671666) with: {'weight_constraint': 2, 'nodes': 240, 'learn_rate': 0.001, 'init_mode': 'normal', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.5, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.19268986560268897 (0.033929556866144024) with: {'weight_constraint': 4, 'nodes': 140, 'learn_rate': 0.001, 'init_mode': 'glorot_normal', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.1, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.1322757257264123 (0.01101296407725804) with: {'weight_constraint': 5, 'nodes': 200, 'learn_rate': 0.0001, 'init_mode': 'normal', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.0, 'batch_size': 40, 'act_func': 'linear'}\n",
            "0.16624211649357365 (0.024678037838437396) with: {'weight_constraint': 2, 'nodes': 180, 'learn_rate': 0.1, 'init_mode': 'glorot_normal', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.30000000000000004, 'batch_size': 10, 'act_func': 'sigmoid'}\n",
            "0.18118069316628427 (0.02918789877013112) with: {'weight_constraint': 1, 'nodes': 160, 'learn_rate': 0.01, 'init_mode': 'normal', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.6000000000000001, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.14334840042914332 (0.018349008971089608) with: {'weight_constraint': 5, 'nodes': 80, 'learn_rate': 0.1, 'init_mode': 'glorot_uniform', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.1, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.18870415301424742 (0.0278144181827994) with: {'weight_constraint': 2, 'nodes': 100, 'learn_rate': 0.01, 'init_mode': 'he_uniform', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.30000000000000004, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.1900407769572869 (0.0332113144944483) with: {'weight_constraint': 4, 'nodes': 160, 'learn_rate': 0.0001, 'init_mode': 'normal', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.1, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.18844016796306917 (0.03207487901451772) with: {'weight_constraint': 3, 'nodes': 100, 'learn_rate': 0.1, 'init_mode': 'normal', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.1, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.18749472732422348 (0.031008376346107463) with: {'weight_constraint': 2, 'nodes': 220, 'learn_rate': 0.001, 'init_mode': 'normal', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.4, 'batch_size': 40, 'act_func': 'linear'}\n",
            "0.1876874634599258 (0.028721231619189797) with: {'weight_constraint': 3, 'nodes': 220, 'learn_rate': 0.01, 'init_mode': 'glorot_uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.6000000000000001, 'batch_size': 10, 'act_func': 'relu'}\n",
            "0.14231330542773563 (0.019628789852601823) with: {'weight_constraint': 4, 'nodes': 140, 'learn_rate': 0.0001, 'init_mode': 'he_normal', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.30000000000000004, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.14869677407773274 (0.03841093211529799) with: {'weight_constraint': 2, 'nodes': 140, 'learn_rate': 0.1, 'init_mode': 'glorot_normal', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.9, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.1926968203449519 (0.023052946930149677) with: {'weight_constraint': 2, 'nodes': 180, 'learn_rate': 0.01, 'init_mode': 'he_uniform', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.30000000000000004, 'batch_size': 80, 'act_func': 'relu'}\n",
            "0.18576975363469295 (0.027303345383809362) with: {'weight_constraint': 2, 'nodes': 120, 'learn_rate': 0.01, 'init_mode': 'glorot_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.7000000000000001, 'batch_size': 10, 'act_func': 'relu'}\n",
            "0.1795580651735424 (0.022721420455792857) with: {'weight_constraint': 4, 'nodes': 220, 'learn_rate': 0.01, 'init_mode': 'he_uniform', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.7000000000000001, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.1890876294454724 (0.03285563810846348) with: {'weight_constraint': 2, 'nodes': 180, 'learn_rate': 0.01, 'init_mode': 'glorot_normal', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.7000000000000001, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.18737836398697758 (0.029631179559697775) with: {'weight_constraint': 2, 'nodes': 240, 'learn_rate': 0.01, 'init_mode': 'he_normal', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.6000000000000001, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.17964818443850492 (0.023713547457325554) with: {'weight_constraint': 2, 'nodes': 240, 'learn_rate': 0.01, 'init_mode': 'he_uniform', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.0, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.18747099928710328 (0.030699654304146864) with: {'weight_constraint': 5, 'nodes': 240, 'learn_rate': 0.01, 'init_mode': 'uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.6000000000000001, 'batch_size': 40, 'act_func': 'linear'}\n",
            "0.1812769171072177 (0.027193746252488944) with: {'weight_constraint': 4, 'nodes': 240, 'learn_rate': 0.01, 'init_mode': 'lecun_uniform', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.7000000000000001, 'batch_size': 40, 'act_func': 'linear'}\n",
            "0.17569437726877854 (0.02731132818110232) with: {'weight_constraint': 5, 'nodes': 200, 'learn_rate': 0.1, 'init_mode': 'glorot_uniform', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.4, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.1858062179152128 (0.030037934826376837) with: {'weight_constraint': 1, 'nodes': 220, 'learn_rate': 0.01, 'init_mode': 'glorot_normal', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.5, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.12375672317334763 (0.04800622015016772) with: {'weight_constraint': 4, 'nodes': 80, 'learn_rate': 0.0001, 'init_mode': 'he_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.6000000000000001, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.18565393218909682 (0.032803268156508844) with: {'weight_constraint': 1, 'nodes': 220, 'learn_rate': 0.01, 'init_mode': 'glorot_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.0, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.16651528124246023 (0.02308544024995217) with: {'weight_constraint': 2, 'nodes': 120, 'learn_rate': 0.1, 'init_mode': 'normal', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.4, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.18868281170613174 (0.03511705288532287) with: {'weight_constraint': 5, 'nodes': 100, 'learn_rate': 0.01, 'init_mode': 'normal', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.6000000000000001, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.1854202479120665 (0.02721946018974764) with: {'weight_constraint': 3, 'nodes': 240, 'learn_rate': 0.01, 'init_mode': 'lecun_uniform', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.9, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.13255579714934917 (0.01588617836791021) with: {'weight_constraint': 5, 'nodes': 100, 'learn_rate': 0.001, 'init_mode': 'lecun_uniform', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.8, 'batch_size': 40, 'act_func': 'linear'}\n",
            "0.1926177817537579 (0.02370682769501508) with: {'weight_constraint': 1, 'nodes': 100, 'learn_rate': 0.001, 'init_mode': 'lecun_uniform', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.30000000000000004, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.17260330526533546 (0.03152517459370864) with: {'weight_constraint': 5, 'nodes': 60, 'learn_rate': 0.1, 'init_mode': 'uniform', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.0, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.15090792354546195 (0.03072184595387247) with: {'weight_constraint': 1, 'nodes': 120, 'learn_rate': 0.1, 'init_mode': 'uniform', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.5, 'batch_size': 10, 'act_func': 'sigmoid'}\n",
            "0.18646815936975847 (0.030982756947371203) with: {'weight_constraint': 2, 'nodes': 140, 'learn_rate': 0.01, 'init_mode': 'uniform', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.8, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.15013562235998376 (0.015200320570582545) with: {'weight_constraint': 3, 'nodes': 120, 'learn_rate': 0.0001, 'init_mode': 'he_uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.8, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.14606885543568665 (0.03066605341830824) with: {'weight_constraint': 2, 'nodes': 140, 'learn_rate': 0.1, 'init_mode': 'he_normal', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.9, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.18918424935795466 (0.030191516210983114) with: {'weight_constraint': 3, 'nodes': 160, 'learn_rate': 0.01, 'init_mode': 'uniform', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.7000000000000001, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.05713906865489772 (0.013207850930476698) with: {'weight_constraint': 2, 'nodes': 60, 'learn_rate': 0.1, 'init_mode': 'lecun_uniform', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.6000000000000001, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.18879918139332622 (0.02598316707363334) with: {'weight_constraint': 2, 'nodes': 200, 'learn_rate': 0.001, 'init_mode': 'glorot_normal', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.6000000000000001, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.1624351918594302 (0.014374963163379812) with: {'weight_constraint': 4, 'nodes': 200, 'learn_rate': 0.0001, 'init_mode': 'uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.4, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.15723495372465326 (0.013197821526811466) with: {'weight_constraint': 1, 'nodes': 140, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.9, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.1871938311010519 (0.028237277265800907) with: {'weight_constraint': 1, 'nodes': 80, 'learn_rate': 0.01, 'init_mode': 'he_uniform', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.18862072391562212 (0.021816232789137347) with: {'weight_constraint': 2, 'nodes': 100, 'learn_rate': 0.001, 'init_mode': 'he_normal', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.2, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.1798305808110628 (0.035058995142507085) with: {'weight_constraint': 3, 'nodes': 240, 'learn_rate': 0.1, 'init_mode': 'glorot_normal', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.1, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.18741356561782926 (0.03064707185576855) with: {'weight_constraint': 5, 'nodes': 120, 'learn_rate': 0.0001, 'init_mode': 'lecun_uniform', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.4, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.17665699656028325 (0.016569042150258433) with: {'weight_constraint': 2, 'nodes': 200, 'learn_rate': 0.0001, 'init_mode': 'he_uniform', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.5, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.18485394623195 (0.026518133770953738) with: {'weight_constraint': 2, 'nodes': 200, 'learn_rate': 0.01, 'init_mode': 'uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.8, 'batch_size': 40, 'act_func': 'linear'}\n",
            "0.17626152263865508 (0.020583926068584567) with: {'weight_constraint': 3, 'nodes': 80, 'learn_rate': 0.01, 'init_mode': 'he_uniform', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.4, 'batch_size': 10, 'act_func': 'sigmoid'}\n",
            "0.17392585836538563 (0.03358468638461644) with: {'weight_constraint': 5, 'nodes': 60, 'learn_rate': 0.1, 'init_mode': 'he_uniform', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.9, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.1877720073173194 (0.028699826431375905) with: {'weight_constraint': 5, 'nodes': 140, 'learn_rate': 0.1, 'init_mode': 'he_normal', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.1, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.18134638051858318 (0.030650997308989) with: {'weight_constraint': 1, 'nodes': 120, 'learn_rate': 0.1, 'init_mode': 'he_uniform', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.2, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.18498724573431083 (0.026377439317225262) with: {'weight_constraint': 1, 'nodes': 160, 'learn_rate': 0.01, 'init_mode': 'glorot_uniform', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.6000000000000001, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.18803380621114363 (0.029596407770835914) with: {'weight_constraint': 5, 'nodes': 140, 'learn_rate': 0.01, 'init_mode': 'glorot_uniform', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.9, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.17887131007218968 (0.030884079814837196) with: {'weight_constraint': 4, 'nodes': 160, 'learn_rate': 0.1, 'init_mode': 'he_normal', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.0, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.056043528609795924 (0.00409760873609018) with: {'weight_constraint': 4, 'nodes': 100, 'learn_rate': 0.1, 'init_mode': 'glorot_uniform', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.9, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.17461644157439715 (0.03232303224322815) with: {'weight_constraint': 2, 'nodes': 80, 'learn_rate': 0.1, 'init_mode': 'glorot_uniform', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.6000000000000001, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.17789352132455064 (0.019542166210302622) with: {'weight_constraint': 1, 'nodes': 240, 'learn_rate': 0.001, 'init_mode': 'he_uniform', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.7000000000000001, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.18887399538708888 (0.022713628331294342) with: {'weight_constraint': 5, 'nodes': 200, 'learn_rate': 0.001, 'init_mode': 'glorot_normal', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.0, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.14650840122833403 (0.029259443389937037) with: {'weight_constraint': 1, 'nodes': 180, 'learn_rate': 0.0001, 'init_mode': 'he_uniform', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.8, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.1888802273582876 (0.02909630171157594) with: {'weight_constraint': 5, 'nodes': 180, 'learn_rate': 0.01, 'init_mode': 'glorot_normal', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.9, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.18671415355161888 (0.02614356495411081) with: {'weight_constraint': 3, 'nodes': 120, 'learn_rate': 0.001, 'init_mode': 'he_normal', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.049115139868757166 (0.0011810418416724592) with: {'weight_constraint': 2, 'nodes': 240, 'learn_rate': 0.1, 'init_mode': 'normal', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.9, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.17059180098829121 (0.03654644811115815) with: {'weight_constraint': 2, 'nodes': 60, 'learn_rate': 0.1, 'init_mode': 'he_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.4, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.05237430156511831 (0.004420009042366809) with: {'weight_constraint': 5, 'nodes': 240, 'learn_rate': 0.1, 'init_mode': 'uniform', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.9, 'batch_size': 80, 'act_func': 'relu'}\n",
            "0.18513184536720864 (0.024007907354902686) with: {'weight_constraint': 1, 'nodes': 220, 'learn_rate': 0.01, 'init_mode': 'normal', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.2, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.18846180616750483 (0.030881856072295228) with: {'weight_constraint': 1, 'nodes': 200, 'learn_rate': 0.001, 'init_mode': 'normal', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.4, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.14964351547763616 (0.01196092059747961) with: {'weight_constraint': 2, 'nodes': 220, 'learn_rate': 0.0001, 'init_mode': 'glorot_uniform', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.6000000000000001, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.16931341211184417 (0.031643215735753245) with: {'weight_constraint': 4, 'nodes': 180, 'learn_rate': 0.1, 'init_mode': 'uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.5, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.14769501037243898 (0.031769704398722606) with: {'weight_constraint': 5, 'nodes': 200, 'learn_rate': 0.1, 'init_mode': 'uniform', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.2, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.189008301685989 (0.03383535868781865) with: {'weight_constraint': 2, 'nodes': 60, 'learn_rate': 0.001, 'init_mode': 'lecun_uniform', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.6000000000000001, 'batch_size': 10, 'act_func': 'sigmoid'}\n",
            "0.1872993330092758 (0.0355636505422763) with: {'weight_constraint': 2, 'nodes': 220, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.2, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.17945492119625076 (0.02314487458769006) with: {'weight_constraint': 5, 'nodes': 140, 'learn_rate': 0.0001, 'init_mode': 'glorot_uniform', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.5, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.18738696092396495 (0.02984710297821889) with: {'weight_constraint': 3, 'nodes': 140, 'learn_rate': 0.001, 'init_mode': 'glorot_uniform', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.6000000000000001, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.15340705750509281 (0.023573214043684402) with: {'weight_constraint': 1, 'nodes': 160, 'learn_rate': 0.1, 'init_mode': 'normal', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.7000000000000001, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.15431182420291495 (0.01718654196321397) with: {'weight_constraint': 2, 'nodes': 140, 'learn_rate': 0.1, 'init_mode': 'glorot_uniform', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.1, 'batch_size': 40, 'act_func': 'linear'}\n",
            "0.13234206067660542 (0.010965115838067335) with: {'weight_constraint': 4, 'nodes': 80, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.30000000000000004, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.18578670988077553 (0.02369797121697458) with: {'weight_constraint': 2, 'nodes': 100, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.2, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.16861368695622259 (0.017697241748157042) with: {'weight_constraint': 4, 'nodes': 140, 'learn_rate': 0.0001, 'init_mode': 'normal', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.6000000000000001, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.1931245753742116 (0.031621024031692715) with: {'weight_constraint': 5, 'nodes': 140, 'learn_rate': 0.01, 'init_mode': 'lecun_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.7000000000000001, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.17665250792030524 (0.01988947762326528) with: {'weight_constraint': 5, 'nodes': 200, 'learn_rate': 0.01, 'init_mode': 'he_normal', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.6000000000000001, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.18564228239735184 (0.027259228790313776) with: {'weight_constraint': 2, 'nodes': 60, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 80, 'act_func': 'relu'}\n",
            "0.17175851764421693 (0.028471635325524044) with: {'weight_constraint': 5, 'nodes': 220, 'learn_rate': 0.1, 'init_mode': 'lecun_uniform', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.2, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.13494844540310957 (0.01021136310785577) with: {'weight_constraint': 3, 'nodes': 160, 'learn_rate': 0.001, 'init_mode': 'uniform', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.8, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.15142411443025405 (0.010710396860366561) with: {'weight_constraint': 2, 'nodes': 240, 'learn_rate': 0.001, 'init_mode': 'glorot_normal', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.8, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.18563297612914656 (0.02623480852385892) with: {'weight_constraint': 4, 'nodes': 180, 'learn_rate': 0.001, 'init_mode': 'he_uniform', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.9, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.13119847171503057 (0.013186753533650264) with: {'weight_constraint': 2, 'nodes': 240, 'learn_rate': 0.0001, 'init_mode': 'glorot_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.9, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.18459787490895394 (0.025064518070036623) with: {'weight_constraint': 4, 'nodes': 60, 'learn_rate': 0.01, 'init_mode': 'he_uniform', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.8, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.18132869358202722 (0.029374455413999388) with: {'weight_constraint': 2, 'nodes': 60, 'learn_rate': 0.001, 'init_mode': 'glorot_normal', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.0, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.13630244624081986 (0.013129769165813345) with: {'weight_constraint': 2, 'nodes': 100, 'learn_rate': 0.0001, 'init_mode': 'normal', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.0, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.18643003741089742 (0.030395817964108403) with: {'weight_constraint': 5, 'nodes': 140, 'learn_rate': 0.01, 'init_mode': 'uniform', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.1, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.18776300311175786 (0.024405233541915605) with: {'weight_constraint': 1, 'nodes': 160, 'learn_rate': 0.01, 'init_mode': 'he_normal', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.1, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.18234940713824616 (0.02911525956893876) with: {'weight_constraint': 5, 'nodes': 220, 'learn_rate': 0.01, 'init_mode': 'glorot_normal', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.6000000000000001, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.12957623745495353 (0.03887806955279276) with: {'weight_constraint': 4, 'nodes': 120, 'learn_rate': 0.1, 'init_mode': 'he_uniform', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.30000000000000004, 'batch_size': 10, 'act_func': 'sigmoid'}\n",
            "0.19338959593387778 (0.02223630798827195) with: {'weight_constraint': 2, 'nodes': 120, 'learn_rate': 0.001, 'init_mode': 'he_uniform', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.4, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.18464760403697106 (0.02950104862705648) with: {'weight_constraint': 1, 'nodes': 200, 'learn_rate': 0.001, 'init_mode': 'uniform', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.4, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.19088773861653346 (0.0322310831951765) with: {'weight_constraint': 1, 'nodes': 240, 'learn_rate': 0.001, 'init_mode': 'uniform', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.6000000000000001, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.19263721978802112 (0.027207996447956212) with: {'weight_constraint': 4, 'nodes': 60, 'learn_rate': 0.1, 'init_mode': 'he_normal', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.30000000000000004, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.1826823063772119 (0.023691605005931773) with: {'weight_constraint': 5, 'nodes': 120, 'learn_rate': 0.01, 'init_mode': 'uniform', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.6000000000000001, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.1731215552003083 (0.027540736780627875) with: {'weight_constraint': 1, 'nodes': 80, 'learn_rate': 0.1, 'init_mode': 'he_uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.7000000000000001, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.18874614351458893 (0.026048265271036958) with: {'weight_constraint': 1, 'nodes': 160, 'learn_rate': 0.01, 'init_mode': 'he_normal', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.2, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.18392034747068162 (0.019792749323511275) with: {'weight_constraint': 2, 'nodes': 140, 'learn_rate': 0.001, 'init_mode': 'he_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.1714729899250746 (0.010136783991516275) with: {'weight_constraint': 2, 'nodes': 200, 'learn_rate': 0.01, 'init_mode': 'he_normal', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.7000000000000001, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.16361616699378412 (0.05525999278026879) with: {'weight_constraint': 2, 'nodes': 180, 'learn_rate': 0.1, 'init_mode': 'normal', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.0, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.19011658908770168 (0.03259905022806198) with: {'weight_constraint': 3, 'nodes': 80, 'learn_rate': 0.001, 'init_mode': 'uniform', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.8, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.19066420248204902 (0.021754280256745844) with: {'weight_constraint': 5, 'nodes': 220, 'learn_rate': 0.001, 'init_mode': 'lecun_uniform', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.1, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.18370163270327128 (0.013706694859644973) with: {'weight_constraint': 1, 'nodes': 240, 'learn_rate': 0.001, 'init_mode': 'he_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.7000000000000001, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.17626000918959234 (0.01780971012687487) with: {'weight_constraint': 3, 'nodes': 220, 'learn_rate': 0.0001, 'init_mode': 'lecun_uniform', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.6000000000000001, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.10110437530526643 (0.032852859994335404) with: {'weight_constraint': 1, 'nodes': 100, 'learn_rate': 0.1, 'init_mode': 'lecun_uniform', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.0, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.18155767496787928 (0.021468036222332846) with: {'weight_constraint': 3, 'nodes': 240, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.1, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.11124852215939944 (0.030078496261676062) with: {'weight_constraint': 5, 'nodes': 200, 'learn_rate': 0.1, 'init_mode': 'lecun_uniform', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.5, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.1824343631795587 (0.01963698270726692) with: {'weight_constraint': 5, 'nodes': 160, 'learn_rate': 0.001, 'init_mode': 'glorot_normal', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.4, 'batch_size': 80, 'act_func': 'relu'}\n",
            "0.17729879990475297 (0.030284377879737315) with: {'weight_constraint': 3, 'nodes': 200, 'learn_rate': 0.001, 'init_mode': 'uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.7000000000000001, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.13015959582119616 (0.01944661604919945) with: {'weight_constraint': 2, 'nodes': 100, 'learn_rate': 0.0001, 'init_mode': 'he_normal', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.30000000000000004, 'batch_size': 80, 'act_func': 'relu'}\n",
            "0.19057046893179597 (0.03197312662368379) with: {'weight_constraint': 4, 'nodes': 60, 'learn_rate': 0.001, 'init_mode': 'normal', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.8, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.18017477956539707 (0.01524629669379265) with: {'weight_constraint': 3, 'nodes': 100, 'learn_rate': 0.0001, 'init_mode': 'he_uniform', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.4, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.1895277387713257 (0.02089945685166408) with: {'weight_constraint': 3, 'nodes': 120, 'learn_rate': 0.0001, 'init_mode': 'he_uniform', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.1, 'batch_size': 10, 'act_func': 'sigmoid'}\n",
            "0.18085712513975577 (0.032278854368522514) with: {'weight_constraint': 3, 'nodes': 140, 'learn_rate': 0.0001, 'init_mode': 'normal', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.4, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.18921243380099348 (0.03187971505610729) with: {'weight_constraint': 4, 'nodes': 200, 'learn_rate': 0.001, 'init_mode': 'normal', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.7000000000000001, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.17331614953650104 (0.018939641555615925) with: {'weight_constraint': 1, 'nodes': 80, 'learn_rate': 0.001, 'init_mode': 'he_normal', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.2, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.18688231312317183 (0.024573947872849198) with: {'weight_constraint': 2, 'nodes': 240, 'learn_rate': 0.01, 'init_mode': 'glorot_normal', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.7000000000000001, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.14796228550424653 (0.025768181185107708) with: {'weight_constraint': 5, 'nodes': 140, 'learn_rate': 0.0001, 'init_mode': 'he_uniform', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.6000000000000001, 'batch_size': 80, 'act_func': 'relu'}\n",
            "0.14827318014737736 (0.013364267583283003) with: {'weight_constraint': 5, 'nodes': 140, 'learn_rate': 0.001, 'init_mode': 'glorot_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.7000000000000001, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.19016668684042118 (0.030475729771865825) with: {'weight_constraint': 4, 'nodes': 180, 'learn_rate': 0.001, 'init_mode': 'glorot_uniform', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.17832179532049194 (0.03817668252522067) with: {'weight_constraint': 4, 'nodes': 220, 'learn_rate': 0.01, 'init_mode': 'he_uniform', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.19112414798391403 (0.03454161678980332) with: {'weight_constraint': 5, 'nodes': 200, 'learn_rate': 0.01, 'init_mode': 'glorot_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.2, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.191563050422083 (0.02656515934518041) with: {'weight_constraint': 2, 'nodes': 200, 'learn_rate': 0.001, 'init_mode': 'he_uniform', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.6000000000000001, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.14811447477611078 (0.026101055203426475) with: {'weight_constraint': 4, 'nodes': 140, 'learn_rate': 0.0001, 'init_mode': 'he_normal', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.7000000000000001, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.17469281047240823 (0.019531753656001863) with: {'weight_constraint': 5, 'nodes': 180, 'learn_rate': 0.0001, 'init_mode': 'normal', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.7000000000000001, 'batch_size': 40, 'act_func': 'linear'}\n",
            "0.1677841828346319 (0.018587699860994133) with: {'weight_constraint': 1, 'nodes': 160, 'learn_rate': 0.0001, 'init_mode': 'glorot_uniform', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.30000000000000004, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.14171353672578366 (0.009425086403189233) with: {'weight_constraint': 1, 'nodes': 240, 'learn_rate': 0.0001, 'init_mode': 'normal', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.1, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.18779426947036487 (0.02745482984493545) with: {'weight_constraint': 4, 'nodes': 220, 'learn_rate': 0.0001, 'init_mode': 'he_normal', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.7000000000000001, 'batch_size': 10, 'act_func': 'sigmoid'}\n",
            "0.18664832391462635 (0.03276550647661069) with: {'weight_constraint': 3, 'nodes': 80, 'learn_rate': 0.001, 'init_mode': 'glorot_uniform', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.6000000000000001, 'batch_size': 10, 'act_func': 'sigmoid'}\n",
            "0.19004749181260433 (0.032061457776883524) with: {'weight_constraint': 4, 'nodes': 180, 'learn_rate': 0.01, 'init_mode': 'glorot_uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.4, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.18761216084264254 (0.02496500859837332) with: {'weight_constraint': 2, 'nodes': 100, 'learn_rate': 0.001, 'init_mode': 'uniform', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.0, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.16613308994935763 (0.016957527266415858) with: {'weight_constraint': 4, 'nodes': 200, 'learn_rate': 0.001, 'init_mode': 'glorot_normal', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.4, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.18522979418363342 (0.02921582793729366) with: {'weight_constraint': 4, 'nodes': 160, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.8, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.1856175581382346 (0.03093746648222876) with: {'weight_constraint': 5, 'nodes': 80, 'learn_rate': 0.1, 'init_mode': 'glorot_normal', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.0, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.1734789915105763 (0.018813700863190376) with: {'weight_constraint': 3, 'nodes': 60, 'learn_rate': 0.001, 'init_mode': 'he_normal', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.9, 'batch_size': 40, 'act_func': 'linear'}\n",
            "0.1842197821877077 (0.020211944252619556) with: {'weight_constraint': 3, 'nodes': 80, 'learn_rate': 0.01, 'init_mode': 'normal', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.2, 'batch_size': 10, 'act_func': 'sigmoid'}\n",
            "0.17904873789253453 (0.020760926502477354) with: {'weight_constraint': 2, 'nodes': 220, 'learn_rate': 0.0001, 'init_mode': 'uniform', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.4, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.1647407330787517 (0.02461435195123073) with: {'weight_constraint': 2, 'nodes': 240, 'learn_rate': 0.1, 'init_mode': 'glorot_normal', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.2, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.13646222268055716 (0.01560843844006149) with: {'weight_constraint': 1, 'nodes': 60, 'learn_rate': 0.0001, 'init_mode': 'lecun_uniform', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.6000000000000001, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.18306789557824138 (0.021706010857710827) with: {'weight_constraint': 5, 'nodes': 100, 'learn_rate': 0.0001, 'init_mode': 'he_uniform', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.2, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.18537410286720063 (0.024785775262737824) with: {'weight_constraint': 2, 'nodes': 60, 'learn_rate': 0.0001, 'init_mode': 'glorot_uniform', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.0, 'batch_size': 10, 'act_func': 'relu'}\n",
            "0.11535280633167995 (0.031159856142170723) with: {'weight_constraint': 5, 'nodes': 80, 'learn_rate': 0.1, 'init_mode': 'glorot_uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.8, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.1366453353478722 (0.01784348300750897) with: {'weight_constraint': 2, 'nodes': 60, 'learn_rate': 0.0001, 'init_mode': 'he_uniform', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.7000000000000001, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.17415247905737102 (0.03130349988062494) with: {'weight_constraint': 3, 'nodes': 100, 'learn_rate': 0.01, 'init_mode': 'glorot_normal', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.7000000000000001, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.17672388405908648 (0.02667277090582705) with: {'weight_constraint': 4, 'nodes': 200, 'learn_rate': 0.1, 'init_mode': 'uniform', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.4, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.1874838030165344 (0.01880886478339049) with: {'weight_constraint': 4, 'nodes': 80, 'learn_rate': 0.01, 'init_mode': 'he_normal', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.2, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.1498518602553633 (0.03090584928380965) with: {'weight_constraint': 3, 'nodes': 140, 'learn_rate': 0.1, 'init_mode': 'normal', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.18673812134588885 (0.037204376566156445) with: {'weight_constraint': 3, 'nodes': 180, 'learn_rate': 0.001, 'init_mode': 'glorot_uniform', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.4, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.19002851179477281 (0.027245133750149426) with: {'weight_constraint': 1, 'nodes': 160, 'learn_rate': 0.001, 'init_mode': 'lecun_uniform', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.5, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.09370866292349919 (0.013452250493213358) with: {'weight_constraint': 3, 'nodes': 140, 'learn_rate': 0.1, 'init_mode': 'normal', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.1, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.1887774061942781 (0.034487731155650375) with: {'weight_constraint': 5, 'nodes': 240, 'learn_rate': 0.0001, 'init_mode': 'he_normal', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.0, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.05923315257954338 (0.011756294485466438) with: {'weight_constraint': 4, 'nodes': 240, 'learn_rate': 0.1, 'init_mode': 'uniform', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.6000000000000001, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.07971764949701488 (0.023397319215662217) with: {'weight_constraint': 4, 'nodes': 100, 'learn_rate': 0.1, 'init_mode': 'uniform', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.30000000000000004, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.167138807970238 (0.025035101676826526) with: {'weight_constraint': 1, 'nodes': 160, 'learn_rate': 0.1, 'init_mode': 'normal', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.9, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.09022795269786407 (0.008849006231233076) with: {'weight_constraint': 5, 'nodes': 160, 'learn_rate': 0.1, 'init_mode': 'he_normal', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.4, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.15959730445206527 (0.020874833977988685) with: {'weight_constraint': 2, 'nodes': 220, 'learn_rate': 0.001, 'init_mode': 'he_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.4, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.19186092994803094 (0.03372483946302607) with: {'weight_constraint': 4, 'nodes': 80, 'learn_rate': 0.001, 'init_mode': 'glorot_normal', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.7000000000000001, 'batch_size': 40, 'act_func': 'linear'}\n",
            "0.19788512015775558 (0.03280917728893678) with: {'weight_constraint': 4, 'nodes': 240, 'learn_rate': 0.01, 'init_mode': 'glorot_uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.1, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.19198444171394388 (0.02204012006142396) with: {'weight_constraint': 2, 'nodes': 60, 'learn_rate': 0.001, 'init_mode': 'he_normal', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.7000000000000001, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.14715488648763217 (0.020636817439880616) with: {'weight_constraint': 5, 'nodes': 160, 'learn_rate': 0.1, 'init_mode': 'lecun_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.9, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.1543128445498429 (0.04176625744801716) with: {'weight_constraint': 3, 'nodes': 180, 'learn_rate': 0.1, 'init_mode': 'glorot_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.0, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.1685406238831965 (0.01721462766140514) with: {'weight_constraint': 3, 'nodes': 240, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.18717223413869646 (0.03222145310522173) with: {'weight_constraint': 4, 'nodes': 160, 'learn_rate': 0.001, 'init_mode': 'normal', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.1, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.1731855758250636 (0.025485651042082422) with: {'weight_constraint': 3, 'nodes': 200, 'learn_rate': 0.1, 'init_mode': 'he_normal', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.1, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.18500913721955273 (0.02288590137153261) with: {'weight_constraint': 2, 'nodes': 140, 'learn_rate': 0.001, 'init_mode': 'glorot_normal', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.6000000000000001, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.12667176495808957 (0.03192089852712992) with: {'weight_constraint': 2, 'nodes': 180, 'learn_rate': 0.0001, 'init_mode': 'he_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.15821740768798054 (0.01810225940314965) with: {'weight_constraint': 4, 'nodes': 200, 'learn_rate': 0.0001, 'init_mode': 'lecun_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.6000000000000001, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.18321966275684218 (0.02864977396539879) with: {'weight_constraint': 2, 'nodes': 100, 'learn_rate': 0.01, 'init_mode': 'he_uniform', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.1854524129629313 (0.023917586553827887) with: {'weight_constraint': 2, 'nodes': 60, 'learn_rate': 0.01, 'init_mode': 'normal', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 10, 'act_func': 'sigmoid'}\n",
            "0.17349147587340022 (0.019009681333522162) with: {'weight_constraint': 4, 'nodes': 100, 'learn_rate': 0.01, 'init_mode': 'normal', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.30000000000000004, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.18634918481995086 (0.030246333150616693) with: {'weight_constraint': 5, 'nodes': 120, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.0, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.14107593719901704 (0.03229278128700643) with: {'weight_constraint': 3, 'nodes': 220, 'learn_rate': 0.1, 'init_mode': 'he_uniform', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.7000000000000001, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.17640502480405457 (0.020619708324449298) with: {'weight_constraint': 2, 'nodes': 180, 'learn_rate': 0.0001, 'init_mode': 'he_normal', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.6000000000000001, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.1600565443733412 (0.014595413290941859) with: {'weight_constraint': 3, 'nodes': 240, 'learn_rate': 0.0001, 'init_mode': 'glorot_uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.30000000000000004, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.17826266269227303 (0.026813091411142666) with: {'weight_constraint': 1, 'nodes': 100, 'learn_rate': 0.1, 'init_mode': 'he_uniform', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.2, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.049692170972485836 (0.0015807027767047105) with: {'weight_constraint': 2, 'nodes': 80, 'learn_rate': 0.1, 'init_mode': 'normal', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 10, 'act_func': 'relu'}\n",
            "0.19359443318660946 (0.020939075726198134) with: {'weight_constraint': 1, 'nodes': 180, 'learn_rate': 0.001, 'init_mode': 'lecun_uniform', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.4, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.1836072799294923 (0.024537556443800183) with: {'weight_constraint': 4, 'nodes': 60, 'learn_rate': 0.01, 'init_mode': 'lecun_uniform', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.2, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.16579185165803215 (0.026220467255937272) with: {'weight_constraint': 1, 'nodes': 180, 'learn_rate': 0.1, 'init_mode': 'normal', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.6000000000000001, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.16766922093263656 (0.03448401101237467) with: {'weight_constraint': 1, 'nodes': 240, 'learn_rate': 0.1, 'init_mode': 'normal', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.6000000000000001, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.1740449839292764 (0.03029684184564743) with: {'weight_constraint': 1, 'nodes': 220, 'learn_rate': 0.1, 'init_mode': 'lecun_uniform', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.5, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.18123473475628055 (0.02449611344721748) with: {'weight_constraint': 2, 'nodes': 180, 'learn_rate': 0.01, 'init_mode': 'glorot_normal', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.2, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.17658151464774038 (0.03858123132748195) with: {'weight_constraint': 4, 'nodes': 180, 'learn_rate': 0.1, 'init_mode': 'glorot_normal', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.0, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.05049689476974595 (0.004751577544070687) with: {'weight_constraint': 3, 'nodes': 80, 'learn_rate': 0.1, 'init_mode': 'glorot_uniform', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.7000000000000001, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.18530573449126841 (0.03571343741055507) with: {'weight_constraint': 5, 'nodes': 60, 'learn_rate': 0.01, 'init_mode': 'uniform', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.0, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.17970588867269552 (0.02050369181114253) with: {'weight_constraint': 5, 'nodes': 180, 'learn_rate': 0.01, 'init_mode': 'uniform', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.5, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.10394382697820445 (0.01957333409818585) with: {'weight_constraint': 2, 'nodes': 200, 'learn_rate': 0.1, 'init_mode': 'he_uniform', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.4, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.19109242426126416 (0.03146871173675248) with: {'weight_constraint': 4, 'nodes': 120, 'learn_rate': 0.0001, 'init_mode': 'lecun_uniform', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.8, 'batch_size': 10, 'act_func': 'sigmoid'}\n",
            "0.16724421793138355 (0.025771299081579487) with: {'weight_constraint': 2, 'nodes': 100, 'learn_rate': 0.01, 'init_mode': 'glorot_uniform', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.8, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.1815179204198919 (0.026296242183838654) with: {'weight_constraint': 1, 'nodes': 240, 'learn_rate': 0.0001, 'init_mode': 'glorot_uniform', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.6000000000000001, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.08690601550473598 (0.011493227340565315) with: {'weight_constraint': 3, 'nodes': 100, 'learn_rate': 0.1, 'init_mode': 'glorot_normal', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.5, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.1830085750785904 (0.02607470196378926) with: {'weight_constraint': 3, 'nodes': 140, 'learn_rate': 0.01, 'init_mode': 'glorot_uniform', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.0, 'batch_size': 10, 'act_func': 'sigmoid'}\n",
            "0.11082743689297322 (0.009283963991617388) with: {'weight_constraint': 2, 'nodes': 240, 'learn_rate': 0.1, 'init_mode': 'glorot_normal', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.2, 'batch_size': 80, 'act_func': 'relu'}\n",
            "0.1853713152384972 (0.02858207038592875) with: {'weight_constraint': 1, 'nodes': 180, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.0, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.18897889300930398 (0.02178442950966611) with: {'weight_constraint': 5, 'nodes': 240, 'learn_rate': 0.01, 'init_mode': 'normal', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.1, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.14263778867391547 (0.012924546510803053) with: {'weight_constraint': 2, 'nodes': 160, 'learn_rate': 0.001, 'init_mode': 'uniform', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.7000000000000001, 'batch_size': 40, 'act_func': 'linear'}\n",
            "0.16953505991157475 (0.025075207831730062) with: {'weight_constraint': 3, 'nodes': 100, 'learn_rate': 0.1, 'init_mode': 'uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.8, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.18216146989005472 (0.02326336840097075) with: {'weight_constraint': 5, 'nodes': 160, 'learn_rate': 0.001, 'init_mode': 'uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.2, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.1479012524409779 (0.015756767790381796) with: {'weight_constraint': 3, 'nodes': 240, 'learn_rate': 0.0001, 'init_mode': 'he_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.30000000000000004, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.18686819556074866 (0.02533730950056931) with: {'weight_constraint': 1, 'nodes': 140, 'learn_rate': 0.0001, 'init_mode': 'he_normal', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.6000000000000001, 'batch_size': 10, 'act_func': 'relu'}\n",
            "0.1873818937656872 (0.022741073201482397) with: {'weight_constraint': 3, 'nodes': 240, 'learn_rate': 0.001, 'init_mode': 'he_normal', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.5, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.18024991418536768 (0.022051028494071683) with: {'weight_constraint': 1, 'nodes': 240, 'learn_rate': 0.0001, 'init_mode': 'normal', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.06345048820716107 (0.01207553142018281) with: {'weight_constraint': 4, 'nodes': 200, 'learn_rate': 0.1, 'init_mode': 'he_uniform', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.7000000000000001, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.12307552749528079 (0.04691401895006185) with: {'weight_constraint': 5, 'nodes': 120, 'learn_rate': 0.1, 'init_mode': 'glorot_uniform', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.30000000000000004, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.1903408287055868 (0.033183501395641496) with: {'weight_constraint': 4, 'nodes': 60, 'learn_rate': 0.01, 'init_mode': 'he_uniform', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.11184663165189399 (0.014484872541207764) with: {'weight_constraint': 2, 'nodes': 100, 'learn_rate': 0.1, 'init_mode': 'lecun_uniform', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.5, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.18663014314271525 (0.02887053833465485) with: {'weight_constraint': 4, 'nodes': 100, 'learn_rate': 0.01, 'init_mode': 'normal', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.2, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.15575220917466323 (0.02578244117791887) with: {'weight_constraint': 4, 'nodes': 160, 'learn_rate': 0.0001, 'init_mode': 'he_normal', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.1399808087885401 (0.011848726074266888) with: {'weight_constraint': 1, 'nodes': 120, 'learn_rate': 0.0001, 'init_mode': 'he_uniform', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.8, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.17607060935467894 (0.020403281610928907) with: {'weight_constraint': 3, 'nodes': 160, 'learn_rate': 0.01, 'init_mode': 'he_normal', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.30000000000000004, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.17838364708593935 (0.028702997616825286) with: {'weight_constraint': 1, 'nodes': 80, 'learn_rate': 0.0001, 'init_mode': 'he_normal', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.1, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.178912331916602 (0.0242017896304959) with: {'weight_constraint': 5, 'nodes': 200, 'learn_rate': 0.01, 'init_mode': 'he_normal', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.6000000000000001, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.18367786088051977 (0.031392187184717334) with: {'weight_constraint': 1, 'nodes': 160, 'learn_rate': 0.1, 'init_mode': 'he_normal', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.0, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.17207004756443678 (0.01976745736042493) with: {'weight_constraint': 4, 'nodes': 80, 'learn_rate': 0.0001, 'init_mode': 'he_uniform', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.6000000000000001, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.1773285551393526 (0.018398786776755736) with: {'weight_constraint': 5, 'nodes': 140, 'learn_rate': 0.0001, 'init_mode': 'he_normal', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.7000000000000001, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.18596499080791157 (0.026050597404336902) with: {'weight_constraint': 5, 'nodes': 160, 'learn_rate': 0.001, 'init_mode': 'he_uniform', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.9, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.13340848219819093 (0.011437466678278089) with: {'weight_constraint': 3, 'nodes': 120, 'learn_rate': 0.0001, 'init_mode': 'normal', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.2, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.18567320263849418 (0.017972585181643564) with: {'weight_constraint': 5, 'nodes': 180, 'learn_rate': 0.001, 'init_mode': 'he_uniform', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.2, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.11362052500245463 (0.030214739355790877) with: {'weight_constraint': 2, 'nodes': 220, 'learn_rate': 0.1, 'init_mode': 'glorot_uniform', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.9, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.1330688023409033 (0.011239811040832597) with: {'weight_constraint': 1, 'nodes': 140, 'learn_rate': 0.0001, 'init_mode': 'uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.1470244942216382 (0.013579090403365078) with: {'weight_constraint': 3, 'nodes': 160, 'learn_rate': 0.001, 'init_mode': 'glorot_normal', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.1, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.19103983060809182 (0.024816963960083767) with: {'weight_constraint': 2, 'nodes': 220, 'learn_rate': 0.01, 'init_mode': 'uniform', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.6000000000000001, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.19154866484168176 (0.034703345307917646) with: {'weight_constraint': 3, 'nodes': 160, 'learn_rate': 0.01, 'init_mode': 'glorot_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.1, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.14489767083257238 (0.011868341195920269) with: {'weight_constraint': 1, 'nodes': 240, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.9, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.1807580504742238 (0.022745581109173345) with: {'weight_constraint': 2, 'nodes': 200, 'learn_rate': 0.01, 'init_mode': 'he_uniform', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.1, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.10958483707808017 (0.017752029226949614) with: {'weight_constraint': 5, 'nodes': 200, 'learn_rate': 0.1, 'init_mode': 'he_normal', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.30000000000000004, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.18751064041210613 (0.029986936105349714) with: {'weight_constraint': 1, 'nodes': 120, 'learn_rate': 0.01, 'init_mode': 'glorot_normal', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.1, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.15246926361044136 (0.01435884522896209) with: {'weight_constraint': 5, 'nodes': 80, 'learn_rate': 0.001, 'init_mode': 'lecun_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.17823462991281622 (0.024297796545556086) with: {'weight_constraint': 5, 'nodes': 160, 'learn_rate': 0.0001, 'init_mode': 'lecun_uniform', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.6000000000000001, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.18457498696963065 (0.02983848461561826) with: {'weight_constraint': 4, 'nodes': 140, 'learn_rate': 0.01, 'init_mode': 'lecun_uniform', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.12908703480434075 (0.03542938219929934) with: {'weight_constraint': 4, 'nodes': 140, 'learn_rate': 0.0001, 'init_mode': 'lecun_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.0, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.18834928653532818 (0.03676366391024915) with: {'weight_constraint': 5, 'nodes': 160, 'learn_rate': 0.1, 'init_mode': 'glorot_normal', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.0, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.18843613058825426 (0.02742050116395313) with: {'weight_constraint': 5, 'nodes': 80, 'learn_rate': 0.001, 'init_mode': 'glorot_uniform', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.4, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.1840452543373984 (0.03192980237762158) with: {'weight_constraint': 5, 'nodes': 200, 'learn_rate': 0.01, 'init_mode': 'glorot_normal', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.6000000000000001, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.18658577994725284 (0.027045225898931588) with: {'weight_constraint': 2, 'nodes': 160, 'learn_rate': 0.001, 'init_mode': 'he_normal', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.7000000000000001, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.11793727948122448 (0.05135024892983397) with: {'weight_constraint': 2, 'nodes': 60, 'learn_rate': 0.1, 'init_mode': 'uniform', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.9, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.18517645582431208 (0.029174573779037705) with: {'weight_constraint': 4, 'nodes': 240, 'learn_rate': 0.001, 'init_mode': 'uniform', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.0, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.19007122415565364 (0.02563981080030478) with: {'weight_constraint': 1, 'nodes': 80, 'learn_rate': 0.01, 'init_mode': 'glorot_uniform', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.5, 'batch_size': 40, 'act_func': 'linear'}\n",
            "0.16056804106363715 (0.021831036349151307) with: {'weight_constraint': 4, 'nodes': 120, 'learn_rate': 0.001, 'init_mode': 'he_uniform', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.5, 'batch_size': 80, 'act_func': 'relu'}\n",
            "0.1898150277250184 (0.029696439536682415) with: {'weight_constraint': 3, 'nodes': 240, 'learn_rate': 0.001, 'init_mode': 'glorot_normal', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.7000000000000001, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.1829395851718501 (0.01907328377196131) with: {'weight_constraint': 1, 'nodes': 60, 'learn_rate': 0.001, 'init_mode': 'he_uniform', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.6000000000000001, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.16588795266091969 (0.027320616821546104) with: {'weight_constraint': 2, 'nodes': 240, 'learn_rate': 0.1, 'init_mode': 'glorot_uniform', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.2, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.1928622311739038 (0.030524852240515876) with: {'weight_constraint': 4, 'nodes': 60, 'learn_rate': 0.001, 'init_mode': 'glorot_uniform', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.5, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.19014232194839625 (0.030941344113980206) with: {'weight_constraint': 1, 'nodes': 100, 'learn_rate': 0.01, 'init_mode': 'glorot_uniform', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.7000000000000001, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.16475333994061359 (0.01396115819901791) with: {'weight_constraint': 3, 'nodes': 80, 'learn_rate': 0.1, 'init_mode': 'lecun_uniform', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.0, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.089856125381745 (0.019968675652847514) with: {'weight_constraint': 3, 'nodes': 80, 'learn_rate': 0.1, 'init_mode': 'lecun_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.17049770021345032 (0.027899872964417274) with: {'weight_constraint': 3, 'nodes': 160, 'learn_rate': 0.01, 'init_mode': 'glorot_normal', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.9, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.17823482250285044 (0.020239796281676384) with: {'weight_constraint': 4, 'nodes': 160, 'learn_rate': 0.001, 'init_mode': 'uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.4, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.15430556484627184 (0.056562221358586) with: {'weight_constraint': 2, 'nodes': 120, 'learn_rate': 0.1, 'init_mode': 'uniform', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.1814888972826823 (0.022692561767027046) with: {'weight_constraint': 2, 'nodes': 240, 'learn_rate': 0.01, 'init_mode': 'glorot_uniform', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.7000000000000001, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.19215623711371982 (0.029186308834053556) with: {'weight_constraint': 1, 'nodes': 120, 'learn_rate': 0.001, 'init_mode': 'glorot_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.0, 'batch_size': 10, 'act_func': 'relu'}\n",
            "0.193374274913719 (0.03236223627984687) with: {'weight_constraint': 1, 'nodes': 140, 'learn_rate': 0.0001, 'init_mode': 'uniform', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.0, 'batch_size': 10, 'act_func': 'relu'}\n",
            "0.1772859966959438 (0.021227401324606442) with: {'weight_constraint': 2, 'nodes': 140, 'learn_rate': 0.0001, 'init_mode': 'he_uniform', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.9, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.14910429256294827 (0.015853981505298907) with: {'weight_constraint': 1, 'nodes': 220, 'learn_rate': 0.001, 'init_mode': 'he_uniform', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.9, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.17486825126704864 (0.023396221396494585) with: {'weight_constraint': 1, 'nodes': 180, 'learn_rate': 0.001, 'init_mode': 'lecun_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.4, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.08888125558179731 (0.02763268380794088) with: {'weight_constraint': 1, 'nodes': 100, 'learn_rate': 0.1, 'init_mode': 'uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.0, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.18231767553670458 (0.02351587671525825) with: {'weight_constraint': 4, 'nodes': 100, 'learn_rate': 0.01, 'init_mode': 'he_uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.7000000000000001, 'batch_size': 40, 'act_func': 'linear'}\n",
            "0.18549765773345211 (0.03017176323497468) with: {'weight_constraint': 1, 'nodes': 180, 'learn_rate': 0.001, 'init_mode': 'glorot_normal', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.0, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.19710708624328652 (0.03406509909359429) with: {'weight_constraint': 4, 'nodes': 100, 'learn_rate': 0.001, 'init_mode': 'glorot_uniform', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.7000000000000001, 'batch_size': 10, 'act_func': 'relu'}\n",
            "0.18663628061304488 (0.03187068223185531) with: {'weight_constraint': 1, 'nodes': 140, 'learn_rate': 0.0001, 'init_mode': 'he_normal', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.5, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.13922794465319535 (0.01220043584909263) with: {'weight_constraint': 4, 'nodes': 200, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.5, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.17906962367384605 (0.020352315238497405) with: {'weight_constraint': 3, 'nodes': 80, 'learn_rate': 0.001, 'init_mode': 'glorot_normal', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.8, 'batch_size': 40, 'act_func': 'linear'}\n",
            "0.1934851878883425 (0.030954296892627253) with: {'weight_constraint': 4, 'nodes': 200, 'learn_rate': 0.0001, 'init_mode': 'normal', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.6000000000000001, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.13248078869634722 (0.013914960025242418) with: {'weight_constraint': 5, 'nodes': 240, 'learn_rate': 0.0001, 'init_mode': 'lecun_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.1, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.180790324590756 (0.02356346617393294) with: {'weight_constraint': 5, 'nodes': 80, 'learn_rate': 0.01, 'init_mode': 'glorot_normal', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.4, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.17632916176152238 (0.022371183696152343) with: {'weight_constraint': 1, 'nodes': 240, 'learn_rate': 0.0001, 'init_mode': 'uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.7000000000000001, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.19142366102158093 (0.02956201508927634) with: {'weight_constraint': 5, 'nodes': 100, 'learn_rate': 0.001, 'init_mode': 'glorot_normal', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.5, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.13462293390813865 (0.009940796689564275) with: {'weight_constraint': 2, 'nodes': 160, 'learn_rate': 0.001, 'init_mode': 'uniform', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.7000000000000001, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.16118418927118489 (0.02014631523681519) with: {'weight_constraint': 4, 'nodes': 140, 'learn_rate': 0.0001, 'init_mode': 'lecun_uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.1, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.15719084098750363 (0.04172003125118004) with: {'weight_constraint': 4, 'nodes': 180, 'learn_rate': 0.1, 'init_mode': 'uniform', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.2, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.1914576145882493 (0.028118041512916244) with: {'weight_constraint': 1, 'nodes': 240, 'learn_rate': 0.001, 'init_mode': 'glorot_normal', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.8, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.17709279336875777 (0.015863798409550364) with: {'weight_constraint': 1, 'nodes': 240, 'learn_rate': 0.0001, 'init_mode': 'he_normal', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.7000000000000001, 'batch_size': 80, 'act_func': 'relu'}\n",
            "0.18270506210367057 (0.02479957270922456) with: {'weight_constraint': 3, 'nodes': 80, 'learn_rate': 0.0001, 'init_mode': 'normal', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.6000000000000001, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.09658315512517952 (0.038333200547339644) with: {'weight_constraint': 5, 'nodes': 80, 'learn_rate': 0.0001, 'init_mode': 'he_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.17951107194360705 (0.019105500236858888) with: {'weight_constraint': 4, 'nodes': 80, 'learn_rate': 0.001, 'init_mode': 'lecun_uniform', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.30000000000000004, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.1733181730843248 (0.017928821436999837) with: {'weight_constraint': 5, 'nodes': 80, 'learn_rate': 0.001, 'init_mode': 'lecun_uniform', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.7000000000000001, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.1890062423330393 (0.03509889249275329) with: {'weight_constraint': 4, 'nodes': 160, 'learn_rate': 0.01, 'init_mode': 'uniform', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.4, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.1893676530577807 (0.021411976317694977) with: {'weight_constraint': 2, 'nodes': 100, 'learn_rate': 0.001, 'init_mode': 'he_uniform', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.13417686110102622 (0.026188538965139164) with: {'weight_constraint': 4, 'nodes': 140, 'learn_rate': 0.1, 'init_mode': 'glorot_uniform', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.14087208583374525 (0.01630784522709206) with: {'weight_constraint': 2, 'nodes': 200, 'learn_rate': 0.0001, 'init_mode': 'he_uniform', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.2, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.19450505717411953 (0.021305202322221065) with: {'weight_constraint': 5, 'nodes': 120, 'learn_rate': 0.01, 'init_mode': 'lecun_uniform', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.1, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.14350686293951306 (0.01789379528751042) with: {'weight_constraint': 1, 'nodes': 220, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.4, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.17585266015578488 (0.020577616736118413) with: {'weight_constraint': 1, 'nodes': 80, 'learn_rate': 0.0001, 'init_mode': 'uniform', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.30000000000000004, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.15228544599434132 (0.013233495942987183) with: {'weight_constraint': 4, 'nodes': 180, 'learn_rate': 0.0001, 'init_mode': 'normal', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.4, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.17063689791528855 (0.020711222258943975) with: {'weight_constraint': 5, 'nodes': 100, 'learn_rate': 0.001, 'init_mode': 'uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.4, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.18328744409279163 (0.02530563249834598) with: {'weight_constraint': 3, 'nodes': 240, 'learn_rate': 0.001, 'init_mode': 'normal', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.30000000000000004, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.18388494367760094 (0.021313985633677517) with: {'weight_constraint': 5, 'nodes': 240, 'learn_rate': 0.01, 'init_mode': 'normal', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.2, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.07762135225775527 (0.023796691273119102) with: {'weight_constraint': 4, 'nodes': 140, 'learn_rate': 0.1, 'init_mode': 'lecun_uniform', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.6000000000000001, 'batch_size': 80, 'act_func': 'relu'}\n",
            "0.18838463828124194 (0.03727887564786247) with: {'weight_constraint': 2, 'nodes': 240, 'learn_rate': 0.001, 'init_mode': 'glorot_normal', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.30000000000000004, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.19412998134717424 (0.02507448214871315) with: {'weight_constraint': 3, 'nodes': 200, 'learn_rate': 0.001, 'init_mode': 'lecun_uniform', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.18721590640958005 (0.022257772666619685) with: {'weight_constraint': 5, 'nodes': 100, 'learn_rate': 0.01, 'init_mode': 'he_uniform', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.6000000000000001, 'batch_size': 80, 'act_func': 'relu'}\n",
            "0.09251674491328994 (0.012027228014812697) with: {'weight_constraint': 4, 'nodes': 180, 'learn_rate': 0.1, 'init_mode': 'he_uniform', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.4, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.17615641789943062 (0.031605353675790156) with: {'weight_constraint': 3, 'nodes': 240, 'learn_rate': 0.1, 'init_mode': 'glorot_uniform', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.30000000000000004, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.14640569957945168 (0.014638532804687346) with: {'weight_constraint': 2, 'nodes': 180, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.18174262159669002 (0.02263241143749667) with: {'weight_constraint': 5, 'nodes': 140, 'learn_rate': 0.01, 'init_mode': 'glorot_normal', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.7000000000000001, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.16765481692950046 (0.021240155261905088) with: {'weight_constraint': 1, 'nodes': 80, 'learn_rate': 0.001, 'init_mode': 'lecun_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.2, 'batch_size': 80, 'act_func': 'relu'}\n",
            "0.0936546839770849 (0.00871564541681303) with: {'weight_constraint': 1, 'nodes': 180, 'learn_rate': 0.1, 'init_mode': 'uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.07652287072404648 (0.01222016378872728) with: {'weight_constraint': 2, 'nodes': 180, 'learn_rate': 0.1, 'init_mode': 'normal', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.6000000000000001, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.1852849005138348 (0.02799706659769802) with: {'weight_constraint': 5, 'nodes': 200, 'learn_rate': 0.001, 'init_mode': 'uniform', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.9, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.13664456756097457 (0.022487786722360355) with: {'weight_constraint': 4, 'nodes': 60, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.6000000000000001, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.18890388636727012 (0.03180081460212316) with: {'weight_constraint': 2, 'nodes': 200, 'learn_rate': 0.001, 'init_mode': 'glorot_uniform', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.6000000000000001, 'batch_size': 10, 'act_func': 'sigmoid'}\n",
            "0.14860660675613474 (0.020208000506881287) with: {'weight_constraint': 5, 'nodes': 80, 'learn_rate': 0.1, 'init_mode': 'glorot_normal', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.0, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.18363302632810638 (0.03470723518636801) with: {'weight_constraint': 3, 'nodes': 80, 'learn_rate': 0.01, 'init_mode': 'normal', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.6000000000000001, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.1889037858422245 (0.022342357050868917) with: {'weight_constraint': 1, 'nodes': 180, 'learn_rate': 0.01, 'init_mode': 'uniform', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.1, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.17680585944483798 (0.019086330248756764) with: {'weight_constraint': 2, 'nodes': 120, 'learn_rate': 0.0001, 'init_mode': 'uniform', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.18875732897097236 (0.030316323943051452) with: {'weight_constraint': 1, 'nodes': 180, 'learn_rate': 0.001, 'init_mode': 'he_uniform', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.5, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.1916681963944762 (0.0189700987595888) with: {'weight_constraint': 3, 'nodes': 160, 'learn_rate': 0.001, 'init_mode': 'lecun_uniform', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.30000000000000004, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.1200408614467717 (0.07058492189600145) with: {'weight_constraint': 3, 'nodes': 140, 'learn_rate': 0.1, 'init_mode': 'normal', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.1, 'batch_size': 10, 'act_func': 'sigmoid'}\n",
            "0.18561617949673126 (0.02651227060283987) with: {'weight_constraint': 4, 'nodes': 200, 'learn_rate': 0.001, 'init_mode': 'lecun_uniform', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.6000000000000001, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.17623891440025766 (0.017950217955568556) with: {'weight_constraint': 1, 'nodes': 80, 'learn_rate': 0.001, 'init_mode': 'glorot_normal', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.9, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.1853444301218535 (0.025704443754769397) with: {'weight_constraint': 3, 'nodes': 160, 'learn_rate': 0.0001, 'init_mode': 'he_uniform', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.5, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.17770297998213963 (0.021255984072464155) with: {'weight_constraint': 3, 'nodes': 60, 'learn_rate': 0.0001, 'init_mode': 'uniform', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.8, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.0488997555012225 (0.0) with: {'weight_constraint': 2, 'nodes': 80, 'learn_rate': 0.1, 'init_mode': 'glorot_uniform', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.8, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.18755652151489344 (0.020768281168173593) with: {'weight_constraint': 5, 'nodes': 200, 'learn_rate': 0.01, 'init_mode': 'he_normal', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.1, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.1937283823204978 (0.029638231689781115) with: {'weight_constraint': 2, 'nodes': 240, 'learn_rate': 0.0001, 'init_mode': 'he_normal', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.0, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.1172587179481515 (0.027507439064206884) with: {'weight_constraint': 4, 'nodes': 200, 'learn_rate': 0.1, 'init_mode': 'glorot_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.18855210175341602 (0.03462264498448923) with: {'weight_constraint': 2, 'nodes': 180, 'learn_rate': 0.01, 'init_mode': 'normal', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.9, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.1510527312214131 (0.01741310393109986) with: {'weight_constraint': 5, 'nodes': 80, 'learn_rate': 0.1, 'init_mode': 'uniform', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.6000000000000001, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.18377514925269406 (0.02561934151141514) with: {'weight_constraint': 2, 'nodes': 200, 'learn_rate': 0.1, 'init_mode': 'lecun_uniform', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.5, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.16868345618913533 (0.014236870430104503) with: {'weight_constraint': 2, 'nodes': 100, 'learn_rate': 0.1, 'init_mode': 'he_normal', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.5, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.14585708693621374 (0.012223168954177709) with: {'weight_constraint': 3, 'nodes': 160, 'learn_rate': 0.0001, 'init_mode': 'lecun_uniform', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.8, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.190382886319996 (0.020037577265047537) with: {'weight_constraint': 3, 'nodes': 80, 'learn_rate': 0.001, 'init_mode': 'he_uniform', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.1, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.18468099297431267 (0.026877414659998922) with: {'weight_constraint': 5, 'nodes': 220, 'learn_rate': 0.001, 'init_mode': 'he_normal', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.2, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.15787036137378133 (0.01471046428066284) with: {'weight_constraint': 1, 'nodes': 200, 'learn_rate': 0.1, 'init_mode': 'he_normal', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.7000000000000001, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.18859743183493682 (0.028873619268059585) with: {'weight_constraint': 2, 'nodes': 160, 'learn_rate': 0.0001, 'init_mode': 'normal', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.16654169040021546 (0.027022129678566133) with: {'weight_constraint': 1, 'nodes': 160, 'learn_rate': 0.0001, 'init_mode': 'lecun_uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.8, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.19419101287350984 (0.024564554442125658) with: {'weight_constraint': 5, 'nodes': 240, 'learn_rate': 0.001, 'init_mode': 'glorot_normal', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.5, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.19225852848314967 (0.019184148922975115) with: {'weight_constraint': 5, 'nodes': 80, 'learn_rate': 0.001, 'init_mode': 'glorot_uniform', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.30000000000000004, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.1797106299473754 (0.021019337485581213) with: {'weight_constraint': 5, 'nodes': 240, 'learn_rate': 0.001, 'init_mode': 'glorot_uniform', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.1, 'batch_size': 10, 'act_func': 'sigmoid'}\n",
            "0.18945244265227468 (0.03776346985212469) with: {'weight_constraint': 1, 'nodes': 100, 'learn_rate': 0.001, 'init_mode': 'glorot_normal', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.0, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.17263125451719868 (0.022509124006811883) with: {'weight_constraint': 3, 'nodes': 160, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.2, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.18859093681011382 (0.02643852448265382) with: {'weight_constraint': 1, 'nodes': 220, 'learn_rate': 0.0001, 'init_mode': 'glorot_uniform', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.30000000000000004, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.1390611343045925 (0.010764286353911664) with: {'weight_constraint': 3, 'nodes': 120, 'learn_rate': 0.0001, 'init_mode': 'normal', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.6000000000000001, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.15390887109033338 (0.016463163659518686) with: {'weight_constraint': 2, 'nodes': 120, 'learn_rate': 0.1, 'init_mode': 'glorot_uniform', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.7000000000000001, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.18817586791243984 (0.024428306448521658) with: {'weight_constraint': 1, 'nodes': 200, 'learn_rate': 0.0001, 'init_mode': 'normal', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.6000000000000001, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.18695222638525466 (0.025747716994598817) with: {'weight_constraint': 1, 'nodes': 120, 'learn_rate': 0.01, 'init_mode': 'he_normal', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.5, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.1941353070573934 (0.029602617503119964) with: {'weight_constraint': 2, 'nodes': 60, 'learn_rate': 0.001, 'init_mode': 'glorot_normal', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.4, 'batch_size': 10, 'act_func': 'relu'}\n",
            "0.18905077611542037 (0.024690074155364058) with: {'weight_constraint': 2, 'nodes': 220, 'learn_rate': 0.0001, 'init_mode': 'lecun_uniform', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.7000000000000001, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.18651906052968542 (0.02686281906429743) with: {'weight_constraint': 1, 'nodes': 60, 'learn_rate': 0.1, 'init_mode': 'glorot_normal', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.7000000000000001, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.17054840919471842 (0.019180056810576298) with: {'weight_constraint': 3, 'nodes': 240, 'learn_rate': 0.01, 'init_mode': 'he_uniform', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.30000000000000004, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.1876360649928813 (0.02346285250971929) with: {'weight_constraint': 3, 'nodes': 240, 'learn_rate': 0.0001, 'init_mode': 'he_normal', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.2, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.15831026338480814 (0.01322704671719544) with: {'weight_constraint': 3, 'nodes': 140, 'learn_rate': 0.0001, 'init_mode': 'uniform', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.4, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.18977755096636278 (0.029535524006630683) with: {'weight_constraint': 2, 'nodes': 240, 'learn_rate': 0.001, 'init_mode': 'glorot_uniform', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.4, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.18577399565350247 (0.03572731211325429) with: {'weight_constraint': 4, 'nodes': 60, 'learn_rate': 0.001, 'init_mode': 'normal', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.1, 'batch_size': 10, 'act_func': 'sigmoid'}\n",
            "0.14489908987047964 (0.01175557701484779) with: {'weight_constraint': 5, 'nodes': 120, 'learn_rate': 0.001, 'init_mode': 'normal', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.6000000000000001, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.15804067222605658 (0.019507815703693848) with: {'weight_constraint': 4, 'nodes': 220, 'learn_rate': 0.01, 'init_mode': 'he_normal', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.6000000000000001, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.18845264489907682 (0.03605183248199064) with: {'weight_constraint': 2, 'nodes': 100, 'learn_rate': 0.01, 'init_mode': 'glorot_uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.0, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.18978936060696577 (0.03192163050881286) with: {'weight_constraint': 5, 'nodes': 60, 'learn_rate': 0.1, 'init_mode': 'normal', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.2, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.17906503656143943 (0.02677638139882742) with: {'weight_constraint': 5, 'nodes': 200, 'learn_rate': 0.001, 'init_mode': 'uniform', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.6000000000000001, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.13682114629475908 (0.03155470999783472) with: {'weight_constraint': 4, 'nodes': 80, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.2, 'batch_size': 80, 'act_func': 'relu'}\n",
            "0.1910075485096213 (0.030391844166920944) with: {'weight_constraint': 4, 'nodes': 160, 'learn_rate': 0.0001, 'init_mode': 'uniform', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.7000000000000001, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.1769541399932546 (0.01777398658480826) with: {'weight_constraint': 5, 'nodes': 220, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.9, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.09522541189761871 (0.027320062155052355) with: {'weight_constraint': 3, 'nodes': 160, 'learn_rate': 0.1, 'init_mode': 'he_uniform', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.30000000000000004, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.19036517546246076 (0.033953584711939495) with: {'weight_constraint': 5, 'nodes': 100, 'learn_rate': 0.0001, 'init_mode': 'uniform', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.1, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.19286539453691626 (0.027581954772480797) with: {'weight_constraint': 2, 'nodes': 100, 'learn_rate': 0.0001, 'init_mode': 'lecun_uniform', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.2, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.18957266284033825 (0.0300659831941669) with: {'weight_constraint': 1, 'nodes': 220, 'learn_rate': 0.0001, 'init_mode': 'he_normal', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.2, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.1813744971309637 (0.02355365727376202) with: {'weight_constraint': 1, 'nodes': 180, 'learn_rate': 0.001, 'init_mode': 'glorot_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.2, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.1803917132120163 (0.023802708120618857) with: {'weight_constraint': 3, 'nodes': 100, 'learn_rate': 0.001, 'init_mode': 'uniform', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.9, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.18575558787090823 (0.020412512727435845) with: {'weight_constraint': 3, 'nodes': 100, 'learn_rate': 0.01, 'init_mode': 'he_uniform', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.30000000000000004, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.19026231697387716 (0.022686027660419345) with: {'weight_constraint': 3, 'nodes': 240, 'learn_rate': 0.001, 'init_mode': 'he_uniform', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.0, 'batch_size': 10, 'act_func': 'sigmoid'}\n",
            "0.19056232071649187 (0.031227008784926968) with: {'weight_constraint': 3, 'nodes': 200, 'learn_rate': 0.01, 'init_mode': 'normal', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.5, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.18221052778982572 (0.023756646910357893) with: {'weight_constraint': 2, 'nodes': 140, 'learn_rate': 0.01, 'init_mode': 'he_uniform', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.4, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.17610430520660367 (0.016673277672137627) with: {'weight_constraint': 4, 'nodes': 160, 'learn_rate': 0.01, 'init_mode': 'lecun_uniform', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.0, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.1780775363372748 (0.01739538982693793) with: {'weight_constraint': 1, 'nodes': 240, 'learn_rate': 0.001, 'init_mode': 'glorot_normal', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.17843671274982406 (0.020696731140853793) with: {'weight_constraint': 5, 'nodes': 200, 'learn_rate': 0.01, 'init_mode': 'he_normal', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.1, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.1860741447808721 (0.029885678414103497) with: {'weight_constraint': 3, 'nodes': 80, 'learn_rate': 0.1, 'init_mode': 'uniform', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.0, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.06723813006930081 (0.02227736440172363) with: {'weight_constraint': 2, 'nodes': 200, 'learn_rate': 0.1, 'init_mode': 'he_normal', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.2, 'batch_size': 10, 'act_func': 'relu'}\n",
            "0.18928686269017472 (0.03563847035535307) with: {'weight_constraint': 5, 'nodes': 80, 'learn_rate': 0.01, 'init_mode': 'normal', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.1, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.1914198203433309 (0.026262980798767235) with: {'weight_constraint': 1, 'nodes': 100, 'learn_rate': 0.01, 'init_mode': 'glorot_uniform', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.1, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.19009814172252854 (0.03078987898945273) with: {'weight_constraint': 1, 'nodes': 140, 'learn_rate': 0.01, 'init_mode': 'normal', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.8, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.08944460093274201 (0.010304252723039422) with: {'weight_constraint': 3, 'nodes': 240, 'learn_rate': 0.1, 'init_mode': 'uniform', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.1082100313759959 (0.03909953954175708) with: {'weight_constraint': 5, 'nodes': 160, 'learn_rate': 0.1, 'init_mode': 'he_uniform', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.30000000000000004, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.17526222630330315 (0.016433814941438484) with: {'weight_constraint': 5, 'nodes': 160, 'learn_rate': 0.001, 'init_mode': 'glorot_uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.5, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.19271323663652784 (0.02218188505159714) with: {'weight_constraint': 5, 'nodes': 160, 'learn_rate': 0.0001, 'init_mode': 'lecun_uniform', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.5, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.18997867347000572 (0.03325492401222806) with: {'weight_constraint': 5, 'nodes': 120, 'learn_rate': 0.01, 'init_mode': 'glorot_uniform', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.5, 'batch_size': 40, 'act_func': 'linear'}\n",
            "0.187399032920895 (0.024539382285767193) with: {'weight_constraint': 5, 'nodes': 80, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.4, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.1891260072848434 (0.03121377929375946) with: {'weight_constraint': 2, 'nodes': 160, 'learn_rate': 0.001, 'init_mode': 'uniform', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.8, 'batch_size': 40, 'act_func': 'linear'}\n",
            "0.12495632312882417 (0.044388165702078215) with: {'weight_constraint': 1, 'nodes': 180, 'learn_rate': 0.1, 'init_mode': 'glorot_uniform', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.8, 'batch_size': 40, 'act_func': 'linear'}\n",
            "0.18601844461673805 (0.021283823365596272) with: {'weight_constraint': 4, 'nodes': 120, 'learn_rate': 0.001, 'init_mode': 'lecun_uniform', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.30000000000000004, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.1844457094744348 (0.029680305356228013) with: {'weight_constraint': 1, 'nodes': 240, 'learn_rate': 0.01, 'init_mode': 'he_uniform', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.7000000000000001, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.16128737897425402 (0.026088556820366933) with: {'weight_constraint': 4, 'nodes': 60, 'learn_rate': 0.1, 'init_mode': 'glorot_uniform', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.9, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.16308383607486923 (0.016708239608133904) with: {'weight_constraint': 3, 'nodes': 160, 'learn_rate': 0.01, 'init_mode': 'he_normal', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.6000000000000001, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.18575322461097016 (0.024571494688026253) with: {'weight_constraint': 4, 'nodes': 100, 'learn_rate': 0.0001, 'init_mode': 'he_uniform', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.8, 'batch_size': 10, 'act_func': 'sigmoid'}\n",
            "0.18853726576956914 (0.02655940492918638) with: {'weight_constraint': 3, 'nodes': 120, 'learn_rate': 0.001, 'init_mode': 'he_uniform', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.9, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.1443281713411424 (0.03701885256819828) with: {'weight_constraint': 4, 'nodes': 200, 'learn_rate': 0.1, 'init_mode': 'normal', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.30000000000000004, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.19150352520243846 (0.0314912498369444) with: {'weight_constraint': 1, 'nodes': 60, 'learn_rate': 0.001, 'init_mode': 'lecun_uniform', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.6000000000000001, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.18818002822912594 (0.028803575725867652) with: {'weight_constraint': 5, 'nodes': 160, 'learn_rate': 0.01, 'init_mode': 'he_uniform', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.6000000000000001, 'batch_size': 80, 'act_func': 'relu'}\n",
            "0.15171277592883942 (0.013268839701002677) with: {'weight_constraint': 5, 'nodes': 140, 'learn_rate': 0.1, 'init_mode': 'lecun_uniform', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.1, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.18767742547309313 (0.03143257242570679) with: {'weight_constraint': 5, 'nodes': 140, 'learn_rate': 0.001, 'init_mode': 'uniform', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.6000000000000001, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.17112535148471797 (0.018555884606031147) with: {'weight_constraint': 3, 'nodes': 200, 'learn_rate': 0.0001, 'init_mode': 'glorot_uniform', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.8, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.19365158987394926 (0.031406041120975066) with: {'weight_constraint': 5, 'nodes': 140, 'learn_rate': 0.001, 'init_mode': 'glorot_uniform', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.2, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.17597088000101885 (0.02765981479398613) with: {'weight_constraint': 2, 'nodes': 80, 'learn_rate': 0.01, 'init_mode': 'glorot_uniform', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.8, 'batch_size': 10, 'act_func': 'relu'}\n",
            "0.1322007465370696 (0.010178117695205737) with: {'weight_constraint': 2, 'nodes': 180, 'learn_rate': 0.001, 'init_mode': 'glorot_uniform', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.9, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.12444397732108647 (0.04144191078332353) with: {'weight_constraint': 5, 'nodes': 220, 'learn_rate': 0.1, 'init_mode': 'he_uniform', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.6000000000000001, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.1697374029612197 (0.01715800491885404) with: {'weight_constraint': 1, 'nodes': 240, 'learn_rate': 0.0001, 'init_mode': 'glorot_uniform', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.7000000000000001, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.17646721377752445 (0.02853723006426663) with: {'weight_constraint': 1, 'nodes': 60, 'learn_rate': 0.1, 'init_mode': 'glorot_normal', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.2, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.18608121981715325 (0.01989893858430929) with: {'weight_constraint': 1, 'nodes': 220, 'learn_rate': 0.001, 'init_mode': 'he_normal', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.30000000000000004, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.19118808622995712 (0.03216315109564648) with: {'weight_constraint': 2, 'nodes': 100, 'learn_rate': 0.01, 'init_mode': 'glorot_uniform', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 80, 'act_func': 'relu'}\n",
            "0.1442186661794465 (0.0104231524763541) with: {'weight_constraint': 2, 'nodes': 160, 'learn_rate': 0.0001, 'init_mode': 'glorot_uniform', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.4, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.19295671204426293 (0.029106502886365543) with: {'weight_constraint': 3, 'nodes': 180, 'learn_rate': 0.001, 'init_mode': 'uniform', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 80, 'act_func': 'relu'}\n",
            "0.15618353749517172 (0.050698188226736246) with: {'weight_constraint': 2, 'nodes': 120, 'learn_rate': 0.1, 'init_mode': 'glorot_uniform', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.17340244670364308 (0.028753821619139194) with: {'weight_constraint': 4, 'nodes': 120, 'learn_rate': 0.1, 'init_mode': 'he_uniform', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.30000000000000004, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.18802166577010804 (0.02512327511849913) with: {'weight_constraint': 4, 'nodes': 80, 'learn_rate': 0.001, 'init_mode': 'glorot_uniform', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.9, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.17534175113644118 (0.01811779973853296) with: {'weight_constraint': 5, 'nodes': 200, 'learn_rate': 0.0001, 'init_mode': 'normal', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.7000000000000001, 'batch_size': 40, 'act_func': 'linear'}\n",
            "0.1767924867063593 (0.025290985484818) with: {'weight_constraint': 3, 'nodes': 100, 'learn_rate': 0.01, 'init_mode': 'he_uniform', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.6000000000000001, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.19487273500344163 (0.027523599018933836) with: {'weight_constraint': 2, 'nodes': 80, 'learn_rate': 0.1, 'init_mode': 'normal', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.1, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.18438612263921333 (0.026786066083945525) with: {'weight_constraint': 2, 'nodes': 120, 'learn_rate': 0.01, 'init_mode': 'he_uniform', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.6000000000000001, 'batch_size': 10, 'act_func': 'sigmoid'}\n",
            "0.18598919572850087 (0.02782027542124701) with: {'weight_constraint': 2, 'nodes': 180, 'learn_rate': 0.01, 'init_mode': 'lecun_uniform', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.9, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.16977925568895086 (0.023004387556710845) with: {'weight_constraint': 4, 'nodes': 200, 'learn_rate': 0.01, 'init_mode': 'he_uniform', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.2, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.19111674434739134 (0.02416297284741566) with: {'weight_constraint': 5, 'nodes': 240, 'learn_rate': 0.001, 'init_mode': 'he_normal', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 10, 'act_func': 'sigmoid'}\n",
            "0.18187861275734785 (0.02319487285597366) with: {'weight_constraint': 5, 'nodes': 220, 'learn_rate': 0.001, 'init_mode': 'lecun_uniform', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.6000000000000001, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.13349375760142776 (0.011714429895832141) with: {'weight_constraint': 4, 'nodes': 200, 'learn_rate': 0.0001, 'init_mode': 'glorot_uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.6000000000000001, 'batch_size': 40, 'act_func': 'linear'}\n",
            "0.1839392450737461 (0.024521680729243128) with: {'weight_constraint': 2, 'nodes': 100, 'learn_rate': 0.01, 'init_mode': 'normal', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.8, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.1279229876179048 (0.010136351723972752) with: {'weight_constraint': 4, 'nodes': 220, 'learn_rate': 0.0001, 'init_mode': 'glorot_uniform', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.0, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.18552969425428456 (0.02040717978611682) with: {'weight_constraint': 4, 'nodes': 140, 'learn_rate': 0.01, 'init_mode': 'glorot_uniform', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.4, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.18468818569488693 (0.02923511998925329) with: {'weight_constraint': 3, 'nodes': 160, 'learn_rate': 0.01, 'init_mode': 'uniform', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.4, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.19530442000875972 (0.027190881672947354) with: {'weight_constraint': 2, 'nodes': 80, 'learn_rate': 0.001, 'init_mode': 'he_normal', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.1561592462124764 (0.01388529724431973) with: {'weight_constraint': 5, 'nodes': 180, 'learn_rate': 0.0001, 'init_mode': 'glorot_uniform', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.4, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.1946921683961675 (0.0259812153381088) with: {'weight_constraint': 4, 'nodes': 140, 'learn_rate': 0.001, 'init_mode': 'glorot_normal', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.7000000000000001, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.18293558968666473 (0.031052116849563608) with: {'weight_constraint': 4, 'nodes': 220, 'learn_rate': 0.001, 'init_mode': 'he_uniform', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.4, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.19172445658574272 (0.03856847268792724) with: {'weight_constraint': 5, 'nodes': 220, 'learn_rate': 0.0001, 'init_mode': 'lecun_uniform', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.1, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.18956300160523007 (0.02762560745578363) with: {'weight_constraint': 3, 'nodes': 240, 'learn_rate': 0.0001, 'init_mode': 'normal', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.8, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.19141352403036954 (0.0309018371942678) with: {'weight_constraint': 1, 'nodes': 160, 'learn_rate': 0.01, 'init_mode': 'he_uniform', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.7000000000000001, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.18538986673576235 (0.023316761213588246) with: {'weight_constraint': 4, 'nodes': 120, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.2, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.18953951366538493 (0.031288855160939856) with: {'weight_constraint': 3, 'nodes': 240, 'learn_rate': 0.0001, 'init_mode': 'glorot_uniform', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.0, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.18314733872280392 (0.01901245667014617) with: {'weight_constraint': 3, 'nodes': 180, 'learn_rate': 0.01, 'init_mode': 'uniform', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.9, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.17667361167382936 (0.021871674331054997) with: {'weight_constraint': 4, 'nodes': 80, 'learn_rate': 0.0001, 'init_mode': 'glorot_uniform', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.30000000000000004, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.14675909398627804 (0.011867804878615804) with: {'weight_constraint': 4, 'nodes': 80, 'learn_rate': 0.0001, 'init_mode': 'he_uniform', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.9, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.19165511271437746 (0.03359331565627861) with: {'weight_constraint': 2, 'nodes': 220, 'learn_rate': 0.001, 'init_mode': 'uniform', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.6000000000000001, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.17331087255010488 (0.014495108579786316) with: {'weight_constraint': 1, 'nodes': 60, 'learn_rate': 0.001, 'init_mode': 'he_normal', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.8, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.18331324296847484 (0.024481039196795826) with: {'weight_constraint': 3, 'nodes': 120, 'learn_rate': 0.01, 'init_mode': 'lecun_uniform', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.8, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.15071071629260807 (0.010248289689064738) with: {'weight_constraint': 2, 'nodes': 180, 'learn_rate': 0.001, 'init_mode': 'uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.0, 'batch_size': 80, 'act_func': 'relu'}\n",
            "0.1628409385795802 (0.020142812671721255) with: {'weight_constraint': 2, 'nodes': 80, 'learn_rate': 0.0001, 'init_mode': 'glorot_uniform', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.1, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.18170803283992984 (0.029494255431012945) with: {'weight_constraint': 5, 'nodes': 100, 'learn_rate': 0.1, 'init_mode': 'lecun_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.1, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.18817361737557556 (0.03349651399373106) with: {'weight_constraint': 4, 'nodes': 160, 'learn_rate': 0.0001, 'init_mode': 'normal', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.30000000000000004, 'batch_size': 10, 'act_func': 'relu'}\n",
            "0.18884060582712753 (0.029913706099001774) with: {'weight_constraint': 5, 'nodes': 140, 'learn_rate': 0.01, 'init_mode': 'glorot_normal', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.2, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.16024659807657035 (0.02832618018518806) with: {'weight_constraint': 5, 'nodes': 240, 'learn_rate': 0.1, 'init_mode': 'normal', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.5, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.17224465381410178 (0.03526367431849558) with: {'weight_constraint': 4, 'nodes': 100, 'learn_rate': 0.1, 'init_mode': 'he_normal', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.5, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.19010830235216744 (0.03266205532644088) with: {'weight_constraint': 5, 'nodes': 220, 'learn_rate': 0.01, 'init_mode': 'glorot_normal', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.6000000000000001, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.18989425659309184 (0.032938114829880516) with: {'weight_constraint': 5, 'nodes': 140, 'learn_rate': 0.01, 'init_mode': 'glorot_uniform', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.6000000000000001, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.15721562066536482 (0.01716347901573552) with: {'weight_constraint': 5, 'nodes': 60, 'learn_rate': 0.0001, 'init_mode': 'lecun_uniform', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.2, 'batch_size': 40, 'act_func': 'linear'}\n",
            "0.16419519244483977 (0.03705828253078579) with: {'weight_constraint': 4, 'nodes': 120, 'learn_rate': 0.1, 'init_mode': 'he_normal', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.30000000000000004, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.050488911136194733 (0.00475418657439584) with: {'weight_constraint': 3, 'nodes': 80, 'learn_rate': 0.1, 'init_mode': 'glorot_uniform', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.7000000000000001, 'batch_size': 10, 'act_func': 'relu'}\n",
            "0.18520649688947136 (0.02738133568133828) with: {'weight_constraint': 5, 'nodes': 160, 'learn_rate': 0.01, 'init_mode': 'he_uniform', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.7000000000000001, 'batch_size': 10, 'act_func': 'relu'}\n",
            "0.1899804557529124 (0.03149653175052971) with: {'weight_constraint': 3, 'nodes': 220, 'learn_rate': 0.01, 'init_mode': 'glorot_uniform', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.6000000000000001, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.18019700012266762 (0.02027909797216517) with: {'weight_constraint': 1, 'nodes': 200, 'learn_rate': 0.001, 'init_mode': 'normal', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.5, 'batch_size': 10, 'act_func': 'relu'}\n",
            "0.17902001996746814 (0.0200483647789202) with: {'weight_constraint': 3, 'nodes': 180, 'learn_rate': 0.01, 'init_mode': 'glorot_normal', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.2, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.17091460919168666 (0.026590517615645248) with: {'weight_constraint': 1, 'nodes': 120, 'learn_rate': 0.1, 'init_mode': 'uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 10, 'act_func': 'sigmoid'}\n",
            "0.16331567598131774 (0.010510146287434987) with: {'weight_constraint': 5, 'nodes': 140, 'learn_rate': 0.0001, 'init_mode': 'uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.30000000000000004, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.18496790973118776 (0.029010780452439468) with: {'weight_constraint': 3, 'nodes': 160, 'learn_rate': 0.001, 'init_mode': 'normal', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.2, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.18597129833003287 (0.03813474671888161) with: {'weight_constraint': 2, 'nodes': 100, 'learn_rate': 0.1, 'init_mode': 'he_uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.30000000000000004, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.17870978774193674 (0.02210698298903406) with: {'weight_constraint': 4, 'nodes': 140, 'learn_rate': 0.001, 'init_mode': 'he_normal', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.9, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.1791424412931922 (0.02518065115415565) with: {'weight_constraint': 3, 'nodes': 120, 'learn_rate': 0.01, 'init_mode': 'he_normal', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.2, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.18993701066796825 (0.0229353922723796) with: {'weight_constraint': 5, 'nodes': 80, 'learn_rate': 0.0001, 'init_mode': 'glorot_uniform', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.0, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.1917677743948689 (0.03068162516403433) with: {'weight_constraint': 1, 'nodes': 100, 'learn_rate': 0.001, 'init_mode': 'normal', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.8, 'batch_size': 80, 'act_func': 'relu'}\n",
            "0.1936642690441747 (0.03090307970330357) with: {'weight_constraint': 5, 'nodes': 160, 'learn_rate': 0.0001, 'init_mode': 'uniform', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.4, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.1481946715728811 (0.021048560955513298) with: {'weight_constraint': 2, 'nodes': 160, 'learn_rate': 0.0001, 'init_mode': 'he_uniform', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.9, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.17164917461433288 (0.018080489412417546) with: {'weight_constraint': 2, 'nodes': 180, 'learn_rate': 0.1, 'init_mode': 'he_normal', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.0, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.17162987118602163 (0.02418075509205194) with: {'weight_constraint': 5, 'nodes': 180, 'learn_rate': 0.0001, 'init_mode': 'lecun_uniform', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.2, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.15942878055004145 (0.02200126301619455) with: {'weight_constraint': 1, 'nodes': 200, 'learn_rate': 0.1, 'init_mode': 'uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.6000000000000001, 'batch_size': 20, 'act_func': 'elu'}\n",
            "0.15903878047254105 (0.015085905653652143) with: {'weight_constraint': 1, 'nodes': 160, 'learn_rate': 0.001, 'init_mode': 'he_normal', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.9, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.18937837208972363 (0.03407074814347308) with: {'weight_constraint': 4, 'nodes': 140, 'learn_rate': 0.01, 'init_mode': 'glorot_normal', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.6000000000000001, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.1795586253434854 (0.027147588098641987) with: {'weight_constraint': 5, 'nodes': 80, 'learn_rate': 0.01, 'init_mode': 'uniform', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.7000000000000001, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.18389217858501122 (0.027619837740217576) with: {'weight_constraint': 5, 'nodes': 200, 'learn_rate': 0.01, 'init_mode': 'lecun_uniform', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.4, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.1887351674845683 (0.018768149642431703) with: {'weight_constraint': 5, 'nodes': 180, 'learn_rate': 0.001, 'init_mode': 'uniform', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.30000000000000004, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.17380692842356388 (0.01860239254897979) with: {'weight_constraint': 2, 'nodes': 240, 'learn_rate': 0.0001, 'init_mode': 'uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.15865993734033848 (0.012984661792016072) with: {'weight_constraint': 1, 'nodes': 60, 'learn_rate': 0.0001, 'init_mode': 'normal', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.1, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.08445253344439921 (0.022122414463128168) with: {'weight_constraint': 3, 'nodes': 160, 'learn_rate': 0.1, 'init_mode': 'glorot_uniform', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.4, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.18977014530041864 (0.0278788267444783) with: {'weight_constraint': 3, 'nodes': 240, 'learn_rate': 0.0001, 'init_mode': 'lecun_uniform', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.0, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.19266021369304634 (0.03273145181027021) with: {'weight_constraint': 1, 'nodes': 200, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.5, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.17166638486656607 (0.018999568517546014) with: {'weight_constraint': 1, 'nodes': 240, 'learn_rate': 0.1, 'init_mode': 'uniform', 'epsilon': 0.001, 'epochs': 100, 'drop_rate': 0.1, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.18397601539967487 (0.02397401933062827) with: {'weight_constraint': 1, 'nodes': 180, 'learn_rate': 0.0001, 'init_mode': 'normal', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.9, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.1933912760996682 (0.029455854493141902) with: {'weight_constraint': 2, 'nodes': 220, 'learn_rate': 0.001, 'init_mode': 'he_normal', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.7000000000000001, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.17827571169396608 (0.02775475990990721) with: {'weight_constraint': 4, 'nodes': 180, 'learn_rate': 0.01, 'init_mode': 'he_normal', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.0, 'batch_size': 10, 'act_func': 'linear'}\n",
            "0.1915122316159377 (0.021441198194309594) with: {'weight_constraint': 2, 'nodes': 100, 'learn_rate': 0.001, 'init_mode': 'lecun_uniform', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.1, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.1822215641810419 (0.028005054567429296) with: {'weight_constraint': 2, 'nodes': 160, 'learn_rate': 0.01, 'init_mode': 'normal', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.7000000000000001, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.16508536647679736 (0.025628428582404755) with: {'weight_constraint': 3, 'nodes': 100, 'learn_rate': 0.01, 'init_mode': 'he_uniform', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.1, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.18228633315158704 (0.02705199088382273) with: {'weight_constraint': 1, 'nodes': 80, 'learn_rate': 0.01, 'init_mode': 'he_normal', 'epsilon': 1e-07, 'epochs': 100, 'drop_rate': 0.6000000000000001, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.152666676107724 (0.018152367430011734) with: {'weight_constraint': 3, 'nodes': 80, 'learn_rate': 0.001, 'init_mode': 'glorot_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.1, 'batch_size': 80, 'act_func': 'relu'}\n",
            "0.16427535290365966 (0.029376633249989938) with: {'weight_constraint': 3, 'nodes': 120, 'learn_rate': 0.1, 'init_mode': 'he_normal', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.7000000000000001, 'batch_size': 60, 'act_func': 'relu'}\n",
            "0.18400456425213402 (0.024495056006420563) with: {'weight_constraint': 2, 'nodes': 80, 'learn_rate': 0.01, 'init_mode': 'he_normal', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.1874792506384597 (0.03045103519811853) with: {'weight_constraint': 3, 'nodes': 140, 'learn_rate': 0.001, 'init_mode': 'glorot_uniform', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.6000000000000001, 'batch_size': 80, 'act_func': 'sigmoid'}\n",
            "0.18718126249625197 (0.030971353329488978) with: {'weight_constraint': 2, 'nodes': 100, 'learn_rate': 0.01, 'init_mode': 'glorot_normal', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.7000000000000001, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.13537362973765804 (0.012456327855457158) with: {'weight_constraint': 2, 'nodes': 120, 'learn_rate': 0.0001, 'init_mode': 'glorot_uniform', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.9, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.17340953402392673 (0.01795613768370402) with: {'weight_constraint': 4, 'nodes': 140, 'learn_rate': 0.01, 'init_mode': 'he_normal', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.9, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.17041757606814958 (0.016718807752274866) with: {'weight_constraint': 1, 'nodes': 120, 'learn_rate': 0.0001, 'init_mode': 'glorot_uniform', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.4, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.16547897428794323 (0.012788756794353612) with: {'weight_constraint': 3, 'nodes': 220, 'learn_rate': 0.0001, 'init_mode': 'glorot_uniform', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.4, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.16592368227835866 (0.026895136905537968) with: {'weight_constraint': 1, 'nodes': 60, 'learn_rate': 0.0001, 'init_mode': 'normal', 'epsilon': 0.1, 'epochs': 50, 'drop_rate': 0.9, 'batch_size': 40, 'act_func': 'sigmoid'}\n",
            "0.18844950459582877 (0.02954051958177964) with: {'weight_constraint': 5, 'nodes': 80, 'learn_rate': 0.01, 'init_mode': 'glorot_normal', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.1, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.19018548637773644 (0.027412812545780586) with: {'weight_constraint': 2, 'nodes': 200, 'learn_rate': 0.01, 'init_mode': 'he_normal', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.9, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.17905634658206657 (0.03635739196316884) with: {'weight_constraint': 3, 'nodes': 100, 'learn_rate': 0.01, 'init_mode': 'glorot_uniform', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.6000000000000001, 'batch_size': 10, 'act_func': 'sigmoid'}\n",
            "0.1825946802599012 (0.038797360127512205) with: {'weight_constraint': 3, 'nodes': 60, 'learn_rate': 0.1, 'init_mode': 'he_normal', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.4, 'batch_size': 40, 'act_func': 'linear'}\n",
            "0.1711974686879587 (0.025212447486396197) with: {'weight_constraint': 3, 'nodes': 200, 'learn_rate': 0.1, 'init_mode': 'he_normal', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.6000000000000001, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.162027078189288 (0.015116046996388912) with: {'weight_constraint': 2, 'nodes': 60, 'learn_rate': 0.001, 'init_mode': 'glorot_uniform', 'epsilon': 1, 'epochs': 200, 'drop_rate': 0.9, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.14482108752209064 (0.019942958441605922) with: {'weight_constraint': 4, 'nodes': 140, 'learn_rate': 0.0001, 'init_mode': 'glorot_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.5, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.18853490160374847 (0.025056651627850368) with: {'weight_constraint': 5, 'nodes': 60, 'learn_rate': 0.001, 'init_mode': 'normal', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.1, 'batch_size': 10, 'act_func': 'sigmoid'}\n",
            "0.18858037852217982 (0.03701896708192507) with: {'weight_constraint': 3, 'nodes': 160, 'learn_rate': 0.0001, 'init_mode': 'glorot_uniform', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.2, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.19003529502180252 (0.02774534512934825) with: {'weight_constraint': 4, 'nodes': 200, 'learn_rate': 0.0001, 'init_mode': 'normal', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.7000000000000001, 'batch_size': 60, 'act_func': 'elu'}\n",
            "0.15602018582655566 (0.029741081827562202) with: {'weight_constraint': 2, 'nodes': 80, 'learn_rate': 0.1, 'init_mode': 'he_normal', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.7000000000000001, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.18422154266960106 (0.022246851961316347) with: {'weight_constraint': 2, 'nodes': 240, 'learn_rate': 0.01, 'init_mode': 'uniform', 'epsilon': 1e-05, 'epochs': 100, 'drop_rate': 0.0, 'batch_size': 80, 'act_func': 'elu'}\n",
            "0.19408938481843188 (0.027052958856246843) with: {'weight_constraint': 1, 'nodes': 220, 'learn_rate': 0.001, 'init_mode': 'he_uniform', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.4, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.1861833244985393 (0.030145735722540107) with: {'weight_constraint': 4, 'nodes': 100, 'learn_rate': 0.01, 'init_mode': 'normal', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.8, 'batch_size': 60, 'act_func': 'linear'}\n",
            "0.13514664479898922 (0.013272047606441755) with: {'weight_constraint': 4, 'nodes': 240, 'learn_rate': 0.0001, 'init_mode': 'glorot_normal', 'epsilon': 1, 'epochs': 50, 'drop_rate': 0.7000000000000001, 'batch_size': 40, 'act_func': 'elu'}\n",
            "0.1932636904269362 (0.018408888457900816) with: {'weight_constraint': 5, 'nodes': 180, 'learn_rate': 0.001, 'init_mode': 'he_uniform', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.6000000000000001, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.18626720827101648 (0.031898880408901806) with: {'weight_constraint': 1, 'nodes': 240, 'learn_rate': 0.01, 'init_mode': 'he_normal', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.1, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.1889947060943895 (0.023295745473009048) with: {'weight_constraint': 1, 'nodes': 100, 'learn_rate': 0.001, 'init_mode': 'lecun_uniform', 'epsilon': 0.1, 'epochs': 200, 'drop_rate': 0.2, 'batch_size': 10, 'act_func': 'sigmoid'}\n",
            "0.17757922586340838 (0.03094978732296629) with: {'weight_constraint': 2, 'nodes': 180, 'learn_rate': 0.1, 'init_mode': 'lecun_uniform', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.0, 'batch_size': 60, 'act_func': 'sigmoid'}\n",
            "0.15446928303916502 (0.014340458532690193) with: {'weight_constraint': 4, 'nodes': 200, 'learn_rate': 0.0001, 'init_mode': 'uniform', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.5, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.17726057850231974 (0.020366119005725204) with: {'weight_constraint': 3, 'nodes': 160, 'learn_rate': 0.0001, 'init_mode': 'lecun_uniform', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.9, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.1851237269712697 (0.025170430009393164) with: {'weight_constraint': 1, 'nodes': 140, 'learn_rate': 0.0001, 'init_mode': 'uniform', 'epsilon': 0.001, 'epochs': 50, 'drop_rate': 0.4, 'batch_size': 20, 'act_func': 'sigmoid'}\n",
            "0.1791674256311005 (0.028110622260335574) with: {'weight_constraint': 1, 'nodes': 200, 'learn_rate': 0.1, 'init_mode': 'lecun_uniform', 'epsilon': 1, 'epochs': 100, 'drop_rate': 0.2, 'batch_size': 20, 'act_func': 'linear'}\n",
            "0.06671761413860801 (0.0177392937634469) with: {'weight_constraint': 4, 'nodes': 240, 'learn_rate': 0.1, 'init_mode': 'he_normal', 'epsilon': 1e-05, 'epochs': 50, 'drop_rate': 0.4, 'batch_size': 20, 'act_func': 'relu'}\n",
            "0.18402231718192608 (0.03128669736260317) with: {'weight_constraint': 1, 'nodes': 160, 'learn_rate': 0.01, 'init_mode': 'glorot_normal', 'epsilon': 1e-07, 'epochs': 200, 'drop_rate': 0.6000000000000001, 'batch_size': 40, 'act_func': 'linear'}\n",
            "0.18532571642176637 (0.023188888444213556) with: {'weight_constraint': 4, 'nodes': 160, 'learn_rate': 0.0001, 'init_mode': 'lecun_uniform', 'epsilon': 1e-05, 'epochs': 200, 'drop_rate': 0.6000000000000001, 'batch_size': 40, 'act_func': 'relu'}\n",
            "0.1869044584206003 (0.02782151008862356) with: {'weight_constraint': 2, 'nodes': 100, 'learn_rate': 0.01, 'init_mode': 'glorot_uniform', 'epsilon': 1e-07, 'epochs': 50, 'drop_rate': 0.7000000000000001, 'batch_size': 40, 'act_func': 'linear'}\n",
            "0.11275858207824292 (0.0517470585227545) with: {'weight_constraint': 2, 'nodes': 60, 'learn_rate': 0.1, 'init_mode': 'uniform', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.8, 'batch_size': 10, 'act_func': 'elu'}\n",
            "0.1792702126102606 (0.0294275326252259) with: {'weight_constraint': 5, 'nodes': 180, 'learn_rate': 0.1, 'init_mode': 'normal', 'epsilon': 0.1, 'epochs': 100, 'drop_rate': 0.2, 'batch_size': 80, 'act_func': 'linear'}\n",
            "0.17738578362668872 (0.03330201667735747) with: {'weight_constraint': 4, 'nodes': 180, 'learn_rate': 0.001, 'init_mode': 'glorot_normal', 'epsilon': 0.001, 'epochs': 200, 'drop_rate': 0.9, 'batch_size': 10, 'act_func': 'sigmoid'}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "param_grid = dict(\n",
        "    batch_size = [10, 20, 40, 60],\n",
        "    epochs = [50, 100, 200],\n",
        "    learn_rate = [0.0001, 0.001, 0.01],\n",
        "    epsilon=[1e-7, 1e-5, 1e-3, 1e-1, 1],\n",
        "    init_mode = ['lecun_uniform', 'normal', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform'],\n",
        "    act_func = ['elu','relu'],\n",
        "    weight_constraint = [1, 2, 3, 4, 5],\n",
        "    drop_rate = np.arange(0.0,0.6,0.1),\n",
        "    nodes = np.arange(60,260,20)\n",
        ")\n",
        "rand_search = RandomizedSearchCV(estimator=dl_clf, \n",
        "                                 param_distributions=param_grid, \n",
        "                                 scoring='average_precision', \n",
        "                                 n_iter=200, \n",
        "                                 n_jobs=-1, \n",
        "                                 cv=StratifiedShuffleSplit(n_splits=10, test_size=0.3, random_state=0), \n",
        "                                 verbose=1)\n",
        "search_result = rand_search.fit(X,y)\n",
        "print(f'Best model {search_result.best_params_} with PR_AUC of {search_result.best_score_}')\n",
        "means = search_result.cv_results_['mean_test_score']\n",
        "stds = search_result.cv_results_['std_test_score']\n",
        "params = search_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"{mean} ({stdev}) with: {param}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'verbose': 0,\n",
              " 'batch_size': 10,\n",
              " 'class_weight': {0: 1.0511699665723837, 1: 20.542713567839197},\n",
              " 'build_fn': <function __main__.create_model(learn_rate=0.0001, epsilon=1e-07, drop_rate=0.3, weight_constraint=2, nodes=140, init_mode='lecun_uniform', act_func='sigmoid')>}"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dl_classifiers = [\n",
        "    \n",
        "    dl_clf\n",
        "]\n",
        "\n",
        "dl_classifiers[0].get_params()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:   34.5s remaining:   23.0s\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   36.8s finished\n"
          ]
        }
      ],
      "source": [
        "log_cols = [\"Classifier\", \"PR_AUC\", \"Recall (TPR)\", \"Fbeta\"]\n",
        "log = pd.DataFrame(columns=log_cols)\n",
        "\n",
        "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.3, random_state=0)\n",
        "scoring = {\n",
        "    'PR_AUC': 'average_precision',\n",
        "    'recall': 'recall',\n",
        "    'Fbeta': make_scorer(fbeta_score, beta=2)\n",
        "}\n",
        "acc_dict = {}\n",
        "\n",
        "for clf in dl_classifiers:\n",
        "    name = clf.__class__.__name__\n",
        "    scores = cross_validate(clf, X, y, scoring=scoring, cv=sss, verbose=1, n_jobs=-1)\n",
        "    roc_auc = scores['test_PR_AUC'].mean()\n",
        "    recall = scores['test_recall'].mean()\n",
        "    fbeta = scores['test_Fbeta'].mean()\n",
        "    \n",
        "    acc_dict[name] = np.array([roc_auc, recall, fbeta])\n",
        "\n",
        "for clf in acc_dict:\n",
        "    log_entry = pd.DataFrame([[clf, acc_dict[clf][0], acc_dict[clf][1], acc_dict[clf][2]]], columns = log_cols)\n",
        "    log = log.append(log_entry)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Classifier</th>\n",
              "      <th>PR_AUC</th>\n",
              "      <th>Recall (TPR)</th>\n",
              "      <th>Fbeta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KerasClassifier</td>\n",
              "      <td>0.108358</td>\n",
              "      <td>0.231667</td>\n",
              "      <td>0.095489</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Classifier    PR_AUC  Recall (TPR)     Fbeta\n",
              "0  KerasClassifier  0.108358      0.231667  0.095489"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:title={'center':'Classifier Accuracy'}, xlabel='model performance', ylabel='Classifier'>"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(log)\n",
        "\n",
        "plt.title('Classifier Accuracy')\n",
        "log = pd.melt(log, id_vars='Classifier', var_name='metrics', value_name='model performance')\n",
        "sns.set_color_codes(\"muted\")\n",
        "sns.barplot(x = 'model performance', y = 'Classifier', data = log, hue='metrics')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model export and validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "import json\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from utils.dataloader import DataLoader \n",
        "from settings.constants import TRAIN_CSV\n",
        "\n",
        "\n",
        "with open('settings/specifications.json') as f:\n",
        "    specifications = json.load(f)\n",
        "\n",
        "raw_train = pd.read_csv(TRAIN_CSV)\n",
        "x_columns = specifications['description']['X']\n",
        "y_column = specifications['description']['y']\n",
        "\n",
        "X_raw = raw_train[x_columns]\n",
        "\n",
        "loader = DataLoader()\n",
        "loader.fit(X_raw)\n",
        "X = loader.load_data()\n",
        "y = raw_train.stroke\n",
        "\n",
        "model = trad_classifiers[0]\n",
        "model.fit(X, y)\n",
        "with open(f'models/{model.__class__.__name__}.pickle', 'wb')as f:\n",
        "    pickle.dump(model, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6438356164383562"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pickle\n",
        "import json\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from utils.dataloader import DataLoader \n",
        "from settings.constants import VAL_CSV\n",
        "\n",
        "\n",
        "with open('settings/specifications.json') as f:\n",
        "    specifications = json.load(f)\n",
        "\n",
        "x_columns = specifications['description']['X']\n",
        "y_column = specifications['description']['y']\n",
        "\n",
        "raw_val = pd.read_csv(VAL_CSV)\n",
        "x_raw = raw_val[x_columns]\n",
        "\n",
        "loader = DataLoader()\n",
        "loader.fit(x_raw)\n",
        "X = loader.load_data()\n",
        "y = raw_val.stroke\n",
        "\n",
        "loaded_model = pickle.load(open('models/SVC.pickle', 'rb'))\n",
        "loaded_model.score(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Normalized CM\n",
            "[[0.63374486 0.36625514]\n",
            " [0.16       0.84      ]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Michel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, \"SVC(C=0.005, class_weight='balanced')\")"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(f'Normalized CM')\n",
        "print(confusion_matrix(y,\n",
        "                       loaded_model.predict(X),\n",
        "                       normalize='true'))\n",
        "disp = plot_confusion_matrix(loaded_model, X, y,\n",
        "                             display_labels=['No stroke', 'Had stroke'],\n",
        "                             cmap=plt.cm.Blues)\n",
        "disp.ax_.set_title(f'{loaded_model}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   No stroke       0.99      0.63      0.77       972\n",
            "      Stroke       0.11      0.84      0.19        50\n",
            "\n",
            "    accuracy                           0.64      1022\n",
            "   macro avg       0.55      0.74      0.48      1022\n",
            "weighted avg       0.94      0.64      0.74      1022\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "target_names = ['No stroke', 'Stroke']\n",
        "print(classification_report(y, loaded_model.predict(X), target_names=target_names))"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "cdee9eadb9b977665eddab0174636e427a3e7d8af2ef4607c2ce666a91de4557"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit ('env': venv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
